{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NCx8Mc7DwG",
        "outputId": "0b688dcd-b27a-4f6f-8ef1-8adec13bbb06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "4Ievu6ie7KcN",
        "outputId": "72c3583f-2d40-41e3-d8ed-936266d5fd07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b1a5c8e-78a6-4765-a6b3-3ef8129d25cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b1a5c8e-78a6-4765-a6b3-3ef8129d25cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bpf-740.npy to bpf-740 (1).npy\n",
            "Saving blosum-740.npy to blosum-740 (1).npy\n",
            "Saving bits-740.npy to bits-740 (1).npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello')"
      ],
      "metadata": {
        "id": "FX3zyL04oizd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95c3ea3-76aa-4c66-eb1e-6486b7046ee3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Neural Networks:\n",
        "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
        "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
        "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
        "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
        "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
        "from tensorflow.keras.models import (Sequential, Model)\n",
        "\n",
        "# Core:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import interp\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Performance:\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
        "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
        "\n",
        "#Utilities:\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
        "from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "#end-import\n",
        "\n",
        "def lossPlot(results):\n",
        "    plt.title(label='Loss: Training and Validation')\n",
        "    plt.plot(results.history['loss'], label='Training Loss')\n",
        "    plt.plot(results.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def accuracyPlot(results):\n",
        "    plt.title(label='Accuracy: Training and Validation')\n",
        "    plt.plot(results.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def rocPlot(TPR, meanFPR):\n",
        "    plt.plot([0,1], [0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "    meanTPR = np.mean(TPR, axis=0)\n",
        "    meanAUC = auc(meanFPR, meanTPR)\n",
        "    plt.plot(meanFPR, meanTPR, color='blue',\n",
        "            label=r'Mean ROC (AUC = %0.2f )' % (meanAUC),lw=2, alpha=1)\n",
        "\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('ROC-740.png')\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "T = 15 # terminus_length\n",
        "\n",
        "X1 = np.load('bpf-740.npy')\n",
        "X2 = np.load('bits-740.npy')\n",
        "X3 = np.load('blosum-740.npy')\n",
        "\n",
        "\n",
        "X1 = X1[:,0:T,:]\n",
        "X2 = X2[:,0:T,:]\n",
        "X3 = X3[:,0:T,:]\n",
        "\n",
        "\n",
        "Y  = [1 for _ in range(376)]\n",
        "Y += [0 for _ in range(364)]\n",
        "\n",
        "Y = labelEncoding(Y, dtype=int)\n",
        "\n",
        "\n",
        "print(X1.shape)\n",
        "print(X2.shape)\n",
        "print(X3.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "### Model-740\n",
        "\n",
        "def Network():\n",
        "    ### Head-1:\n",
        "    input1 = Input(shape=X1[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.80)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-2:\n",
        "    # input2 = Input(shape=X2[0].shape)\n",
        "\n",
        "    # x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-3:\n",
        "    input3 = Input(shape=X3[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu',)(input3)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head3 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # merge\n",
        "    merge = Concatenate()([head1, head3])\n",
        "\n",
        "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(rate=0.70)(output)\n",
        "\n",
        "    output = Dense(units=2, activation='softmax')(output)\n",
        "\n",
        "    return Model(inputs=[input1, input3], outputs=[output])\n",
        "#end-def\n",
        "\n",
        "model = Network()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model-740.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "setEpochNumber     = 500     # Performed-welled in epoch 600.\n",
        "setBatchSizeNumber = 8\n",
        "####################################################\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=101)\n",
        "\n",
        "Accuracy = []\n",
        "Sensitivity = []\n",
        "Specificity = []\n",
        "Precision = []\n",
        "MCC = []\n",
        "\n",
        "# ROC Curve:\n",
        "fig1 = plt.figure(figsize=[12,12])\n",
        "\n",
        "TPR = []\n",
        "meanFPR = np.linspace(0, 1, 100)\n",
        "\n",
        "i = 1\n",
        "\n",
        "# CM = np.array([\n",
        "#      [0, 0],\n",
        "#      [0, 0],\n",
        "# ], dtype=int)\n",
        "\n",
        "for train, test in cv.split(Y):\n",
        "\n",
        "    # Compile Model:\n",
        "    model = Network()\n",
        "    model.compile(optimizer=Adam(lr=0.005),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Run Model:\n",
        "    results = model.fit(x=[X1[train,:,:], X3[train,:,:]],\n",
        "                        y=Y[train,:],\n",
        "                        validation_data=([X1[test,:,:], X3[test,:,:],], Y[test,:]),\n",
        "                        batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "                        verbose=1,\n",
        "                        callbacks=[])\n",
        "\n",
        "    # Evaluate the Model:\n",
        "    accuracy = model.evaluate(x=[X1[test,:,:], X3[test,:,:]], y=Y[test,:])\n",
        "    Accuracy.append(accuracy[1])\n",
        "\n",
        "    # Performance Metices:\n",
        "    Yactual = Y[test,:].argmax(axis=1)\n",
        "    Yp = model.predict([X1[test,:,:], X3[test,:,:]])\n",
        "    v = Yp\n",
        "    Yp = Yp.argmax(axis=1)\n",
        "\n",
        "    CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "    TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "    MCC.append(matthews_corrcoef(y_true=Yactual, y_pred=Yp))\n",
        "    Sensitivity.append( TP / (TP + FN) )\n",
        "    Specificity.append( TN / (TN + FP) )\n",
        "    Precision.append(precision_score(y_true=Yactual, y_pred=Yp))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(Yactual, v[:,1])\n",
        "    TPR.append(interp(meanFPR, fpr, tpr))\n",
        "    rocauc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, rocauc))\n",
        "    i= i+1\n",
        "\n",
        "    # # Performance Plot\n",
        "    # print('#################################################')\n",
        "    # print('Fold\\'s Accuracy: {:.2f}'.format(accuracy[1]*100.0))\n",
        "    # lossPlot(results)\n",
        "    # accuracyPlot(results)\n",
        "    # print('#################################################')\n",
        "\n",
        "#end-for\n",
        "\n",
        "rocPlot(TPR, meanFPR)\n",
        "\n",
        "print(Accuracy)\n",
        "print('Accuracy: {:.2f}'.format(np.sum(Accuracy)/5.0))\n",
        "print('Sensitivity: {0:.4f}'.format(np.sum(Sensitivity)/5.00))\n",
        "print('Specificity: {0:.4f}'.format(np.sum(Specificity)/5.00))\n",
        "print('MCC: {0:.4f}'.format(np.sum(MCC)/5.00))\n",
        "print('Precision: {0:.4f}'.format(np.sum(Precision)/5.00))"
      ],
      "metadata": {
        "id": "_o28L8jW7KnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "786439f4-e0dc-430a-e6a3-85897bc73791"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're using TF-2.15.0.\n",
            "(740, 15, 20)\n",
            "(740, 15, 31)\n",
            "(740, 15, 20)\n",
            "(740, 2)\n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_25 (InputLayer)       [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " input_26 (InputLayer)       [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " conv1d_48 (Conv1D)          (None, 15, 10)               810       ['input_25[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_50 (Conv1D)          (None, 15, 10)               810       ['input_26[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 15, 10)               40        ['conv1d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 15, 10)               40        ['conv1d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_60 (Dropout)        (None, 15, 10)               0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)        (None, 15, 10)               0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_49 (Conv1D)          (None, 15, 8)                248       ['dropout_60[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_51 (Conv1D)          (None, 15, 8)                248       ['dropout_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 15, 8)                32        ['conv1d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 15, 8)                32        ['conv1d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_61 (Dropout)        (None, 15, 8)                0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)        (None, 15, 8)                0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " flatten_24 (Flatten)        (None, 120)                  0         ['dropout_61[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_25 (Flatten)        (None, 120)                  0         ['dropout_63[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 240)                  0         ['flatten_24[0][0]',          \n",
            " e)                                                                  'flatten_25[0][0]']          \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 8)                    1928      ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 8)                    32        ['dense_24[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)        (None, 8)                    0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 2)                    18        ['dropout_64[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4238 (16.55 KB)\n",
            "Trainable params: 4150 (16.21 KB)\n",
            "Non-trainable params: 88 (352.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 11s 35ms/step - loss: 1.6118 - accuracy: 0.5017 - val_loss: 1.1424 - val_accuracy: 0.4865\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 2s 28ms/step - loss: 1.4664 - accuracy: 0.4831 - val_loss: 1.1366 - val_accuracy: 0.4730\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 2s 31ms/step - loss: 1.3180 - accuracy: 0.5051 - val_loss: 1.1222 - val_accuracy: 0.4797\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 1.2389 - accuracy: 0.5338 - val_loss: 1.1058 - val_accuracy: 0.5135\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.2030 - accuracy: 0.5405 - val_loss: 1.0910 - val_accuracy: 0.5203\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.2013 - accuracy: 0.4916 - val_loss: 1.0820 - val_accuracy: 0.5135\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1376 - accuracy: 0.5068 - val_loss: 1.0754 - val_accuracy: 0.5203\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1004 - accuracy: 0.5253 - val_loss: 1.0661 - val_accuracy: 0.5000\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 1.0913 - accuracy: 0.5304 - val_loss: 1.0554 - val_accuracy: 0.5270\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0889 - accuracy: 0.5034 - val_loss: 1.0440 - val_accuracy: 0.5676\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.0628 - accuracy: 0.5051 - val_loss: 1.0346 - val_accuracy: 0.5473\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0384 - accuracy: 0.5372 - val_loss: 1.0254 - val_accuracy: 0.5541\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0311 - accuracy: 0.5186 - val_loss: 1.0175 - val_accuracy: 0.5338\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0150 - accuracy: 0.5304 - val_loss: 1.0078 - val_accuracy: 0.4797\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0003 - accuracy: 0.5169 - val_loss: 0.9962 - val_accuracy: 0.5676\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9945 - accuracy: 0.5000 - val_loss: 0.9864 - val_accuracy: 0.5811\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.5541 - val_loss: 0.9741 - val_accuracy: 0.6081\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.5253 - val_loss: 0.9630 - val_accuracy: 0.6757\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9606 - accuracy: 0.5338 - val_loss: 0.9537 - val_accuracy: 0.6419\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9503 - accuracy: 0.5220 - val_loss: 0.9431 - val_accuracy: 0.6149\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9352 - accuracy: 0.5439 - val_loss: 0.9324 - val_accuracy: 0.6622\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9182 - accuracy: 0.5557 - val_loss: 0.9206 - val_accuracy: 0.6689\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9223 - accuracy: 0.5355 - val_loss: 0.9108 - val_accuracy: 0.6892\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.9017 - accuracy: 0.5693 - val_loss: 0.8982 - val_accuracy: 0.6486\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8965 - accuracy: 0.5473 - val_loss: 0.8887 - val_accuracy: 0.6689\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8925 - accuracy: 0.5524 - val_loss: 0.8798 - val_accuracy: 0.6824\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8743 - accuracy: 0.5422 - val_loss: 0.8711 - val_accuracy: 0.6757\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8769 - accuracy: 0.5439 - val_loss: 0.8604 - val_accuracy: 0.7162\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8556 - accuracy: 0.5591 - val_loss: 0.8520 - val_accuracy: 0.6824\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8506 - accuracy: 0.5574 - val_loss: 0.8408 - val_accuracy: 0.7162\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8267 - accuracy: 0.6014 - val_loss: 0.8237 - val_accuracy: 0.6824\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.5980 - val_loss: 0.8073 - val_accuracy: 0.6622\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8074 - accuracy: 0.6166 - val_loss: 0.7952 - val_accuracy: 0.6824\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8049 - accuracy: 0.6182 - val_loss: 0.7875 - val_accuracy: 0.6351\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7983 - accuracy: 0.5980 - val_loss: 0.7846 - val_accuracy: 0.6351\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7987 - accuracy: 0.5726 - val_loss: 0.7775 - val_accuracy: 0.6554\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7742 - accuracy: 0.6368 - val_loss: 0.7658 - val_accuracy: 0.6689\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7521 - accuracy: 0.6284 - val_loss: 0.7580 - val_accuracy: 0.6689\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7669 - accuracy: 0.6098 - val_loss: 0.7448 - val_accuracy: 0.6824\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7885 - accuracy: 0.5946 - val_loss: 0.7358 - val_accuracy: 0.7095\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7486 - accuracy: 0.6453 - val_loss: 0.7297 - val_accuracy: 0.7027\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.6470 - val_loss: 0.7205 - val_accuracy: 0.7095\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.6537 - val_loss: 0.7048 - val_accuracy: 0.7432\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.6453 - val_loss: 0.6918 - val_accuracy: 0.7500\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7288 - accuracy: 0.6453 - val_loss: 0.6865 - val_accuracy: 0.7297\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.6503 - val_loss: 0.6781 - val_accuracy: 0.7500\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.6791 - val_loss: 0.6682 - val_accuracy: 0.7297\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7087 - accuracy: 0.6909 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.6909 - val_loss: 0.6477 - val_accuracy: 0.7635\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.6723 - val_loss: 0.6430 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.6740 - val_loss: 0.6241 - val_accuracy: 0.7568\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.6689 - val_loss: 0.6156 - val_accuracy: 0.7770\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.6976 - val_loss: 0.6111 - val_accuracy: 0.7635\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.6824 - val_loss: 0.6191 - val_accuracy: 0.7635\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6654 - accuracy: 0.7314 - val_loss: 0.6227 - val_accuracy: 0.7365\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6652 - accuracy: 0.7179 - val_loss: 0.6117 - val_accuracy: 0.7432\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6599 - accuracy: 0.6976 - val_loss: 0.6003 - val_accuracy: 0.7905\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6713 - accuracy: 0.7128 - val_loss: 0.5907 - val_accuracy: 0.8041\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6288 - accuracy: 0.7196 - val_loss: 0.5852 - val_accuracy: 0.7838\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6633 - accuracy: 0.6959 - val_loss: 0.5826 - val_accuracy: 0.7703\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.7128 - val_loss: 0.5737 - val_accuracy: 0.7973\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.7145 - val_loss: 0.5708 - val_accuracy: 0.8041\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7280 - val_loss: 0.5652 - val_accuracy: 0.7973\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6135 - accuracy: 0.7466 - val_loss: 0.5600 - val_accuracy: 0.8041\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7280 - val_loss: 0.5639 - val_accuracy: 0.8041\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.7314 - val_loss: 0.5538 - val_accuracy: 0.7770\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.7128 - val_loss: 0.5510 - val_accuracy: 0.7838\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.7111 - val_loss: 0.5539 - val_accuracy: 0.7838\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.7061 - val_loss: 0.5500 - val_accuracy: 0.7905\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.7432 - val_loss: 0.5448 - val_accuracy: 0.7973\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.7348 - val_loss: 0.5420 - val_accuracy: 0.8108\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.7889 - val_loss: 0.5321 - val_accuracy: 0.8176\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5832 - accuracy: 0.7601 - val_loss: 0.5323 - val_accuracy: 0.7838\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7483 - val_loss: 0.5275 - val_accuracy: 0.8108\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.7466 - val_loss: 0.5246 - val_accuracy: 0.8041\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.7213 - val_loss: 0.5310 - val_accuracy: 0.8176\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7449 - val_loss: 0.5298 - val_accuracy: 0.8311\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7517 - val_loss: 0.5267 - val_accuracy: 0.8378\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7466 - val_loss: 0.5251 - val_accuracy: 0.8176\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.7483 - val_loss: 0.5232 - val_accuracy: 0.8243\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7196 - val_loss: 0.5223 - val_accuracy: 0.8311\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.7027 - val_loss: 0.5228 - val_accuracy: 0.8514\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.7331 - val_loss: 0.5293 - val_accuracy: 0.8311\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6002 - accuracy: 0.7382 - val_loss: 0.5328 - val_accuracy: 0.8311\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7483 - val_loss: 0.5210 - val_accuracy: 0.8176\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5544 - accuracy: 0.7753 - val_loss: 0.5196 - val_accuracy: 0.8176\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.7230 - val_loss: 0.5178 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5813 - accuracy: 0.7753 - val_loss: 0.5179 - val_accuracy: 0.7973\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5871 - accuracy: 0.7517 - val_loss: 0.5114 - val_accuracy: 0.7973\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5740 - accuracy: 0.7618 - val_loss: 0.5029 - val_accuracy: 0.8311\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5850 - accuracy: 0.7568 - val_loss: 0.5084 - val_accuracy: 0.8108\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.7213 - val_loss: 0.5141 - val_accuracy: 0.7905\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6102 - accuracy: 0.7416 - val_loss: 0.5145 - val_accuracy: 0.8041\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6107 - accuracy: 0.7264 - val_loss: 0.5197 - val_accuracy: 0.7973\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7736 - val_loss: 0.5199 - val_accuracy: 0.7973\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.7736 - val_loss: 0.5099 - val_accuracy: 0.7973\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.7416 - val_loss: 0.5196 - val_accuracy: 0.7905\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5530 - accuracy: 0.7720 - val_loss: 0.5148 - val_accuracy: 0.7905\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.7534 - val_loss: 0.5202 - val_accuracy: 0.8041\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7534 - val_loss: 0.5162 - val_accuracy: 0.8041\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7736 - val_loss: 0.5053 - val_accuracy: 0.8243\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.7534 - val_loss: 0.5164 - val_accuracy: 0.8041\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7905 - val_loss: 0.5132 - val_accuracy: 0.8041\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5663 - accuracy: 0.7652 - val_loss: 0.5192 - val_accuracy: 0.7838\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.7466 - val_loss: 0.5172 - val_accuracy: 0.7905\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7736 - val_loss: 0.5135 - val_accuracy: 0.7838\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7534 - val_loss: 0.5166 - val_accuracy: 0.8108\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.7669 - val_loss: 0.5244 - val_accuracy: 0.8176\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.7534 - val_loss: 0.5231 - val_accuracy: 0.8041\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5547 - accuracy: 0.7703 - val_loss: 0.5192 - val_accuracy: 0.8041\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5761 - accuracy: 0.7736 - val_loss: 0.5120 - val_accuracy: 0.8041\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7584 - val_loss: 0.5051 - val_accuracy: 0.8176\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.7551 - val_loss: 0.5040 - val_accuracy: 0.8311\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7838 - val_loss: 0.5012 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.8159 - val_loss: 0.4942 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7584 - val_loss: 0.5012 - val_accuracy: 0.8176\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7804 - val_loss: 0.4962 - val_accuracy: 0.7973\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.7483 - val_loss: 0.4923 - val_accuracy: 0.7973\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7838 - val_loss: 0.4873 - val_accuracy: 0.8108\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7770 - val_loss: 0.4858 - val_accuracy: 0.8041\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7669 - val_loss: 0.4905 - val_accuracy: 0.8041\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5399 - accuracy: 0.7872 - val_loss: 0.4826 - val_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5690 - accuracy: 0.7669 - val_loss: 0.4881 - val_accuracy: 0.7703\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5702 - accuracy: 0.7551 - val_loss: 0.4797 - val_accuracy: 0.8176\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5672 - accuracy: 0.7483 - val_loss: 0.4789 - val_accuracy: 0.8243\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5645 - accuracy: 0.7652 - val_loss: 0.4832 - val_accuracy: 0.8176\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5422 - accuracy: 0.7669 - val_loss: 0.4847 - val_accuracy: 0.8176\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5307 - accuracy: 0.8024 - val_loss: 0.4781 - val_accuracy: 0.8108\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.7753 - val_loss: 0.4739 - val_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.7635 - val_loss: 0.4755 - val_accuracy: 0.8311\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.7618 - val_loss: 0.4845 - val_accuracy: 0.8378\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7720 - val_loss: 0.4763 - val_accuracy: 0.8311\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7905 - val_loss: 0.4828 - val_accuracy: 0.8176\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5817 - accuracy: 0.7838 - val_loss: 0.4848 - val_accuracy: 0.8176\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.8193 - val_loss: 0.4776 - val_accuracy: 0.8041\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7736 - val_loss: 0.4812 - val_accuracy: 0.8041\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7584 - val_loss: 0.4817 - val_accuracy: 0.8041\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.7618 - val_loss: 0.4727 - val_accuracy: 0.8108\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7753 - val_loss: 0.4694 - val_accuracy: 0.8041\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7720 - val_loss: 0.4735 - val_accuracy: 0.8108\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7770 - val_loss: 0.4811 - val_accuracy: 0.8108\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7804 - val_loss: 0.4855 - val_accuracy: 0.7973\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7922 - val_loss: 0.4920 - val_accuracy: 0.7973\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.7821 - val_loss: 0.4898 - val_accuracy: 0.8041\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7432 - val_loss: 0.4993 - val_accuracy: 0.8108\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7584 - val_loss: 0.4922 - val_accuracy: 0.8041\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7720 - val_loss: 0.4959 - val_accuracy: 0.8108\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.8024 - val_loss: 0.5008 - val_accuracy: 0.7973\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.8074 - val_loss: 0.5043 - val_accuracy: 0.7838\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7821 - val_loss: 0.4993 - val_accuracy: 0.7973\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5404 - accuracy: 0.7618 - val_loss: 0.5026 - val_accuracy: 0.7838\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7956 - val_loss: 0.4974 - val_accuracy: 0.7905\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5434 - accuracy: 0.7872 - val_loss: 0.4909 - val_accuracy: 0.7973\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7889 - val_loss: 0.4881 - val_accuracy: 0.8041\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5242 - accuracy: 0.8125 - val_loss: 0.4836 - val_accuracy: 0.8041\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5502 - accuracy: 0.7922 - val_loss: 0.4936 - val_accuracy: 0.7973\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5275 - accuracy: 0.7821 - val_loss: 0.4878 - val_accuracy: 0.7973\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5245 - accuracy: 0.7889 - val_loss: 0.4883 - val_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5387 - accuracy: 0.7922 - val_loss: 0.4741 - val_accuracy: 0.8108\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5709 - accuracy: 0.7568 - val_loss: 0.4748 - val_accuracy: 0.8108\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5060 - accuracy: 0.7821 - val_loss: 0.4768 - val_accuracy: 0.8176\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7736 - val_loss: 0.4671 - val_accuracy: 0.8311\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.7652 - val_loss: 0.4714 - val_accuracy: 0.8378\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7922 - val_loss: 0.4755 - val_accuracy: 0.8378\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.7922 - val_loss: 0.4792 - val_accuracy: 0.8311\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5623 - accuracy: 0.7686 - val_loss: 0.4830 - val_accuracy: 0.8243\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7872 - val_loss: 0.4915 - val_accuracy: 0.7973\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7922 - val_loss: 0.4808 - val_accuracy: 0.8311\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7787 - val_loss: 0.4776 - val_accuracy: 0.8311\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7770 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.8041 - val_loss: 0.4836 - val_accuracy: 0.8041\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5479 - accuracy: 0.7821 - val_loss: 0.4954 - val_accuracy: 0.8243\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.8024 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.8041 - val_loss: 0.4789 - val_accuracy: 0.8311\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7855 - val_loss: 0.4886 - val_accuracy: 0.8378\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.8024 - val_loss: 0.4963 - val_accuracy: 0.8108\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7973 - val_loss: 0.4902 - val_accuracy: 0.8108\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7787 - val_loss: 0.4790 - val_accuracy: 0.8041\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.8176 - val_loss: 0.4813 - val_accuracy: 0.8176\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7889 - val_loss: 0.4858 - val_accuracy: 0.7973\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5656 - accuracy: 0.7736 - val_loss: 0.4939 - val_accuracy: 0.7973\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.8007 - val_loss: 0.4995 - val_accuracy: 0.8176\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7990 - val_loss: 0.4929 - val_accuracy: 0.8041\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.8074 - val_loss: 0.4874 - val_accuracy: 0.8108\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.8159 - val_loss: 0.4912 - val_accuracy: 0.7973\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.7753 - val_loss: 0.4883 - val_accuracy: 0.8108\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5101 - accuracy: 0.7905 - val_loss: 0.4911 - val_accuracy: 0.8041\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5427 - accuracy: 0.7838 - val_loss: 0.4948 - val_accuracy: 0.8041\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.8041 - val_loss: 0.4986 - val_accuracy: 0.8108\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5182 - accuracy: 0.7939 - val_loss: 0.4996 - val_accuracy: 0.8176\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5268 - accuracy: 0.7973 - val_loss: 0.4999 - val_accuracy: 0.8108\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5394 - accuracy: 0.8057 - val_loss: 0.4983 - val_accuracy: 0.7838\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.7855 - val_loss: 0.5068 - val_accuracy: 0.7973\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7889 - val_loss: 0.5041 - val_accuracy: 0.7973\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.7601 - val_loss: 0.5035 - val_accuracy: 0.7973\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7956 - val_loss: 0.5019 - val_accuracy: 0.8041\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7872 - val_loss: 0.5068 - val_accuracy: 0.8041\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7922 - val_loss: 0.5013 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.8007 - val_loss: 0.5012 - val_accuracy: 0.7905\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5585 - accuracy: 0.7872 - val_loss: 0.5101 - val_accuracy: 0.8041\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7618 - val_loss: 0.5060 - val_accuracy: 0.8108\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.8125 - val_loss: 0.5066 - val_accuracy: 0.8041\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7618 - val_loss: 0.5088 - val_accuracy: 0.7973\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.7703 - val_loss: 0.4977 - val_accuracy: 0.7973\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7804 - val_loss: 0.5081 - val_accuracy: 0.7973\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.8024 - val_loss: 0.5007 - val_accuracy: 0.7973\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7872 - val_loss: 0.4915 - val_accuracy: 0.8108\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7838 - val_loss: 0.4975 - val_accuracy: 0.8041\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7922 - val_loss: 0.5002 - val_accuracy: 0.7973\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4993 - accuracy: 0.7821 - val_loss: 0.5029 - val_accuracy: 0.7973\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.8007 - val_loss: 0.4984 - val_accuracy: 0.8108\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.8041 - val_loss: 0.4970 - val_accuracy: 0.8041\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.8091 - val_loss: 0.5040 - val_accuracy: 0.8041\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7736 - val_loss: 0.4989 - val_accuracy: 0.7973\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7889 - val_loss: 0.4986 - val_accuracy: 0.8243\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.7922 - val_loss: 0.4932 - val_accuracy: 0.8108\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7601 - val_loss: 0.4881 - val_accuracy: 0.7973\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7956 - val_loss: 0.4845 - val_accuracy: 0.8041\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5279 - accuracy: 0.8108 - val_loss: 0.4850 - val_accuracy: 0.8041\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5299 - accuracy: 0.7872 - val_loss: 0.4875 - val_accuracy: 0.8108\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5218 - accuracy: 0.7821 - val_loss: 0.4855 - val_accuracy: 0.8041\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5209 - accuracy: 0.7736 - val_loss: 0.4789 - val_accuracy: 0.8176\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7889 - val_loss: 0.4810 - val_accuracy: 0.8176\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5559 - accuracy: 0.7770 - val_loss: 0.4830 - val_accuracy: 0.8176\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5521 - accuracy: 0.7584 - val_loss: 0.5035 - val_accuracy: 0.7973\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5352 - accuracy: 0.7956 - val_loss: 0.5053 - val_accuracy: 0.7703\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7720 - val_loss: 0.4966 - val_accuracy: 0.8108\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.8024 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5740 - accuracy: 0.7736 - val_loss: 0.4846 - val_accuracy: 0.8176\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5103 - accuracy: 0.8226 - val_loss: 0.4884 - val_accuracy: 0.8108\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7905 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7686 - val_loss: 0.4868 - val_accuracy: 0.8176\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7956 - val_loss: 0.4872 - val_accuracy: 0.8108\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5404 - accuracy: 0.7804 - val_loss: 0.4864 - val_accuracy: 0.8176\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.8260 - val_loss: 0.4829 - val_accuracy: 0.8108\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7990 - val_loss: 0.4907 - val_accuracy: 0.8041\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7889 - val_loss: 0.4919 - val_accuracy: 0.8108\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.8159 - val_loss: 0.4852 - val_accuracy: 0.8243\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4828 - accuracy: 0.8125 - val_loss: 0.4789 - val_accuracy: 0.8176\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5046 - accuracy: 0.8074 - val_loss: 0.4829 - val_accuracy: 0.8243\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7973 - val_loss: 0.4843 - val_accuracy: 0.7973\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5083 - accuracy: 0.8091 - val_loss: 0.4834 - val_accuracy: 0.8176\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.8176 - val_loss: 0.4921 - val_accuracy: 0.8041\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.8311 - val_loss: 0.4809 - val_accuracy: 0.8108\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7990 - val_loss: 0.4757 - val_accuracy: 0.8176\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5287 - accuracy: 0.7973 - val_loss: 0.4833 - val_accuracy: 0.8108\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5170 - accuracy: 0.8074 - val_loss: 0.4848 - val_accuracy: 0.8176\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.7669 - val_loss: 0.4880 - val_accuracy: 0.8243\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7956 - val_loss: 0.4915 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7686 - val_loss: 0.4908 - val_accuracy: 0.7973\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.7821 - val_loss: 0.5045 - val_accuracy: 0.8041\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7838 - val_loss: 0.4921 - val_accuracy: 0.8108\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5277 - accuracy: 0.7956 - val_loss: 0.4882 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.8108 - val_loss: 0.4838 - val_accuracy: 0.8176\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7939 - val_loss: 0.4832 - val_accuracy: 0.8108\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4988 - accuracy: 0.7973 - val_loss: 0.4941 - val_accuracy: 0.8041\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5454 - accuracy: 0.7838 - val_loss: 0.4859 - val_accuracy: 0.8176\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5412 - accuracy: 0.7720 - val_loss: 0.4817 - val_accuracy: 0.8378\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5238 - accuracy: 0.7821 - val_loss: 0.4869 - val_accuracy: 0.8243\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7855 - val_loss: 0.4852 - val_accuracy: 0.8311\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7956 - val_loss: 0.4840 - val_accuracy: 0.8176\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5012 - accuracy: 0.8125 - val_loss: 0.4870 - val_accuracy: 0.8176\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7753 - val_loss: 0.4790 - val_accuracy: 0.8243\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7990 - val_loss: 0.4828 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7905 - val_loss: 0.4862 - val_accuracy: 0.8176\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.8041 - val_loss: 0.4747 - val_accuracy: 0.8378\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7872 - val_loss: 0.4829 - val_accuracy: 0.8311\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5103 - accuracy: 0.8041 - val_loss: 0.4836 - val_accuracy: 0.8176\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.8091 - val_loss: 0.4882 - val_accuracy: 0.8108\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7872 - val_loss: 0.4809 - val_accuracy: 0.8514\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.8057 - val_loss: 0.4873 - val_accuracy: 0.8311\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.7821 - val_loss: 0.4975 - val_accuracy: 0.8176\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5264 - accuracy: 0.7804 - val_loss: 0.4944 - val_accuracy: 0.8108\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7720 - val_loss: 0.5046 - val_accuracy: 0.7973\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.7973 - val_loss: 0.4936 - val_accuracy: 0.7973\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7855 - val_loss: 0.4931 - val_accuracy: 0.8108\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7973 - val_loss: 0.4985 - val_accuracy: 0.8041\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7956 - val_loss: 0.4918 - val_accuracy: 0.8041\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.7855 - val_loss: 0.4828 - val_accuracy: 0.8176\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5338 - accuracy: 0.7956 - val_loss: 0.4829 - val_accuracy: 0.8243\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7720 - val_loss: 0.4748 - val_accuracy: 0.8243\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5668 - accuracy: 0.7736 - val_loss: 0.4774 - val_accuracy: 0.8108\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.8057 - val_loss: 0.4758 - val_accuracy: 0.8041\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7838 - val_loss: 0.4824 - val_accuracy: 0.8108\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5249 - accuracy: 0.7720 - val_loss: 0.4778 - val_accuracy: 0.7905\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.8176 - val_loss: 0.4875 - val_accuracy: 0.8108\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5095 - accuracy: 0.8142 - val_loss: 0.5041 - val_accuracy: 0.8108\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5741 - accuracy: 0.7872 - val_loss: 0.4835 - val_accuracy: 0.8108\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4950 - accuracy: 0.8243 - val_loss: 0.4866 - val_accuracy: 0.8176\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5063 - accuracy: 0.8108 - val_loss: 0.4871 - val_accuracy: 0.7905\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5296 - accuracy: 0.8108 - val_loss: 0.4961 - val_accuracy: 0.8108\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4976 - accuracy: 0.8429 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7821 - val_loss: 0.4770 - val_accuracy: 0.8108\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5212 - accuracy: 0.7922 - val_loss: 0.4864 - val_accuracy: 0.7905\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.7804 - val_loss: 0.4773 - val_accuracy: 0.8041\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7905 - val_loss: 0.4742 - val_accuracy: 0.7973\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7872 - val_loss: 0.4832 - val_accuracy: 0.8108\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.8024 - val_loss: 0.4860 - val_accuracy: 0.7973\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5201 - accuracy: 0.8024 - val_loss: 0.4812 - val_accuracy: 0.8108\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7939 - val_loss: 0.4757 - val_accuracy: 0.8041\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.8142 - val_loss: 0.4830 - val_accuracy: 0.8108\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4994 - accuracy: 0.8074 - val_loss: 0.4795 - val_accuracy: 0.8243\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.8074 - val_loss: 0.4837 - val_accuracy: 0.8378\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.8007 - val_loss: 0.4839 - val_accuracy: 0.8243\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.8125 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.7990 - val_loss: 0.4918 - val_accuracy: 0.8311\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.8041 - val_loss: 0.4943 - val_accuracy: 0.7973\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.8125 - val_loss: 0.4930 - val_accuracy: 0.7973\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.8091 - val_loss: 0.4974 - val_accuracy: 0.8041\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.7855 - val_loss: 0.4930 - val_accuracy: 0.7973\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7956 - val_loss: 0.4906 - val_accuracy: 0.7973\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5715 - accuracy: 0.7686 - val_loss: 0.4900 - val_accuracy: 0.8108\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.8176 - val_loss: 0.4913 - val_accuracy: 0.7973\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7838 - val_loss: 0.4787 - val_accuracy: 0.8176\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5092 - accuracy: 0.8007 - val_loss: 0.4704 - val_accuracy: 0.8176\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7922 - val_loss: 0.4732 - val_accuracy: 0.8041\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8007 - val_loss: 0.4740 - val_accuracy: 0.8041\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5057 - accuracy: 0.8007 - val_loss: 0.4754 - val_accuracy: 0.8243\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4951 - accuracy: 0.7770 - val_loss: 0.4791 - val_accuracy: 0.7973\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4956 - accuracy: 0.8159 - val_loss: 0.4747 - val_accuracy: 0.8041\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4962 - accuracy: 0.8125 - val_loss: 0.4774 - val_accuracy: 0.7973\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4945 - accuracy: 0.8024 - val_loss: 0.4685 - val_accuracy: 0.7905\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5201 - accuracy: 0.8159 - val_loss: 0.4624 - val_accuracy: 0.8176\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4692 - accuracy: 0.8243 - val_loss: 0.4695 - val_accuracy: 0.8108\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5414 - accuracy: 0.7770 - val_loss: 0.4852 - val_accuracy: 0.7905\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7635 - val_loss: 0.4914 - val_accuracy: 0.7905\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.8125 - val_loss: 0.4998 - val_accuracy: 0.8041\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.8142 - val_loss: 0.4931 - val_accuracy: 0.8041\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7922 - val_loss: 0.4869 - val_accuracy: 0.8041\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.8024 - val_loss: 0.4892 - val_accuracy: 0.8041\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5135 - accuracy: 0.8024 - val_loss: 0.4849 - val_accuracy: 0.7905\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.8041 - val_loss: 0.4908 - val_accuracy: 0.8041\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7889 - val_loss: 0.4867 - val_accuracy: 0.8311\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.8074 - val_loss: 0.4840 - val_accuracy: 0.8176\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8024 - val_loss: 0.4804 - val_accuracy: 0.8041\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.8226 - val_loss: 0.4794 - val_accuracy: 0.8108\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7804 - val_loss: 0.4843 - val_accuracy: 0.8243\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7703 - val_loss: 0.4810 - val_accuracy: 0.8243\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.8091 - val_loss: 0.4754 - val_accuracy: 0.8243\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.8345 - val_loss: 0.4735 - val_accuracy: 0.8243\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5204 - accuracy: 0.7939 - val_loss: 0.4915 - val_accuracy: 0.8041\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7889 - val_loss: 0.4802 - val_accuracy: 0.8176\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.7956 - val_loss: 0.4834 - val_accuracy: 0.8041\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.8243 - val_loss: 0.4814 - val_accuracy: 0.8108\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5283 - accuracy: 0.7905 - val_loss: 0.4769 - val_accuracy: 0.7973\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7973 - val_loss: 0.4717 - val_accuracy: 0.8041\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7872 - val_loss: 0.4803 - val_accuracy: 0.8041\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.8074 - val_loss: 0.4823 - val_accuracy: 0.8176\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7669 - val_loss: 0.4797 - val_accuracy: 0.7905\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.7855 - val_loss: 0.4759 - val_accuracy: 0.8108\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5001 - accuracy: 0.8142 - val_loss: 0.4793 - val_accuracy: 0.8176\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4849 - accuracy: 0.8260 - val_loss: 0.4785 - val_accuracy: 0.8041\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5055 - accuracy: 0.7956 - val_loss: 0.4829 - val_accuracy: 0.8176\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4858 - accuracy: 0.8277 - val_loss: 0.4880 - val_accuracy: 0.8311\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5323 - accuracy: 0.7652 - val_loss: 0.4948 - val_accuracy: 0.7838\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5541 - accuracy: 0.8024 - val_loss: 0.4950 - val_accuracy: 0.7838\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5156 - accuracy: 0.7804 - val_loss: 0.4899 - val_accuracy: 0.7838\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.8024 - val_loss: 0.4806 - val_accuracy: 0.8041\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7939 - val_loss: 0.4707 - val_accuracy: 0.8311\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.7872 - val_loss: 0.4690 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7922 - val_loss: 0.4689 - val_accuracy: 0.8243\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7821 - val_loss: 0.4738 - val_accuracy: 0.8446\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5014 - accuracy: 0.8209 - val_loss: 0.4736 - val_accuracy: 0.8378\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7804 - val_loss: 0.4708 - val_accuracy: 0.8311\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.8243 - val_loss: 0.4891 - val_accuracy: 0.8041\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.8057 - val_loss: 0.4849 - val_accuracy: 0.7973\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7990 - val_loss: 0.4761 - val_accuracy: 0.8176\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.8108 - val_loss: 0.4811 - val_accuracy: 0.8108\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.8209 - val_loss: 0.4828 - val_accuracy: 0.8041\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.8057 - val_loss: 0.4890 - val_accuracy: 0.8041\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.8074 - val_loss: 0.4766 - val_accuracy: 0.8176\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.8277 - val_loss: 0.4736 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.8057 - val_loss: 0.4856 - val_accuracy: 0.8108\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7990 - val_loss: 0.4983 - val_accuracy: 0.8041\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.8091 - val_loss: 0.4988 - val_accuracy: 0.7838\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.8159 - val_loss: 0.4953 - val_accuracy: 0.8041\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.7872 - val_loss: 0.4857 - val_accuracy: 0.8108\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.8041 - val_loss: 0.4842 - val_accuracy: 0.8176\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7990 - val_loss: 0.4885 - val_accuracy: 0.8041\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7838 - val_loss: 0.4772 - val_accuracy: 0.8176\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8057 - val_loss: 0.4801 - val_accuracy: 0.8108\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.8091 - val_loss: 0.4767 - val_accuracy: 0.8108\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5103 - accuracy: 0.8209 - val_loss: 0.4861 - val_accuracy: 0.8243\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5222 - accuracy: 0.7889 - val_loss: 0.4897 - val_accuracy: 0.8041\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5211 - accuracy: 0.8209 - val_loss: 0.4840 - val_accuracy: 0.8176\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5078 - accuracy: 0.7905 - val_loss: 0.4880 - val_accuracy: 0.8176\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4748 - accuracy: 0.8243 - val_loss: 0.4874 - val_accuracy: 0.7973\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5013 - accuracy: 0.8074 - val_loss: 0.4847 - val_accuracy: 0.8041\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5487 - accuracy: 0.7770 - val_loss: 0.4740 - val_accuracy: 0.8243\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4930 - accuracy: 0.8007 - val_loss: 0.4714 - val_accuracy: 0.8311\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5095 - accuracy: 0.7787 - val_loss: 0.4762 - val_accuracy: 0.8176\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7973 - val_loss: 0.4777 - val_accuracy: 0.8176\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.8125 - val_loss: 0.4766 - val_accuracy: 0.8176\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.8057 - val_loss: 0.4746 - val_accuracy: 0.8243\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7990 - val_loss: 0.4771 - val_accuracy: 0.8108\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.8041 - val_loss: 0.4907 - val_accuracy: 0.8176\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.8260 - val_loss: 0.4912 - val_accuracy: 0.8108\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4728 - accuracy: 0.8294 - val_loss: 0.4959 - val_accuracy: 0.8108\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8395 - val_loss: 0.5003 - val_accuracy: 0.8108\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7956 - val_loss: 0.5052 - val_accuracy: 0.8041\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7872 - val_loss: 0.4992 - val_accuracy: 0.8041\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.8007 - val_loss: 0.4902 - val_accuracy: 0.8108\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.8074 - val_loss: 0.4806 - val_accuracy: 0.8176\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.7956 - val_loss: 0.4841 - val_accuracy: 0.8176\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.8074 - val_loss: 0.4807 - val_accuracy: 0.8176\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.8142 - val_loss: 0.4690 - val_accuracy: 0.8378\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.8142 - val_loss: 0.4630 - val_accuracy: 0.8311\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.8159 - val_loss: 0.4672 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7855 - val_loss: 0.4689 - val_accuracy: 0.8311\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7804 - val_loss: 0.4707 - val_accuracy: 0.8311\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5086 - accuracy: 0.8007 - val_loss: 0.4768 - val_accuracy: 0.8243\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.8108 - val_loss: 0.4783 - val_accuracy: 0.8311\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7872 - val_loss: 0.4852 - val_accuracy: 0.8108\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.8260 - val_loss: 0.4892 - val_accuracy: 0.8243\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.8057 - val_loss: 0.4812 - val_accuracy: 0.8243\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5217 - accuracy: 0.7855 - val_loss: 0.4951 - val_accuracy: 0.8108\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5171 - accuracy: 0.7990 - val_loss: 0.4830 - val_accuracy: 0.8108\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5203 - accuracy: 0.7889 - val_loss: 0.4834 - val_accuracy: 0.8176\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5110 - accuracy: 0.8041 - val_loss: 0.4844 - val_accuracy: 0.8041\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5607 - accuracy: 0.7720 - val_loss: 0.4905 - val_accuracy: 0.7905\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4900 - accuracy: 0.8176 - val_loss: 0.4990 - val_accuracy: 0.8176\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5070 - accuracy: 0.7956 - val_loss: 0.4922 - val_accuracy: 0.7905\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5297 - accuracy: 0.7872 - val_loss: 0.4902 - val_accuracy: 0.8041\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5043 - accuracy: 0.8041 - val_loss: 0.4799 - val_accuracy: 0.8041\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.8108 - val_loss: 0.4776 - val_accuracy: 0.8108\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7821 - val_loss: 0.4681 - val_accuracy: 0.8176\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7939 - val_loss: 0.4639 - val_accuracy: 0.8243\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5254 - accuracy: 0.8057 - val_loss: 0.4759 - val_accuracy: 0.8108\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.8209 - val_loss: 0.4830 - val_accuracy: 0.8311\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.8024 - val_loss: 0.4719 - val_accuracy: 0.8311\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5080 - accuracy: 0.7821 - val_loss: 0.4674 - val_accuracy: 0.8446\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4788 - accuracy: 0.8041 - val_loss: 0.4758 - val_accuracy: 0.8243\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.8091 - val_loss: 0.4710 - val_accuracy: 0.8176\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.8243 - val_loss: 0.4613 - val_accuracy: 0.8378\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4770 - accuracy: 0.8159 - val_loss: 0.4565 - val_accuracy: 0.8176\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.8209 - val_loss: 0.4564 - val_accuracy: 0.8378\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.8243 - val_loss: 0.4590 - val_accuracy: 0.8311\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7804 - val_loss: 0.4621 - val_accuracy: 0.8311\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.8176 - val_loss: 0.4812 - val_accuracy: 0.8176\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.7922 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5289 - accuracy: 0.7990 - val_loss: 0.4780 - val_accuracy: 0.8311\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7889 - val_loss: 0.4704 - val_accuracy: 0.8176\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7973 - val_loss: 0.4669 - val_accuracy: 0.8378\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.8091 - val_loss: 0.4672 - val_accuracy: 0.8311\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.8108 - val_loss: 0.4597 - val_accuracy: 0.8378\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.8159 - val_loss: 0.4598 - val_accuracy: 0.8108\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.8024 - val_loss: 0.4537 - val_accuracy: 0.8311\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.8176 - val_loss: 0.4648 - val_accuracy: 0.8176\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.8142 - val_loss: 0.4768 - val_accuracy: 0.8176\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4647 - accuracy: 0.8260 - val_loss: 0.4655 - val_accuracy: 0.8378\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5224 - accuracy: 0.7922 - val_loss: 0.4821 - val_accuracy: 0.8311\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4636 - accuracy: 0.8193 - val_loss: 0.4806 - val_accuracy: 0.8243\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5079 - accuracy: 0.8328 - val_loss: 0.4629 - val_accuracy: 0.8108\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.8074 - val_loss: 0.4613 - val_accuracy: 0.8311\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5077 - accuracy: 0.7905 - val_loss: 0.4609 - val_accuracy: 0.8176\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.7905 - val_loss: 0.4676 - val_accuracy: 0.8446\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4613 - accuracy: 0.8361 - val_loss: 0.4596 - val_accuracy: 0.8514\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5186 - accuracy: 0.8142 - val_loss: 0.4634 - val_accuracy: 0.8378\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7905 - val_loss: 0.4746 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.8091 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.8041 - val_loss: 0.4795 - val_accuracy: 0.8108\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7686 - val_loss: 0.4680 - val_accuracy: 0.8311\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7889 - val_loss: 0.4714 - val_accuracy: 0.8243\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4889 - accuracy: 0.8243 - val_loss: 0.4664 - val_accuracy: 0.8243\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.8159 - val_loss: 0.4642 - val_accuracy: 0.8311\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.8074 - val_loss: 0.4675 - val_accuracy: 0.8243\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.8243 - val_loss: 0.4631 - val_accuracy: 0.8446\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.8041 - val_loss: 0.4894 - val_accuracy: 0.8243\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.8176 - val_loss: 0.4757 - val_accuracy: 0.8243\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7838 - val_loss: 0.4711 - val_accuracy: 0.8176\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.7872 - val_loss: 0.4693 - val_accuracy: 0.8243\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.8108 - val_loss: 0.4717 - val_accuracy: 0.8243\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8176 - val_loss: 0.4672 - val_accuracy: 0.8378\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.8193 - val_loss: 0.4670 - val_accuracy: 0.8378\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.8074 - val_loss: 0.4729 - val_accuracy: 0.8311\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.8142 - val_loss: 0.4657 - val_accuracy: 0.8243\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.8142 - val_loss: 0.4614 - val_accuracy: 0.8243\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.8057 - val_loss: 0.4699 - val_accuracy: 0.8311\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.8176 - val_loss: 0.4623 - val_accuracy: 0.8446\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.8209 - val_loss: 0.4651 - val_accuracy: 0.8378\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8176 - val_loss: 0.4710 - val_accuracy: 0.8176\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7855 - val_loss: 0.4631 - val_accuracy: 0.8378\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4725 - accuracy: 0.8041 - val_loss: 0.4673 - val_accuracy: 0.8176\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.8125 - val_loss: 0.4756 - val_accuracy: 0.8243\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4524 - accuracy: 0.8345 - val_loss: 0.4658 - val_accuracy: 0.8243\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5168 - accuracy: 0.8091 - val_loss: 0.4670 - val_accuracy: 0.8243\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4954 - accuracy: 0.8125 - val_loss: 0.4726 - val_accuracy: 0.8243\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4956 - accuracy: 0.8041 - val_loss: 0.4654 - val_accuracy: 0.8311\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.8024 - val_loss: 0.4692 - val_accuracy: 0.8311\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5136 - accuracy: 0.7956 - val_loss: 0.4689 - val_accuracy: 0.8311\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5144 - accuracy: 0.8159 - val_loss: 0.4627 - val_accuracy: 0.8243\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7990 - val_loss: 0.4736 - val_accuracy: 0.8041\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.8142 - val_loss: 0.4734 - val_accuracy: 0.8243\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.8260 - val_loss: 0.4731 - val_accuracy: 0.8311\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.7922 - val_loss: 0.4614 - val_accuracy: 0.8446\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7939 - val_loss: 0.4719 - val_accuracy: 0.8378\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7872 - val_loss: 0.4771 - val_accuracy: 0.8243\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7990 - val_loss: 0.4776 - val_accuracy: 0.8108\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.8260 - val_loss: 0.4547 - val_accuracy: 0.8378\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7939 - val_loss: 0.4624 - val_accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c605e467ca37>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 3s 9ms/step - loss: 1.7857 - accuracy: 0.4983 - val_loss: 1.1847 - val_accuracy: 0.4527\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5868 - accuracy: 0.5034 - val_loss: 1.1601 - val_accuracy: 0.4595\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4483 - accuracy: 0.5220 - val_loss: 1.1559 - val_accuracy: 0.4189\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.3909 - accuracy: 0.4983 - val_loss: 1.1400 - val_accuracy: 0.4257\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.3343 - accuracy: 0.4949 - val_loss: 1.1239 - val_accuracy: 0.4324\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.2903 - accuracy: 0.4916 - val_loss: 1.1118 - val_accuracy: 0.4595\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.2167 - accuracy: 0.5220 - val_loss: 1.0959 - val_accuracy: 0.4662\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.2040 - accuracy: 0.5270 - val_loss: 1.0885 - val_accuracy: 0.4527\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.1454 - accuracy: 0.5186 - val_loss: 1.0851 - val_accuracy: 0.4324\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1242 - accuracy: 0.4966 - val_loss: 1.0713 - val_accuracy: 0.4459\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0905 - accuracy: 0.5236 - val_loss: 1.0577 - val_accuracy: 0.4527\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.0795 - accuracy: 0.4848 - val_loss: 1.0497 - val_accuracy: 0.4392\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.0584 - accuracy: 0.5068 - val_loss: 1.0385 - val_accuracy: 0.4459\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.0483 - accuracy: 0.4966 - val_loss: 1.0255 - val_accuracy: 0.4595\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.0299 - accuracy: 0.5101 - val_loss: 1.0145 - val_accuracy: 0.4662\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0043 - accuracy: 0.5287 - val_loss: 1.0035 - val_accuracy: 0.4865\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9967 - accuracy: 0.5287 - val_loss: 0.9936 - val_accuracy: 0.4932\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9880 - accuracy: 0.5321 - val_loss: 0.9842 - val_accuracy: 0.4730\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9850 - accuracy: 0.5287 - val_loss: 0.9753 - val_accuracy: 0.4730\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9580 - accuracy: 0.5507 - val_loss: 0.9618 - val_accuracy: 0.5473\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9581 - accuracy: 0.5355 - val_loss: 0.9545 - val_accuracy: 0.5000\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9522 - accuracy: 0.5186 - val_loss: 0.9479 - val_accuracy: 0.4459\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9424 - accuracy: 0.5338 - val_loss: 0.9401 - val_accuracy: 0.4459\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9293 - accuracy: 0.5591 - val_loss: 0.9319 - val_accuracy: 0.4257\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9207 - accuracy: 0.5422 - val_loss: 0.9212 - val_accuracy: 0.4324\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9069 - accuracy: 0.5490 - val_loss: 0.9068 - val_accuracy: 0.5608\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9011 - accuracy: 0.5203 - val_loss: 0.8954 - val_accuracy: 0.6216\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8896 - accuracy: 0.5743 - val_loss: 0.8855 - val_accuracy: 0.6824\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8817 - accuracy: 0.5490 - val_loss: 0.8690 - val_accuracy: 0.7365\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8681 - accuracy: 0.5524 - val_loss: 0.8568 - val_accuracy: 0.7162\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8684 - accuracy: 0.5625 - val_loss: 0.8516 - val_accuracy: 0.7162\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8508 - accuracy: 0.5642 - val_loss: 0.8409 - val_accuracy: 0.7230\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8451 - accuracy: 0.5963 - val_loss: 0.8293 - val_accuracy: 0.7297\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8420 - accuracy: 0.5828 - val_loss: 0.8193 - val_accuracy: 0.7162\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8252 - accuracy: 0.5980 - val_loss: 0.8077 - val_accuracy: 0.7230\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8273 - accuracy: 0.5642 - val_loss: 0.8004 - val_accuracy: 0.7230\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8111 - accuracy: 0.6098 - val_loss: 0.7862 - val_accuracy: 0.7365\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8074 - accuracy: 0.5997 - val_loss: 0.7761 - val_accuracy: 0.6959\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7859 - accuracy: 0.6014 - val_loss: 0.7657 - val_accuracy: 0.7230\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7814 - accuracy: 0.6064 - val_loss: 0.7550 - val_accuracy: 0.7297\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7768 - accuracy: 0.6115 - val_loss: 0.7451 - val_accuracy: 0.7365\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7657 - accuracy: 0.6199 - val_loss: 0.7348 - val_accuracy: 0.7297\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7552 - accuracy: 0.6334 - val_loss: 0.7273 - val_accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7358 - accuracy: 0.6470 - val_loss: 0.7189 - val_accuracy: 0.7432\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7272 - accuracy: 0.6672 - val_loss: 0.7084 - val_accuracy: 0.7230\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7388 - accuracy: 0.6318 - val_loss: 0.7046 - val_accuracy: 0.7027\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7224 - accuracy: 0.6943 - val_loss: 0.6946 - val_accuracy: 0.7162\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7093 - accuracy: 0.6639 - val_loss: 0.6907 - val_accuracy: 0.7095\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7042 - accuracy: 0.6723 - val_loss: 0.6816 - val_accuracy: 0.7365\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.6622 - val_loss: 0.6739 - val_accuracy: 0.7365\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.6976 - val_loss: 0.6637 - val_accuracy: 0.7500\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.6419 - val_loss: 0.6647 - val_accuracy: 0.7432\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6813 - accuracy: 0.7179 - val_loss: 0.6505 - val_accuracy: 0.7568\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6815 - accuracy: 0.6892 - val_loss: 0.6467 - val_accuracy: 0.7568\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6645 - accuracy: 0.6926 - val_loss: 0.6329 - val_accuracy: 0.7635\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.7145 - val_loss: 0.6267 - val_accuracy: 0.7432\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.6976 - val_loss: 0.6232 - val_accuracy: 0.7365\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.7078 - val_loss: 0.6203 - val_accuracy: 0.7770\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.6976 - val_loss: 0.6132 - val_accuracy: 0.7905\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.7078 - val_loss: 0.6162 - val_accuracy: 0.7838\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.6875 - val_loss: 0.6068 - val_accuracy: 0.7838\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.7010 - val_loss: 0.5974 - val_accuracy: 0.7770\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.6791 - val_loss: 0.5964 - val_accuracy: 0.7838\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.7348 - val_loss: 0.5995 - val_accuracy: 0.7568\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.7297 - val_loss: 0.5855 - val_accuracy: 0.7703\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.7314 - val_loss: 0.5825 - val_accuracy: 0.7973\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.6959 - val_loss: 0.5806 - val_accuracy: 0.7838\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.7280 - val_loss: 0.5723 - val_accuracy: 0.8041\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6425 - accuracy: 0.7230 - val_loss: 0.5778 - val_accuracy: 0.8108\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.7416 - val_loss: 0.5739 - val_accuracy: 0.8041\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6414 - accuracy: 0.7145 - val_loss: 0.5694 - val_accuracy: 0.8108\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.7348 - val_loss: 0.5615 - val_accuracy: 0.8108\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.7162 - val_loss: 0.5608 - val_accuracy: 0.8176\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6242 - accuracy: 0.7280 - val_loss: 0.5529 - val_accuracy: 0.7973\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5991 - accuracy: 0.7483 - val_loss: 0.5464 - val_accuracy: 0.8176\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6335 - accuracy: 0.7280 - val_loss: 0.5513 - val_accuracy: 0.8108\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5876 - accuracy: 0.7584 - val_loss: 0.5488 - val_accuracy: 0.8108\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6140 - accuracy: 0.7348 - val_loss: 0.5364 - val_accuracy: 0.8041\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6054 - accuracy: 0.7399 - val_loss: 0.5474 - val_accuracy: 0.7973\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5720 - accuracy: 0.7753 - val_loss: 0.5454 - val_accuracy: 0.7905\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7686 - val_loss: 0.5364 - val_accuracy: 0.8041\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.7517 - val_loss: 0.5258 - val_accuracy: 0.8041\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5765 - accuracy: 0.7635 - val_loss: 0.5284 - val_accuracy: 0.8041\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6054 - accuracy: 0.7500 - val_loss: 0.5294 - val_accuracy: 0.7973\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.7736 - val_loss: 0.5356 - val_accuracy: 0.7973\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.7348 - val_loss: 0.5390 - val_accuracy: 0.7905\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.7365 - val_loss: 0.5341 - val_accuracy: 0.7973\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5639 - accuracy: 0.7601 - val_loss: 0.5289 - val_accuracy: 0.8108\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.7466 - val_loss: 0.5242 - val_accuracy: 0.8041\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.7348 - val_loss: 0.5285 - val_accuracy: 0.7838\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.7568 - val_loss: 0.5236 - val_accuracy: 0.8041\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7517 - val_loss: 0.5236 - val_accuracy: 0.8108\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7584 - val_loss: 0.5187 - val_accuracy: 0.8243\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5724 - accuracy: 0.7753 - val_loss: 0.5156 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7652 - val_loss: 0.5197 - val_accuracy: 0.8041\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.7466 - val_loss: 0.5146 - val_accuracy: 0.8041\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7736 - val_loss: 0.5152 - val_accuracy: 0.7973\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.7584 - val_loss: 0.5167 - val_accuracy: 0.8108\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7534 - val_loss: 0.5166 - val_accuracy: 0.7905\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7416 - val_loss: 0.5183 - val_accuracy: 0.8108\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7787 - val_loss: 0.5083 - val_accuracy: 0.7973\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.7348 - val_loss: 0.5116 - val_accuracy: 0.8108\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5760 - accuracy: 0.7601 - val_loss: 0.5098 - val_accuracy: 0.7973\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7568 - val_loss: 0.5095 - val_accuracy: 0.8041\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5612 - accuracy: 0.7889 - val_loss: 0.5065 - val_accuracy: 0.8243\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5529 - accuracy: 0.7889 - val_loss: 0.4961 - val_accuracy: 0.8243\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5741 - accuracy: 0.7956 - val_loss: 0.4855 - val_accuracy: 0.8311\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5275 - accuracy: 0.7956 - val_loss: 0.4739 - val_accuracy: 0.8311\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5713 - accuracy: 0.7736 - val_loss: 0.4866 - val_accuracy: 0.8243\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5640 - accuracy: 0.8007 - val_loss: 0.4948 - val_accuracy: 0.8311\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5731 - accuracy: 0.7551 - val_loss: 0.4966 - val_accuracy: 0.8378\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5817 - accuracy: 0.7703 - val_loss: 0.5017 - val_accuracy: 0.8378\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5565 - accuracy: 0.7703 - val_loss: 0.4958 - val_accuracy: 0.8311\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5905 - accuracy: 0.7686 - val_loss: 0.4876 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7939 - val_loss: 0.4926 - val_accuracy: 0.8243\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5571 - accuracy: 0.7720 - val_loss: 0.4899 - val_accuracy: 0.8311\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5468 - accuracy: 0.7855 - val_loss: 0.4938 - val_accuracy: 0.8378\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7905 - val_loss: 0.4958 - val_accuracy: 0.8243\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.7601 - val_loss: 0.4919 - val_accuracy: 0.8243\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5578 - accuracy: 0.7686 - val_loss: 0.4983 - val_accuracy: 0.8176\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7534 - val_loss: 0.5015 - val_accuracy: 0.8041\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5627 - accuracy: 0.7770 - val_loss: 0.4998 - val_accuracy: 0.8108\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5512 - accuracy: 0.7669 - val_loss: 0.5026 - val_accuracy: 0.8176\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7804 - val_loss: 0.4892 - val_accuracy: 0.8311\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7973 - val_loss: 0.4909 - val_accuracy: 0.8311\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.8057 - val_loss: 0.4914 - val_accuracy: 0.8378\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7432 - val_loss: 0.4918 - val_accuracy: 0.8176\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7922 - val_loss: 0.4990 - val_accuracy: 0.8041\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7770 - val_loss: 0.4807 - val_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5413 - accuracy: 0.7905 - val_loss: 0.4789 - val_accuracy: 0.8311\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7601 - val_loss: 0.4782 - val_accuracy: 0.8311\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7889 - val_loss: 0.4830 - val_accuracy: 0.8176\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5474 - accuracy: 0.7905 - val_loss: 0.4798 - val_accuracy: 0.8108\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5407 - accuracy: 0.7956 - val_loss: 0.4813 - val_accuracy: 0.8378\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.7618 - val_loss: 0.4889 - val_accuracy: 0.8446\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.7787 - val_loss: 0.4906 - val_accuracy: 0.8378\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7804 - val_loss: 0.4780 - val_accuracy: 0.8378\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.7770 - val_loss: 0.4812 - val_accuracy: 0.8243\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5464 - accuracy: 0.8108 - val_loss: 0.4862 - val_accuracy: 0.8311\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5197 - accuracy: 0.8024 - val_loss: 0.4727 - val_accuracy: 0.8243\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5356 - accuracy: 0.8007 - val_loss: 0.4606 - val_accuracy: 0.8311\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5204 - accuracy: 0.7736 - val_loss: 0.4572 - val_accuracy: 0.8446\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4994 - accuracy: 0.8074 - val_loss: 0.4540 - val_accuracy: 0.8311\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.8294 - val_loss: 0.4463 - val_accuracy: 0.8243\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.7551 - val_loss: 0.4567 - val_accuracy: 0.8311\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.7956 - val_loss: 0.4617 - val_accuracy: 0.8311\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.8024 - val_loss: 0.4650 - val_accuracy: 0.8176\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7905 - val_loss: 0.4533 - val_accuracy: 0.8446\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7821 - val_loss: 0.4502 - val_accuracy: 0.8243\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5402 - accuracy: 0.7770 - val_loss: 0.4571 - val_accuracy: 0.8311\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7939 - val_loss: 0.4551 - val_accuracy: 0.8243\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7584 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5460 - accuracy: 0.7872 - val_loss: 0.4652 - val_accuracy: 0.8311\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7872 - val_loss: 0.4640 - val_accuracy: 0.8243\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.8007 - val_loss: 0.4634 - val_accuracy: 0.8243\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7956 - val_loss: 0.4679 - val_accuracy: 0.8378\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7922 - val_loss: 0.4646 - val_accuracy: 0.8311\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5368 - accuracy: 0.7990 - val_loss: 0.4693 - val_accuracy: 0.8446\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7686 - val_loss: 0.4666 - val_accuracy: 0.8311\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.8024 - val_loss: 0.4662 - val_accuracy: 0.8311\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7736 - val_loss: 0.4779 - val_accuracy: 0.8311\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7990 - val_loss: 0.4701 - val_accuracy: 0.8311\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.8142 - val_loss: 0.4654 - val_accuracy: 0.8243\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.8007 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5406 - accuracy: 0.7838 - val_loss: 0.4671 - val_accuracy: 0.8311\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7720 - val_loss: 0.4621 - val_accuracy: 0.8311\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5190 - accuracy: 0.7753 - val_loss: 0.4549 - val_accuracy: 0.8176\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7770 - val_loss: 0.4491 - val_accuracy: 0.8311\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5701 - accuracy: 0.7652 - val_loss: 0.4519 - val_accuracy: 0.8243\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.8159 - val_loss: 0.4481 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5434 - accuracy: 0.7720 - val_loss: 0.4592 - val_accuracy: 0.8108\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4964 - accuracy: 0.8024 - val_loss: 0.4569 - val_accuracy: 0.8243\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5041 - accuracy: 0.8243 - val_loss: 0.4631 - val_accuracy: 0.8311\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4815 - accuracy: 0.8260 - val_loss: 0.4749 - val_accuracy: 0.7973\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5404 - accuracy: 0.7872 - val_loss: 0.4607 - val_accuracy: 0.8311\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4889 - accuracy: 0.8024 - val_loss: 0.4627 - val_accuracy: 0.8176\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.8074 - val_loss: 0.4632 - val_accuracy: 0.8311\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.8007 - val_loss: 0.4683 - val_accuracy: 0.8243\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7990 - val_loss: 0.4835 - val_accuracy: 0.8311\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7872 - val_loss: 0.4842 - val_accuracy: 0.8176\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7973 - val_loss: 0.4712 - val_accuracy: 0.8311\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7703 - val_loss: 0.4673 - val_accuracy: 0.8378\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7872 - val_loss: 0.4690 - val_accuracy: 0.8446\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.7635 - val_loss: 0.4702 - val_accuracy: 0.8243\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5599 - accuracy: 0.8007 - val_loss: 0.4654 - val_accuracy: 0.8243\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5485 - accuracy: 0.7889 - val_loss: 0.4709 - val_accuracy: 0.8311\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7855 - val_loss: 0.4618 - val_accuracy: 0.8311\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.8142 - val_loss: 0.4667 - val_accuracy: 0.8378\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7939 - val_loss: 0.4732 - val_accuracy: 0.8176\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.8108 - val_loss: 0.4694 - val_accuracy: 0.8108\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.8345 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7956 - val_loss: 0.4733 - val_accuracy: 0.8243\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7990 - val_loss: 0.4794 - val_accuracy: 0.8243\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.8024 - val_loss: 0.4710 - val_accuracy: 0.8176\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7973 - val_loss: 0.4744 - val_accuracy: 0.8108\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7922 - val_loss: 0.4634 - val_accuracy: 0.8176\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.8041 - val_loss: 0.4738 - val_accuracy: 0.8176\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.8074 - val_loss: 0.4858 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.8007 - val_loss: 0.4845 - val_accuracy: 0.8176\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.7855 - val_loss: 0.4822 - val_accuracy: 0.8243\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.8125 - val_loss: 0.4674 - val_accuracy: 0.8041\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4998 - accuracy: 0.8378 - val_loss: 0.4711 - val_accuracy: 0.8108\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5265 - accuracy: 0.7872 - val_loss: 0.4686 - val_accuracy: 0.8176\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5673 - accuracy: 0.7534 - val_loss: 0.4711 - val_accuracy: 0.8243\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5004 - accuracy: 0.7956 - val_loss: 0.4724 - val_accuracy: 0.8108\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4940 - accuracy: 0.8311 - val_loss: 0.4692 - val_accuracy: 0.8176\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5349 - accuracy: 0.7770 - val_loss: 0.4764 - val_accuracy: 0.8176\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5386 - accuracy: 0.8091 - val_loss: 0.4638 - val_accuracy: 0.8176\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.7939 - val_loss: 0.4680 - val_accuracy: 0.8243\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7821 - val_loss: 0.4842 - val_accuracy: 0.8108\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7939 - val_loss: 0.4678 - val_accuracy: 0.8176\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7838 - val_loss: 0.4645 - val_accuracy: 0.8176\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4779 - accuracy: 0.8041 - val_loss: 0.4605 - val_accuracy: 0.8176\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4834 - accuracy: 0.8260 - val_loss: 0.4538 - val_accuracy: 0.8243\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.8074 - val_loss: 0.4552 - val_accuracy: 0.8311\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8209 - val_loss: 0.4537 - val_accuracy: 0.8243\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7922 - val_loss: 0.4479 - val_accuracy: 0.8243\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7669 - val_loss: 0.4502 - val_accuracy: 0.8243\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.8024 - val_loss: 0.4462 - val_accuracy: 0.8378\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7872 - val_loss: 0.4484 - val_accuracy: 0.8378\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.8108 - val_loss: 0.4438 - val_accuracy: 0.8311\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.8024 - val_loss: 0.4445 - val_accuracy: 0.8311\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.8024 - val_loss: 0.4444 - val_accuracy: 0.8311\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7922 - val_loss: 0.4455 - val_accuracy: 0.8378\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7922 - val_loss: 0.4459 - val_accuracy: 0.8378\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7872 - val_loss: 0.4505 - val_accuracy: 0.8378\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.8091 - val_loss: 0.4544 - val_accuracy: 0.8311\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.8074 - val_loss: 0.4462 - val_accuracy: 0.8243\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7889 - val_loss: 0.4447 - val_accuracy: 0.8446\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.8007 - val_loss: 0.4443 - val_accuracy: 0.8243\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7838 - val_loss: 0.4490 - val_accuracy: 0.8378\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7990 - val_loss: 0.4430 - val_accuracy: 0.8243\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.8193 - val_loss: 0.4457 - val_accuracy: 0.8243\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5101 - accuracy: 0.8041 - val_loss: 0.4384 - val_accuracy: 0.8311\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4951 - accuracy: 0.7973 - val_loss: 0.4355 - val_accuracy: 0.8378\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5339 - accuracy: 0.7872 - val_loss: 0.4365 - val_accuracy: 0.8243\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5027 - accuracy: 0.8074 - val_loss: 0.4537 - val_accuracy: 0.8311\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5053 - accuracy: 0.7973 - val_loss: 0.4531 - val_accuracy: 0.8108\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5099 - accuracy: 0.8108 - val_loss: 0.4536 - val_accuracy: 0.8243\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5157 - accuracy: 0.8057 - val_loss: 0.4429 - val_accuracy: 0.8311\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.8378 - val_loss: 0.4292 - val_accuracy: 0.8243\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5317 - accuracy: 0.7990 - val_loss: 0.4303 - val_accuracy: 0.8446\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.8277 - val_loss: 0.4249 - val_accuracy: 0.8514\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8176 - val_loss: 0.4316 - val_accuracy: 0.8311\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7889 - val_loss: 0.4433 - val_accuracy: 0.8378\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.8159 - val_loss: 0.4447 - val_accuracy: 0.8311\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.8142 - val_loss: 0.4519 - val_accuracy: 0.8378\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7905 - val_loss: 0.4607 - val_accuracy: 0.8378\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8142 - val_loss: 0.4599 - val_accuracy: 0.8311\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7855 - val_loss: 0.4606 - val_accuracy: 0.8378\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5026 - accuracy: 0.8057 - val_loss: 0.4647 - val_accuracy: 0.8311\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7905 - val_loss: 0.4680 - val_accuracy: 0.8311\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.8125 - val_loss: 0.4700 - val_accuracy: 0.8311\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.8007 - val_loss: 0.4630 - val_accuracy: 0.8243\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7753 - val_loss: 0.4551 - val_accuracy: 0.8176\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.8361 - val_loss: 0.4586 - val_accuracy: 0.8176\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.8260 - val_loss: 0.4520 - val_accuracy: 0.8243\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.8277 - val_loss: 0.4444 - val_accuracy: 0.8243\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7889 - val_loss: 0.4468 - val_accuracy: 0.8311\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7889 - val_loss: 0.4503 - val_accuracy: 0.8243\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.8007 - val_loss: 0.4519 - val_accuracy: 0.8311\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.8108 - val_loss: 0.4429 - val_accuracy: 0.8378\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.8057 - val_loss: 0.4433 - val_accuracy: 0.8378\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.8057 - val_loss: 0.4340 - val_accuracy: 0.8446\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5071 - accuracy: 0.7973 - val_loss: 0.4371 - val_accuracy: 0.8378\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5161 - accuracy: 0.8057 - val_loss: 0.4383 - val_accuracy: 0.8378\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4917 - accuracy: 0.8260 - val_loss: 0.4395 - val_accuracy: 0.8446\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4932 - accuracy: 0.8074 - val_loss: 0.4369 - val_accuracy: 0.8311\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4669 - accuracy: 0.8260 - val_loss: 0.4566 - val_accuracy: 0.8311\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4975 - accuracy: 0.8142 - val_loss: 0.4521 - val_accuracy: 0.8311\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4827 - accuracy: 0.8361 - val_loss: 0.4470 - val_accuracy: 0.8378\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5139 - accuracy: 0.8091 - val_loss: 0.4532 - val_accuracy: 0.8378\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.8041 - val_loss: 0.4440 - val_accuracy: 0.8378\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.8074 - val_loss: 0.4411 - val_accuracy: 0.8446\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5307 - accuracy: 0.7889 - val_loss: 0.4463 - val_accuracy: 0.8514\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.8074 - val_loss: 0.4487 - val_accuracy: 0.8446\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.8311 - val_loss: 0.4533 - val_accuracy: 0.8243\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.8074 - val_loss: 0.4530 - val_accuracy: 0.8243\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.8024 - val_loss: 0.4415 - val_accuracy: 0.8243\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.8108 - val_loss: 0.4511 - val_accuracy: 0.8311\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7939 - val_loss: 0.4549 - val_accuracy: 0.8378\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7905 - val_loss: 0.4490 - val_accuracy: 0.8243\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.8125 - val_loss: 0.4596 - val_accuracy: 0.8378\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.8057 - val_loss: 0.4562 - val_accuracy: 0.8176\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7770 - val_loss: 0.4628 - val_accuracy: 0.8311\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7804 - val_loss: 0.4612 - val_accuracy: 0.8311\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7939 - val_loss: 0.4590 - val_accuracy: 0.8378\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.8226 - val_loss: 0.4607 - val_accuracy: 0.8243\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.8007 - val_loss: 0.4763 - val_accuracy: 0.8108\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8057 - val_loss: 0.4652 - val_accuracy: 0.8108\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.8243 - val_loss: 0.4572 - val_accuracy: 0.8108\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.8159 - val_loss: 0.4524 - val_accuracy: 0.8378\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8277 - val_loss: 0.4495 - val_accuracy: 0.8311\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.8142 - val_loss: 0.4548 - val_accuracy: 0.8243\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.8074 - val_loss: 0.4458 - val_accuracy: 0.8108\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.8226 - val_loss: 0.4435 - val_accuracy: 0.8243\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4732 - accuracy: 0.8142 - val_loss: 0.4399 - val_accuracy: 0.8514\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.7922 - val_loss: 0.4510 - val_accuracy: 0.8041\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4917 - accuracy: 0.8226 - val_loss: 0.4383 - val_accuracy: 0.8243\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4997 - accuracy: 0.7973 - val_loss: 0.4357 - val_accuracy: 0.8243\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.8024 - val_loss: 0.4442 - val_accuracy: 0.8108\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4812 - accuracy: 0.8159 - val_loss: 0.4391 - val_accuracy: 0.8311\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5084 - accuracy: 0.8142 - val_loss: 0.4536 - val_accuracy: 0.8243\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4959 - accuracy: 0.8294 - val_loss: 0.4458 - val_accuracy: 0.8378\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4728 - accuracy: 0.8209 - val_loss: 0.4437 - val_accuracy: 0.8378\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.8209 - val_loss: 0.4349 - val_accuracy: 0.8446\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.8057 - val_loss: 0.4291 - val_accuracy: 0.8514\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.8260 - val_loss: 0.4300 - val_accuracy: 0.8446\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8277 - val_loss: 0.4253 - val_accuracy: 0.8446\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.8057 - val_loss: 0.4232 - val_accuracy: 0.8378\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.8226 - val_loss: 0.4341 - val_accuracy: 0.8446\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8091 - val_loss: 0.4355 - val_accuracy: 0.8311\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.8074 - val_loss: 0.4336 - val_accuracy: 0.8446\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7889 - val_loss: 0.4329 - val_accuracy: 0.8446\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7939 - val_loss: 0.4293 - val_accuracy: 0.8378\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.8328 - val_loss: 0.4280 - val_accuracy: 0.8311\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.8074 - val_loss: 0.4316 - val_accuracy: 0.8311\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.8395 - val_loss: 0.4588 - val_accuracy: 0.7973\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.8142 - val_loss: 0.4478 - val_accuracy: 0.8108\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.8176 - val_loss: 0.4389 - val_accuracy: 0.8311\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.8277 - val_loss: 0.4465 - val_accuracy: 0.8041\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4826 - accuracy: 0.8176 - val_loss: 0.4398 - val_accuracy: 0.8243\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.8328 - val_loss: 0.4444 - val_accuracy: 0.8446\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.8243 - val_loss: 0.4561 - val_accuracy: 0.8176\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.8395 - val_loss: 0.4684 - val_accuracy: 0.8446\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.8007 - val_loss: 0.4663 - val_accuracy: 0.8243\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4837 - accuracy: 0.8193 - val_loss: 0.4704 - val_accuracy: 0.8108\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4773 - accuracy: 0.8260 - val_loss: 0.4559 - val_accuracy: 0.8311\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5471 - accuracy: 0.8007 - val_loss: 0.4402 - val_accuracy: 0.8378\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4739 - accuracy: 0.8193 - val_loss: 0.4380 - val_accuracy: 0.8446\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4746 - accuracy: 0.8395 - val_loss: 0.4468 - val_accuracy: 0.8378\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.8125 - val_loss: 0.4410 - val_accuracy: 0.8378\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4959 - accuracy: 0.8024 - val_loss: 0.4445 - val_accuracy: 0.8311\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5377 - accuracy: 0.7804 - val_loss: 0.4415 - val_accuracy: 0.8514\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4906 - accuracy: 0.8311 - val_loss: 0.4421 - val_accuracy: 0.8378\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5036 - accuracy: 0.8007 - val_loss: 0.4340 - val_accuracy: 0.8446\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7787 - val_loss: 0.4348 - val_accuracy: 0.8514\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.8024 - val_loss: 0.4399 - val_accuracy: 0.8378\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8345 - val_loss: 0.4467 - val_accuracy: 0.8243\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7922 - val_loss: 0.4422 - val_accuracy: 0.8311\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.8057 - val_loss: 0.4374 - val_accuracy: 0.8311\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.7889 - val_loss: 0.4369 - val_accuracy: 0.8243\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.8412 - val_loss: 0.4381 - val_accuracy: 0.8243\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.8294 - val_loss: 0.4351 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.8243 - val_loss: 0.4432 - val_accuracy: 0.8108\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.8024 - val_loss: 0.4362 - val_accuracy: 0.8176\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.8074 - val_loss: 0.4330 - val_accuracy: 0.8311\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.8142 - val_loss: 0.4324 - val_accuracy: 0.8243\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.8091 - val_loss: 0.4432 - val_accuracy: 0.8176\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.8243 - val_loss: 0.4543 - val_accuracy: 0.8243\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.8159 - val_loss: 0.4646 - val_accuracy: 0.8243\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.8159 - val_loss: 0.4649 - val_accuracy: 0.8176\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.8176 - val_loss: 0.4710 - val_accuracy: 0.8176\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.8193 - val_loss: 0.4740 - val_accuracy: 0.8041\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.8159 - val_loss: 0.4587 - val_accuracy: 0.8176\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.8041 - val_loss: 0.4555 - val_accuracy: 0.8041\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.8328 - val_loss: 0.4314 - val_accuracy: 0.8311\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.8209 - val_loss: 0.4468 - val_accuracy: 0.8311\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4945 - accuracy: 0.8142 - val_loss: 0.4439 - val_accuracy: 0.8243\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4633 - accuracy: 0.8378 - val_loss: 0.4447 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4975 - accuracy: 0.8125 - val_loss: 0.4438 - val_accuracy: 0.8378\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4951 - accuracy: 0.8159 - val_loss: 0.4359 - val_accuracy: 0.8446\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4652 - accuracy: 0.8243 - val_loss: 0.4372 - val_accuracy: 0.8311\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4641 - accuracy: 0.8277 - val_loss: 0.4371 - val_accuracy: 0.8378\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5229 - accuracy: 0.8125 - val_loss: 0.4587 - val_accuracy: 0.8243\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4952 - accuracy: 0.8074 - val_loss: 0.4511 - val_accuracy: 0.8243\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4700 - accuracy: 0.8125 - val_loss: 0.4415 - val_accuracy: 0.8378\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.8277 - val_loss: 0.4360 - val_accuracy: 0.8378\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.8142 - val_loss: 0.4414 - val_accuracy: 0.8311\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5136 - accuracy: 0.7990 - val_loss: 0.4408 - val_accuracy: 0.8311\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.8446 - val_loss: 0.4396 - val_accuracy: 0.8311\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7973 - val_loss: 0.4541 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8142 - val_loss: 0.4530 - val_accuracy: 0.8176\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8226 - val_loss: 0.4338 - val_accuracy: 0.8378\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7821 - val_loss: 0.4451 - val_accuracy: 0.8108\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7939 - val_loss: 0.4271 - val_accuracy: 0.8378\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7973 - val_loss: 0.4285 - val_accuracy: 0.8311\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5134 - accuracy: 0.7956 - val_loss: 0.4391 - val_accuracy: 0.8243\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.8125 - val_loss: 0.4311 - val_accuracy: 0.8378\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.8345 - val_loss: 0.4334 - val_accuracy: 0.8176\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7922 - val_loss: 0.4365 - val_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.8125 - val_loss: 0.4359 - val_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.8125 - val_loss: 0.4388 - val_accuracy: 0.8108\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.8057 - val_loss: 0.4412 - val_accuracy: 0.8243\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.8277 - val_loss: 0.4407 - val_accuracy: 0.8108\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8193 - val_loss: 0.4515 - val_accuracy: 0.8041\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.8041 - val_loss: 0.4382 - val_accuracy: 0.8108\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.8209 - val_loss: 0.4372 - val_accuracy: 0.8243\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.8024 - val_loss: 0.4324 - val_accuracy: 0.8378\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5005 - accuracy: 0.8176 - val_loss: 0.4348 - val_accuracy: 0.8446\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4627 - accuracy: 0.8294 - val_loss: 0.4374 - val_accuracy: 0.8176\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4673 - accuracy: 0.8294 - val_loss: 0.4338 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5457 - accuracy: 0.8007 - val_loss: 0.4488 - val_accuracy: 0.8041\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4835 - accuracy: 0.8193 - val_loss: 0.4511 - val_accuracy: 0.8176\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5104 - accuracy: 0.8057 - val_loss: 0.4405 - val_accuracy: 0.8243\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4999 - accuracy: 0.8041 - val_loss: 0.4371 - val_accuracy: 0.8311\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4830 - accuracy: 0.8142 - val_loss: 0.4378 - val_accuracy: 0.8243\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4943 - accuracy: 0.8108 - val_loss: 0.4328 - val_accuracy: 0.8311\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8226 - val_loss: 0.4335 - val_accuracy: 0.8243\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.8226 - val_loss: 0.4268 - val_accuracy: 0.8378\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.8311 - val_loss: 0.4210 - val_accuracy: 0.8378\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.8277 - val_loss: 0.4177 - val_accuracy: 0.8446\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8209 - val_loss: 0.4200 - val_accuracy: 0.8446\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.8108 - val_loss: 0.4227 - val_accuracy: 0.8243\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.8142 - val_loss: 0.4196 - val_accuracy: 0.8378\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.8294 - val_loss: 0.4200 - val_accuracy: 0.8243\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7973 - val_loss: 0.4251 - val_accuracy: 0.8243\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.8243 - val_loss: 0.4328 - val_accuracy: 0.8108\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.8091 - val_loss: 0.4278 - val_accuracy: 0.8243\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.8007 - val_loss: 0.4324 - val_accuracy: 0.8243\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.8446 - val_loss: 0.4279 - val_accuracy: 0.8378\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8243 - val_loss: 0.4282 - val_accuracy: 0.8378\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7990 - val_loss: 0.4257 - val_accuracy: 0.8311\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7939 - val_loss: 0.4311 - val_accuracy: 0.8311\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.8260 - val_loss: 0.4365 - val_accuracy: 0.8311\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.8328 - val_loss: 0.4359 - val_accuracy: 0.8243\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8446 - val_loss: 0.4211 - val_accuracy: 0.8446\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7889 - val_loss: 0.4286 - val_accuracy: 0.8311\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.8277 - val_loss: 0.4371 - val_accuracy: 0.8176\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7889 - val_loss: 0.4324 - val_accuracy: 0.8311\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.8057 - val_loss: 0.4285 - val_accuracy: 0.8243\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4593 - accuracy: 0.8209 - val_loss: 0.4223 - val_accuracy: 0.8311\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5082 - accuracy: 0.8091 - val_loss: 0.4230 - val_accuracy: 0.8243\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4273 - accuracy: 0.8497 - val_loss: 0.4141 - val_accuracy: 0.8311\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.8311 - val_loss: 0.4191 - val_accuracy: 0.8176\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5278 - accuracy: 0.7753 - val_loss: 0.4343 - val_accuracy: 0.8108\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4892 - accuracy: 0.8125 - val_loss: 0.4144 - val_accuracy: 0.8378\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4825 - accuracy: 0.8024 - val_loss: 0.4083 - val_accuracy: 0.8311\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4968 - accuracy: 0.8209 - val_loss: 0.4179 - val_accuracy: 0.8243\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5175 - accuracy: 0.7922 - val_loss: 0.4213 - val_accuracy: 0.8243\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.8041 - val_loss: 0.4308 - val_accuracy: 0.8176\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7939 - val_loss: 0.4410 - val_accuracy: 0.8041\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.8142 - val_loss: 0.4328 - val_accuracy: 0.8378\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7821 - val_loss: 0.4353 - val_accuracy: 0.8446\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.8260 - val_loss: 0.4416 - val_accuracy: 0.8311\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.8209 - val_loss: 0.4384 - val_accuracy: 0.8446\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.8041 - val_loss: 0.4501 - val_accuracy: 0.8378\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.8007 - val_loss: 0.4446 - val_accuracy: 0.8311\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.8193 - val_loss: 0.4420 - val_accuracy: 0.8311\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.8226 - val_loss: 0.4443 - val_accuracy: 0.8176\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7939 - val_loss: 0.4387 - val_accuracy: 0.8176\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8193 - val_loss: 0.4438 - val_accuracy: 0.8176\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7855 - val_loss: 0.4465 - val_accuracy: 0.8176\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7872 - val_loss: 0.4292 - val_accuracy: 0.8243\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7939 - val_loss: 0.4397 - val_accuracy: 0.8108\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.8091 - val_loss: 0.4443 - val_accuracy: 0.7973\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.8345 - val_loss: 0.4353 - val_accuracy: 0.8243\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.8277 - val_loss: 0.4307 - val_accuracy: 0.8243\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.8260 - val_loss: 0.4252 - val_accuracy: 0.8311\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7855 - val_loss: 0.4364 - val_accuracy: 0.8243\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.8108 - val_loss: 0.4316 - val_accuracy: 0.8243\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7973 - val_loss: 0.4312 - val_accuracy: 0.8378\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.8007 - val_loss: 0.4412 - val_accuracy: 0.8243\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.8159 - val_loss: 0.4440 - val_accuracy: 0.8176\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4547 - accuracy: 0.8378 - val_loss: 0.4415 - val_accuracy: 0.8378\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.8074 - val_loss: 0.4533 - val_accuracy: 0.8176\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.8176 - val_loss: 0.4479 - val_accuracy: 0.8311\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4575 - accuracy: 0.8193 - val_loss: 0.4704 - val_accuracy: 0.8041\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5060 - accuracy: 0.8074 - val_loss: 0.4509 - val_accuracy: 0.8176\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4613 - accuracy: 0.8311 - val_loss: 0.4467 - val_accuracy: 0.8243\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4920 - accuracy: 0.7939 - val_loss: 0.4355 - val_accuracy: 0.8243\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4627 - accuracy: 0.8226 - val_loss: 0.4382 - val_accuracy: 0.8243\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.8125 - val_loss: 0.4411 - val_accuracy: 0.8176\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.8074 - val_loss: 0.4481 - val_accuracy: 0.8041\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.8159 - val_loss: 0.4408 - val_accuracy: 0.8176\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5063 - accuracy: 0.8007 - val_loss: 0.4529 - val_accuracy: 0.7973\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7973 - val_loss: 0.4519 - val_accuracy: 0.8108\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7905 - val_loss: 0.4617 - val_accuracy: 0.7973\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.8091 - val_loss: 0.4490 - val_accuracy: 0.8108\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7990 - val_loss: 0.4410 - val_accuracy: 0.8176\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8260 - val_loss: 0.4381 - val_accuracy: 0.8311\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8260 - val_loss: 0.4393 - val_accuracy: 0.8176\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.8176 - val_loss: 0.4465 - val_accuracy: 0.7973\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8125 - val_loss: 0.4369 - val_accuracy: 0.8311\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8176 - val_loss: 0.4338 - val_accuracy: 0.8311\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.8294 - val_loss: 0.4361 - val_accuracy: 0.8176\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.8142 - val_loss: 0.4267 - val_accuracy: 0.8311\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4441 - accuracy: 0.8345 - val_loss: 0.4236 - val_accuracy: 0.8108\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.8007 - val_loss: 0.4349 - val_accuracy: 0.7905\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8260 - val_loss: 0.4430 - val_accuracy: 0.7973\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.8125 - val_loss: 0.4395 - val_accuracy: 0.8176\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.8125 - val_loss: 0.4650 - val_accuracy: 0.8041\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.8328 - val_loss: 0.4512 - val_accuracy: 0.8176\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.8311 - val_loss: 0.4469 - val_accuracy: 0.8176\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4581 - accuracy: 0.8463 - val_loss: 0.4493 - val_accuracy: 0.8176\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4328 - accuracy: 0.8497 - val_loss: 0.4383 - val_accuracy: 0.8446\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4403 - accuracy: 0.8277 - val_loss: 0.4412 - val_accuracy: 0.8108\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4624 - accuracy: 0.8311 - val_loss: 0.4495 - val_accuracy: 0.8311\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4990 - accuracy: 0.8260 - val_loss: 0.4623 - val_accuracy: 0.8176\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4616 - accuracy: 0.8328 - val_loss: 0.4411 - val_accuracy: 0.8378\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4833 - accuracy: 0.8277 - val_loss: 0.4626 - val_accuracy: 0.8041\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4682 - accuracy: 0.8007 - val_loss: 0.4465 - val_accuracy: 0.8176\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5158 - accuracy: 0.8074 - val_loss: 0.4497 - val_accuracy: 0.8243\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.8176 - val_loss: 0.4535 - val_accuracy: 0.8378\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4873 - accuracy: 0.7905 - val_loss: 0.4405 - val_accuracy: 0.8446\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7973 - val_loss: 0.4363 - val_accuracy: 0.8378\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7821 - val_loss: 0.4365 - val_accuracy: 0.8378\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7939 - val_loss: 0.4309 - val_accuracy: 0.8378\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7973 - val_loss: 0.4316 - val_accuracy: 0.8378\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.8412 - val_loss: 0.4359 - val_accuracy: 0.8378\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8378\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c605e467ca37>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 10ms/step - loss: 1.7202 - accuracy: 0.4949 - val_loss: 1.1746 - val_accuracy: 0.5135\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.6148 - accuracy: 0.5017 - val_loss: 1.1723 - val_accuracy: 0.5270\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.5119 - accuracy: 0.4966 - val_loss: 1.1571 - val_accuracy: 0.5270\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.4017 - accuracy: 0.5236 - val_loss: 1.1448 - val_accuracy: 0.5135\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 1.3455 - accuracy: 0.5101 - val_loss: 1.1195 - val_accuracy: 0.5135\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.3069 - accuracy: 0.5000 - val_loss: 1.1041 - val_accuracy: 0.5405\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.2275 - accuracy: 0.5000 - val_loss: 1.0936 - val_accuracy: 0.5405\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 1.1677 - accuracy: 0.5236 - val_loss: 1.0861 - val_accuracy: 0.5270\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.1244 - accuracy: 0.5439 - val_loss: 1.0756 - val_accuracy: 0.5405\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.1467 - accuracy: 0.5236 - val_loss: 1.0669 - val_accuracy: 0.5270\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0760 - accuracy: 0.5405 - val_loss: 1.0563 - val_accuracy: 0.5338\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0488 - accuracy: 0.5591 - val_loss: 1.0448 - val_accuracy: 0.5676\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0711 - accuracy: 0.5135 - val_loss: 1.0355 - val_accuracy: 0.5676\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0591 - accuracy: 0.5304 - val_loss: 1.0265 - val_accuracy: 0.5338\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0378 - accuracy: 0.5422 - val_loss: 1.0162 - val_accuracy: 0.5541\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0204 - accuracy: 0.5084 - val_loss: 1.0063 - val_accuracy: 0.5743\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.5389 - val_loss: 0.9957 - val_accuracy: 0.5811\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0062 - accuracy: 0.5422 - val_loss: 0.9860 - val_accuracy: 0.5676\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9971 - accuracy: 0.4983 - val_loss: 0.9772 - val_accuracy: 0.5811\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9802 - accuracy: 0.5321 - val_loss: 0.9680 - val_accuracy: 0.5743\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9685 - accuracy: 0.5473 - val_loss: 0.9579 - val_accuracy: 0.5878\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9520 - accuracy: 0.5524 - val_loss: 0.9471 - val_accuracy: 0.5946\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9374 - accuracy: 0.5507 - val_loss: 0.9349 - val_accuracy: 0.6014\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9373 - accuracy: 0.5236 - val_loss: 0.9253 - val_accuracy: 0.5811\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9276 - accuracy: 0.5321 - val_loss: 0.9154 - val_accuracy: 0.6149\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9166 - accuracy: 0.5473 - val_loss: 0.9077 - val_accuracy: 0.6554\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9007 - accuracy: 0.5642 - val_loss: 0.8954 - val_accuracy: 0.6689\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8889 - accuracy: 0.5608 - val_loss: 0.8853 - val_accuracy: 0.6554\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8843 - accuracy: 0.5608 - val_loss: 0.8747 - val_accuracy: 0.6689\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8817 - accuracy: 0.5304 - val_loss: 0.8664 - val_accuracy: 0.6757\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8657 - accuracy: 0.5574 - val_loss: 0.8573 - val_accuracy: 0.6757\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8536 - accuracy: 0.5726 - val_loss: 0.8405 - val_accuracy: 0.7162\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8423 - accuracy: 0.5828 - val_loss: 0.8309 - val_accuracy: 0.7027\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8437 - accuracy: 0.5895 - val_loss: 0.8223 - val_accuracy: 0.7162\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8098 - accuracy: 0.6368 - val_loss: 0.8100 - val_accuracy: 0.7027\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8188 - accuracy: 0.5777 - val_loss: 0.7931 - val_accuracy: 0.7095\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8162 - accuracy: 0.6081 - val_loss: 0.7848 - val_accuracy: 0.7027\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8013 - accuracy: 0.5878 - val_loss: 0.7750 - val_accuracy: 0.6959\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7776 - accuracy: 0.6267 - val_loss: 0.7644 - val_accuracy: 0.7027\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7795 - accuracy: 0.6216 - val_loss: 0.7509 - val_accuracy: 0.7230\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7681 - accuracy: 0.6385 - val_loss: 0.7405 - val_accuracy: 0.7500\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.6503 - val_loss: 0.7297 - val_accuracy: 0.7432\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7708 - accuracy: 0.6250 - val_loss: 0.7175 - val_accuracy: 0.7635\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7777 - accuracy: 0.6115 - val_loss: 0.7119 - val_accuracy: 0.7838\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7452 - accuracy: 0.6503 - val_loss: 0.7086 - val_accuracy: 0.7635\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7265 - accuracy: 0.6639 - val_loss: 0.6849 - val_accuracy: 0.7703\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7288 - accuracy: 0.6622 - val_loss: 0.6752 - val_accuracy: 0.7635\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7278 - accuracy: 0.6588 - val_loss: 0.6694 - val_accuracy: 0.7838\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7194 - accuracy: 0.6672 - val_loss: 0.6583 - val_accuracy: 0.7770\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7173 - accuracy: 0.6605 - val_loss: 0.6554 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.6875 - val_loss: 0.6485 - val_accuracy: 0.7365\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7251 - accuracy: 0.6622 - val_loss: 0.6493 - val_accuracy: 0.7500\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7113 - accuracy: 0.6588 - val_loss: 0.6513 - val_accuracy: 0.7432\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.6926 - val_loss: 0.6443 - val_accuracy: 0.7635\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.6723 - val_loss: 0.6226 - val_accuracy: 0.7568\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.6791 - val_loss: 0.6175 - val_accuracy: 0.7635\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6744 - accuracy: 0.7044 - val_loss: 0.6136 - val_accuracy: 0.7703\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.6757 - val_loss: 0.6108 - val_accuracy: 0.7770\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6631 - accuracy: 0.7061 - val_loss: 0.6073 - val_accuracy: 0.7770\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6533 - accuracy: 0.6824 - val_loss: 0.6001 - val_accuracy: 0.7770\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6600 - accuracy: 0.6655 - val_loss: 0.5913 - val_accuracy: 0.7770\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6476 - accuracy: 0.7331 - val_loss: 0.5846 - val_accuracy: 0.7635\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6475 - accuracy: 0.6841 - val_loss: 0.5773 - val_accuracy: 0.7568\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6544 - accuracy: 0.7010 - val_loss: 0.5768 - val_accuracy: 0.7770\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6436 - accuracy: 0.7095 - val_loss: 0.5728 - val_accuracy: 0.7703\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6262 - accuracy: 0.7264 - val_loss: 0.5689 - val_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.7264 - val_loss: 0.5696 - val_accuracy: 0.7568\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.7128 - val_loss: 0.5626 - val_accuracy: 0.7770\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.7280 - val_loss: 0.5616 - val_accuracy: 0.7770\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.7095 - val_loss: 0.5579 - val_accuracy: 0.7770\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7230 - val_loss: 0.5465 - val_accuracy: 0.7838\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.7297 - val_loss: 0.5441 - val_accuracy: 0.7703\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6443 - accuracy: 0.7196 - val_loss: 0.5523 - val_accuracy: 0.7770\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6259 - accuracy: 0.7111 - val_loss: 0.5529 - val_accuracy: 0.7770\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7703 - val_loss: 0.5369 - val_accuracy: 0.7770\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7703 - val_loss: 0.5287 - val_accuracy: 0.7838\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6167 - accuracy: 0.7466 - val_loss: 0.5290 - val_accuracy: 0.7905\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6341 - accuracy: 0.7365 - val_loss: 0.5363 - val_accuracy: 0.7905\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.7466 - val_loss: 0.5309 - val_accuracy: 0.7905\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.7348 - val_loss: 0.5324 - val_accuracy: 0.8311\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.7483 - val_loss: 0.5249 - val_accuracy: 0.8176\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7230 - val_loss: 0.5223 - val_accuracy: 0.7973\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7686 - val_loss: 0.5189 - val_accuracy: 0.8108\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.7044 - val_loss: 0.5162 - val_accuracy: 0.8311\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5954 - accuracy: 0.7635 - val_loss: 0.5160 - val_accuracy: 0.8108\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7534 - val_loss: 0.4995 - val_accuracy: 0.8378\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7736 - val_loss: 0.4984 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.7449 - val_loss: 0.5029 - val_accuracy: 0.8378\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.7466 - val_loss: 0.5006 - val_accuracy: 0.8243\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7500 - val_loss: 0.4940 - val_accuracy: 0.8176\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7821 - val_loss: 0.4960 - val_accuracy: 0.8243\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5925 - accuracy: 0.7551 - val_loss: 0.4867 - val_accuracy: 0.8378\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5825 - accuracy: 0.7432 - val_loss: 0.4941 - val_accuracy: 0.8176\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5966 - accuracy: 0.7416 - val_loss: 0.5082 - val_accuracy: 0.8041\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5671 - accuracy: 0.7703 - val_loss: 0.5111 - val_accuracy: 0.7973\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.7432 - val_loss: 0.5120 - val_accuracy: 0.8041\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5952 - accuracy: 0.7449 - val_loss: 0.5084 - val_accuracy: 0.8108\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5763 - accuracy: 0.7483 - val_loss: 0.5055 - val_accuracy: 0.8041\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5651 - accuracy: 0.7568 - val_loss: 0.4995 - val_accuracy: 0.7905\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5906 - accuracy: 0.7753 - val_loss: 0.4991 - val_accuracy: 0.7905\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.7568 - val_loss: 0.5011 - val_accuracy: 0.8108\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7449 - val_loss: 0.5086 - val_accuracy: 0.7905\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5788 - accuracy: 0.7804 - val_loss: 0.5015 - val_accuracy: 0.8041\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5682 - accuracy: 0.7601 - val_loss: 0.4979 - val_accuracy: 0.8108\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5969 - accuracy: 0.7432 - val_loss: 0.4997 - val_accuracy: 0.8243\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.7500 - val_loss: 0.4973 - val_accuracy: 0.8041\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6407 - accuracy: 0.7010 - val_loss: 0.5051 - val_accuracy: 0.7973\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.7855 - val_loss: 0.4942 - val_accuracy: 0.8176\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5953 - accuracy: 0.7720 - val_loss: 0.4882 - val_accuracy: 0.8311\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5999 - accuracy: 0.7551 - val_loss: 0.4951 - val_accuracy: 0.8176\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7736 - val_loss: 0.4896 - val_accuracy: 0.8108\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5935 - accuracy: 0.7652 - val_loss: 0.4827 - val_accuracy: 0.8311\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7821 - val_loss: 0.4756 - val_accuracy: 0.8378\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7686 - val_loss: 0.4677 - val_accuracy: 0.8446\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7787 - val_loss: 0.4722 - val_accuracy: 0.8243\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7753 - val_loss: 0.4711 - val_accuracy: 0.8311\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5632 - accuracy: 0.7787 - val_loss: 0.4772 - val_accuracy: 0.8378\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5704 - accuracy: 0.7787 - val_loss: 0.4725 - val_accuracy: 0.8243\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.8057 - val_loss: 0.4726 - val_accuracy: 0.8378\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.7517 - val_loss: 0.4672 - val_accuracy: 0.8243\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.7466 - val_loss: 0.4714 - val_accuracy: 0.8378\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7770 - val_loss: 0.4706 - val_accuracy: 0.8176\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.7770 - val_loss: 0.4820 - val_accuracy: 0.8108\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.7584 - val_loss: 0.4629 - val_accuracy: 0.8176\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5470 - accuracy: 0.7787 - val_loss: 0.4705 - val_accuracy: 0.8108\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5282 - accuracy: 0.7872 - val_loss: 0.4744 - val_accuracy: 0.8041\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5502 - accuracy: 0.7635 - val_loss: 0.4710 - val_accuracy: 0.8108\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5532 - accuracy: 0.7753 - val_loss: 0.4662 - val_accuracy: 0.8378\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5740 - accuracy: 0.7753 - val_loss: 0.4696 - val_accuracy: 0.8378\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5905 - accuracy: 0.7720 - val_loss: 0.4765 - val_accuracy: 0.8378\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5615 - accuracy: 0.7787 - val_loss: 0.4744 - val_accuracy: 0.8243\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5525 - accuracy: 0.7736 - val_loss: 0.4683 - val_accuracy: 0.8243\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5608 - accuracy: 0.7449 - val_loss: 0.4604 - val_accuracy: 0.8311\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7720 - val_loss: 0.4681 - val_accuracy: 0.8446\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7855 - val_loss: 0.4767 - val_accuracy: 0.8243\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7736 - val_loss: 0.4732 - val_accuracy: 0.8311\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7838 - val_loss: 0.4606 - val_accuracy: 0.8243\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7669 - val_loss: 0.4590 - val_accuracy: 0.8378\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5737 - accuracy: 0.7703 - val_loss: 0.4672 - val_accuracy: 0.8176\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.8125 - val_loss: 0.4728 - val_accuracy: 0.8108\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7787 - val_loss: 0.4586 - val_accuracy: 0.8108\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6076 - accuracy: 0.7517 - val_loss: 0.4741 - val_accuracy: 0.7973\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.8024 - val_loss: 0.4701 - val_accuracy: 0.8041\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6013 - accuracy: 0.7534 - val_loss: 0.4829 - val_accuracy: 0.8108\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.8074 - val_loss: 0.4723 - val_accuracy: 0.7838\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7787 - val_loss: 0.4693 - val_accuracy: 0.7905\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5684 - accuracy: 0.7872 - val_loss: 0.4655 - val_accuracy: 0.8108\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7736 - val_loss: 0.4627 - val_accuracy: 0.8108\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.8041 - val_loss: 0.4534 - val_accuracy: 0.8176\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5775 - accuracy: 0.7753 - val_loss: 0.4561 - val_accuracy: 0.8311\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5611 - accuracy: 0.7770 - val_loss: 0.4594 - val_accuracy: 0.8108\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7753 - val_loss: 0.4638 - val_accuracy: 0.8176\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.8041 - val_loss: 0.4688 - val_accuracy: 0.8176\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5497 - accuracy: 0.7736 - val_loss: 0.4653 - val_accuracy: 0.8311\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.7669 - val_loss: 0.4571 - val_accuracy: 0.8243\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7838 - val_loss: 0.4613 - val_accuracy: 0.8311\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7736 - val_loss: 0.4585 - val_accuracy: 0.8378\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7838 - val_loss: 0.4556 - val_accuracy: 0.8311\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.7787 - val_loss: 0.4533 - val_accuracy: 0.8311\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5760 - accuracy: 0.7618 - val_loss: 0.4588 - val_accuracy: 0.8311\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.7956 - val_loss: 0.4512 - val_accuracy: 0.8378\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.7922 - val_loss: 0.4539 - val_accuracy: 0.8243\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7939 - val_loss: 0.4513 - val_accuracy: 0.8378\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5514 - accuracy: 0.7753 - val_loss: 0.4471 - val_accuracy: 0.8311\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.7432 - val_loss: 0.4618 - val_accuracy: 0.8108\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5494 - accuracy: 0.7889 - val_loss: 0.4511 - val_accuracy: 0.8311\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7956 - val_loss: 0.4509 - val_accuracy: 0.8311\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5491 - accuracy: 0.7652 - val_loss: 0.4422 - val_accuracy: 0.8581\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7956 - val_loss: 0.4475 - val_accuracy: 0.8311\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7838 - val_loss: 0.4524 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7753 - val_loss: 0.4473 - val_accuracy: 0.8378\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7686 - val_loss: 0.4574 - val_accuracy: 0.8176\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7770 - val_loss: 0.4596 - val_accuracy: 0.8311\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7872 - val_loss: 0.4549 - val_accuracy: 0.8378\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7990 - val_loss: 0.4549 - val_accuracy: 0.8243\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.8007 - val_loss: 0.4579 - val_accuracy: 0.8176\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7872 - val_loss: 0.4574 - val_accuracy: 0.8176\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7736 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7973 - val_loss: 0.4586 - val_accuracy: 0.8446\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7956 - val_loss: 0.4630 - val_accuracy: 0.8378\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.7787 - val_loss: 0.4615 - val_accuracy: 0.8243\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.8057 - val_loss: 0.4612 - val_accuracy: 0.8311\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5521 - accuracy: 0.7855 - val_loss: 0.4612 - val_accuracy: 0.8243\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7939 - val_loss: 0.4567 - val_accuracy: 0.8378\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7872 - val_loss: 0.4594 - val_accuracy: 0.8311\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.8041 - val_loss: 0.4625 - val_accuracy: 0.8176\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7956 - val_loss: 0.4669 - val_accuracy: 0.8108\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.7753 - val_loss: 0.4585 - val_accuracy: 0.8378\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7787 - val_loss: 0.4526 - val_accuracy: 0.8311\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5674 - accuracy: 0.7669 - val_loss: 0.4645 - val_accuracy: 0.8041\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.8074 - val_loss: 0.4567 - val_accuracy: 0.8311\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5017 - accuracy: 0.8024 - val_loss: 0.4562 - val_accuracy: 0.8108\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.7872 - val_loss: 0.4549 - val_accuracy: 0.8243\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5342 - accuracy: 0.7753 - val_loss: 0.4561 - val_accuracy: 0.8108\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5538 - accuracy: 0.7652 - val_loss: 0.4522 - val_accuracy: 0.8311\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5372 - accuracy: 0.7872 - val_loss: 0.4643 - val_accuracy: 0.8041\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5548 - accuracy: 0.7703 - val_loss: 0.4710 - val_accuracy: 0.7973\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4852 - accuracy: 0.8159 - val_loss: 0.4633 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5299 - accuracy: 0.7889 - val_loss: 0.4490 - val_accuracy: 0.8446\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.8193 - val_loss: 0.4584 - val_accuracy: 0.8176\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7838 - val_loss: 0.4747 - val_accuracy: 0.8108\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.7804 - val_loss: 0.4616 - val_accuracy: 0.8378\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5506 - accuracy: 0.7889 - val_loss: 0.4662 - val_accuracy: 0.8311\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7736 - val_loss: 0.4704 - val_accuracy: 0.8243\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.8024 - val_loss: 0.4661 - val_accuracy: 0.8243\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.8041 - val_loss: 0.4520 - val_accuracy: 0.8378\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7652 - val_loss: 0.4595 - val_accuracy: 0.8243\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.8091 - val_loss: 0.4497 - val_accuracy: 0.8581\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7939 - val_loss: 0.4535 - val_accuracy: 0.8514\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.7838 - val_loss: 0.4625 - val_accuracy: 0.8041\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7939 - val_loss: 0.4639 - val_accuracy: 0.8108\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7804 - val_loss: 0.4680 - val_accuracy: 0.8041\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7973 - val_loss: 0.4701 - val_accuracy: 0.8108\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4984 - accuracy: 0.8074 - val_loss: 0.4724 - val_accuracy: 0.7973\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7787 - val_loss: 0.4680 - val_accuracy: 0.7973\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.8159 - val_loss: 0.4693 - val_accuracy: 0.7973\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.8108 - val_loss: 0.4616 - val_accuracy: 0.8311\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.7939 - val_loss: 0.4632 - val_accuracy: 0.8243\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7905 - val_loss: 0.4581 - val_accuracy: 0.8243\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7787 - val_loss: 0.4561 - val_accuracy: 0.8378\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7787 - val_loss: 0.4602 - val_accuracy: 0.8311\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7922 - val_loss: 0.4618 - val_accuracy: 0.8243\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5272 - accuracy: 0.7889 - val_loss: 0.4606 - val_accuracy: 0.8108\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7838 - val_loss: 0.4677 - val_accuracy: 0.7973\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4939 - accuracy: 0.8108 - val_loss: 0.4680 - val_accuracy: 0.8041\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5385 - accuracy: 0.7956 - val_loss: 0.4656 - val_accuracy: 0.8041\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5240 - accuracy: 0.8142 - val_loss: 0.4627 - val_accuracy: 0.8041\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5342 - accuracy: 0.7905 - val_loss: 0.4600 - val_accuracy: 0.8108\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.8007 - val_loss: 0.4580 - val_accuracy: 0.8108\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.8074 - val_loss: 0.4644 - val_accuracy: 0.8176\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5752 - accuracy: 0.7804 - val_loss: 0.4542 - val_accuracy: 0.8446\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5778 - accuracy: 0.7686 - val_loss: 0.4604 - val_accuracy: 0.8514\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.8074 - val_loss: 0.4519 - val_accuracy: 0.8446\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7990 - val_loss: 0.4535 - val_accuracy: 0.8243\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7922 - val_loss: 0.4505 - val_accuracy: 0.8311\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7872 - val_loss: 0.4601 - val_accuracy: 0.8176\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5410 - accuracy: 0.7787 - val_loss: 0.4609 - val_accuracy: 0.8176\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5536 - accuracy: 0.7855 - val_loss: 0.4688 - val_accuracy: 0.8243\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.8007 - val_loss: 0.4530 - val_accuracy: 0.8446\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5476 - accuracy: 0.7922 - val_loss: 0.4581 - val_accuracy: 0.8378\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7939 - val_loss: 0.4653 - val_accuracy: 0.8041\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7905 - val_loss: 0.4488 - val_accuracy: 0.8446\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5577 - accuracy: 0.7855 - val_loss: 0.4507 - val_accuracy: 0.8311\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.8226 - val_loss: 0.4461 - val_accuracy: 0.8378\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5110 - accuracy: 0.8176 - val_loss: 0.4481 - val_accuracy: 0.8176\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.8091 - val_loss: 0.4531 - val_accuracy: 0.8176\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5089 - accuracy: 0.8041 - val_loss: 0.4560 - val_accuracy: 0.8108\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.7922 - val_loss: 0.4524 - val_accuracy: 0.8311\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4755 - accuracy: 0.8074 - val_loss: 0.4376 - val_accuracy: 0.8446\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.8260 - val_loss: 0.4535 - val_accuracy: 0.8176\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5295 - accuracy: 0.7872 - val_loss: 0.4530 - val_accuracy: 0.8108\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7753 - val_loss: 0.4520 - val_accuracy: 0.8243\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.8277 - val_loss: 0.4437 - val_accuracy: 0.8311\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4897 - accuracy: 0.8159 - val_loss: 0.4433 - val_accuracy: 0.8378\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7990 - val_loss: 0.4584 - val_accuracy: 0.8176\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7905 - val_loss: 0.4530 - val_accuracy: 0.8378\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7821 - val_loss: 0.4501 - val_accuracy: 0.8446\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5196 - accuracy: 0.8125 - val_loss: 0.4530 - val_accuracy: 0.8311\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5150 - accuracy: 0.8007 - val_loss: 0.4708 - val_accuracy: 0.8176\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5069 - accuracy: 0.8176 - val_loss: 0.4684 - val_accuracy: 0.8041\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5128 - accuracy: 0.7905 - val_loss: 0.4570 - val_accuracy: 0.8243\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4912 - accuracy: 0.8007 - val_loss: 0.4722 - val_accuracy: 0.8041\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5286 - accuracy: 0.7855 - val_loss: 0.4611 - val_accuracy: 0.8108\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5269 - accuracy: 0.8041 - val_loss: 0.4560 - val_accuracy: 0.8311\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5212 - accuracy: 0.7872 - val_loss: 0.4638 - val_accuracy: 0.8176\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.8041 - val_loss: 0.4701 - val_accuracy: 0.8108\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8041 - val_loss: 0.4593 - val_accuracy: 0.8311\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.8007 - val_loss: 0.4732 - val_accuracy: 0.8041\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7922 - val_loss: 0.4709 - val_accuracy: 0.8108\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7635 - val_loss: 0.4624 - val_accuracy: 0.7973\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.8209 - val_loss: 0.4571 - val_accuracy: 0.8243\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.8328 - val_loss: 0.4564 - val_accuracy: 0.8108\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7770 - val_loss: 0.4476 - val_accuracy: 0.8176\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5370 - accuracy: 0.7838 - val_loss: 0.4572 - val_accuracy: 0.8041\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.8108 - val_loss: 0.4486 - val_accuracy: 0.8176\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.7939 - val_loss: 0.4562 - val_accuracy: 0.8108\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7889 - val_loss: 0.4584 - val_accuracy: 0.8041\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7787 - val_loss: 0.4682 - val_accuracy: 0.8108\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.8091 - val_loss: 0.4668 - val_accuracy: 0.8041\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.8057 - val_loss: 0.4631 - val_accuracy: 0.8108\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5020 - accuracy: 0.8193 - val_loss: 0.4701 - val_accuracy: 0.8041\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.7956 - val_loss: 0.4669 - val_accuracy: 0.8243\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7855 - val_loss: 0.4743 - val_accuracy: 0.7973\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4965 - accuracy: 0.8243 - val_loss: 0.4815 - val_accuracy: 0.8108\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7703 - val_loss: 0.4829 - val_accuracy: 0.7973\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.8159 - val_loss: 0.4728 - val_accuracy: 0.8041\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7652 - val_loss: 0.4773 - val_accuracy: 0.8041\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8361 - val_loss: 0.4833 - val_accuracy: 0.8108\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5286 - accuracy: 0.7889 - val_loss: 0.4710 - val_accuracy: 0.8108\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5571 - accuracy: 0.7736 - val_loss: 0.4767 - val_accuracy: 0.7973\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.7905 - val_loss: 0.4777 - val_accuracy: 0.7838\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4927 - accuracy: 0.8091 - val_loss: 0.4675 - val_accuracy: 0.7838\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5292 - accuracy: 0.8041 - val_loss: 0.4718 - val_accuracy: 0.7838\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4988 - accuracy: 0.8193 - val_loss: 0.4893 - val_accuracy: 0.7838\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.7584 - val_loss: 0.4832 - val_accuracy: 0.8041\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5087 - accuracy: 0.7956 - val_loss: 0.4813 - val_accuracy: 0.8108\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5265 - accuracy: 0.7922 - val_loss: 0.4751 - val_accuracy: 0.8041\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.8378 - val_loss: 0.4746 - val_accuracy: 0.8041\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7922 - val_loss: 0.4770 - val_accuracy: 0.8108\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.8024 - val_loss: 0.4690 - val_accuracy: 0.8108\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.7838 - val_loss: 0.4717 - val_accuracy: 0.8108\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.8176 - val_loss: 0.4679 - val_accuracy: 0.8176\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.7990 - val_loss: 0.4605 - val_accuracy: 0.8176\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7922 - val_loss: 0.4719 - val_accuracy: 0.8108\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.8159 - val_loss: 0.4722 - val_accuracy: 0.8041\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7821 - val_loss: 0.4608 - val_accuracy: 0.8108\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.8193 - val_loss: 0.4624 - val_accuracy: 0.8108\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.8108 - val_loss: 0.4531 - val_accuracy: 0.8108\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7889 - val_loss: 0.4522 - val_accuracy: 0.8311\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.8108 - val_loss: 0.4458 - val_accuracy: 0.8243\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7736 - val_loss: 0.4608 - val_accuracy: 0.8176\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.8108 - val_loss: 0.4635 - val_accuracy: 0.8041\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.8328 - val_loss: 0.4499 - val_accuracy: 0.8243\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.8142 - val_loss: 0.4489 - val_accuracy: 0.8243\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8361 - val_loss: 0.4662 - val_accuracy: 0.8041\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.8007 - val_loss: 0.4758 - val_accuracy: 0.8041\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.8176 - val_loss: 0.4672 - val_accuracy: 0.8176\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7990 - val_loss: 0.4627 - val_accuracy: 0.8108\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.8074 - val_loss: 0.4589 - val_accuracy: 0.8108\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7939 - val_loss: 0.4530 - val_accuracy: 0.8176\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4859 - accuracy: 0.7990 - val_loss: 0.4650 - val_accuracy: 0.8108\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5253 - accuracy: 0.8041 - val_loss: 0.4651 - val_accuracy: 0.8176\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5356 - accuracy: 0.7905 - val_loss: 0.4827 - val_accuracy: 0.8176\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4849 - accuracy: 0.8142 - val_loss: 0.4782 - val_accuracy: 0.8108\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4733 - accuracy: 0.8328 - val_loss: 0.4745 - val_accuracy: 0.8108\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5090 - accuracy: 0.7956 - val_loss: 0.4700 - val_accuracy: 0.8041\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5449 - accuracy: 0.7821 - val_loss: 0.4676 - val_accuracy: 0.7973\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5239 - accuracy: 0.8108 - val_loss: 0.4678 - val_accuracy: 0.7973\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5464 - accuracy: 0.8057 - val_loss: 0.4693 - val_accuracy: 0.7973\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7905 - val_loss: 0.4703 - val_accuracy: 0.8041\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7939 - val_loss: 0.4703 - val_accuracy: 0.7973\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.7855 - val_loss: 0.4730 - val_accuracy: 0.7838\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7973 - val_loss: 0.4683 - val_accuracy: 0.7838\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.8125 - val_loss: 0.4648 - val_accuracy: 0.7905\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.8142 - val_loss: 0.4611 - val_accuracy: 0.7973\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.8142 - val_loss: 0.4552 - val_accuracy: 0.8108\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7922 - val_loss: 0.4887 - val_accuracy: 0.8041\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.8007 - val_loss: 0.4767 - val_accuracy: 0.7905\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7990 - val_loss: 0.4745 - val_accuracy: 0.7973\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7956 - val_loss: 0.4654 - val_accuracy: 0.8108\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.8057 - val_loss: 0.4718 - val_accuracy: 0.8041\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7973 - val_loss: 0.4786 - val_accuracy: 0.7973\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7872 - val_loss: 0.4623 - val_accuracy: 0.8108\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.8108 - val_loss: 0.4588 - val_accuracy: 0.8108\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7889 - val_loss: 0.4722 - val_accuracy: 0.7973\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.8024 - val_loss: 0.4643 - val_accuracy: 0.7973\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5255 - accuracy: 0.8074 - val_loss: 0.4660 - val_accuracy: 0.8108\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5023 - accuracy: 0.8159 - val_loss: 0.4491 - val_accuracy: 0.8176\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.8209 - val_loss: 0.4502 - val_accuracy: 0.8243\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.8260 - val_loss: 0.4512 - val_accuracy: 0.8176\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.8074 - val_loss: 0.4659 - val_accuracy: 0.8108\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5109 - accuracy: 0.8074 - val_loss: 0.4654 - val_accuracy: 0.8041\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4991 - accuracy: 0.8108 - val_loss: 0.4623 - val_accuracy: 0.8041\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4827 - accuracy: 0.8007 - val_loss: 0.4628 - val_accuracy: 0.8041\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4812 - accuracy: 0.8125 - val_loss: 0.4543 - val_accuracy: 0.8108\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5006 - accuracy: 0.7922 - val_loss: 0.4611 - val_accuracy: 0.8176\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5368 - accuracy: 0.8159 - val_loss: 0.4671 - val_accuracy: 0.7973\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4898 - accuracy: 0.7973 - val_loss: 0.4861 - val_accuracy: 0.8176\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5306 - accuracy: 0.8125 - val_loss: 0.4637 - val_accuracy: 0.8041\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5091 - accuracy: 0.8007 - val_loss: 0.4668 - val_accuracy: 0.8108\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.7838 - val_loss: 0.4830 - val_accuracy: 0.7973\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4807 - accuracy: 0.8074 - val_loss: 0.4820 - val_accuracy: 0.7905\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7821 - val_loss: 0.4792 - val_accuracy: 0.7905\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5193 - accuracy: 0.8074 - val_loss: 0.4692 - val_accuracy: 0.8108\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7889 - val_loss: 0.4690 - val_accuracy: 0.8041\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.8108 - val_loss: 0.4673 - val_accuracy: 0.7838\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7973 - val_loss: 0.4855 - val_accuracy: 0.7770\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.8277 - val_loss: 0.4696 - val_accuracy: 0.8041\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.8108 - val_loss: 0.4675 - val_accuracy: 0.7973\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.8074 - val_loss: 0.4650 - val_accuracy: 0.7905\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5436 - accuracy: 0.7838 - val_loss: 0.4721 - val_accuracy: 0.8041\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5082 - accuracy: 0.8209 - val_loss: 0.4739 - val_accuracy: 0.8108\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.8142 - val_loss: 0.4643 - val_accuracy: 0.8041\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5027 - accuracy: 0.8142 - val_loss: 0.4584 - val_accuracy: 0.8041\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4981 - accuracy: 0.8176 - val_loss: 0.4612 - val_accuracy: 0.7905\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.8497 - val_loss: 0.4715 - val_accuracy: 0.8041\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.8108 - val_loss: 0.4760 - val_accuracy: 0.8041\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.8176 - val_loss: 0.4885 - val_accuracy: 0.7905\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.8243 - val_loss: 0.4797 - val_accuracy: 0.8041\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.8243 - val_loss: 0.4660 - val_accuracy: 0.8176\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.8007 - val_loss: 0.4853 - val_accuracy: 0.8108\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.8260 - val_loss: 0.4959 - val_accuracy: 0.7973\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.8243 - val_loss: 0.4789 - val_accuracy: 0.8041\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4911 - accuracy: 0.8260 - val_loss: 0.4753 - val_accuracy: 0.7905\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5379 - accuracy: 0.7905 - val_loss: 0.4771 - val_accuracy: 0.7973\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5151 - accuracy: 0.8041 - val_loss: 0.4726 - val_accuracy: 0.8041\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5161 - accuracy: 0.7770 - val_loss: 0.4633 - val_accuracy: 0.8041\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7922 - val_loss: 0.4576 - val_accuracy: 0.8108\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4984 - accuracy: 0.8125 - val_loss: 0.4573 - val_accuracy: 0.8176\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5104 - accuracy: 0.7872 - val_loss: 0.4550 - val_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5319 - accuracy: 0.8024 - val_loss: 0.4561 - val_accuracy: 0.8176\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5354 - accuracy: 0.7669 - val_loss: 0.4691 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4860 - accuracy: 0.8125 - val_loss: 0.4752 - val_accuracy: 0.8041\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7922 - val_loss: 0.4673 - val_accuracy: 0.8176\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7939 - val_loss: 0.4710 - val_accuracy: 0.8243\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.8176 - val_loss: 0.4842 - val_accuracy: 0.8041\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7889 - val_loss: 0.4675 - val_accuracy: 0.8041\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.8007 - val_loss: 0.4644 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.8311 - val_loss: 0.4704 - val_accuracy: 0.8108\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.8007 - val_loss: 0.4615 - val_accuracy: 0.8176\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7973 - val_loss: 0.4546 - val_accuracy: 0.8243\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.8057 - val_loss: 0.4680 - val_accuracy: 0.8311\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.8311 - val_loss: 0.4734 - val_accuracy: 0.8108\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.8277 - val_loss: 0.4850 - val_accuracy: 0.8041\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8260 - val_loss: 0.4783 - val_accuracy: 0.7973\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5243 - accuracy: 0.7838 - val_loss: 0.4751 - val_accuracy: 0.8108\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.8024 - val_loss: 0.4881 - val_accuracy: 0.8041\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7922 - val_loss: 0.4911 - val_accuracy: 0.8176\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.8125 - val_loss: 0.4967 - val_accuracy: 0.8108\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.8159 - val_loss: 0.5045 - val_accuracy: 0.8041\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7990 - val_loss: 0.4929 - val_accuracy: 0.7973\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7990 - val_loss: 0.4843 - val_accuracy: 0.8041\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.8041 - val_loss: 0.4803 - val_accuracy: 0.8041\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.8226 - val_loss: 0.4903 - val_accuracy: 0.7838\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7905 - val_loss: 0.4735 - val_accuracy: 0.8041\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7956 - val_loss: 0.4750 - val_accuracy: 0.8108\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5206 - accuracy: 0.8176 - val_loss: 0.4778 - val_accuracy: 0.8041\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5486 - accuracy: 0.8057 - val_loss: 0.4803 - val_accuracy: 0.8041\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.7905 - val_loss: 0.4768 - val_accuracy: 0.7973\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5067 - accuracy: 0.8091 - val_loss: 0.4854 - val_accuracy: 0.7838\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5207 - accuracy: 0.8125 - val_loss: 0.4704 - val_accuracy: 0.8243\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5260 - accuracy: 0.7990 - val_loss: 0.4753 - val_accuracy: 0.8176\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4981 - accuracy: 0.8226 - val_loss: 0.4701 - val_accuracy: 0.7973\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.8057 - val_loss: 0.4721 - val_accuracy: 0.7905\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5111 - accuracy: 0.8108 - val_loss: 0.4656 - val_accuracy: 0.8176\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.7872 - val_loss: 0.4839 - val_accuracy: 0.7838\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.8091 - val_loss: 0.4730 - val_accuracy: 0.7770\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.7770 - val_loss: 0.4758 - val_accuracy: 0.7905\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.8176 - val_loss: 0.4721 - val_accuracy: 0.7905\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7922 - val_loss: 0.4666 - val_accuracy: 0.8041\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.8108 - val_loss: 0.4814 - val_accuracy: 0.7973\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.8108 - val_loss: 0.4779 - val_accuracy: 0.8108\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.8074 - val_loss: 0.4710 - val_accuracy: 0.8108\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.8074 - val_loss: 0.4735 - val_accuracy: 0.8108\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.8142 - val_loss: 0.4746 - val_accuracy: 0.8243\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.8057 - val_loss: 0.4800 - val_accuracy: 0.7973\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.8041 - val_loss: 0.4856 - val_accuracy: 0.8176\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8091 - val_loss: 0.4902 - val_accuracy: 0.7905\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.8159 - val_loss: 0.4808 - val_accuracy: 0.8108\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4982 - accuracy: 0.7889 - val_loss: 0.4784 - val_accuracy: 0.7838\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4778 - accuracy: 0.8209 - val_loss: 0.4707 - val_accuracy: 0.7905\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7905 - val_loss: 0.4955 - val_accuracy: 0.7838\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7956 - val_loss: 0.4872 - val_accuracy: 0.7838\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5085 - accuracy: 0.7922 - val_loss: 0.4838 - val_accuracy: 0.7973\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.8142 - val_loss: 0.4790 - val_accuracy: 0.7973\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.8041 - val_loss: 0.4937 - val_accuracy: 0.7973\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7855 - val_loss: 0.4942 - val_accuracy: 0.7973\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7821 - val_loss: 0.4937 - val_accuracy: 0.7905\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.8142 - val_loss: 0.4937 - val_accuracy: 0.7973\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7956 - val_loss: 0.4925 - val_accuracy: 0.8041\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5187 - accuracy: 0.7973 - val_loss: 0.4863 - val_accuracy: 0.8176\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4936 - accuracy: 0.8260 - val_loss: 0.4934 - val_accuracy: 0.8041\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4885 - accuracy: 0.8142 - val_loss: 0.4896 - val_accuracy: 0.8041\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4759 - accuracy: 0.8091 - val_loss: 0.4903 - val_accuracy: 0.7905\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4955 - accuracy: 0.7872 - val_loss: 0.5079 - val_accuracy: 0.7770\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5020 - accuracy: 0.8041 - val_loss: 0.4858 - val_accuracy: 0.8108\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8159 - val_loss: 0.4849 - val_accuracy: 0.8041\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.8159 - val_loss: 0.4774 - val_accuracy: 0.7905\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4584 - accuracy: 0.8209 - val_loss: 0.4821 - val_accuracy: 0.7770\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.8176 - val_loss: 0.4758 - val_accuracy: 0.7770\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.8024 - val_loss: 0.4752 - val_accuracy: 0.8041\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.8193 - val_loss: 0.4792 - val_accuracy: 0.7838\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7939 - val_loss: 0.4753 - val_accuracy: 0.8108\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.8091 - val_loss: 0.4877 - val_accuracy: 0.7973\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7990 - val_loss: 0.4917 - val_accuracy: 0.7905\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.8395 - val_loss: 0.4938 - val_accuracy: 0.7905\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.8142 - val_loss: 0.4760 - val_accuracy: 0.7973\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.8193 - val_loss: 0.4771 - val_accuracy: 0.8041\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.8074 - val_loss: 0.4757 - val_accuracy: 0.7973\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7889 - val_loss: 0.4699 - val_accuracy: 0.7973\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7973 - val_loss: 0.4821 - val_accuracy: 0.8041\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7821 - val_loss: 0.4806 - val_accuracy: 0.8041\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.8074 - val_loss: 0.4882 - val_accuracy: 0.7838\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.8446 - val_loss: 0.4979 - val_accuracy: 0.7635\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.8311 - val_loss: 0.4813 - val_accuracy: 0.7770\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8125 - val_loss: 0.4809 - val_accuracy: 0.8041\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.8159 - val_loss: 0.4709 - val_accuracy: 0.7838\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.7855 - val_loss: 0.4729 - val_accuracy: 0.7905\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5057 - accuracy: 0.8277 - val_loss: 0.4757 - val_accuracy: 0.7905\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.8091 - val_loss: 0.4704 - val_accuracy: 0.8108\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8260 - val_loss: 0.4579 - val_accuracy: 0.8243\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4644 - accuracy: 0.8226 - val_loss: 0.4612 - val_accuracy: 0.8176\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4630 - accuracy: 0.8176 - val_loss: 0.4582 - val_accuracy: 0.8108\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4827 - accuracy: 0.8125 - val_loss: 0.4578 - val_accuracy: 0.7905\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4979 - accuracy: 0.8226 - val_loss: 0.4539 - val_accuracy: 0.7973\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5104 - accuracy: 0.8378 - val_loss: 0.4617 - val_accuracy: 0.7905\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5023 - accuracy: 0.7956 - val_loss: 0.4544 - val_accuracy: 0.8041\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.8260 - val_loss: 0.4584 - val_accuracy: 0.8041\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4828 - accuracy: 0.8142 - val_loss: 0.4618 - val_accuracy: 0.8176\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.8176 - val_loss: 0.4594 - val_accuracy: 0.8041\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4749 - accuracy: 0.7939 - val_loss: 0.4652 - val_accuracy: 0.8176\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4752 - accuracy: 0.8260 - val_loss: 0.4630 - val_accuracy: 0.8108\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.8074 - val_loss: 0.4737 - val_accuracy: 0.7973\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.8024 - val_loss: 0.4687 - val_accuracy: 0.7973\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.8328 - val_loss: 0.4637 - val_accuracy: 0.7973\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.8074 - val_loss: 0.4697 - val_accuracy: 0.8108\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.8108 - val_loss: 0.4800 - val_accuracy: 0.7905\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.8311 - val_loss: 0.4741 - val_accuracy: 0.8041\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.8243 - val_loss: 0.4656 - val_accuracy: 0.8108\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8243 - val_loss: 0.4715 - val_accuracy: 0.8041\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.8041\n",
            "5/5 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c605e467ca37>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 10ms/step - loss: 1.4303 - accuracy: 0.5051 - val_loss: 1.1403 - val_accuracy: 0.4527\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3267 - accuracy: 0.5152 - val_loss: 1.1263 - val_accuracy: 0.4730\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.2921 - accuracy: 0.4949 - val_loss: 1.1040 - val_accuracy: 0.5000\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.1725 - accuracy: 0.5236 - val_loss: 1.0919 - val_accuracy: 0.5203\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1749 - accuracy: 0.5169 - val_loss: 1.0788 - val_accuracy: 0.5405\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1780 - accuracy: 0.5236 - val_loss: 1.0645 - val_accuracy: 0.5676\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0945 - accuracy: 0.5084 - val_loss: 1.0517 - val_accuracy: 0.5541\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0901 - accuracy: 0.5000 - val_loss: 1.0381 - val_accuracy: 0.5946\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0507 - accuracy: 0.5270 - val_loss: 1.0257 - val_accuracy: 0.5541\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0384 - accuracy: 0.4983 - val_loss: 1.0131 - val_accuracy: 0.5405\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.9983 - accuracy: 0.5439 - val_loss: 0.9985 - val_accuracy: 0.5405\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9870 - accuracy: 0.5895 - val_loss: 0.9820 - val_accuracy: 0.5541\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.9950 - accuracy: 0.4780 - val_loss: 0.9684 - val_accuracy: 0.5541\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9699 - accuracy: 0.5186 - val_loss: 0.9574 - val_accuracy: 0.5068\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9582 - accuracy: 0.4916 - val_loss: 0.9447 - val_accuracy: 0.4797\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9426 - accuracy: 0.5220 - val_loss: 0.9308 - val_accuracy: 0.4730\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9277 - accuracy: 0.5287 - val_loss: 0.9170 - val_accuracy: 0.5068\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9068 - accuracy: 0.5490 - val_loss: 0.9042 - val_accuracy: 0.5000\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8929 - accuracy: 0.5456 - val_loss: 0.8908 - val_accuracy: 0.5068\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8867 - accuracy: 0.5726 - val_loss: 0.8774 - val_accuracy: 0.5000\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8682 - accuracy: 0.5507 - val_loss: 0.8645 - val_accuracy: 0.5473\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8607 - accuracy: 0.5608 - val_loss: 0.8509 - val_accuracy: 0.5878\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8528 - accuracy: 0.5659 - val_loss: 0.8410 - val_accuracy: 0.5541\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8379 - accuracy: 0.5743 - val_loss: 0.8320 - val_accuracy: 0.5405\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.5777 - val_loss: 0.8215 - val_accuracy: 0.5608\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8252 - accuracy: 0.5811 - val_loss: 0.8148 - val_accuracy: 0.5338\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8016 - accuracy: 0.6098 - val_loss: 0.8036 - val_accuracy: 0.5338\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8057 - accuracy: 0.6014 - val_loss: 0.7814 - val_accuracy: 0.6014\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7979 - accuracy: 0.5861 - val_loss: 0.7697 - val_accuracy: 0.6216\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.6098 - val_loss: 0.7532 - val_accuracy: 0.6419\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7515 - accuracy: 0.6486 - val_loss: 0.7340 - val_accuracy: 0.6351\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7668 - accuracy: 0.6233 - val_loss: 0.7041 - val_accuracy: 0.6824\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7624 - accuracy: 0.6115 - val_loss: 0.6934 - val_accuracy: 0.7027\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.6385 - val_loss: 0.6827 - val_accuracy: 0.6892\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7369 - accuracy: 0.6520 - val_loss: 0.6843 - val_accuracy: 0.6689\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7259 - accuracy: 0.6537 - val_loss: 0.6636 - val_accuracy: 0.7095\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7158 - accuracy: 0.6605 - val_loss: 0.6564 - val_accuracy: 0.7162\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.6943 - val_loss: 0.6484 - val_accuracy: 0.7095\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7220 - accuracy: 0.6503 - val_loss: 0.6477 - val_accuracy: 0.6959\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7081 - accuracy: 0.6791 - val_loss: 0.6404 - val_accuracy: 0.7095\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.7078 - val_loss: 0.6199 - val_accuracy: 0.7365\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7015 - accuracy: 0.6723 - val_loss: 0.6178 - val_accuracy: 0.7635\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7063 - accuracy: 0.6453 - val_loss: 0.6146 - val_accuracy: 0.7568\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6886 - accuracy: 0.6605 - val_loss: 0.6234 - val_accuracy: 0.7365\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6956 - accuracy: 0.6926 - val_loss: 0.6153 - val_accuracy: 0.7500\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6749 - accuracy: 0.6943 - val_loss: 0.6090 - val_accuracy: 0.7703\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6670 - accuracy: 0.6774 - val_loss: 0.5861 - val_accuracy: 0.7703\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6549 - accuracy: 0.6824 - val_loss: 0.5784 - val_accuracy: 0.7568\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6850 - accuracy: 0.6875 - val_loss: 0.5672 - val_accuracy: 0.7838\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.7196 - val_loss: 0.5605 - val_accuracy: 0.7838\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.6791 - val_loss: 0.5702 - val_accuracy: 0.7905\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6612 - accuracy: 0.7078 - val_loss: 0.5727 - val_accuracy: 0.7770\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.7230 - val_loss: 0.5490 - val_accuracy: 0.8041\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6445 - accuracy: 0.7264 - val_loss: 0.5444 - val_accuracy: 0.8108\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.7162 - val_loss: 0.5634 - val_accuracy: 0.7905\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6266 - accuracy: 0.7179 - val_loss: 0.5566 - val_accuracy: 0.7703\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.7061 - val_loss: 0.5431 - val_accuracy: 0.8243\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.7365 - val_loss: 0.5372 - val_accuracy: 0.8311\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.7010 - val_loss: 0.5515 - val_accuracy: 0.7838\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.7280 - val_loss: 0.5271 - val_accuracy: 0.8243\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.7145 - val_loss: 0.5114 - val_accuracy: 0.8378\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.7247 - val_loss: 0.5208 - val_accuracy: 0.8514\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6105 - accuracy: 0.7264 - val_loss: 0.5322 - val_accuracy: 0.8041\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.7179 - val_loss: 0.5232 - val_accuracy: 0.8176\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6029 - accuracy: 0.7331 - val_loss: 0.5107 - val_accuracy: 0.8446\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.7500 - val_loss: 0.5084 - val_accuracy: 0.8446\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6158 - accuracy: 0.7314 - val_loss: 0.5075 - val_accuracy: 0.8243\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.7196 - val_loss: 0.5119 - val_accuracy: 0.8176\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6103 - accuracy: 0.7196 - val_loss: 0.5123 - val_accuracy: 0.8176\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6008 - accuracy: 0.7365 - val_loss: 0.5018 - val_accuracy: 0.8243\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6017 - accuracy: 0.7483 - val_loss: 0.5119 - val_accuracy: 0.8243\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.7517 - val_loss: 0.5119 - val_accuracy: 0.8243\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6127 - accuracy: 0.7264 - val_loss: 0.5073 - val_accuracy: 0.8311\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6253 - accuracy: 0.7483 - val_loss: 0.5144 - val_accuracy: 0.8176\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6269 - accuracy: 0.7196 - val_loss: 0.5178 - val_accuracy: 0.8108\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6123 - accuracy: 0.7416 - val_loss: 0.5108 - val_accuracy: 0.8108\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6125 - accuracy: 0.7314 - val_loss: 0.5048 - val_accuracy: 0.8176\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6279 - accuracy: 0.7280 - val_loss: 0.5051 - val_accuracy: 0.8176\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6048 - accuracy: 0.7399 - val_loss: 0.4976 - val_accuracy: 0.8243\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6173 - accuracy: 0.7280 - val_loss: 0.4913 - val_accuracy: 0.8243\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5939 - accuracy: 0.7534 - val_loss: 0.5018 - val_accuracy: 0.8108\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.7787 - val_loss: 0.4889 - val_accuracy: 0.8176\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.7635 - val_loss: 0.4863 - val_accuracy: 0.8108\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.7635 - val_loss: 0.5014 - val_accuracy: 0.7838\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.7500 - val_loss: 0.4963 - val_accuracy: 0.7838\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.7618 - val_loss: 0.4995 - val_accuracy: 0.7770\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.7247 - val_loss: 0.4861 - val_accuracy: 0.7838\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.7230 - val_loss: 0.5101 - val_accuracy: 0.7770\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5999 - accuracy: 0.7618 - val_loss: 0.4865 - val_accuracy: 0.7905\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5699 - accuracy: 0.7618 - val_loss: 0.4918 - val_accuracy: 0.7838\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5624 - accuracy: 0.7720 - val_loss: 0.4870 - val_accuracy: 0.7905\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.7652 - val_loss: 0.4803 - val_accuracy: 0.8041\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7618 - val_loss: 0.4801 - val_accuracy: 0.8041\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7416 - val_loss: 0.4769 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5827 - accuracy: 0.7466 - val_loss: 0.4716 - val_accuracy: 0.8311\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.7517 - val_loss: 0.4699 - val_accuracy: 0.8446\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6179 - accuracy: 0.7432 - val_loss: 0.4796 - val_accuracy: 0.8311\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5838 - accuracy: 0.7736 - val_loss: 0.4675 - val_accuracy: 0.8514\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.7551 - val_loss: 0.4704 - val_accuracy: 0.8581\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5968 - accuracy: 0.7584 - val_loss: 0.4613 - val_accuracy: 0.8514\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5813 - accuracy: 0.7618 - val_loss: 0.4593 - val_accuracy: 0.8446\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.7584 - val_loss: 0.4627 - val_accuracy: 0.8311\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7804 - val_loss: 0.4530 - val_accuracy: 0.8514\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7584 - val_loss: 0.4476 - val_accuracy: 0.8514\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6023 - accuracy: 0.7534 - val_loss: 0.4590 - val_accuracy: 0.8446\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5886 - accuracy: 0.7483 - val_loss: 0.4688 - val_accuracy: 0.8378\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5554 - accuracy: 0.7652 - val_loss: 0.4484 - val_accuracy: 0.8649\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5856 - accuracy: 0.7517 - val_loss: 0.4367 - val_accuracy: 0.8514\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5268 - accuracy: 0.7855 - val_loss: 0.4412 - val_accuracy: 0.8378\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5643 - accuracy: 0.7821 - val_loss: 0.4445 - val_accuracy: 0.8378\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5774 - accuracy: 0.7500 - val_loss: 0.4413 - val_accuracy: 0.8581\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5574 - accuracy: 0.7686 - val_loss: 0.4406 - val_accuracy: 0.8446\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5358 - accuracy: 0.7973 - val_loss: 0.4268 - val_accuracy: 0.8649\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5736 - accuracy: 0.7517 - val_loss: 0.4411 - val_accuracy: 0.8378\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.7551 - val_loss: 0.4269 - val_accuracy: 0.8716\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.7382 - val_loss: 0.4392 - val_accuracy: 0.8784\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7635 - val_loss: 0.4389 - val_accuracy: 0.8716\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5635 - accuracy: 0.7804 - val_loss: 0.4432 - val_accuracy: 0.8378\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7736 - val_loss: 0.4254 - val_accuracy: 0.8581\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5596 - accuracy: 0.7635 - val_loss: 0.4262 - val_accuracy: 0.8446\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.7753 - val_loss: 0.4170 - val_accuracy: 0.8581\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.7669 - val_loss: 0.4145 - val_accuracy: 0.8716\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.7483 - val_loss: 0.4439 - val_accuracy: 0.8378\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7720 - val_loss: 0.4327 - val_accuracy: 0.8581\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.7787 - val_loss: 0.4409 - val_accuracy: 0.8378\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.7787 - val_loss: 0.4317 - val_accuracy: 0.8851\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5739 - accuracy: 0.7618 - val_loss: 0.4386 - val_accuracy: 0.8716\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7939 - val_loss: 0.4205 - val_accuracy: 0.8581\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7872 - val_loss: 0.4229 - val_accuracy: 0.8716\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.7770 - val_loss: 0.4312 - val_accuracy: 0.8514\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7635 - val_loss: 0.4142 - val_accuracy: 0.8514\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.7601 - val_loss: 0.4290 - val_accuracy: 0.8649\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7483 - val_loss: 0.4374 - val_accuracy: 0.8311\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7720 - val_loss: 0.4189 - val_accuracy: 0.8446\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5634 - accuracy: 0.7770 - val_loss: 0.4297 - val_accuracy: 0.8716\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5662 - accuracy: 0.7753 - val_loss: 0.4422 - val_accuracy: 0.8311\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5387 - accuracy: 0.7838 - val_loss: 0.4219 - val_accuracy: 0.8784\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5571 - accuracy: 0.7703 - val_loss: 0.4143 - val_accuracy: 0.8716\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5641 - accuracy: 0.7804 - val_loss: 0.4142 - val_accuracy: 0.8581\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5590 - accuracy: 0.7838 - val_loss: 0.4264 - val_accuracy: 0.8649\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5320 - accuracy: 0.8007 - val_loss: 0.4398 - val_accuracy: 0.8243\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5252 - accuracy: 0.7905 - val_loss: 0.4181 - val_accuracy: 0.8581\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5541 - accuracy: 0.7787 - val_loss: 0.4130 - val_accuracy: 0.8649\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7838 - val_loss: 0.4023 - val_accuracy: 0.8716\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5479 - accuracy: 0.7753 - val_loss: 0.4154 - val_accuracy: 0.8514\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5420 - accuracy: 0.7838 - val_loss: 0.4107 - val_accuracy: 0.8581\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7905 - val_loss: 0.4135 - val_accuracy: 0.8514\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5517 - accuracy: 0.7905 - val_loss: 0.4445 - val_accuracy: 0.8378\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7821 - val_loss: 0.4113 - val_accuracy: 0.8649\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5358 - accuracy: 0.7703 - val_loss: 0.4119 - val_accuracy: 0.8649\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5160 - accuracy: 0.8074 - val_loss: 0.4107 - val_accuracy: 0.8851\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5122 - accuracy: 0.7922 - val_loss: 0.4071 - val_accuracy: 0.8649\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7990 - val_loss: 0.4223 - val_accuracy: 0.8716\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7939 - val_loss: 0.4416 - val_accuracy: 0.8243\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7973 - val_loss: 0.4192 - val_accuracy: 0.8514\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7821 - val_loss: 0.4175 - val_accuracy: 0.8378\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7703 - val_loss: 0.4185 - val_accuracy: 0.8514\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.8108 - val_loss: 0.4185 - val_accuracy: 0.8649\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.8057 - val_loss: 0.4020 - val_accuracy: 0.8716\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5728 - accuracy: 0.7652 - val_loss: 0.4098 - val_accuracy: 0.8716\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7905 - val_loss: 0.4208 - val_accuracy: 0.8514\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7432 - val_loss: 0.4354 - val_accuracy: 0.8446\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7635 - val_loss: 0.4239 - val_accuracy: 0.8649\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5351 - accuracy: 0.7905 - val_loss: 0.4188 - val_accuracy: 0.8514\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5270 - accuracy: 0.7889 - val_loss: 0.4069 - val_accuracy: 0.8716\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.7872 - val_loss: 0.3804 - val_accuracy: 0.8919\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5770 - accuracy: 0.7736 - val_loss: 0.4057 - val_accuracy: 0.8784\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5459 - accuracy: 0.7770 - val_loss: 0.4053 - val_accuracy: 0.8851\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7956 - val_loss: 0.4019 - val_accuracy: 0.8716\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5442 - accuracy: 0.7905 - val_loss: 0.3901 - val_accuracy: 0.8784\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5548 - accuracy: 0.7956 - val_loss: 0.3934 - val_accuracy: 0.8784\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5496 - accuracy: 0.7686 - val_loss: 0.4242 - val_accuracy: 0.8649\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5229 - accuracy: 0.7922 - val_loss: 0.4117 - val_accuracy: 0.8649\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.8057 - val_loss: 0.4143 - val_accuracy: 0.8649\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.7973 - val_loss: 0.4195 - val_accuracy: 0.8649\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5609 - accuracy: 0.7652 - val_loss: 0.4154 - val_accuracy: 0.8649\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5506 - accuracy: 0.7534 - val_loss: 0.4333 - val_accuracy: 0.8446\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7973 - val_loss: 0.4132 - val_accuracy: 0.8514\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5678 - accuracy: 0.7534 - val_loss: 0.4144 - val_accuracy: 0.8716\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.7990 - val_loss: 0.4232 - val_accuracy: 0.8649\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7770 - val_loss: 0.4155 - val_accuracy: 0.8649\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5527 - accuracy: 0.7720 - val_loss: 0.4142 - val_accuracy: 0.8649\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5314 - accuracy: 0.7753 - val_loss: 0.4087 - val_accuracy: 0.8716\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7720 - val_loss: 0.4182 - val_accuracy: 0.8784\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.8057 - val_loss: 0.3947 - val_accuracy: 0.8716\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7736 - val_loss: 0.4043 - val_accuracy: 0.8716\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.7804 - val_loss: 0.4083 - val_accuracy: 0.8649\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7872 - val_loss: 0.4200 - val_accuracy: 0.8649\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7922 - val_loss: 0.4018 - val_accuracy: 0.8716\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5789 - accuracy: 0.7618 - val_loss: 0.4310 - val_accuracy: 0.8581\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7821 - val_loss: 0.4129 - val_accuracy: 0.8649\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7787 - val_loss: 0.4078 - val_accuracy: 0.8784\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7956 - val_loss: 0.4155 - val_accuracy: 0.8581\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7956 - val_loss: 0.4015 - val_accuracy: 0.8581\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4977 - accuracy: 0.8057 - val_loss: 0.4000 - val_accuracy: 0.8716\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.7821 - val_loss: 0.4036 - val_accuracy: 0.8649\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4971 - accuracy: 0.8294 - val_loss: 0.4019 - val_accuracy: 0.8716\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7905 - val_loss: 0.4009 - val_accuracy: 0.8581\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7855 - val_loss: 0.4057 - val_accuracy: 0.8581\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5260 - accuracy: 0.7956 - val_loss: 0.4077 - val_accuracy: 0.8446\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7922 - val_loss: 0.4040 - val_accuracy: 0.8514\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.7821 - val_loss: 0.4013 - val_accuracy: 0.8716\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5264 - accuracy: 0.7956 - val_loss: 0.4075 - val_accuracy: 0.8378\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7973 - val_loss: 0.4066 - val_accuracy: 0.8716\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7770 - val_loss: 0.4098 - val_accuracy: 0.8649\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5272 - accuracy: 0.8007 - val_loss: 0.4192 - val_accuracy: 0.8514\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5186 - accuracy: 0.7770 - val_loss: 0.4149 - val_accuracy: 0.8446\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5226 - accuracy: 0.7905 - val_loss: 0.3952 - val_accuracy: 0.8649\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5169 - accuracy: 0.8024 - val_loss: 0.3964 - val_accuracy: 0.8716\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5533 - accuracy: 0.7939 - val_loss: 0.4012 - val_accuracy: 0.8649\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.8024 - val_loss: 0.3944 - val_accuracy: 0.8784\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7973 - val_loss: 0.3843 - val_accuracy: 0.8716\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7922 - val_loss: 0.3949 - val_accuracy: 0.8649\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7787 - val_loss: 0.3999 - val_accuracy: 0.8649\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5045 - accuracy: 0.8057 - val_loss: 0.4008 - val_accuracy: 0.8716\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5239 - accuracy: 0.7804 - val_loss: 0.3948 - val_accuracy: 0.8649\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5427 - accuracy: 0.7736 - val_loss: 0.3863 - val_accuracy: 0.8514\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5665 - accuracy: 0.7787 - val_loss: 0.3945 - val_accuracy: 0.8716\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.7889 - val_loss: 0.3940 - val_accuracy: 0.8716\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.8074 - val_loss: 0.3886 - val_accuracy: 0.8514\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7855 - val_loss: 0.3951 - val_accuracy: 0.8716\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7804 - val_loss: 0.4028 - val_accuracy: 0.8446\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5053 - accuracy: 0.7956 - val_loss: 0.3986 - val_accuracy: 0.8514\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.8024 - val_loss: 0.3981 - val_accuracy: 0.8649\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.8074 - val_loss: 0.4064 - val_accuracy: 0.8581\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5336 - accuracy: 0.7838 - val_loss: 0.3972 - val_accuracy: 0.8581\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.8024 - val_loss: 0.3851 - val_accuracy: 0.8581\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7855 - val_loss: 0.3914 - val_accuracy: 0.8649\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8074 - val_loss: 0.4000 - val_accuracy: 0.8446\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5495 - accuracy: 0.8108 - val_loss: 0.3983 - val_accuracy: 0.8378\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.8007 - val_loss: 0.3955 - val_accuracy: 0.8514\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4994 - accuracy: 0.7922 - val_loss: 0.3883 - val_accuracy: 0.8514\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7703 - val_loss: 0.3881 - val_accuracy: 0.8581\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7939 - val_loss: 0.3883 - val_accuracy: 0.8649\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.8125 - val_loss: 0.3766 - val_accuracy: 0.8649\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5601 - accuracy: 0.7770 - val_loss: 0.3966 - val_accuracy: 0.8446\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5256 - accuracy: 0.7990 - val_loss: 0.4063 - val_accuracy: 0.8581\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4769 - accuracy: 0.8024 - val_loss: 0.3910 - val_accuracy: 0.8649\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5236 - accuracy: 0.7736 - val_loss: 0.3917 - val_accuracy: 0.8378\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5099 - accuracy: 0.7905 - val_loss: 0.3906 - val_accuracy: 0.8446\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5119 - accuracy: 0.7838 - val_loss: 0.3986 - val_accuracy: 0.8446\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5038 - accuracy: 0.8125 - val_loss: 0.3997 - val_accuracy: 0.8514\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.8176 - val_loss: 0.3956 - val_accuracy: 0.8514\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7939 - val_loss: 0.3855 - val_accuracy: 0.8581\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.7736 - val_loss: 0.3954 - val_accuracy: 0.8784\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7770 - val_loss: 0.4037 - val_accuracy: 0.8716\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7804 - val_loss: 0.3862 - val_accuracy: 0.8581\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.7601 - val_loss: 0.4033 - val_accuracy: 0.8514\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5501 - accuracy: 0.7905 - val_loss: 0.4012 - val_accuracy: 0.8716\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7939 - val_loss: 0.4005 - val_accuracy: 0.8716\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7770 - val_loss: 0.3888 - val_accuracy: 0.8649\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8277 - val_loss: 0.3831 - val_accuracy: 0.8919\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8024 - val_loss: 0.3853 - val_accuracy: 0.8649\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.8159 - val_loss: 0.3742 - val_accuracy: 0.8716\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5475 - accuracy: 0.7939 - val_loss: 0.3813 - val_accuracy: 0.8514\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5852 - accuracy: 0.7652 - val_loss: 0.4059 - val_accuracy: 0.8514\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7855 - val_loss: 0.3968 - val_accuracy: 0.8581\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5683 - accuracy: 0.7584 - val_loss: 0.4048 - val_accuracy: 0.8581\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.8108 - val_loss: 0.4009 - val_accuracy: 0.8581\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.8226 - val_loss: 0.3853 - val_accuracy: 0.8716\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.8041 - val_loss: 0.3880 - val_accuracy: 0.8649\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7838 - val_loss: 0.3863 - val_accuracy: 0.8649\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7905 - val_loss: 0.3808 - val_accuracy: 0.8716\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.8041 - val_loss: 0.3771 - val_accuracy: 0.8716\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5241 - accuracy: 0.7855 - val_loss: 0.3869 - val_accuracy: 0.8784\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7872 - val_loss: 0.3809 - val_accuracy: 0.8716\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5017 - accuracy: 0.7973 - val_loss: 0.3795 - val_accuracy: 0.8851\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7956 - val_loss: 0.3914 - val_accuracy: 0.8784\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4847 - accuracy: 0.8007 - val_loss: 0.3860 - val_accuracy: 0.8649\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5478 - accuracy: 0.7821 - val_loss: 0.3943 - val_accuracy: 0.8784\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.7956 - val_loss: 0.3886 - val_accuracy: 0.8716\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5059 - accuracy: 0.8041 - val_loss: 0.3950 - val_accuracy: 0.8649\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.8193 - val_loss: 0.3928 - val_accuracy: 0.8581\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5743 - accuracy: 0.7956 - val_loss: 0.4123 - val_accuracy: 0.8784\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5170 - accuracy: 0.7973 - val_loss: 0.3908 - val_accuracy: 0.8649\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4932 - accuracy: 0.8074 - val_loss: 0.3866 - val_accuracy: 0.8649\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5115 - accuracy: 0.8041 - val_loss: 0.3872 - val_accuracy: 0.8716\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7973 - val_loss: 0.3913 - val_accuracy: 0.8716\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.8074 - val_loss: 0.3883 - val_accuracy: 0.8784\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5185 - accuracy: 0.8159 - val_loss: 0.3972 - val_accuracy: 0.8784\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7872 - val_loss: 0.3996 - val_accuracy: 0.8716\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5612 - accuracy: 0.7838 - val_loss: 0.3904 - val_accuracy: 0.8716\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7905 - val_loss: 0.3951 - val_accuracy: 0.8784\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.8108 - val_loss: 0.3995 - val_accuracy: 0.8784\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.7787 - val_loss: 0.3893 - val_accuracy: 0.8649\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.7990 - val_loss: 0.3884 - val_accuracy: 0.8649\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7855 - val_loss: 0.3869 - val_accuracy: 0.8716\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5768 - accuracy: 0.7804 - val_loss: 0.3978 - val_accuracy: 0.8716\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.8142 - val_loss: 0.3924 - val_accuracy: 0.8581\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.8159 - val_loss: 0.3874 - val_accuracy: 0.8649\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7889 - val_loss: 0.3894 - val_accuracy: 0.8581\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5313 - accuracy: 0.7872 - val_loss: 0.3764 - val_accuracy: 0.8784\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7922 - val_loss: 0.3787 - val_accuracy: 0.8716\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7956 - val_loss: 0.3676 - val_accuracy: 0.8851\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7922 - val_loss: 0.3882 - val_accuracy: 0.8446\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.8108 - val_loss: 0.3743 - val_accuracy: 0.8649\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.8159 - val_loss: 0.3724 - val_accuracy: 0.8649\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.7990 - val_loss: 0.3917 - val_accuracy: 0.8581\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7905 - val_loss: 0.3951 - val_accuracy: 0.8581\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7922 - val_loss: 0.3855 - val_accuracy: 0.8649\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.8159 - val_loss: 0.3847 - val_accuracy: 0.8649\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4682 - accuracy: 0.8209 - val_loss: 0.3889 - val_accuracy: 0.8649\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5163 - accuracy: 0.7990 - val_loss: 0.3840 - val_accuracy: 0.8581\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.7872 - val_loss: 0.3810 - val_accuracy: 0.8716\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4921 - accuracy: 0.8159 - val_loss: 0.3756 - val_accuracy: 0.8581\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4942 - accuracy: 0.8159 - val_loss: 0.3767 - val_accuracy: 0.8649\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.8125 - val_loss: 0.3761 - val_accuracy: 0.8716\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4818 - accuracy: 0.8125 - val_loss: 0.3820 - val_accuracy: 0.8581\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7889 - val_loss: 0.3802 - val_accuracy: 0.8649\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5105 - accuracy: 0.8057 - val_loss: 0.3691 - val_accuracy: 0.8649\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7956 - val_loss: 0.3824 - val_accuracy: 0.8716\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7821 - val_loss: 0.3779 - val_accuracy: 0.8716\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5039 - accuracy: 0.8209 - val_loss: 0.3808 - val_accuracy: 0.8649\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.8074 - val_loss: 0.3731 - val_accuracy: 0.8716\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.8193 - val_loss: 0.3784 - val_accuracy: 0.8581\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.7872 - val_loss: 0.3749 - val_accuracy: 0.8784\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.8024 - val_loss: 0.3822 - val_accuracy: 0.8716\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7939 - val_loss: 0.3979 - val_accuracy: 0.8649\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.8142 - val_loss: 0.4040 - val_accuracy: 0.8649\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.8007 - val_loss: 0.4061 - val_accuracy: 0.8581\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.8311 - val_loss: 0.3850 - val_accuracy: 0.8716\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.8024 - val_loss: 0.4007 - val_accuracy: 0.8581\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.8041 - val_loss: 0.3883 - val_accuracy: 0.8716\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.8108 - val_loss: 0.3829 - val_accuracy: 0.8581\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.8142 - val_loss: 0.3932 - val_accuracy: 0.8649\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.8361 - val_loss: 0.3809 - val_accuracy: 0.8716\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5165 - accuracy: 0.8057 - val_loss: 0.3789 - val_accuracy: 0.8716\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5617 - accuracy: 0.7652 - val_loss: 0.3960 - val_accuracy: 0.8649\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7956 - val_loss: 0.3959 - val_accuracy: 0.8514\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.8074 - val_loss: 0.4126 - val_accuracy: 0.8243\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7905 - val_loss: 0.4031 - val_accuracy: 0.8581\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.8074 - val_loss: 0.4072 - val_accuracy: 0.8581\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7973 - val_loss: 0.3935 - val_accuracy: 0.8851\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7821 - val_loss: 0.3894 - val_accuracy: 0.8649\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4915 - accuracy: 0.7973 - val_loss: 0.3886 - val_accuracy: 0.8649\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5335 - accuracy: 0.7939 - val_loss: 0.3981 - val_accuracy: 0.8514\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5214 - accuracy: 0.7956 - val_loss: 0.3877 - val_accuracy: 0.8649\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4950 - accuracy: 0.8142 - val_loss: 0.3804 - val_accuracy: 0.8784\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5181 - accuracy: 0.7990 - val_loss: 0.3872 - val_accuracy: 0.8581\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4938 - accuracy: 0.8260 - val_loss: 0.3933 - val_accuracy: 0.8784\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.8057 - val_loss: 0.3922 - val_accuracy: 0.8784\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5430 - accuracy: 0.7889 - val_loss: 0.3976 - val_accuracy: 0.8649\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4720 - accuracy: 0.8277 - val_loss: 0.3955 - val_accuracy: 0.8716\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7973 - val_loss: 0.4031 - val_accuracy: 0.8716\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5426 - accuracy: 0.7855 - val_loss: 0.3939 - val_accuracy: 0.8649\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7770 - val_loss: 0.4153 - val_accuracy: 0.8784\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.8176 - val_loss: 0.3891 - val_accuracy: 0.8581\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4792 - accuracy: 0.8024 - val_loss: 0.3800 - val_accuracy: 0.8581\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.8193 - val_loss: 0.3801 - val_accuracy: 0.8581\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.8226 - val_loss: 0.4018 - val_accuracy: 0.8649\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.8226 - val_loss: 0.4110 - val_accuracy: 0.8784\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7889 - val_loss: 0.4039 - val_accuracy: 0.8581\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5019 - accuracy: 0.8108 - val_loss: 0.3875 - val_accuracy: 0.8649\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5401 - accuracy: 0.7787 - val_loss: 0.3865 - val_accuracy: 0.8649\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4976 - accuracy: 0.8057 - val_loss: 0.4021 - val_accuracy: 0.8716\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5220 - accuracy: 0.7872 - val_loss: 0.4026 - val_accuracy: 0.8716\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7787 - val_loss: 0.4075 - val_accuracy: 0.8581\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7770 - val_loss: 0.3993 - val_accuracy: 0.8581\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4852 - accuracy: 0.8226 - val_loss: 0.3950 - val_accuracy: 0.8716\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7872 - val_loss: 0.3982 - val_accuracy: 0.8581\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.8176 - val_loss: 0.3950 - val_accuracy: 0.8581\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7973 - val_loss: 0.3960 - val_accuracy: 0.8649\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.8193 - val_loss: 0.3977 - val_accuracy: 0.8716\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7922 - val_loss: 0.4001 - val_accuracy: 0.8514\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.8041 - val_loss: 0.3978 - val_accuracy: 0.8649\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.8041 - val_loss: 0.4018 - val_accuracy: 0.8581\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7872 - val_loss: 0.3954 - val_accuracy: 0.8649\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.8041 - val_loss: 0.3859 - val_accuracy: 0.8716\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5045 - accuracy: 0.8176 - val_loss: 0.3885 - val_accuracy: 0.8649\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4867 - accuracy: 0.8041 - val_loss: 0.3787 - val_accuracy: 0.8716\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5048 - accuracy: 0.7838 - val_loss: 0.3786 - val_accuracy: 0.8784\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5011 - accuracy: 0.7905 - val_loss: 0.3763 - val_accuracy: 0.8716\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4983 - accuracy: 0.8024 - val_loss: 0.3851 - val_accuracy: 0.8716\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5206 - accuracy: 0.7872 - val_loss: 0.3844 - val_accuracy: 0.8851\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4772 - accuracy: 0.8209 - val_loss: 0.3736 - val_accuracy: 0.8919\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.8108 - val_loss: 0.3744 - val_accuracy: 0.8784\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.7922 - val_loss: 0.3897 - val_accuracy: 0.8851\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.8074 - val_loss: 0.3878 - val_accuracy: 0.8649\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7753 - val_loss: 0.3905 - val_accuracy: 0.8581\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5006 - accuracy: 0.7889 - val_loss: 0.3916 - val_accuracy: 0.8649\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5001 - accuracy: 0.8176 - val_loss: 0.3887 - val_accuracy: 0.8784\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5362 - accuracy: 0.7855 - val_loss: 0.3975 - val_accuracy: 0.8649\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7922 - val_loss: 0.3985 - val_accuracy: 0.8649\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5069 - accuracy: 0.7905 - val_loss: 0.3916 - val_accuracy: 0.8581\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.8041 - val_loss: 0.3954 - val_accuracy: 0.8784\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.8041 - val_loss: 0.4040 - val_accuracy: 0.8581\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7990 - val_loss: 0.4024 - val_accuracy: 0.8581\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.8041 - val_loss: 0.3962 - val_accuracy: 0.8581\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.8176 - val_loss: 0.3940 - val_accuracy: 0.8716\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.8091 - val_loss: 0.3944 - val_accuracy: 0.8784\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8226 - val_loss: 0.3894 - val_accuracy: 0.8851\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.8057 - val_loss: 0.3966 - val_accuracy: 0.8716\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.7821 - val_loss: 0.3837 - val_accuracy: 0.8784\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7872 - val_loss: 0.3890 - val_accuracy: 0.8784\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7956 - val_loss: 0.3891 - val_accuracy: 0.8716\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5566 - accuracy: 0.7872 - val_loss: 0.3957 - val_accuracy: 0.8784\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.8142 - val_loss: 0.3849 - val_accuracy: 0.8919\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.8024 - val_loss: 0.3779 - val_accuracy: 0.8851\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.8260 - val_loss: 0.3787 - val_accuracy: 0.8716\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7905 - val_loss: 0.3770 - val_accuracy: 0.8649\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.7956 - val_loss: 0.3812 - val_accuracy: 0.8784\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4873 - accuracy: 0.7990 - val_loss: 0.3872 - val_accuracy: 0.8581\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5010 - accuracy: 0.8091 - val_loss: 0.3909 - val_accuracy: 0.8514\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4719 - accuracy: 0.8429 - val_loss: 0.3921 - val_accuracy: 0.8716\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5439 - accuracy: 0.8074 - val_loss: 0.3863 - val_accuracy: 0.8851\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4973 - accuracy: 0.8277 - val_loss: 0.3920 - val_accuracy: 0.8649\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5372 - accuracy: 0.7939 - val_loss: 0.3933 - val_accuracy: 0.8716\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4658 - accuracy: 0.8243 - val_loss: 0.3899 - val_accuracy: 0.8716\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5096 - accuracy: 0.7956 - val_loss: 0.3918 - val_accuracy: 0.8581\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7990 - val_loss: 0.3889 - val_accuracy: 0.8581\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8311 - val_loss: 0.3854 - val_accuracy: 0.8581\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7905 - val_loss: 0.3923 - val_accuracy: 0.8649\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.8125 - val_loss: 0.3914 - val_accuracy: 0.8581\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7956 - val_loss: 0.3926 - val_accuracy: 0.8514\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5013 - accuracy: 0.7973 - val_loss: 0.3940 - val_accuracy: 0.8581\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8091 - val_loss: 0.3849 - val_accuracy: 0.8581\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8209 - val_loss: 0.3746 - val_accuracy: 0.8716\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4939 - accuracy: 0.8142 - val_loss: 0.3780 - val_accuracy: 0.8581\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7956 - val_loss: 0.3780 - val_accuracy: 0.8649\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.8057 - val_loss: 0.3849 - val_accuracy: 0.8851\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.8226 - val_loss: 0.3764 - val_accuracy: 0.8784\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.8074 - val_loss: 0.3811 - val_accuracy: 0.8784\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7922 - val_loss: 0.3694 - val_accuracy: 0.8716\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.8176 - val_loss: 0.3697 - val_accuracy: 0.8716\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.8142 - val_loss: 0.3660 - val_accuracy: 0.8784\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.8041 - val_loss: 0.3739 - val_accuracy: 0.8784\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.8226 - val_loss: 0.3811 - val_accuracy: 0.8784\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7973 - val_loss: 0.3731 - val_accuracy: 0.8581\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.8074 - val_loss: 0.3728 - val_accuracy: 0.8716\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.8277 - val_loss: 0.3816 - val_accuracy: 0.8649\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4759 - accuracy: 0.8041 - val_loss: 0.3818 - val_accuracy: 0.8649\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7905 - val_loss: 0.3806 - val_accuracy: 0.8649\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4696 - accuracy: 0.8260 - val_loss: 0.3807 - val_accuracy: 0.8649\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4825 - accuracy: 0.8074 - val_loss: 0.3781 - val_accuracy: 0.8784\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4977 - accuracy: 0.7838 - val_loss: 0.3848 - val_accuracy: 0.8649\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4860 - accuracy: 0.8041 - val_loss: 0.3837 - val_accuracy: 0.8649\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.8024 - val_loss: 0.3913 - val_accuracy: 0.8581\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7770 - val_loss: 0.3916 - val_accuracy: 0.8446\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5013 - accuracy: 0.8125 - val_loss: 0.4001 - val_accuracy: 0.8514\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4832 - accuracy: 0.8142 - val_loss: 0.3796 - val_accuracy: 0.8649\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5074 - accuracy: 0.7922 - val_loss: 0.3797 - val_accuracy: 0.8649\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.8024 - val_loss: 0.3837 - val_accuracy: 0.8784\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8209 - val_loss: 0.3761 - val_accuracy: 0.8716\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4885 - accuracy: 0.7956 - val_loss: 0.3851 - val_accuracy: 0.8784\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7821 - val_loss: 0.3750 - val_accuracy: 0.8784\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.8328 - val_loss: 0.3789 - val_accuracy: 0.8649\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.8226 - val_loss: 0.3800 - val_accuracy: 0.8581\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.8142 - val_loss: 0.3824 - val_accuracy: 0.8581\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.8226 - val_loss: 0.3810 - val_accuracy: 0.8581\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.8074 - val_loss: 0.3816 - val_accuracy: 0.8649\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8395 - val_loss: 0.3790 - val_accuracy: 0.8649\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.8159 - val_loss: 0.3817 - val_accuracy: 0.8716\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.8007 - val_loss: 0.3806 - val_accuracy: 0.8649\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7889 - val_loss: 0.3904 - val_accuracy: 0.8716\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.8074 - val_loss: 0.3864 - val_accuracy: 0.8649\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5042 - accuracy: 0.8007 - val_loss: 0.3926 - val_accuracy: 0.8649\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.8057 - val_loss: 0.3871 - val_accuracy: 0.8649\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4843 - accuracy: 0.8294 - val_loss: 0.3823 - val_accuracy: 0.8716\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.8108 - val_loss: 0.3775 - val_accuracy: 0.8649\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7990 - val_loss: 0.3866 - val_accuracy: 0.8649\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7922 - val_loss: 0.3946 - val_accuracy: 0.8649\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7905 - val_loss: 0.3893 - val_accuracy: 0.8649\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.8311 - val_loss: 0.3783 - val_accuracy: 0.8716\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4775 - accuracy: 0.8226 - val_loss: 0.3865 - val_accuracy: 0.8649\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5088 - accuracy: 0.8108 - val_loss: 0.3911 - val_accuracy: 0.8581\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4994 - accuracy: 0.8091 - val_loss: 0.3974 - val_accuracy: 0.8581\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5190 - accuracy: 0.7956 - val_loss: 0.4008 - val_accuracy: 0.8514\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5247 - accuracy: 0.7939 - val_loss: 0.3993 - val_accuracy: 0.8514\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4975 - accuracy: 0.7956 - val_loss: 0.3972 - val_accuracy: 0.8649\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5074 - accuracy: 0.7973 - val_loss: 0.3881 - val_accuracy: 0.8581\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4844 - accuracy: 0.8007 - val_loss: 0.3899 - val_accuracy: 0.8581\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4880 - accuracy: 0.8041 - val_loss: 0.3844 - val_accuracy: 0.8784\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7990 - val_loss: 0.3870 - val_accuracy: 0.8851\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.8328 - val_loss: 0.3876 - val_accuracy: 0.8649\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.8176 - val_loss: 0.3817 - val_accuracy: 0.8784\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.8260 - val_loss: 0.3783 - val_accuracy: 0.8716\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.8057 - val_loss: 0.3853 - val_accuracy: 0.8649\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.8277 - val_loss: 0.3841 - val_accuracy: 0.8784\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.8041 - val_loss: 0.3838 - val_accuracy: 0.8716\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.8125 - val_loss: 0.3724 - val_accuracy: 0.8716\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.8007 - val_loss: 0.3737 - val_accuracy: 0.8514\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.8074 - val_loss: 0.3787 - val_accuracy: 0.8649\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.8108 - val_loss: 0.3881 - val_accuracy: 0.8716\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8243 - val_loss: 0.4016 - val_accuracy: 0.8649\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.8074 - val_loss: 0.3976 - val_accuracy: 0.8514\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.7720 - val_loss: 0.4027 - val_accuracy: 0.8514\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.7956 - val_loss: 0.3909 - val_accuracy: 0.8784\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4908 - accuracy: 0.8159 - val_loss: 0.3984 - val_accuracy: 0.8716\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.8024 - val_loss: 0.3844 - val_accuracy: 0.8784\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.8429 - val_loss: 0.4011 - val_accuracy: 0.8851\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.8142 - val_loss: 0.3843 - val_accuracy: 0.8716\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.8226 - val_loss: 0.3853 - val_accuracy: 0.8649\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.8057 - val_loss: 0.3911 - val_accuracy: 0.8581\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4891 - accuracy: 0.8193 - val_loss: 0.3913 - val_accuracy: 0.8581\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5329 - accuracy: 0.7939 - val_loss: 0.4020 - val_accuracy: 0.8784\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5164 - accuracy: 0.7889 - val_loss: 0.4008 - val_accuracy: 0.8851\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.8108 - val_loss: 0.3969 - val_accuracy: 0.8581\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4602 - accuracy: 0.8311 - val_loss: 0.3911 - val_accuracy: 0.8784\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.7872 - val_loss: 0.3947 - val_accuracy: 0.8649\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5353 - accuracy: 0.7990 - val_loss: 0.4028 - val_accuracy: 0.8784\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8784\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c605e467ca37>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 10ms/step - loss: 1.6041 - accuracy: 0.5287 - val_loss: 1.1559 - val_accuracy: 0.4797\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.5751 - accuracy: 0.5253 - val_loss: 1.1782 - val_accuracy: 0.4865\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.4513 - accuracy: 0.4916 - val_loss: 1.1847 - val_accuracy: 0.4932\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.4092 - accuracy: 0.4932 - val_loss: 1.1678 - val_accuracy: 0.4865\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.2486 - accuracy: 0.5220 - val_loss: 1.1433 - val_accuracy: 0.4865\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.2256 - accuracy: 0.5355 - val_loss: 1.1210 - val_accuracy: 0.4932\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1840 - accuracy: 0.5321 - val_loss: 1.1095 - val_accuracy: 0.4932\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.1854 - accuracy: 0.4831 - val_loss: 1.0930 - val_accuracy: 0.4932\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.1136 - accuracy: 0.5389 - val_loss: 1.0769 - val_accuracy: 0.5000\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0920 - accuracy: 0.5287 - val_loss: 1.0638 - val_accuracy: 0.5000\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0791 - accuracy: 0.5220 - val_loss: 1.0514 - val_accuracy: 0.4932\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0484 - accuracy: 0.5777 - val_loss: 1.0429 - val_accuracy: 0.4865\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0322 - accuracy: 0.5642 - val_loss: 1.0297 - val_accuracy: 0.4932\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0352 - accuracy: 0.5270 - val_loss: 1.0176 - val_accuracy: 0.4932\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0146 - accuracy: 0.5389 - val_loss: 1.0060 - val_accuracy: 0.4865\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0046 - accuracy: 0.5220 - val_loss: 0.9942 - val_accuracy: 0.4865\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9848 - accuracy: 0.5236 - val_loss: 0.9815 - val_accuracy: 0.4865\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9754 - accuracy: 0.5338 - val_loss: 0.9710 - val_accuracy: 0.4865\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9675 - accuracy: 0.5186 - val_loss: 0.9577 - val_accuracy: 0.4865\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9591 - accuracy: 0.4932 - val_loss: 0.9457 - val_accuracy: 0.4865\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9442 - accuracy: 0.5220 - val_loss: 0.9345 - val_accuracy: 0.4865\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9366 - accuracy: 0.4932 - val_loss: 0.9249 - val_accuracy: 0.4865\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9183 - accuracy: 0.5338 - val_loss: 0.9127 - val_accuracy: 0.4865\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9091 - accuracy: 0.5541 - val_loss: 0.9007 - val_accuracy: 0.4865\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8954 - accuracy: 0.5507 - val_loss: 0.8894 - val_accuracy: 0.4932\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8868 - accuracy: 0.5152 - val_loss: 0.8792 - val_accuracy: 0.5135\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8799 - accuracy: 0.5084 - val_loss: 0.8694 - val_accuracy: 0.5135\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8632 - accuracy: 0.5541 - val_loss: 0.8570 - val_accuracy: 0.5203\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.5236 - val_loss: 0.8453 - val_accuracy: 0.5541\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8382 - accuracy: 0.5726 - val_loss: 0.8284 - val_accuracy: 0.6081\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8277 - accuracy: 0.5693 - val_loss: 0.8183 - val_accuracy: 0.6554\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8296 - accuracy: 0.5490 - val_loss: 0.8068 - val_accuracy: 0.6689\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8130 - accuracy: 0.5861 - val_loss: 0.7953 - val_accuracy: 0.6959\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8020 - accuracy: 0.5777 - val_loss: 0.7803 - val_accuracy: 0.6892\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8006 - accuracy: 0.5895 - val_loss: 0.7682 - val_accuracy: 0.7027\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7857 - accuracy: 0.6132 - val_loss: 0.7579 - val_accuracy: 0.7297\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7928 - accuracy: 0.5895 - val_loss: 0.7508 - val_accuracy: 0.7230\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7807 - accuracy: 0.5743 - val_loss: 0.7403 - val_accuracy: 0.7162\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7486 - accuracy: 0.6334 - val_loss: 0.7121 - val_accuracy: 0.7568\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7417 - accuracy: 0.6098 - val_loss: 0.6812 - val_accuracy: 0.7703\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7406 - accuracy: 0.6081 - val_loss: 0.6758 - val_accuracy: 0.7770\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7256 - accuracy: 0.6436 - val_loss: 0.6662 - val_accuracy: 0.7770\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.6807 - val_loss: 0.6508 - val_accuracy: 0.7770\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7123 - accuracy: 0.6639 - val_loss: 0.6427 - val_accuracy: 0.7703\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7147 - accuracy: 0.6605 - val_loss: 0.6402 - val_accuracy: 0.7703\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.6740 - val_loss: 0.6253 - val_accuracy: 0.7635\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.6622 - val_loss: 0.6206 - val_accuracy: 0.7770\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.6453 - val_loss: 0.6102 - val_accuracy: 0.7703\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.6892 - val_loss: 0.6126 - val_accuracy: 0.7770\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6713 - accuracy: 0.6824 - val_loss: 0.6009 - val_accuracy: 0.7905\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.6976 - val_loss: 0.5934 - val_accuracy: 0.7838\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6609 - accuracy: 0.7078 - val_loss: 0.5752 - val_accuracy: 0.7973\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.6791 - val_loss: 0.5757 - val_accuracy: 0.7905\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.6824 - val_loss: 0.5716 - val_accuracy: 0.7905\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6468 - accuracy: 0.6909 - val_loss: 0.5582 - val_accuracy: 0.7838\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.6757 - val_loss: 0.5560 - val_accuracy: 0.7838\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.7027 - val_loss: 0.5555 - val_accuracy: 0.7973\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6630 - accuracy: 0.6858 - val_loss: 0.5535 - val_accuracy: 0.7905\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6356 - accuracy: 0.7061 - val_loss: 0.5454 - val_accuracy: 0.7973\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6311 - accuracy: 0.7111 - val_loss: 0.5333 - val_accuracy: 0.7905\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6416 - accuracy: 0.7213 - val_loss: 0.5295 - val_accuracy: 0.8108\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.6875 - val_loss: 0.5398 - val_accuracy: 0.8041\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.7061 - val_loss: 0.5392 - val_accuracy: 0.8041\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7365 - val_loss: 0.5340 - val_accuracy: 0.7838\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6123 - accuracy: 0.7399 - val_loss: 0.5207 - val_accuracy: 0.8108\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6192 - accuracy: 0.7230 - val_loss: 0.5166 - val_accuracy: 0.7973\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6315 - accuracy: 0.7213 - val_loss: 0.5212 - val_accuracy: 0.8041\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5949 - accuracy: 0.7449 - val_loss: 0.5173 - val_accuracy: 0.8108\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6155 - accuracy: 0.7280 - val_loss: 0.5102 - val_accuracy: 0.8243\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6311 - accuracy: 0.7331 - val_loss: 0.5213 - val_accuracy: 0.8446\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6263 - accuracy: 0.7179 - val_loss: 0.5238 - val_accuracy: 0.8108\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.7331 - val_loss: 0.5207 - val_accuracy: 0.8176\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6411 - accuracy: 0.7010 - val_loss: 0.5123 - val_accuracy: 0.8446\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.7348 - val_loss: 0.5046 - val_accuracy: 0.8243\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7196 - val_loss: 0.4980 - val_accuracy: 0.8378\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.7466 - val_loss: 0.4988 - val_accuracy: 0.8243\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.7196 - val_loss: 0.4926 - val_accuracy: 0.8243\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7669 - val_loss: 0.4876 - val_accuracy: 0.8311\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.7416 - val_loss: 0.4791 - val_accuracy: 0.8311\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5810 - accuracy: 0.7517 - val_loss: 0.4833 - val_accuracy: 0.8243\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.7449 - val_loss: 0.4801 - val_accuracy: 0.8243\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7399 - val_loss: 0.4759 - val_accuracy: 0.8176\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.7331 - val_loss: 0.4727 - val_accuracy: 0.8311\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5667 - accuracy: 0.7804 - val_loss: 0.4736 - val_accuracy: 0.8311\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7331 - val_loss: 0.4704 - val_accuracy: 0.8514\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7534 - val_loss: 0.4959 - val_accuracy: 0.8041\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.7230 - val_loss: 0.4886 - val_accuracy: 0.7973\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.7297 - val_loss: 0.4878 - val_accuracy: 0.7973\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7230 - val_loss: 0.4914 - val_accuracy: 0.8311\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5881 - accuracy: 0.7432 - val_loss: 0.4853 - val_accuracy: 0.8311\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.7483 - val_loss: 0.4741 - val_accuracy: 0.8243\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.7365 - val_loss: 0.4710 - val_accuracy: 0.8176\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.7027 - val_loss: 0.4688 - val_accuracy: 0.8176\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.7145 - val_loss: 0.4733 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7635 - val_loss: 0.4661 - val_accuracy: 0.8243\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5583 - accuracy: 0.7855 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6032 - accuracy: 0.7348 - val_loss: 0.4692 - val_accuracy: 0.8176\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5703 - accuracy: 0.7922 - val_loss: 0.4593 - val_accuracy: 0.8378\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5686 - accuracy: 0.7551 - val_loss: 0.4519 - val_accuracy: 0.8378\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5995 - accuracy: 0.7348 - val_loss: 0.4503 - val_accuracy: 0.8378\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5564 - accuracy: 0.7787 - val_loss: 0.4508 - val_accuracy: 0.8378\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5772 - accuracy: 0.7720 - val_loss: 0.4466 - val_accuracy: 0.8378\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5765 - accuracy: 0.7584 - val_loss: 0.4492 - val_accuracy: 0.8243\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.7551 - val_loss: 0.4433 - val_accuracy: 0.8649\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7804 - val_loss: 0.4478 - val_accuracy: 0.8311\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5763 - accuracy: 0.7584 - val_loss: 0.4411 - val_accuracy: 0.8041\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.7601 - val_loss: 0.4477 - val_accuracy: 0.8108\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5619 - accuracy: 0.7584 - val_loss: 0.4453 - val_accuracy: 0.8243\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5769 - accuracy: 0.7534 - val_loss: 0.4360 - val_accuracy: 0.8311\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5943 - accuracy: 0.7382 - val_loss: 0.4448 - val_accuracy: 0.8311\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5792 - accuracy: 0.7686 - val_loss: 0.4389 - val_accuracy: 0.8514\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7703 - val_loss: 0.4422 - val_accuracy: 0.8446\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7568 - val_loss: 0.4298 - val_accuracy: 0.8514\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.7568 - val_loss: 0.4286 - val_accuracy: 0.8649\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.7669 - val_loss: 0.4281 - val_accuracy: 0.8581\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7838 - val_loss: 0.4195 - val_accuracy: 0.8716\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.7770 - val_loss: 0.4312 - val_accuracy: 0.8784\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5848 - accuracy: 0.7365 - val_loss: 0.4292 - val_accuracy: 0.8446\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.7838 - val_loss: 0.4281 - val_accuracy: 0.8581\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5707 - accuracy: 0.7821 - val_loss: 0.4200 - val_accuracy: 0.8514\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6004 - accuracy: 0.7365 - val_loss: 0.4320 - val_accuracy: 0.8649\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7855 - val_loss: 0.4300 - val_accuracy: 0.8581\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5800 - accuracy: 0.7635 - val_loss: 0.4290 - val_accuracy: 0.8649\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7686 - val_loss: 0.4256 - val_accuracy: 0.8851\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5827 - accuracy: 0.7635 - val_loss: 0.4245 - val_accuracy: 0.8716\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7753 - val_loss: 0.4185 - val_accuracy: 0.8784\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7449 - val_loss: 0.4119 - val_accuracy: 0.8919\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5243 - accuracy: 0.7821 - val_loss: 0.4046 - val_accuracy: 0.8784\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5945 - accuracy: 0.7382 - val_loss: 0.4104 - val_accuracy: 0.8716\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5477 - accuracy: 0.7703 - val_loss: 0.4133 - val_accuracy: 0.8716\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5761 - accuracy: 0.7568 - val_loss: 0.4189 - val_accuracy: 0.8716\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5500 - accuracy: 0.7821 - val_loss: 0.4186 - val_accuracy: 0.8446\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5488 - accuracy: 0.7872 - val_loss: 0.4043 - val_accuracy: 0.8581\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5702 - accuracy: 0.7568 - val_loss: 0.4077 - val_accuracy: 0.8784\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.7399 - val_loss: 0.4099 - val_accuracy: 0.8851\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7821 - val_loss: 0.4066 - val_accuracy: 0.8716\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7956 - val_loss: 0.4082 - val_accuracy: 0.8784\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.7618 - val_loss: 0.4108 - val_accuracy: 0.8716\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.7449 - val_loss: 0.4183 - val_accuracy: 0.8649\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.7787 - val_loss: 0.4234 - val_accuracy: 0.8784\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7889 - val_loss: 0.4130 - val_accuracy: 0.8784\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.7821 - val_loss: 0.4106 - val_accuracy: 0.8581\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7601 - val_loss: 0.4211 - val_accuracy: 0.8716\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.7568 - val_loss: 0.4249 - val_accuracy: 0.8581\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5667 - accuracy: 0.7787 - val_loss: 0.4194 - val_accuracy: 0.8716\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7720 - val_loss: 0.4153 - val_accuracy: 0.8716\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5669 - accuracy: 0.7736 - val_loss: 0.4238 - val_accuracy: 0.8716\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.7584 - val_loss: 0.4212 - val_accuracy: 0.8784\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5911 - accuracy: 0.7534 - val_loss: 0.4163 - val_accuracy: 0.8716\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7551 - val_loss: 0.4185 - val_accuracy: 0.8784\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5590 - accuracy: 0.7753 - val_loss: 0.4153 - val_accuracy: 0.8716\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7635 - val_loss: 0.4131 - val_accuracy: 0.8784\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5318 - accuracy: 0.7939 - val_loss: 0.4154 - val_accuracy: 0.8716\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7753 - val_loss: 0.4032 - val_accuracy: 0.8784\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.7905 - val_loss: 0.4024 - val_accuracy: 0.8784\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7889 - val_loss: 0.4033 - val_accuracy: 0.8716\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7855 - val_loss: 0.4012 - val_accuracy: 0.8716\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.8007 - val_loss: 0.4078 - val_accuracy: 0.8716\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5635 - accuracy: 0.7618 - val_loss: 0.4237 - val_accuracy: 0.8514\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5772 - accuracy: 0.7720 - val_loss: 0.4246 - val_accuracy: 0.8649\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5521 - accuracy: 0.7736 - val_loss: 0.4253 - val_accuracy: 0.8446\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5567 - accuracy: 0.7686 - val_loss: 0.4108 - val_accuracy: 0.8581\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5225 - accuracy: 0.8024 - val_loss: 0.3941 - val_accuracy: 0.8784\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5514 - accuracy: 0.7736 - val_loss: 0.3906 - val_accuracy: 0.8919\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5577 - accuracy: 0.7889 - val_loss: 0.4038 - val_accuracy: 0.8851\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.7787 - val_loss: 0.4064 - val_accuracy: 0.8649\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7973 - val_loss: 0.4030 - val_accuracy: 0.8649\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7669 - val_loss: 0.4055 - val_accuracy: 0.8716\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7770 - val_loss: 0.4065 - val_accuracy: 0.8716\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5144 - accuracy: 0.7872 - val_loss: 0.4057 - val_accuracy: 0.8649\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7956 - val_loss: 0.3961 - val_accuracy: 0.8919\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7787 - val_loss: 0.3962 - val_accuracy: 0.8851\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7770 - val_loss: 0.3880 - val_accuracy: 0.8649\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7669 - val_loss: 0.3890 - val_accuracy: 0.8784\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7652 - val_loss: 0.3943 - val_accuracy: 0.8784\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7889 - val_loss: 0.3955 - val_accuracy: 0.8649\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7922 - val_loss: 0.3995 - val_accuracy: 0.8716\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7973 - val_loss: 0.3919 - val_accuracy: 0.8716\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7787 - val_loss: 0.3854 - val_accuracy: 0.8784\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6040 - accuracy: 0.7669 - val_loss: 0.4082 - val_accuracy: 0.8581\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7635 - val_loss: 0.4165 - val_accuracy: 0.8649\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5157 - accuracy: 0.8176 - val_loss: 0.4043 - val_accuracy: 0.8649\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7753 - val_loss: 0.4078 - val_accuracy: 0.8581\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7635 - val_loss: 0.3981 - val_accuracy: 0.8716\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7905 - val_loss: 0.3956 - val_accuracy: 0.8784\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7889 - val_loss: 0.3990 - val_accuracy: 0.8581\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.7787 - val_loss: 0.4093 - val_accuracy: 0.8649\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.8041 - val_loss: 0.4005 - val_accuracy: 0.8784\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5420 - accuracy: 0.7973 - val_loss: 0.3945 - val_accuracy: 0.8919\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5312 - accuracy: 0.7804 - val_loss: 0.3953 - val_accuracy: 0.8851\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.8328 - val_loss: 0.3810 - val_accuracy: 0.8986\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5062 - accuracy: 0.7990 - val_loss: 0.3816 - val_accuracy: 0.8919\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5175 - accuracy: 0.8091 - val_loss: 0.4070 - val_accuracy: 0.8649\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.7905 - val_loss: 0.4063 - val_accuracy: 0.8716\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5752 - accuracy: 0.7618 - val_loss: 0.4142 - val_accuracy: 0.8649\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5089 - accuracy: 0.8024 - val_loss: 0.4102 - val_accuracy: 0.8716\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5557 - accuracy: 0.7736 - val_loss: 0.4096 - val_accuracy: 0.8649\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7990 - val_loss: 0.4061 - val_accuracy: 0.8716\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5660 - accuracy: 0.7568 - val_loss: 0.4059 - val_accuracy: 0.8716\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7855 - val_loss: 0.4159 - val_accuracy: 0.8784\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7652 - val_loss: 0.4140 - val_accuracy: 0.8851\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7652 - val_loss: 0.3991 - val_accuracy: 0.8784\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.7652 - val_loss: 0.3899 - val_accuracy: 0.8851\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7703 - val_loss: 0.3930 - val_accuracy: 0.8649\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5316 - accuracy: 0.7804 - val_loss: 0.3954 - val_accuracy: 0.8784\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7787 - val_loss: 0.3848 - val_accuracy: 0.8919\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.8007 - val_loss: 0.3778 - val_accuracy: 0.8986\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7872 - val_loss: 0.3694 - val_accuracy: 0.8919\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7922 - val_loss: 0.3715 - val_accuracy: 0.8919\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7720 - val_loss: 0.3763 - val_accuracy: 0.8986\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7922 - val_loss: 0.3772 - val_accuracy: 0.8919\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7872 - val_loss: 0.3880 - val_accuracy: 0.8716\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7939 - val_loss: 0.3857 - val_accuracy: 0.8851\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5657 - accuracy: 0.7855 - val_loss: 0.3880 - val_accuracy: 0.8919\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7956 - val_loss: 0.3831 - val_accuracy: 0.8851\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5755 - accuracy: 0.7855 - val_loss: 0.3845 - val_accuracy: 0.8851\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5113 - accuracy: 0.8074 - val_loss: 0.3839 - val_accuracy: 0.8784\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5098 - accuracy: 0.8007 - val_loss: 0.3713 - val_accuracy: 0.8919\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7922 - val_loss: 0.3710 - val_accuracy: 0.8851\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5457 - accuracy: 0.7922 - val_loss: 0.3821 - val_accuracy: 0.8851\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5672 - accuracy: 0.7652 - val_loss: 0.3795 - val_accuracy: 0.9054\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5335 - accuracy: 0.7872 - val_loss: 0.3786 - val_accuracy: 0.8986\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5337 - accuracy: 0.7669 - val_loss: 0.3789 - val_accuracy: 0.8919\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5151 - accuracy: 0.8091 - val_loss: 0.3789 - val_accuracy: 0.8986\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5546 - accuracy: 0.7821 - val_loss: 0.3966 - val_accuracy: 0.8851\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5704 - accuracy: 0.7534 - val_loss: 0.4020 - val_accuracy: 0.8851\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5351 - accuracy: 0.8074 - val_loss: 0.4076 - val_accuracy: 0.8784\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5700 - accuracy: 0.7855 - val_loss: 0.4086 - val_accuracy: 0.8716\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5332 - accuracy: 0.7872 - val_loss: 0.4040 - val_accuracy: 0.8716\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7821 - val_loss: 0.4101 - val_accuracy: 0.8649\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7804 - val_loss: 0.4122 - val_accuracy: 0.8784\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7618 - val_loss: 0.3974 - val_accuracy: 0.8851\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7872 - val_loss: 0.3907 - val_accuracy: 0.8581\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5654 - accuracy: 0.7855 - val_loss: 0.3959 - val_accuracy: 0.8649\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5302 - accuracy: 0.7956 - val_loss: 0.3926 - val_accuracy: 0.8581\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7956 - val_loss: 0.4018 - val_accuracy: 0.8649\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5162 - accuracy: 0.7973 - val_loss: 0.3853 - val_accuracy: 0.8784\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.7635 - val_loss: 0.3836 - val_accuracy: 0.8784\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7838 - val_loss: 0.3968 - val_accuracy: 0.8919\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7787 - val_loss: 0.3948 - val_accuracy: 0.8784\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7770 - val_loss: 0.3949 - val_accuracy: 0.8649\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7804 - val_loss: 0.3881 - val_accuracy: 0.8851\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.8007 - val_loss: 0.3910 - val_accuracy: 0.8784\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4976 - accuracy: 0.7973 - val_loss: 0.3746 - val_accuracy: 0.8986\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5368 - accuracy: 0.7686 - val_loss: 0.3726 - val_accuracy: 0.9122\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7889 - val_loss: 0.3788 - val_accuracy: 0.8851\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7990 - val_loss: 0.3921 - val_accuracy: 0.8649\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7905 - val_loss: 0.3773 - val_accuracy: 0.8851\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7990 - val_loss: 0.3862 - val_accuracy: 0.8851\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.7601 - val_loss: 0.3929 - val_accuracy: 0.8649\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7855 - val_loss: 0.3952 - val_accuracy: 0.8514\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5492 - accuracy: 0.8091 - val_loss: 0.3956 - val_accuracy: 0.8581\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5163 - accuracy: 0.7872 - val_loss: 0.4012 - val_accuracy: 0.8514\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5113 - accuracy: 0.7956 - val_loss: 0.3899 - val_accuracy: 0.8784\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5431 - accuracy: 0.7753 - val_loss: 0.3914 - val_accuracy: 0.8716\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7905 - val_loss: 0.3841 - val_accuracy: 0.8716\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5249 - accuracy: 0.7939 - val_loss: 0.3820 - val_accuracy: 0.8784\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4968 - accuracy: 0.7922 - val_loss: 0.3915 - val_accuracy: 0.8649\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5189 - accuracy: 0.7821 - val_loss: 0.3965 - val_accuracy: 0.8514\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5084 - accuracy: 0.7804 - val_loss: 0.3813 - val_accuracy: 0.8649\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7872 - val_loss: 0.3658 - val_accuracy: 0.8851\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5421 - accuracy: 0.8057 - val_loss: 0.3692 - val_accuracy: 0.8919\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.7838 - val_loss: 0.3782 - val_accuracy: 0.8716\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.8041 - val_loss: 0.3856 - val_accuracy: 0.8514\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7956 - val_loss: 0.3793 - val_accuracy: 0.8716\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7889 - val_loss: 0.3797 - val_accuracy: 0.8581\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7838 - val_loss: 0.3979 - val_accuracy: 0.8514\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.8159 - val_loss: 0.3891 - val_accuracy: 0.8446\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7922 - val_loss: 0.3852 - val_accuracy: 0.8581\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7956 - val_loss: 0.3874 - val_accuracy: 0.8716\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7787 - val_loss: 0.3817 - val_accuracy: 0.8581\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.8209 - val_loss: 0.3798 - val_accuracy: 0.8514\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.7973 - val_loss: 0.3769 - val_accuracy: 0.8716\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7669 - val_loss: 0.3853 - val_accuracy: 0.8649\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5030 - accuracy: 0.8041 - val_loss: 0.3896 - val_accuracy: 0.8716\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7990 - val_loss: 0.3814 - val_accuracy: 0.8446\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.8057 - val_loss: 0.3791 - val_accuracy: 0.8514\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7855 - val_loss: 0.3863 - val_accuracy: 0.8649\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.7872 - val_loss: 0.3766 - val_accuracy: 0.8784\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.8142 - val_loss: 0.3824 - val_accuracy: 0.8716\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.8159 - val_loss: 0.3825 - val_accuracy: 0.8581\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7855 - val_loss: 0.3819 - val_accuracy: 0.8514\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5643 - accuracy: 0.7618 - val_loss: 0.3906 - val_accuracy: 0.8446\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4873 - accuracy: 0.8142 - val_loss: 0.3827 - val_accuracy: 0.8649\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5314 - accuracy: 0.8142 - val_loss: 0.3818 - val_accuracy: 0.8649\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5364 - accuracy: 0.7956 - val_loss: 0.3838 - val_accuracy: 0.8649\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5471 - accuracy: 0.7872 - val_loss: 0.3829 - val_accuracy: 0.8851\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5151 - accuracy: 0.7855 - val_loss: 0.3888 - val_accuracy: 0.8581\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5223 - accuracy: 0.7872 - val_loss: 0.3797 - val_accuracy: 0.8851\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5313 - accuracy: 0.7956 - val_loss: 0.3814 - val_accuracy: 0.8784\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7855 - val_loss: 0.3744 - val_accuracy: 0.8986\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.8074 - val_loss: 0.3757 - val_accuracy: 0.8784\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5194 - accuracy: 0.8041 - val_loss: 0.3750 - val_accuracy: 0.8851\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7838 - val_loss: 0.3953 - val_accuracy: 0.8378\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7382 - val_loss: 0.3912 - val_accuracy: 0.8581\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7889 - val_loss: 0.3848 - val_accuracy: 0.8716\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5668 - accuracy: 0.7787 - val_loss: 0.3998 - val_accuracy: 0.8649\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7990 - val_loss: 0.3924 - val_accuracy: 0.8649\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.8074 - val_loss: 0.3838 - val_accuracy: 0.8581\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5229 - accuracy: 0.7821 - val_loss: 0.3838 - val_accuracy: 0.8581\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.7889 - val_loss: 0.3986 - val_accuracy: 0.8581\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.8041 - val_loss: 0.3920 - val_accuracy: 0.8581\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4706 - accuracy: 0.8294 - val_loss: 0.3844 - val_accuracy: 0.8446\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7753 - val_loss: 0.3949 - val_accuracy: 0.8514\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.7770 - val_loss: 0.3757 - val_accuracy: 0.8581\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.8260 - val_loss: 0.3736 - val_accuracy: 0.8581\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.8125 - val_loss: 0.3836 - val_accuracy: 0.8649\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7753 - val_loss: 0.3833 - val_accuracy: 0.8581\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.8057 - val_loss: 0.3854 - val_accuracy: 0.8446\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5612 - accuracy: 0.7821 - val_loss: 0.3846 - val_accuracy: 0.8446\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.7686 - val_loss: 0.3882 - val_accuracy: 0.8649\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5122 - accuracy: 0.8108 - val_loss: 0.3822 - val_accuracy: 0.8581\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5288 - accuracy: 0.7889 - val_loss: 0.3774 - val_accuracy: 0.8649\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4962 - accuracy: 0.8074 - val_loss: 0.3843 - val_accuracy: 0.8514\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5076 - accuracy: 0.8125 - val_loss: 0.3862 - val_accuracy: 0.8716\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5302 - accuracy: 0.7753 - val_loss: 0.3780 - val_accuracy: 0.8649\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5006 - accuracy: 0.8024 - val_loss: 0.3763 - val_accuracy: 0.8514\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5491 - accuracy: 0.7770 - val_loss: 0.3887 - val_accuracy: 0.8716\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5186 - accuracy: 0.7939 - val_loss: 0.3960 - val_accuracy: 0.8649\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5754 - accuracy: 0.7551 - val_loss: 0.3986 - val_accuracy: 0.8649\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.8057 - val_loss: 0.3939 - val_accuracy: 0.8581\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.8074 - val_loss: 0.3969 - val_accuracy: 0.8514\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.8074 - val_loss: 0.3855 - val_accuracy: 0.8581\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.8024 - val_loss: 0.3807 - val_accuracy: 0.8581\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7956 - val_loss: 0.3838 - val_accuracy: 0.8649\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7973 - val_loss: 0.3819 - val_accuracy: 0.8649\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7973 - val_loss: 0.3808 - val_accuracy: 0.8581\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7568 - val_loss: 0.3906 - val_accuracy: 0.8514\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.7905 - val_loss: 0.3977 - val_accuracy: 0.8581\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7804 - val_loss: 0.3986 - val_accuracy: 0.8649\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7787 - val_loss: 0.3978 - val_accuracy: 0.8716\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.8074 - val_loss: 0.3882 - val_accuracy: 0.8919\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.8209 - val_loss: 0.3792 - val_accuracy: 0.8919\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.8159 - val_loss: 0.3790 - val_accuracy: 0.8716\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.8091 - val_loss: 0.3839 - val_accuracy: 0.8514\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5523 - accuracy: 0.7973 - val_loss: 0.3847 - val_accuracy: 0.8716\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.8108 - val_loss: 0.3856 - val_accuracy: 0.8716\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7973 - val_loss: 0.3765 - val_accuracy: 0.8784\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.8277 - val_loss: 0.3858 - val_accuracy: 0.8649\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5367 - accuracy: 0.7973 - val_loss: 0.3797 - val_accuracy: 0.8784\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.8007 - val_loss: 0.3896 - val_accuracy: 0.8581\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4960 - accuracy: 0.8057 - val_loss: 0.3761 - val_accuracy: 0.8649\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7922 - val_loss: 0.3750 - val_accuracy: 0.8649\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4817 - accuracy: 0.8091 - val_loss: 0.3678 - val_accuracy: 0.8784\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5174 - accuracy: 0.8091 - val_loss: 0.3772 - val_accuracy: 0.8649\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5470 - accuracy: 0.7753 - val_loss: 0.3756 - val_accuracy: 0.8649\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5300 - accuracy: 0.7990 - val_loss: 0.3823 - val_accuracy: 0.8716\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4838 - accuracy: 0.7939 - val_loss: 0.3725 - val_accuracy: 0.8784\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5095 - accuracy: 0.8091 - val_loss: 0.3860 - val_accuracy: 0.8649\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.8024 - val_loss: 0.3877 - val_accuracy: 0.8716\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.8125 - val_loss: 0.3817 - val_accuracy: 0.8581\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7956 - val_loss: 0.3758 - val_accuracy: 0.8716\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.8007 - val_loss: 0.3772 - val_accuracy: 0.8514\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.8209 - val_loss: 0.3799 - val_accuracy: 0.8581\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.8649 - val_loss: 0.3673 - val_accuracy: 0.8514\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.8176 - val_loss: 0.3734 - val_accuracy: 0.8649\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.8074 - val_loss: 0.3726 - val_accuracy: 0.8851\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7990 - val_loss: 0.3678 - val_accuracy: 0.8784\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4627 - accuracy: 0.8176 - val_loss: 0.3649 - val_accuracy: 0.8716\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5248 - accuracy: 0.8007 - val_loss: 0.3616 - val_accuracy: 0.8649\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7838 - val_loss: 0.3607 - val_accuracy: 0.8919\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7922 - val_loss: 0.3623 - val_accuracy: 0.8649\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7703 - val_loss: 0.3717 - val_accuracy: 0.8514\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7905 - val_loss: 0.3642 - val_accuracy: 0.8649\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.8024 - val_loss: 0.3635 - val_accuracy: 0.8716\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5454 - accuracy: 0.7956 - val_loss: 0.3809 - val_accuracy: 0.8649\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7770 - val_loss: 0.3833 - val_accuracy: 0.8851\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7855 - val_loss: 0.3743 - val_accuracy: 0.8581\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8378 - val_loss: 0.3684 - val_accuracy: 0.8514\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5467 - accuracy: 0.7889 - val_loss: 0.3797 - val_accuracy: 0.8581\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5121 - accuracy: 0.8091 - val_loss: 0.3853 - val_accuracy: 0.8378\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4502 - accuracy: 0.8159 - val_loss: 0.3875 - val_accuracy: 0.8514\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5122 - accuracy: 0.7939 - val_loss: 0.3792 - val_accuracy: 0.8581\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5216 - accuracy: 0.8057 - val_loss: 0.3800 - val_accuracy: 0.8716\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5038 - accuracy: 0.7956 - val_loss: 0.3717 - val_accuracy: 0.8716\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4781 - accuracy: 0.8277 - val_loss: 0.3648 - val_accuracy: 0.8581\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4924 - accuracy: 0.8041 - val_loss: 0.3726 - val_accuracy: 0.8446\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5141 - accuracy: 0.8007 - val_loss: 0.3729 - val_accuracy: 0.8649\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.8024 - val_loss: 0.3650 - val_accuracy: 0.8716\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7703 - val_loss: 0.3714 - val_accuracy: 0.8649\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.7956 - val_loss: 0.3864 - val_accuracy: 0.8514\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.8041 - val_loss: 0.3812 - val_accuracy: 0.8446\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.8125 - val_loss: 0.3710 - val_accuracy: 0.8378\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.7905 - val_loss: 0.3882 - val_accuracy: 0.8581\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7905 - val_loss: 0.3768 - val_accuracy: 0.8784\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.8024 - val_loss: 0.3915 - val_accuracy: 0.8581\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7905 - val_loss: 0.3933 - val_accuracy: 0.8649\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7956 - val_loss: 0.3892 - val_accuracy: 0.8784\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5145 - accuracy: 0.8041 - val_loss: 0.3814 - val_accuracy: 0.8716\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.8024 - val_loss: 0.3778 - val_accuracy: 0.8851\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7821 - val_loss: 0.3796 - val_accuracy: 0.8784\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7973 - val_loss: 0.3819 - val_accuracy: 0.8581\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.7990 - val_loss: 0.3692 - val_accuracy: 0.8784\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5624 - accuracy: 0.7736 - val_loss: 0.3766 - val_accuracy: 0.8851\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7905 - val_loss: 0.3818 - val_accuracy: 0.8716\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7838 - val_loss: 0.3837 - val_accuracy: 0.8716\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.8057 - val_loss: 0.3794 - val_accuracy: 0.8581\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7889 - val_loss: 0.3710 - val_accuracy: 0.8514\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4984 - accuracy: 0.7990 - val_loss: 0.3644 - val_accuracy: 0.8716\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5221 - accuracy: 0.7872 - val_loss: 0.3730 - val_accuracy: 0.8716\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4784 - accuracy: 0.7939 - val_loss: 0.3669 - val_accuracy: 0.8716\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5023 - accuracy: 0.8024 - val_loss: 0.3662 - val_accuracy: 0.8649\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5351 - accuracy: 0.7838 - val_loss: 0.3647 - val_accuracy: 0.8716\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5039 - accuracy: 0.8041 - val_loss: 0.3694 - val_accuracy: 0.8716\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4808 - accuracy: 0.8159 - val_loss: 0.3689 - val_accuracy: 0.8784\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5005 - accuracy: 0.8074 - val_loss: 0.3785 - val_accuracy: 0.8649\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4695 - accuracy: 0.8108 - val_loss: 0.3678 - val_accuracy: 0.8649\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7872 - val_loss: 0.3871 - val_accuracy: 0.8716\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5168 - accuracy: 0.8193 - val_loss: 0.3797 - val_accuracy: 0.8649\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8345 - val_loss: 0.3785 - val_accuracy: 0.8581\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.8193 - val_loss: 0.3786 - val_accuracy: 0.8716\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7905 - val_loss: 0.3662 - val_accuracy: 0.8649\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.8091 - val_loss: 0.3652 - val_accuracy: 0.8851\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7720 - val_loss: 0.3710 - val_accuracy: 0.8649\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7905 - val_loss: 0.3770 - val_accuracy: 0.8649\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4883 - accuracy: 0.8041 - val_loss: 0.3651 - val_accuracy: 0.8716\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7922 - val_loss: 0.3875 - val_accuracy: 0.8514\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7990 - val_loss: 0.3868 - val_accuracy: 0.8581\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7939 - val_loss: 0.3797 - val_accuracy: 0.8581\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.8125 - val_loss: 0.3789 - val_accuracy: 0.8716\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7872 - val_loss: 0.3837 - val_accuracy: 0.8716\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7787 - val_loss: 0.3827 - val_accuracy: 0.8784\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.8142 - val_loss: 0.3706 - val_accuracy: 0.8649\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.8074 - val_loss: 0.3770 - val_accuracy: 0.8581\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5078 - accuracy: 0.8041 - val_loss: 0.3848 - val_accuracy: 0.8649\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.7905 - val_loss: 0.3771 - val_accuracy: 0.8581\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5056 - accuracy: 0.8209 - val_loss: 0.3807 - val_accuracy: 0.8649\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4989 - accuracy: 0.8057 - val_loss: 0.3838 - val_accuracy: 0.8581\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5085 - accuracy: 0.7855 - val_loss: 0.3726 - val_accuracy: 0.8581\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4735 - accuracy: 0.8193 - val_loss: 0.3807 - val_accuracy: 0.8514\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4492 - accuracy: 0.8226 - val_loss: 0.3871 - val_accuracy: 0.8446\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4895 - accuracy: 0.8159 - val_loss: 0.3685 - val_accuracy: 0.8514\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5574 - accuracy: 0.7939 - val_loss: 0.3767 - val_accuracy: 0.8581\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4858 - accuracy: 0.8074 - val_loss: 0.3881 - val_accuracy: 0.8649\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5047 - accuracy: 0.8024 - val_loss: 0.3767 - val_accuracy: 0.8649\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4700 - accuracy: 0.7956 - val_loss: 0.3835 - val_accuracy: 0.8649\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5034 - accuracy: 0.8007 - val_loss: 0.3698 - val_accuracy: 0.8446\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5444 - accuracy: 0.7905 - val_loss: 0.3762 - val_accuracy: 0.8581\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7905 - val_loss: 0.3688 - val_accuracy: 0.8581\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7990 - val_loss: 0.3631 - val_accuracy: 0.8919\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7922 - val_loss: 0.3640 - val_accuracy: 0.8851\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4718 - accuracy: 0.8226 - val_loss: 0.3631 - val_accuracy: 0.8851\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5180 - accuracy: 0.7872 - val_loss: 0.3695 - val_accuracy: 0.8716\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5071 - accuracy: 0.8024 - val_loss: 0.3818 - val_accuracy: 0.8311\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7973 - val_loss: 0.3821 - val_accuracy: 0.8446\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5295 - accuracy: 0.7821 - val_loss: 0.3839 - val_accuracy: 0.8311\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7905 - val_loss: 0.3917 - val_accuracy: 0.8378\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.8024 - val_loss: 0.3947 - val_accuracy: 0.8446\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4955 - accuracy: 0.7939 - val_loss: 0.3856 - val_accuracy: 0.8311\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.8108 - val_loss: 0.3741 - val_accuracy: 0.8514\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.8041 - val_loss: 0.3607 - val_accuracy: 0.8446\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4651 - accuracy: 0.8277 - val_loss: 0.3428 - val_accuracy: 0.8716\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.8142 - val_loss: 0.3474 - val_accuracy: 0.8649\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.8007 - val_loss: 0.3582 - val_accuracy: 0.8649\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7922 - val_loss: 0.3669 - val_accuracy: 0.8446\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4777 - accuracy: 0.8176 - val_loss: 0.3632 - val_accuracy: 0.8446\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.7720 - val_loss: 0.3508 - val_accuracy: 0.8514\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5157 - accuracy: 0.8024 - val_loss: 0.3509 - val_accuracy: 0.8716\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4968 - accuracy: 0.7905 - val_loss: 0.3726 - val_accuracy: 0.8649\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5179 - accuracy: 0.8074 - val_loss: 0.3861 - val_accuracy: 0.8581\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4369 - accuracy: 0.8446 - val_loss: 0.3604 - val_accuracy: 0.8716\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4435 - accuracy: 0.8378 - val_loss: 0.3592 - val_accuracy: 0.8649\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5096 - accuracy: 0.8108 - val_loss: 0.3535 - val_accuracy: 0.8649\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.8345 - val_loss: 0.3435 - val_accuracy: 0.8716\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.7905 - val_loss: 0.3553 - val_accuracy: 0.8784\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5421 - accuracy: 0.8074 - val_loss: 0.3521 - val_accuracy: 0.8649\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.8057 - val_loss: 0.3608 - val_accuracy: 0.8716\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.8041 - val_loss: 0.3508 - val_accuracy: 0.8581\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.8294 - val_loss: 0.3549 - val_accuracy: 0.8581\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.8074 - val_loss: 0.3543 - val_accuracy: 0.8851\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.8209 - val_loss: 0.3453 - val_accuracy: 0.8784\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.8328 - val_loss: 0.3458 - val_accuracy: 0.8851\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7855 - val_loss: 0.3507 - val_accuracy: 0.8649\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7838 - val_loss: 0.3545 - val_accuracy: 0.8716\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.8361 - val_loss: 0.3493 - val_accuracy: 0.8784\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.8074 - val_loss: 0.3494 - val_accuracy: 0.8581\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.8193 - val_loss: 0.3562 - val_accuracy: 0.8716\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.8091 - val_loss: 0.3630 - val_accuracy: 0.8716\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.8057 - val_loss: 0.3646 - val_accuracy: 0.8514\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7990 - val_loss: 0.3636 - val_accuracy: 0.8514\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.8429 - val_loss: 0.3628 - val_accuracy: 0.8581\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7821 - val_loss: 0.3724 - val_accuracy: 0.8581\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5118 - accuracy: 0.8108 - val_loss: 0.3758 - val_accuracy: 0.8716\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7956 - val_loss: 0.3802 - val_accuracy: 0.8581\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4935 - accuracy: 0.8057 - val_loss: 0.3857 - val_accuracy: 0.8514\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4788 - accuracy: 0.8007 - val_loss: 0.3830 - val_accuracy: 0.8514\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4732 - accuracy: 0.8108 - val_loss: 0.3844 - val_accuracy: 0.8514\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5099 - accuracy: 0.7889 - val_loss: 0.3628 - val_accuracy: 0.8649\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4880 - accuracy: 0.8108 - val_loss: 0.3665 - val_accuracy: 0.8514\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4969 - accuracy: 0.8007 - val_loss: 0.3711 - val_accuracy: 0.8514\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4310 - accuracy: 0.8378 - val_loss: 0.3645 - val_accuracy: 0.8514\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4664 - accuracy: 0.8091 - val_loss: 0.3691 - val_accuracy: 0.8581\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5014 - accuracy: 0.8007 - val_loss: 0.3662 - val_accuracy: 0.8581\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4986 - accuracy: 0.7956 - val_loss: 0.3782 - val_accuracy: 0.8716\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4836 - accuracy: 0.8277 - val_loss: 0.3960 - val_accuracy: 0.8581\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.8024 - val_loss: 0.3849 - val_accuracy: 0.8514\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7973 - val_loss: 0.3777 - val_accuracy: 0.8514\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.7753 - val_loss: 0.3764 - val_accuracy: 0.8649\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7939 - val_loss: 0.3829 - val_accuracy: 0.8514\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.8226 - val_loss: 0.3875 - val_accuracy: 0.8514\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8514\n",
            "5/5 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c605e467ca37>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8310810923576355, 0.837837815284729, 0.8040540814399719, 0.8783783912658691, 0.8513513803482056]\n",
            "Accuracy: 0.84\n",
            "Sensitivity: 0.8711\n",
            "Specificity: 0.8096\n",
            "MCC: 0.6806\n",
            "Precision: 0.8261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn')\n",
        "model.save_weights('acp_mhcnn_weights')"
      ],
      "metadata": {
        "id": "i-ySuIJePlfJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn.keras')"
      ],
      "metadata": {
        "id": "sUnKQ39Oql-p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/acp_mhcnn.zip /content/acp_mhcnn"
      ],
      "metadata": {
        "id": "TCPrPTFlq03j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4aedae-2406-4069-abe1-1bd1e401a621"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/acp_mhcnn/ (stored 0%)\n",
            "updating: content/acp_mhcnn/keras_metadata.pb (deflated 93%)\n",
            "updating: content/acp_mhcnn/saved_model.pb (deflated 90%)\n",
            "updating: content/acp_mhcnn/variables/ (stored 0%)\n",
            "updating: content/acp_mhcnn/variables/variables.data-00000-of-00001 (deflated 30%)\n",
            "updating: content/acp_mhcnn/variables/variables.index (deflated 71%)\n",
            "updating: content/acp_mhcnn/fingerprint.pb (stored 0%)\n",
            "updating: content/acp_mhcnn/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1YZag2MrItN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}