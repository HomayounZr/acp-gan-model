{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NCx8Mc7DwG",
        "outputId": "5ac7042e-056e-4a02-fff9-31b5f6007363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "4Ievu6ie7KcN",
        "outputId": "7122e10f-9385-4105-8514-96ceb7cd0bf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-325b6ec1-75ba-43c5-99d5-d3510628be77\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-325b6ec1-75ba-43c5-99d5-d3510628be77\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bits-740.npy to bits-740.npy\n",
            "Saving blosum-740.npy to blosum-740.npy\n",
            "Saving bpf-740.npy to bpf-740.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Neural Networks:\n",
        "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
        "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
        "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
        "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
        "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
        "from tensorflow.keras.models import (Sequential, Model)\n",
        "\n",
        "# Core:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import interp\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Performance:\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
        "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
        "\n",
        "#Utilities:\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
        "from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "#end-import\n",
        "\n",
        "def lossPlot(results):\n",
        "    plt.title(label='Loss: Training and Validation')\n",
        "    plt.plot(results.history['loss'], label='Training Loss')\n",
        "    plt.plot(results.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def accuracyPlot(results):\n",
        "    plt.title(label='Accuracy: Training and Validation')\n",
        "    plt.plot(results.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def rocPlot(TPR, meanFPR):\n",
        "    plt.plot([0,1], [0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "    meanTPR = np.mean(TPR, axis=0)\n",
        "    meanAUC = auc(meanFPR, meanTPR)\n",
        "    plt.plot(meanFPR, meanTPR, color='blue',\n",
        "            label=r'Mean ROC (AUC = %0.2f )' % (meanAUC),lw=2, alpha=1)\n",
        "\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('ROC-740.png')\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "T = 15 # terminus_length\n",
        "\n",
        "X1 = np.load('bpf-740.npy')\n",
        "X2 = np.load('bits-740.npy')\n",
        "X3 = np.load('blosum-740.npy')\n",
        "\n",
        "\n",
        "X1 = X1[:,0:T,:]\n",
        "X2 = X2[:,0:T,:]\n",
        "X3 = X3[:,0:T,:]\n",
        "\n",
        "\n",
        "Y  = [1 for _ in range(376)]\n",
        "Y += [0 for _ in range(364)]\n",
        "\n",
        "Y = labelEncoding(Y, dtype=int)\n",
        "\n",
        "\n",
        "print(X1.shape)\n",
        "print(X2.shape)\n",
        "print(X3.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "### Model-740\n",
        "\n",
        "def Network():\n",
        "    ### Head-1:\n",
        "    input1 = Input(shape=X1[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.80)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-2:\n",
        "    # input2 = Input(shape=X2[0].shape)\n",
        "\n",
        "    # x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ## Head-3:\n",
        "    input3 = Input(shape=X3[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu',)(input3)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head3 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # merge\n",
        "    # merge = Concatenate()([head1, head3])\n",
        "    merge = Concatenate()([head1, head3])\n",
        "\n",
        "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(rate=0.70)(output)\n",
        "\n",
        "    output = Dense(units=2, activation='softmax')(output)\n",
        "\n",
        "    # return Model(inputs=[input1, input3], outputs=[output])\n",
        "    return Model(inputs=[input1, input3], outputs=[output])\n",
        "#end-def\n",
        "\n",
        "model = Network()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model-740.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "setEpochNumber     = 500     # Performed-welled in epoch 600.\n",
        "setBatchSizeNumber = 8\n",
        "####################################################\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=101)\n",
        "\n",
        "Accuracy = []\n",
        "Sensitivity = []\n",
        "Specificity = []\n",
        "Precision = []\n",
        "MCC = []\n",
        "\n",
        "# ROC Curve:\n",
        "fig1 = plt.figure(figsize=[12,12])\n",
        "\n",
        "TPR = []\n",
        "meanFPR = np.linspace(0, 1, 100)\n",
        "\n",
        "i = 1\n",
        "\n",
        "# CM = np.array([\n",
        "#      [0, 0],\n",
        "#      [0, 0],\n",
        "# ], dtype=int)\n",
        "\n",
        "for train, test in cv.split(Y):\n",
        "\n",
        "    # Compile Model:\n",
        "    model = Network()\n",
        "    model.compile(optimizer=Adam(lr=0.005),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Run Model:\n",
        "    results = model.fit(x=[X1[train,:,:], X3[train,:,:]],\n",
        "                        y=Y[train,:],\n",
        "                        validation_data=([X1[test,:,:], X3[test,:,:]], Y[test,:]),\n",
        "                        batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "                        verbose=1,\n",
        "                        callbacks=[])\n",
        "        # results = model.fit(x=[X1[train,:,:], X3[train,:,:]],\n",
        "        #                 y=Y[train,:],\n",
        "        #                 validation_data=([X1[test,:,:], X3[test,:,:],], Y[test,:]),\n",
        "        #                 batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "        #                 verbose=1,\n",
        "        #                 callbacks=[])\n",
        "\n",
        "    # Evaluate the Model:\n",
        "    # accuracy = model.evaluate(x=[X1[test,:,:], X3[test,:,:]], y=Y[test,:])\n",
        "    accuracy = model.evaluate(x=[X1[test,:,:],X3[test,:,:]], y=Y[test,:])\n",
        "    Accuracy.append(accuracy[1])\n",
        "\n",
        "    # Performance Metices:\n",
        "    Yactual = Y[test,:].argmax(axis=1)\n",
        "    # Yp = model.predict([X1[test,:,:], X3[test,:,:]])\n",
        "    Yp = model.predict([X1[test,:,:],X3[test,:,:]])\n",
        "    v = Yp\n",
        "    Yp = Yp.argmax(axis=1)\n",
        "\n",
        "    CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "    TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "    MCC.append(matthews_corrcoef(y_true=Yactual, y_pred=Yp))\n",
        "    Sensitivity.append( TP / (TP + FN) )\n",
        "    Specificity.append( TN / (TN + FP) )\n",
        "    Precision.append(precision_score(y_true=Yactual, y_pred=Yp))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(Yactual, v[:,1])\n",
        "    TPR.append(interp(meanFPR, fpr, tpr))\n",
        "    rocauc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, rocauc))\n",
        "    i= i+1\n",
        "\n",
        "    # # Performance Plot\n",
        "    # print('#################################################')\n",
        "    # print('Fold\\'s Accuracy: {:.2f}'.format(accuracy[1]*100.0))\n",
        "    # lossPlot(results)\n",
        "    # accuracyPlot(results)\n",
        "    # print('#################################################')\n",
        "\n",
        "#end-for\n",
        "\n",
        "rocPlot(TPR, meanFPR)\n",
        "\n",
        "print(Accuracy)\n",
        "print('Accuracy: {:.2f}'.format(np.sum(Accuracy)/5.0))\n",
        "print('Sensitivity: {0:.4f}'.format(np.sum(Sensitivity)/5.00))\n",
        "print('Specificity: {0:.4f}'.format(np.sum(Specificity)/5.00))\n",
        "print('MCC: {0:.4f}'.format(np.sum(MCC)/5.00))\n",
        "print('Precision: {0:.4f}'.format(np.sum(Precision)/5.00))"
      ],
      "metadata": {
        "id": "_o28L8jW7KnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cfb9571-eae2-4b40-a6f6-b9162156891a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're using TF-2.15.0.\n",
            "(740, 15, 20)\n",
            "(740, 15, 31)\n",
            "(740, 15, 20)\n",
            "(740, 2)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 15, 10)               810       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)          (None, 15, 10)               810       ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 15, 10)               40        ['conv1d_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 15, 10)               40        ['conv1d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 15, 10)               0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 15, 10)               0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 15, 8)                248       ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)          (None, 15, 8)                248       ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 15, 8)                32        ['conv1d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 15, 8)                32        ['conv1d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 15, 8)                0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 15, 8)                0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 120)                  0         ['dropout_11[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 120)                  0         ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 240)                  0         ['flatten_4[0][0]',           \n",
            " )                                                                   'flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 8)                    1928      ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 8)                    32        ['dense_4[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 8)                    0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 2)                    18        ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4238 (16.55 KB)\n",
            "Trainable params: 4150 (16.21 KB)\n",
            "Non-trainable params: 88 (352.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 10ms/step - loss: 1.7447 - accuracy: 0.5355 - val_loss: 1.1722 - val_accuracy: 0.4662\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5879 - accuracy: 0.4966 - val_loss: 1.1464 - val_accuracy: 0.5270\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4729 - accuracy: 0.5541 - val_loss: 1.1283 - val_accuracy: 0.5405\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4219 - accuracy: 0.5253 - val_loss: 1.1124 - val_accuracy: 0.5270\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.3625 - accuracy: 0.5101 - val_loss: 1.0942 - val_accuracy: 0.5338\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2952 - accuracy: 0.4949 - val_loss: 1.0803 - val_accuracy: 0.5405\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1991 - accuracy: 0.5220 - val_loss: 1.0672 - val_accuracy: 0.5946\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2315 - accuracy: 0.5186 - val_loss: 1.0566 - val_accuracy: 0.6486\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1560 - accuracy: 0.5355 - val_loss: 1.0443 - val_accuracy: 0.6757\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.5422 - val_loss: 1.0390 - val_accuracy: 0.6824\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0979 - accuracy: 0.5203 - val_loss: 1.0336 - val_accuracy: 0.6892\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.0682 - accuracy: 0.5625 - val_loss: 1.0255 - val_accuracy: 0.6622\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0827 - accuracy: 0.5101 - val_loss: 1.0182 - val_accuracy: 0.6689\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0493 - accuracy: 0.5507 - val_loss: 1.0115 - val_accuracy: 0.6622\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0566 - accuracy: 0.5135 - val_loss: 1.0042 - val_accuracy: 0.7027\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0055 - accuracy: 0.5574 - val_loss: 0.9936 - val_accuracy: 0.7095\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0149 - accuracy: 0.5422 - val_loss: 0.9856 - val_accuracy: 0.7027\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0037 - accuracy: 0.5220 - val_loss: 0.9736 - val_accuracy: 0.6757\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9831 - accuracy: 0.5473 - val_loss: 0.9636 - val_accuracy: 0.6622\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9728 - accuracy: 0.5591 - val_loss: 0.9550 - val_accuracy: 0.6351\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9636 - accuracy: 0.5422 - val_loss: 0.9470 - val_accuracy: 0.6284\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9500 - accuracy: 0.5507 - val_loss: 0.9388 - val_accuracy: 0.6081\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9375 - accuracy: 0.5591 - val_loss: 0.9275 - val_accuracy: 0.6216\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9308 - accuracy: 0.5473 - val_loss: 0.9202 - val_accuracy: 0.5946\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9193 - accuracy: 0.5743 - val_loss: 0.9073 - val_accuracy: 0.6216\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9151 - accuracy: 0.5507 - val_loss: 0.8961 - val_accuracy: 0.6824\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9059 - accuracy: 0.5659 - val_loss: 0.8876 - val_accuracy: 0.6486\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8997 - accuracy: 0.5912 - val_loss: 0.8770 - val_accuracy: 0.7162\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8753 - accuracy: 0.5980 - val_loss: 0.8604 - val_accuracy: 0.7432\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8719 - accuracy: 0.5811 - val_loss: 0.8525 - val_accuracy: 0.6892\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8632 - accuracy: 0.6250 - val_loss: 0.8421 - val_accuracy: 0.6824\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8555 - accuracy: 0.6064 - val_loss: 0.8263 - val_accuracy: 0.7703\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8295 - accuracy: 0.6014 - val_loss: 0.8109 - val_accuracy: 0.7230\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8409 - accuracy: 0.6081 - val_loss: 0.8052 - val_accuracy: 0.7095\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7996 - accuracy: 0.6486 - val_loss: 0.7905 - val_accuracy: 0.7095\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8130 - accuracy: 0.6098 - val_loss: 0.7866 - val_accuracy: 0.6554\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7958 - accuracy: 0.6402 - val_loss: 0.7755 - val_accuracy: 0.7027\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7790 - accuracy: 0.6470 - val_loss: 0.7638 - val_accuracy: 0.7297\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8051 - accuracy: 0.5946 - val_loss: 0.7595 - val_accuracy: 0.7297\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7744 - accuracy: 0.6351 - val_loss: 0.7459 - val_accuracy: 0.7297\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7683 - accuracy: 0.6318 - val_loss: 0.7377 - val_accuracy: 0.7095\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7901 - accuracy: 0.6267 - val_loss: 0.7286 - val_accuracy: 0.7365\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7352 - accuracy: 0.6706 - val_loss: 0.7117 - val_accuracy: 0.7770\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7413 - accuracy: 0.6672 - val_loss: 0.7007 - val_accuracy: 0.7500\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7223 - accuracy: 0.6639 - val_loss: 0.6863 - val_accuracy: 0.7703\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7033 - accuracy: 0.7010 - val_loss: 0.6721 - val_accuracy: 0.7568\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7452 - accuracy: 0.6622 - val_loss: 0.6777 - val_accuracy: 0.7838\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7124 - accuracy: 0.6909 - val_loss: 0.6671 - val_accuracy: 0.7838\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.6892 - val_loss: 0.6552 - val_accuracy: 0.7770\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.6757 - val_loss: 0.6504 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7217 - accuracy: 0.6774 - val_loss: 0.6429 - val_accuracy: 0.7635\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7162 - accuracy: 0.6655 - val_loss: 0.6393 - val_accuracy: 0.7838\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7001 - accuracy: 0.6655 - val_loss: 0.6289 - val_accuracy: 0.7973\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.7044 - val_loss: 0.6280 - val_accuracy: 0.7973\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.7044 - val_loss: 0.6178 - val_accuracy: 0.8041\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7010 - val_loss: 0.6204 - val_accuracy: 0.7838\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.6858 - val_loss: 0.6167 - val_accuracy: 0.7635\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6736 - accuracy: 0.6774 - val_loss: 0.6104 - val_accuracy: 0.7905\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6471 - accuracy: 0.7044 - val_loss: 0.6041 - val_accuracy: 0.7905\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.6841 - val_loss: 0.6046 - val_accuracy: 0.7905\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.6706 - val_loss: 0.6075 - val_accuracy: 0.7770\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.7044 - val_loss: 0.6026 - val_accuracy: 0.7905\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.6959 - val_loss: 0.5941 - val_accuracy: 0.7905\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.7314 - val_loss: 0.5841 - val_accuracy: 0.7973\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.7162 - val_loss: 0.5880 - val_accuracy: 0.7770\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6317 - accuracy: 0.7314 - val_loss: 0.5911 - val_accuracy: 0.7568\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6561 - accuracy: 0.6959 - val_loss: 0.5867 - val_accuracy: 0.7568\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.7230 - val_loss: 0.5762 - val_accuracy: 0.7838\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6089 - accuracy: 0.7264 - val_loss: 0.5627 - val_accuracy: 0.7973\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6240 - accuracy: 0.7196 - val_loss: 0.5500 - val_accuracy: 0.8041\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6369 - accuracy: 0.7111 - val_loss: 0.5572 - val_accuracy: 0.7973\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6393 - accuracy: 0.7128 - val_loss: 0.5586 - val_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6128 - accuracy: 0.7348 - val_loss: 0.5480 - val_accuracy: 0.7905\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6235 - accuracy: 0.7264 - val_loss: 0.5428 - val_accuracy: 0.8108\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6251 - accuracy: 0.7145 - val_loss: 0.5345 - val_accuracy: 0.8108\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.7264 - val_loss: 0.5439 - val_accuracy: 0.8108\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6529 - accuracy: 0.7196 - val_loss: 0.5461 - val_accuracy: 0.8041\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.7230 - val_loss: 0.5438 - val_accuracy: 0.7973\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6172 - accuracy: 0.7314 - val_loss: 0.5378 - val_accuracy: 0.7973\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.7416 - val_loss: 0.5381 - val_accuracy: 0.8176\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5966 - accuracy: 0.7686 - val_loss: 0.5287 - val_accuracy: 0.8243\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6027 - accuracy: 0.7568 - val_loss: 0.5205 - val_accuracy: 0.8243\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.7568 - val_loss: 0.5148 - val_accuracy: 0.8176\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.7264 - val_loss: 0.5206 - val_accuracy: 0.8108\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6403 - accuracy: 0.6993 - val_loss: 0.5266 - val_accuracy: 0.8446\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7534 - val_loss: 0.5228 - val_accuracy: 0.8378\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5942 - accuracy: 0.7517 - val_loss: 0.5166 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.7500 - val_loss: 0.5130 - val_accuracy: 0.8176\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7601 - val_loss: 0.5096 - val_accuracy: 0.8176\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.7230 - val_loss: 0.5082 - val_accuracy: 0.8243\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5939 - accuracy: 0.7432 - val_loss: 0.5134 - val_accuracy: 0.8243\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.7601 - val_loss: 0.5114 - val_accuracy: 0.8108\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.7196 - val_loss: 0.5288 - val_accuracy: 0.8311\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5985 - accuracy: 0.7568 - val_loss: 0.5321 - val_accuracy: 0.8108\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 0.7483 - val_loss: 0.5351 - val_accuracy: 0.8176\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6420 - accuracy: 0.7111 - val_loss: 0.5465 - val_accuracy: 0.8041\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6074 - accuracy: 0.7399 - val_loss: 0.5371 - val_accuracy: 0.8041\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6216 - accuracy: 0.7179 - val_loss: 0.5381 - val_accuracy: 0.8041\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5712 - accuracy: 0.7669 - val_loss: 0.5245 - val_accuracy: 0.8108\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6191 - accuracy: 0.7399 - val_loss: 0.5187 - val_accuracy: 0.8378\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5810 - accuracy: 0.7669 - val_loss: 0.5210 - val_accuracy: 0.7973\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5638 - accuracy: 0.7686 - val_loss: 0.5154 - val_accuracy: 0.8108\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5915 - accuracy: 0.7297 - val_loss: 0.5155 - val_accuracy: 0.7973\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7753 - val_loss: 0.5027 - val_accuracy: 0.7973\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.7382 - val_loss: 0.5135 - val_accuracy: 0.8108\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5959 - accuracy: 0.7838 - val_loss: 0.5186 - val_accuracy: 0.7770\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.7280 - val_loss: 0.5153 - val_accuracy: 0.8041\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7635 - val_loss: 0.5083 - val_accuracy: 0.8041\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7618 - val_loss: 0.4962 - val_accuracy: 0.8176\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7247 - val_loss: 0.4966 - val_accuracy: 0.8108\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5844 - accuracy: 0.7787 - val_loss: 0.4947 - val_accuracy: 0.8176\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5524 - accuracy: 0.7669 - val_loss: 0.4927 - val_accuracy: 0.8041\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7601 - val_loss: 0.5041 - val_accuracy: 0.8176\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7720 - val_loss: 0.5022 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5914 - accuracy: 0.7348 - val_loss: 0.4976 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.7449 - val_loss: 0.4943 - val_accuracy: 0.8243\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5709 - accuracy: 0.7601 - val_loss: 0.4937 - val_accuracy: 0.8176\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7517 - val_loss: 0.4954 - val_accuracy: 0.8108\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5534 - accuracy: 0.7601 - val_loss: 0.4961 - val_accuracy: 0.8176\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.7787 - val_loss: 0.4931 - val_accuracy: 0.8176\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7635 - val_loss: 0.4846 - val_accuracy: 0.8243\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5741 - accuracy: 0.7686 - val_loss: 0.4932 - val_accuracy: 0.8243\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5582 - accuracy: 0.7652 - val_loss: 0.4920 - val_accuracy: 0.8108\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7804 - val_loss: 0.4930 - val_accuracy: 0.8311\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.7686 - val_loss: 0.4997 - val_accuracy: 0.8243\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5861 - accuracy: 0.7618 - val_loss: 0.5019 - val_accuracy: 0.8243\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5455 - accuracy: 0.7804 - val_loss: 0.4955 - val_accuracy: 0.8378\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5652 - accuracy: 0.7635 - val_loss: 0.4942 - val_accuracy: 0.8446\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5457 - accuracy: 0.7872 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5339 - accuracy: 0.7686 - val_loss: 0.4888 - val_accuracy: 0.8311\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5295 - accuracy: 0.7686 - val_loss: 0.4886 - val_accuracy: 0.8176\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7466 - val_loss: 0.4958 - val_accuracy: 0.8108\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7551 - val_loss: 0.4961 - val_accuracy: 0.8108\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.7382 - val_loss: 0.4926 - val_accuracy: 0.8311\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7872 - val_loss: 0.4885 - val_accuracy: 0.8108\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5609 - accuracy: 0.7551 - val_loss: 0.4889 - val_accuracy: 0.8176\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7821 - val_loss: 0.4902 - val_accuracy: 0.8378\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7652 - val_loss: 0.4953 - val_accuracy: 0.8243\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7855 - val_loss: 0.4969 - val_accuracy: 0.8311\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7736 - val_loss: 0.4995 - val_accuracy: 0.8243\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5491 - accuracy: 0.7838 - val_loss: 0.4970 - val_accuracy: 0.8176\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5545 - accuracy: 0.7939 - val_loss: 0.4930 - val_accuracy: 0.8176\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7922 - val_loss: 0.4958 - val_accuracy: 0.8176\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7753 - val_loss: 0.4987 - val_accuracy: 0.8243\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7770 - val_loss: 0.5034 - val_accuracy: 0.8108\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7939 - val_loss: 0.4991 - val_accuracy: 0.7905\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7889 - val_loss: 0.5011 - val_accuracy: 0.8108\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.8041 - val_loss: 0.5038 - val_accuracy: 0.8041\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7669 - val_loss: 0.4985 - val_accuracy: 0.7973\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.7568 - val_loss: 0.4871 - val_accuracy: 0.8041\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7652 - val_loss: 0.4876 - val_accuracy: 0.8108\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7872 - val_loss: 0.4940 - val_accuracy: 0.8041\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5302 - accuracy: 0.7973 - val_loss: 0.4885 - val_accuracy: 0.8108\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7787 - val_loss: 0.4843 - val_accuracy: 0.8176\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5215 - accuracy: 0.8007 - val_loss: 0.4858 - val_accuracy: 0.7973\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5370 - accuracy: 0.7838 - val_loss: 0.4970 - val_accuracy: 0.7973\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5763 - accuracy: 0.7821 - val_loss: 0.5031 - val_accuracy: 0.7905\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5428 - accuracy: 0.7821 - val_loss: 0.4971 - val_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5163 - accuracy: 0.8007 - val_loss: 0.5021 - val_accuracy: 0.7973\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.7551 - val_loss: 0.5011 - val_accuracy: 0.7905\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5749 - accuracy: 0.7635 - val_loss: 0.5031 - val_accuracy: 0.8041\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.7770 - val_loss: 0.5073 - val_accuracy: 0.7905\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7652 - val_loss: 0.4981 - val_accuracy: 0.8041\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7990 - val_loss: 0.5071 - val_accuracy: 0.8041\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7804 - val_loss: 0.5008 - val_accuracy: 0.7973\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7973 - val_loss: 0.4904 - val_accuracy: 0.8041\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7838 - val_loss: 0.4979 - val_accuracy: 0.8041\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7821 - val_loss: 0.5009 - val_accuracy: 0.7973\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5387 - accuracy: 0.7736 - val_loss: 0.4958 - val_accuracy: 0.7973\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7736 - val_loss: 0.4844 - val_accuracy: 0.8108\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5828 - accuracy: 0.7736 - val_loss: 0.4890 - val_accuracy: 0.8041\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5723 - accuracy: 0.7736 - val_loss: 0.4882 - val_accuracy: 0.8108\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7973 - val_loss: 0.4825 - val_accuracy: 0.8311\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7770 - val_loss: 0.4760 - val_accuracy: 0.8176\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5568 - accuracy: 0.7635 - val_loss: 0.4791 - val_accuracy: 0.8243\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7889 - val_loss: 0.4789 - val_accuracy: 0.8108\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7804 - val_loss: 0.4773 - val_accuracy: 0.8311\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7669 - val_loss: 0.4830 - val_accuracy: 0.8243\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7990 - val_loss: 0.4904 - val_accuracy: 0.8176\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7889 - val_loss: 0.4908 - val_accuracy: 0.8041\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7973 - val_loss: 0.4818 - val_accuracy: 0.8243\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.8007 - val_loss: 0.4890 - val_accuracy: 0.8108\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5604 - accuracy: 0.7669 - val_loss: 0.4948 - val_accuracy: 0.8176\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5747 - accuracy: 0.7466 - val_loss: 0.5058 - val_accuracy: 0.7973\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5394 - accuracy: 0.7770 - val_loss: 0.5005 - val_accuracy: 0.8041\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5546 - accuracy: 0.7720 - val_loss: 0.5030 - val_accuracy: 0.8108\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5005 - accuracy: 0.8041 - val_loss: 0.5009 - val_accuracy: 0.8041\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4938 - accuracy: 0.8007 - val_loss: 0.4951 - val_accuracy: 0.8176\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7821 - val_loss: 0.4954 - val_accuracy: 0.7973\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.7618 - val_loss: 0.4908 - val_accuracy: 0.8041\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5449 - accuracy: 0.7838 - val_loss: 0.4927 - val_accuracy: 0.7905\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.8024 - val_loss: 0.4895 - val_accuracy: 0.7838\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.8176 - val_loss: 0.4930 - val_accuracy: 0.7973\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5161 - accuracy: 0.7973 - val_loss: 0.5027 - val_accuracy: 0.8041\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7736 - val_loss: 0.4946 - val_accuracy: 0.7973\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7939 - val_loss: 0.4915 - val_accuracy: 0.8041\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5409 - accuracy: 0.7855 - val_loss: 0.4954 - val_accuracy: 0.8041\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.7770 - val_loss: 0.5021 - val_accuracy: 0.8041\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5129 - accuracy: 0.8057 - val_loss: 0.5120 - val_accuracy: 0.7905\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.8226 - val_loss: 0.5068 - val_accuracy: 0.7905\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5184 - accuracy: 0.8091 - val_loss: 0.5017 - val_accuracy: 0.7973\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.8125 - val_loss: 0.4975 - val_accuracy: 0.8176\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7889 - val_loss: 0.4881 - val_accuracy: 0.8176\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7855 - val_loss: 0.4853 - val_accuracy: 0.8176\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7838 - val_loss: 0.4948 - val_accuracy: 0.8108\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7787 - val_loss: 0.4919 - val_accuracy: 0.7973\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.7889 - val_loss: 0.4988 - val_accuracy: 0.7905\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5097 - accuracy: 0.7804 - val_loss: 0.4943 - val_accuracy: 0.7973\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7432 - val_loss: 0.4895 - val_accuracy: 0.7905\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7787 - val_loss: 0.4918 - val_accuracy: 0.7905\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.7720 - val_loss: 0.4969 - val_accuracy: 0.7905\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5020 - accuracy: 0.8260 - val_loss: 0.4939 - val_accuracy: 0.8041\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5302 - accuracy: 0.7905 - val_loss: 0.4906 - val_accuracy: 0.8108\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5447 - accuracy: 0.8041 - val_loss: 0.4976 - val_accuracy: 0.8176\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5477 - accuracy: 0.7770 - val_loss: 0.5009 - val_accuracy: 0.8108\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5305 - accuracy: 0.7787 - val_loss: 0.5052 - val_accuracy: 0.7905\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5395 - accuracy: 0.8108 - val_loss: 0.5075 - val_accuracy: 0.7905\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7855 - val_loss: 0.4982 - val_accuracy: 0.8108\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7872 - val_loss: 0.4991 - val_accuracy: 0.7973\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7990 - val_loss: 0.4930 - val_accuracy: 0.8041\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5451 - accuracy: 0.7905 - val_loss: 0.4954 - val_accuracy: 0.8108\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.8041 - val_loss: 0.4954 - val_accuracy: 0.8176\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7787 - val_loss: 0.4990 - val_accuracy: 0.8108\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.8057 - val_loss: 0.4878 - val_accuracy: 0.8243\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.8057 - val_loss: 0.4898 - val_accuracy: 0.8378\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7922 - val_loss: 0.5021 - val_accuracy: 0.8243\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.8007 - val_loss: 0.4999 - val_accuracy: 0.8311\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4915 - accuracy: 0.8125 - val_loss: 0.5005 - val_accuracy: 0.8176\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7838 - val_loss: 0.4953 - val_accuracy: 0.8243\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7669 - val_loss: 0.4943 - val_accuracy: 0.8108\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7990 - val_loss: 0.4967 - val_accuracy: 0.7838\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.8193 - val_loss: 0.4897 - val_accuracy: 0.8176\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.7922 - val_loss: 0.4944 - val_accuracy: 0.7905\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.8125 - val_loss: 0.4914 - val_accuracy: 0.7973\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7686 - val_loss: 0.4838 - val_accuracy: 0.8041\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7922 - val_loss: 0.4821 - val_accuracy: 0.8176\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7855 - val_loss: 0.4890 - val_accuracy: 0.8311\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.8091 - val_loss: 0.4914 - val_accuracy: 0.8243\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5267 - accuracy: 0.7821 - val_loss: 0.4985 - val_accuracy: 0.7973\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4577 - accuracy: 0.8277 - val_loss: 0.4957 - val_accuracy: 0.8108\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4963 - accuracy: 0.8159 - val_loss: 0.4932 - val_accuracy: 0.8108\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5056 - accuracy: 0.7956 - val_loss: 0.4876 - val_accuracy: 0.8108\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5210 - accuracy: 0.7703 - val_loss: 0.4863 - val_accuracy: 0.8176\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4889 - accuracy: 0.7956 - val_loss: 0.4954 - val_accuracy: 0.8176\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5106 - accuracy: 0.8260 - val_loss: 0.4929 - val_accuracy: 0.8243\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5103 - accuracy: 0.7956 - val_loss: 0.5003 - val_accuracy: 0.8041\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.8024 - val_loss: 0.5041 - val_accuracy: 0.8243\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7821 - val_loss: 0.5015 - val_accuracy: 0.8243\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.8007 - val_loss: 0.4925 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7973 - val_loss: 0.4867 - val_accuracy: 0.8243\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7922 - val_loss: 0.4873 - val_accuracy: 0.8243\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5292 - accuracy: 0.7905 - val_loss: 0.4765 - val_accuracy: 0.8311\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.8074 - val_loss: 0.4787 - val_accuracy: 0.8311\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7770 - val_loss: 0.4834 - val_accuracy: 0.8311\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.8176 - val_loss: 0.4763 - val_accuracy: 0.8311\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.8007 - val_loss: 0.4805 - val_accuracy: 0.8378\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7804 - val_loss: 0.4783 - val_accuracy: 0.8378\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.8108 - val_loss: 0.4821 - val_accuracy: 0.8176\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7922 - val_loss: 0.4913 - val_accuracy: 0.8176\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.8193 - val_loss: 0.5033 - val_accuracy: 0.8108\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8209 - val_loss: 0.4923 - val_accuracy: 0.8041\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5484 - accuracy: 0.7939 - val_loss: 0.4851 - val_accuracy: 0.8243\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.8091 - val_loss: 0.4770 - val_accuracy: 0.8311\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.8074 - val_loss: 0.4719 - val_accuracy: 0.8311\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.8125 - val_loss: 0.4725 - val_accuracy: 0.8311\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.8074 - val_loss: 0.4729 - val_accuracy: 0.8311\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5202 - accuracy: 0.7973 - val_loss: 0.4774 - val_accuracy: 0.8378\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5197 - accuracy: 0.7889 - val_loss: 0.4774 - val_accuracy: 0.8378\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5391 - accuracy: 0.8007 - val_loss: 0.4751 - val_accuracy: 0.8311\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5539 - accuracy: 0.7804 - val_loss: 0.4761 - val_accuracy: 0.8311\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5049 - accuracy: 0.8176 - val_loss: 0.4756 - val_accuracy: 0.8378\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5300 - accuracy: 0.7686 - val_loss: 0.4790 - val_accuracy: 0.8243\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.8142 - val_loss: 0.4735 - val_accuracy: 0.8378\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5057 - accuracy: 0.7990 - val_loss: 0.4763 - val_accuracy: 0.8311\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.8125 - val_loss: 0.4732 - val_accuracy: 0.8108\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.8057 - val_loss: 0.4674 - val_accuracy: 0.8108\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5389 - accuracy: 0.7838 - val_loss: 0.4688 - val_accuracy: 0.8108\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7855 - val_loss: 0.4717 - val_accuracy: 0.7905\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7804 - val_loss: 0.4691 - val_accuracy: 0.8108\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.8378 - val_loss: 0.4669 - val_accuracy: 0.8041\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7686 - val_loss: 0.4723 - val_accuracy: 0.8176\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.8193 - val_loss: 0.4754 - val_accuracy: 0.8243\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.8193 - val_loss: 0.4745 - val_accuracy: 0.8041\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.8193 - val_loss: 0.4823 - val_accuracy: 0.8176\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.8142 - val_loss: 0.4870 - val_accuracy: 0.7905\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7922 - val_loss: 0.4772 - val_accuracy: 0.8108\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.8041 - val_loss: 0.4645 - val_accuracy: 0.8108\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8277 - val_loss: 0.4718 - val_accuracy: 0.8041\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.8074 - val_loss: 0.4723 - val_accuracy: 0.8041\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7956 - val_loss: 0.4724 - val_accuracy: 0.8378\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5084 - accuracy: 0.8007 - val_loss: 0.4706 - val_accuracy: 0.8176\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.8057 - val_loss: 0.4708 - val_accuracy: 0.8176\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7872 - val_loss: 0.4663 - val_accuracy: 0.8446\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4915 - accuracy: 0.8041 - val_loss: 0.4737 - val_accuracy: 0.8243\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4766 - accuracy: 0.8091 - val_loss: 0.4842 - val_accuracy: 0.8176\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5312 - accuracy: 0.8007 - val_loss: 0.4736 - val_accuracy: 0.8378\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5099 - accuracy: 0.7956 - val_loss: 0.4803 - val_accuracy: 0.7838\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4954 - accuracy: 0.8108 - val_loss: 0.4694 - val_accuracy: 0.8041\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5264 - accuracy: 0.8024 - val_loss: 0.4800 - val_accuracy: 0.8176\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5349 - accuracy: 0.7618 - val_loss: 0.4771 - val_accuracy: 0.8243\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5144 - accuracy: 0.7990 - val_loss: 0.4728 - val_accuracy: 0.8243\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.8159 - val_loss: 0.4726 - val_accuracy: 0.8243\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.8024 - val_loss: 0.4783 - val_accuracy: 0.8311\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.8108 - val_loss: 0.4744 - val_accuracy: 0.8108\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.8176 - val_loss: 0.4736 - val_accuracy: 0.8243\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.8108 - val_loss: 0.4772 - val_accuracy: 0.8176\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4744 - accuracy: 0.8159 - val_loss: 0.4823 - val_accuracy: 0.8176\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5019 - accuracy: 0.7905 - val_loss: 0.4738 - val_accuracy: 0.8243\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.8108 - val_loss: 0.4694 - val_accuracy: 0.8378\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.8007 - val_loss: 0.4674 - val_accuracy: 0.8311\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.8209 - val_loss: 0.4722 - val_accuracy: 0.8514\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7703 - val_loss: 0.4736 - val_accuracy: 0.8243\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.8125 - val_loss: 0.4748 - val_accuracy: 0.8378\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7939 - val_loss: 0.4820 - val_accuracy: 0.8176\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.7838 - val_loss: 0.4757 - val_accuracy: 0.8311\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7905 - val_loss: 0.4764 - val_accuracy: 0.8378\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.8142 - val_loss: 0.4760 - val_accuracy: 0.8108\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7973 - val_loss: 0.4863 - val_accuracy: 0.7973\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7956 - val_loss: 0.4805 - val_accuracy: 0.8041\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.8193 - val_loss: 0.4785 - val_accuracy: 0.7905\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.8277 - val_loss: 0.4753 - val_accuracy: 0.8243\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.8024 - val_loss: 0.4783 - val_accuracy: 0.8108\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5005 - accuracy: 0.7821 - val_loss: 0.4707 - val_accuracy: 0.7973\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4914 - accuracy: 0.8074 - val_loss: 0.4692 - val_accuracy: 0.8041\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5059 - accuracy: 0.8142 - val_loss: 0.4767 - val_accuracy: 0.8041\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5061 - accuracy: 0.8091 - val_loss: 0.4755 - val_accuracy: 0.8176\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5241 - accuracy: 0.7804 - val_loss: 0.4775 - val_accuracy: 0.8378\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4746 - accuracy: 0.8108 - val_loss: 0.4850 - val_accuracy: 0.8176\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4560 - accuracy: 0.8345 - val_loss: 0.4924 - val_accuracy: 0.8378\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7956 - val_loss: 0.4982 - val_accuracy: 0.8311\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.8142 - val_loss: 0.4909 - val_accuracy: 0.8176\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.8007 - val_loss: 0.4952 - val_accuracy: 0.8243\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.8057 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7838 - val_loss: 0.4833 - val_accuracy: 0.8108\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5294 - accuracy: 0.7804 - val_loss: 0.4935 - val_accuracy: 0.8108\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7821 - val_loss: 0.4825 - val_accuracy: 0.8041\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.8091 - val_loss: 0.4884 - val_accuracy: 0.8176\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7821 - val_loss: 0.4824 - val_accuracy: 0.8243\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.8007 - val_loss: 0.4866 - val_accuracy: 0.7973\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.8193 - val_loss: 0.4878 - val_accuracy: 0.8176\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.8294 - val_loss: 0.4822 - val_accuracy: 0.8311\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7939 - val_loss: 0.4735 - val_accuracy: 0.8243\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7990 - val_loss: 0.4622 - val_accuracy: 0.8514\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5059 - accuracy: 0.7922 - val_loss: 0.4763 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5032 - accuracy: 0.7956 - val_loss: 0.4708 - val_accuracy: 0.8243\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5137 - accuracy: 0.8159 - val_loss: 0.4790 - val_accuracy: 0.8243\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.8159 - val_loss: 0.4820 - val_accuracy: 0.8176\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4963 - accuracy: 0.7973 - val_loss: 0.4807 - val_accuracy: 0.8243\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.8024 - val_loss: 0.4787 - val_accuracy: 0.8378\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5154 - accuracy: 0.8024 - val_loss: 0.4781 - val_accuracy: 0.8311\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5158 - accuracy: 0.8007 - val_loss: 0.4764 - val_accuracy: 0.8176\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5001 - accuracy: 0.8159 - val_loss: 0.4840 - val_accuracy: 0.8108\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4926 - accuracy: 0.8125 - val_loss: 0.4843 - val_accuracy: 0.8243\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5029 - accuracy: 0.8260 - val_loss: 0.5002 - val_accuracy: 0.7973\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4956 - accuracy: 0.7872 - val_loss: 0.4992 - val_accuracy: 0.8108\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5140 - accuracy: 0.8041 - val_loss: 0.4984 - val_accuracy: 0.7905\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.8041 - val_loss: 0.4948 - val_accuracy: 0.8041\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5094 - accuracy: 0.8007 - val_loss: 0.4934 - val_accuracy: 0.8176\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7939 - val_loss: 0.4840 - val_accuracy: 0.8108\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.8108 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7990 - val_loss: 0.4961 - val_accuracy: 0.8041\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.8007 - val_loss: 0.4946 - val_accuracy: 0.8041\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.8176 - val_loss: 0.4949 - val_accuracy: 0.8041\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.7652 - val_loss: 0.4952 - val_accuracy: 0.7905\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4930 - accuracy: 0.8041 - val_loss: 0.5003 - val_accuracy: 0.7973\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4907 - accuracy: 0.8243 - val_loss: 0.4978 - val_accuracy: 0.8108\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.8226 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7990 - val_loss: 0.4871 - val_accuracy: 0.8176\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.8024 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.8243 - val_loss: 0.4941 - val_accuracy: 0.8108\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4836 - accuracy: 0.8125 - val_loss: 0.4863 - val_accuracy: 0.8041\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.8074 - val_loss: 0.4868 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.8243 - val_loss: 0.4876 - val_accuracy: 0.8243\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.8057 - val_loss: 0.4862 - val_accuracy: 0.8243\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4935 - accuracy: 0.8057 - val_loss: 0.4863 - val_accuracy: 0.8311\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5099 - accuracy: 0.8091 - val_loss: 0.4886 - val_accuracy: 0.8243\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4963 - accuracy: 0.8091 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4874 - accuracy: 0.7973 - val_loss: 0.4966 - val_accuracy: 0.8243\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5020 - accuracy: 0.8074 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5283 - accuracy: 0.7838 - val_loss: 0.4913 - val_accuracy: 0.8378\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5050 - accuracy: 0.8007 - val_loss: 0.4841 - val_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4859 - accuracy: 0.7905 - val_loss: 0.4809 - val_accuracy: 0.8446\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5070 - accuracy: 0.8007 - val_loss: 0.4794 - val_accuracy: 0.8378\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5092 - accuracy: 0.8057 - val_loss: 0.4819 - val_accuracy: 0.8108\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7956 - val_loss: 0.4776 - val_accuracy: 0.8041\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7973 - val_loss: 0.4795 - val_accuracy: 0.8311\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7905 - val_loss: 0.4833 - val_accuracy: 0.8176\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.8041 - val_loss: 0.4807 - val_accuracy: 0.8243\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7905 - val_loss: 0.4853 - val_accuracy: 0.8311\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.8226 - val_loss: 0.4878 - val_accuracy: 0.8041\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.8007 - val_loss: 0.4780 - val_accuracy: 0.8311\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.8294 - val_loss: 0.4851 - val_accuracy: 0.8176\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8277 - val_loss: 0.4805 - val_accuracy: 0.8243\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4798 - accuracy: 0.8142 - val_loss: 0.4815 - val_accuracy: 0.8176\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7973 - val_loss: 0.4894 - val_accuracy: 0.8108\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.8142 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5099 - accuracy: 0.7889 - val_loss: 0.4901 - val_accuracy: 0.8378\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.8142 - val_loss: 0.5002 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7990 - val_loss: 0.4953 - val_accuracy: 0.8176\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7990 - val_loss: 0.4998 - val_accuracy: 0.8108\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.8091 - val_loss: 0.4972 - val_accuracy: 0.8041\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5202 - accuracy: 0.7872 - val_loss: 0.4796 - val_accuracy: 0.8311\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.8193 - val_loss: 0.4821 - val_accuracy: 0.8378\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.8024 - val_loss: 0.4780 - val_accuracy: 0.8311\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4888 - accuracy: 0.8176 - val_loss: 0.4782 - val_accuracy: 0.8243\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4754 - accuracy: 0.8361 - val_loss: 0.4768 - val_accuracy: 0.8108\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4922 - accuracy: 0.8007 - val_loss: 0.4792 - val_accuracy: 0.8311\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4981 - accuracy: 0.8108 - val_loss: 0.4781 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5447 - accuracy: 0.7855 - val_loss: 0.4765 - val_accuracy: 0.8311\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4873 - accuracy: 0.8125 - val_loss: 0.4794 - val_accuracy: 0.8311\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5094 - accuracy: 0.7872 - val_loss: 0.4881 - val_accuracy: 0.8108\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4893 - accuracy: 0.8125 - val_loss: 0.4827 - val_accuracy: 0.8243\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.8328 - val_loss: 0.4888 - val_accuracy: 0.8108\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.8277 - val_loss: 0.4742 - val_accuracy: 0.8176\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8193 - val_loss: 0.4752 - val_accuracy: 0.8041\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.8226 - val_loss: 0.4709 - val_accuracy: 0.8311\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.8226 - val_loss: 0.4765 - val_accuracy: 0.8311\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.8024 - val_loss: 0.4743 - val_accuracy: 0.8311\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4957 - accuracy: 0.8125 - val_loss: 0.4767 - val_accuracy: 0.8514\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.8311 - val_loss: 0.4780 - val_accuracy: 0.8311\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.8024 - val_loss: 0.4849 - val_accuracy: 0.8378\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.8074 - val_loss: 0.4743 - val_accuracy: 0.8581\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.8159 - val_loss: 0.4785 - val_accuracy: 0.8311\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5219 - accuracy: 0.8041 - val_loss: 0.4868 - val_accuracy: 0.8311\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7973 - val_loss: 0.4792 - val_accuracy: 0.8311\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7973 - val_loss: 0.4715 - val_accuracy: 0.8243\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.8057 - val_loss: 0.4536 - val_accuracy: 0.8446\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.8209 - val_loss: 0.4664 - val_accuracy: 0.8108\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7669 - val_loss: 0.4686 - val_accuracy: 0.8311\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5334 - accuracy: 0.7905 - val_loss: 0.4662 - val_accuracy: 0.8311\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.8159 - val_loss: 0.4717 - val_accuracy: 0.8243\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.8159 - val_loss: 0.4691 - val_accuracy: 0.8378\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4799 - accuracy: 0.8345 - val_loss: 0.4708 - val_accuracy: 0.8378\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4999 - accuracy: 0.8193 - val_loss: 0.4771 - val_accuracy: 0.8176\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4704 - accuracy: 0.8176 - val_loss: 0.4711 - val_accuracy: 0.8243\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4982 - accuracy: 0.8007 - val_loss: 0.4710 - val_accuracy: 0.8243\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4611 - accuracy: 0.8412 - val_loss: 0.4789 - val_accuracy: 0.8378\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4693 - accuracy: 0.8125 - val_loss: 0.4688 - val_accuracy: 0.8446\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4541 - accuracy: 0.8159 - val_loss: 0.4708 - val_accuracy: 0.8311\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4817 - accuracy: 0.8361 - val_loss: 0.4762 - val_accuracy: 0.8378\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4555 - accuracy: 0.8463 - val_loss: 0.4610 - val_accuracy: 0.8378\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.8260 - val_loss: 0.4649 - val_accuracy: 0.8581\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4752 - accuracy: 0.8378 - val_loss: 0.4609 - val_accuracy: 0.8446\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5014 - accuracy: 0.8176 - val_loss: 0.4680 - val_accuracy: 0.8446\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.8159 - val_loss: 0.4730 - val_accuracy: 0.8176\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7770 - val_loss: 0.4629 - val_accuracy: 0.8311\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.8057 - val_loss: 0.4583 - val_accuracy: 0.8378\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.8176 - val_loss: 0.4633 - val_accuracy: 0.8311\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4686 - accuracy: 0.8311 - val_loss: 0.4591 - val_accuracy: 0.8378\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.8142 - val_loss: 0.4554 - val_accuracy: 0.8311\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4977 - accuracy: 0.8024 - val_loss: 0.4601 - val_accuracy: 0.8378\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4998 - accuracy: 0.8091 - val_loss: 0.4560 - val_accuracy: 0.8514\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.8142 - val_loss: 0.4570 - val_accuracy: 0.8514\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.8125 - val_loss: 0.4555 - val_accuracy: 0.8378\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.8243 - val_loss: 0.4593 - val_accuracy: 0.8514\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.8142 - val_loss: 0.4603 - val_accuracy: 0.8514\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8142 - val_loss: 0.4662 - val_accuracy: 0.8243\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.8193 - val_loss: 0.4607 - val_accuracy: 0.8311\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5271 - accuracy: 0.8041 - val_loss: 0.4520 - val_accuracy: 0.8378\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.8108 - val_loss: 0.4606 - val_accuracy: 0.8514\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4813 - accuracy: 0.8108 - val_loss: 0.4680 - val_accuracy: 0.8378\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4814 - accuracy: 0.8041 - val_loss: 0.4617 - val_accuracy: 0.8378\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5343 - accuracy: 0.8057 - val_loss: 0.4661 - val_accuracy: 0.8243\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5245 - accuracy: 0.7956 - val_loss: 0.4771 - val_accuracy: 0.8243\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5047 - accuracy: 0.8007 - val_loss: 0.4765 - val_accuracy: 0.8311\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5100 - accuracy: 0.7973 - val_loss: 0.4830 - val_accuracy: 0.8176\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5012 - accuracy: 0.8074 - val_loss: 0.4853 - val_accuracy: 0.8311\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.8057 - val_loss: 0.4761 - val_accuracy: 0.8446\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5109 - accuracy: 0.7821 - val_loss: 0.4659 - val_accuracy: 0.8311\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5024 - accuracy: 0.8024 - val_loss: 0.4599 - val_accuracy: 0.8514\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.8125 - val_loss: 0.4464 - val_accuracy: 0.8514\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.8311 - val_loss: 0.4472 - val_accuracy: 0.8514\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.8193 - val_loss: 0.4450 - val_accuracy: 0.8581\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8277 - val_loss: 0.4482 - val_accuracy: 0.8581\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.7956 - val_loss: 0.4624 - val_accuracy: 0.8446\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7922 - val_loss: 0.4571 - val_accuracy: 0.8514\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.8209 - val_loss: 0.4642 - val_accuracy: 0.8446\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.8345 - val_loss: 0.4608 - val_accuracy: 0.8514\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7990 - val_loss: 0.4636 - val_accuracy: 0.8446\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4658 - accuracy: 0.8142 - val_loss: 0.4736 - val_accuracy: 0.8446\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7939 - val_loss: 0.4712 - val_accuracy: 0.8581\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4972 - accuracy: 0.8024 - val_loss: 0.4764 - val_accuracy: 0.8581\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.8057 - val_loss: 0.4665 - val_accuracy: 0.8514\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4939 - accuracy: 0.7872 - val_loss: 0.4623 - val_accuracy: 0.8649\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.8125 - val_loss: 0.4621 - val_accuracy: 0.8581\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4957 - accuracy: 0.7990 - val_loss: 0.4610 - val_accuracy: 0.8514\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4674 - accuracy: 0.8277 - val_loss: 0.4703 - val_accuracy: 0.8514\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5017 - accuracy: 0.8378 - val_loss: 0.4654 - val_accuracy: 0.8784\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4938 - accuracy: 0.8108 - val_loss: 0.4661 - val_accuracy: 0.8649\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4885 - accuracy: 0.8193 - val_loss: 0.4702 - val_accuracy: 0.8378\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4961 - accuracy: 0.8108 - val_loss: 0.4722 - val_accuracy: 0.8311\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4755 - accuracy: 0.8159 - val_loss: 0.4661 - val_accuracy: 0.8514\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4777 - accuracy: 0.7889 - val_loss: 0.4654 - val_accuracy: 0.8311\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5246 - accuracy: 0.8108 - val_loss: 0.4598 - val_accuracy: 0.8514\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4918 - accuracy: 0.8024 - val_loss: 0.4727 - val_accuracy: 0.8243\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.8108 - val_loss: 0.4683 - val_accuracy: 0.8378\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5115 - accuracy: 0.8057 - val_loss: 0.4830 - val_accuracy: 0.8243\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7889 - val_loss: 0.4818 - val_accuracy: 0.8243\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4652 - accuracy: 0.8125 - val_loss: 0.4884 - val_accuracy: 0.8243\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.7922 - val_loss: 0.4953 - val_accuracy: 0.8176\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.8176\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-29c08035a301>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 11ms/step - loss: 1.9235 - accuracy: 0.5034 - val_loss: 1.1335 - val_accuracy: 0.5878\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6768 - accuracy: 0.5203 - val_loss: 1.1268 - val_accuracy: 0.5405\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5552 - accuracy: 0.4882 - val_loss: 1.1134 - val_accuracy: 0.5541\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4115 - accuracy: 0.5270 - val_loss: 1.0983 - val_accuracy: 0.5676\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3290 - accuracy: 0.5473 - val_loss: 1.0818 - val_accuracy: 0.6014\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.2573 - accuracy: 0.5236 - val_loss: 1.0710 - val_accuracy: 0.6149\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.2506 - accuracy: 0.5372 - val_loss: 1.0604 - val_accuracy: 0.5946\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.2646 - accuracy: 0.4848 - val_loss: 1.0573 - val_accuracy: 0.6014\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1636 - accuracy: 0.4882 - val_loss: 1.0527 - val_accuracy: 0.6014\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1344 - accuracy: 0.5405 - val_loss: 1.0480 - val_accuracy: 0.6149\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.1128 - accuracy: 0.5236 - val_loss: 1.0383 - val_accuracy: 0.6149\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0830 - accuracy: 0.4848 - val_loss: 1.0282 - val_accuracy: 0.6486\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0443 - accuracy: 0.5524 - val_loss: 1.0206 - val_accuracy: 0.6419\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0425 - accuracy: 0.5422 - val_loss: 1.0128 - val_accuracy: 0.6419\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0442 - accuracy: 0.5034 - val_loss: 1.0051 - val_accuracy: 0.6689\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0300 - accuracy: 0.4966 - val_loss: 0.9992 - val_accuracy: 0.6284\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0052 - accuracy: 0.5321 - val_loss: 0.9915 - val_accuracy: 0.5608\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9833 - accuracy: 0.5507 - val_loss: 0.9832 - val_accuracy: 0.5338\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9862 - accuracy: 0.5152 - val_loss: 0.9729 - val_accuracy: 0.5473\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9769 - accuracy: 0.5118 - val_loss: 0.9640 - val_accuracy: 0.5608\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9640 - accuracy: 0.5220 - val_loss: 0.9547 - val_accuracy: 0.6014\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9428 - accuracy: 0.5439 - val_loss: 0.9445 - val_accuracy: 0.6014\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9379 - accuracy: 0.5709 - val_loss: 0.9340 - val_accuracy: 0.6014\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9310 - accuracy: 0.5591 - val_loss: 0.9265 - val_accuracy: 0.5608\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9191 - accuracy: 0.5743 - val_loss: 0.9117 - val_accuracy: 0.6486\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9179 - accuracy: 0.5405 - val_loss: 0.9076 - val_accuracy: 0.5676\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9030 - accuracy: 0.5439 - val_loss: 0.8946 - val_accuracy: 0.6081\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8935 - accuracy: 0.5811 - val_loss: 0.8812 - val_accuracy: 0.6892\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8794 - accuracy: 0.5642 - val_loss: 0.8699 - val_accuracy: 0.6486\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8679 - accuracy: 0.5777 - val_loss: 0.8535 - val_accuracy: 0.7162\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8519 - accuracy: 0.5980 - val_loss: 0.8435 - val_accuracy: 0.6892\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8505 - accuracy: 0.5794 - val_loss: 0.8260 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8153 - accuracy: 0.6368 - val_loss: 0.8108 - val_accuracy: 0.7432\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8350 - accuracy: 0.5878 - val_loss: 0.8006 - val_accuracy: 0.7230\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.8316 - accuracy: 0.5642 - val_loss: 0.7932 - val_accuracy: 0.7230\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8194 - accuracy: 0.6233 - val_loss: 0.7873 - val_accuracy: 0.7162\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7885 - accuracy: 0.6318 - val_loss: 0.7686 - val_accuracy: 0.7432\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7910 - accuracy: 0.6199 - val_loss: 0.7606 - val_accuracy: 0.7162\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7898 - accuracy: 0.6047 - val_loss: 0.7437 - val_accuracy: 0.7230\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7779 - accuracy: 0.6182 - val_loss: 0.7398 - val_accuracy: 0.6959\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7690 - accuracy: 0.6267 - val_loss: 0.7297 - val_accuracy: 0.7162\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7689 - accuracy: 0.6199 - val_loss: 0.7197 - val_accuracy: 0.7365\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7309 - accuracy: 0.6774 - val_loss: 0.7103 - val_accuracy: 0.7297\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.6537 - val_loss: 0.6935 - val_accuracy: 0.7432\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7218 - accuracy: 0.6791 - val_loss: 0.6842 - val_accuracy: 0.7365\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7468 - accuracy: 0.6723 - val_loss: 0.6829 - val_accuracy: 0.7500\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7151 - accuracy: 0.6858 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7160 - accuracy: 0.6672 - val_loss: 0.6787 - val_accuracy: 0.7500\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7075 - accuracy: 0.6943 - val_loss: 0.6659 - val_accuracy: 0.7297\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.6959 - val_loss: 0.6611 - val_accuracy: 0.7500\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.7128 - val_loss: 0.6594 - val_accuracy: 0.7297\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.7027 - val_loss: 0.6490 - val_accuracy: 0.7432\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6700 - accuracy: 0.7095 - val_loss: 0.6466 - val_accuracy: 0.7432\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.7162 - val_loss: 0.6459 - val_accuracy: 0.7297\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7213 - val_loss: 0.6435 - val_accuracy: 0.7432\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7179 - val_loss: 0.6345 - val_accuracy: 0.7568\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6401 - accuracy: 0.7196 - val_loss: 0.6215 - val_accuracy: 0.7568\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6584 - accuracy: 0.6909 - val_loss: 0.6250 - val_accuracy: 0.7568\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6509 - accuracy: 0.6926 - val_loss: 0.6171 - val_accuracy: 0.7635\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6425 - accuracy: 0.7348 - val_loss: 0.6204 - val_accuracy: 0.7500\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6144 - accuracy: 0.7314 - val_loss: 0.6123 - val_accuracy: 0.7365\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6367 - accuracy: 0.6976 - val_loss: 0.6093 - val_accuracy: 0.7568\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6688 - accuracy: 0.6959 - val_loss: 0.6114 - val_accuracy: 0.7703\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6327 - accuracy: 0.7196 - val_loss: 0.6040 - val_accuracy: 0.7770\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6073 - accuracy: 0.7466 - val_loss: 0.6010 - val_accuracy: 0.7703\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6419 - accuracy: 0.7128 - val_loss: 0.5859 - val_accuracy: 0.7905\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6260 - accuracy: 0.7432 - val_loss: 0.5861 - val_accuracy: 0.7905\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.7179 - val_loss: 0.5900 - val_accuracy: 0.7905\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.7973\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.7382 - val_loss: 0.5831 - val_accuracy: 0.7905\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6267 - accuracy: 0.7280 - val_loss: 0.5734 - val_accuracy: 0.7838\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6587 - accuracy: 0.6993 - val_loss: 0.5834 - val_accuracy: 0.7973\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7466 - val_loss: 0.5799 - val_accuracy: 0.7838\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6104 - accuracy: 0.7432 - val_loss: 0.5783 - val_accuracy: 0.7905\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.7517 - val_loss: 0.5753 - val_accuracy: 0.7703\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7500 - val_loss: 0.5704 - val_accuracy: 0.7905\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6225 - accuracy: 0.7551 - val_loss: 0.5709 - val_accuracy: 0.7703\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.7584 - val_loss: 0.5694 - val_accuracy: 0.7635\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7534 - val_loss: 0.5681 - val_accuracy: 0.7703\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.7517 - val_loss: 0.5574 - val_accuracy: 0.7703\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5883 - accuracy: 0.7534 - val_loss: 0.5562 - val_accuracy: 0.7838\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.7331 - val_loss: 0.5524 - val_accuracy: 0.7838\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.7534 - val_loss: 0.5523 - val_accuracy: 0.7838\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5970 - accuracy: 0.7399 - val_loss: 0.5612 - val_accuracy: 0.7703\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5977 - accuracy: 0.7365 - val_loss: 0.5624 - val_accuracy: 0.7568\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7821 - val_loss: 0.5527 - val_accuracy: 0.7703\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.7348 - val_loss: 0.5561 - val_accuracy: 0.7703\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5765 - accuracy: 0.7466 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5959 - accuracy: 0.7618 - val_loss: 0.5699 - val_accuracy: 0.7635\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7703 - val_loss: 0.5577 - val_accuracy: 0.7770\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5633 - accuracy: 0.7618 - val_loss: 0.5577 - val_accuracy: 0.7500\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5909 - accuracy: 0.7652 - val_loss: 0.5660 - val_accuracy: 0.7568\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5651 - accuracy: 0.7652 - val_loss: 0.5575 - val_accuracy: 0.7703\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6013 - accuracy: 0.7584 - val_loss: 0.5532 - val_accuracy: 0.7635\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.7382 - val_loss: 0.5420 - val_accuracy: 0.7770\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.7635 - val_loss: 0.5277 - val_accuracy: 0.8108\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5722 - accuracy: 0.7466 - val_loss: 0.5282 - val_accuracy: 0.7905\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7770 - val_loss: 0.5326 - val_accuracy: 0.7905\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5632 - accuracy: 0.7618 - val_loss: 0.5359 - val_accuracy: 0.7838\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7652 - val_loss: 0.5389 - val_accuracy: 0.7838\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5542 - accuracy: 0.7686 - val_loss: 0.5441 - val_accuracy: 0.7973\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7517 - val_loss: 0.5360 - val_accuracy: 0.7770\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7939 - val_loss: 0.5346 - val_accuracy: 0.7703\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.7601 - val_loss: 0.5286 - val_accuracy: 0.7838\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7939 - val_loss: 0.5319 - val_accuracy: 0.7838\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5580 - accuracy: 0.7652 - val_loss: 0.5271 - val_accuracy: 0.7635\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7669 - val_loss: 0.5160 - val_accuracy: 0.7973\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5890 - accuracy: 0.7601 - val_loss: 0.5231 - val_accuracy: 0.7905\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.7584 - val_loss: 0.5228 - val_accuracy: 0.7905\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.7264 - val_loss: 0.5422 - val_accuracy: 0.7770\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.7584 - val_loss: 0.5446 - val_accuracy: 0.7770\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5786 - accuracy: 0.7635 - val_loss: 0.5355 - val_accuracy: 0.7838\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7483 - val_loss: 0.5407 - val_accuracy: 0.7973\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7956 - val_loss: 0.5377 - val_accuracy: 0.7905\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5881 - accuracy: 0.7297 - val_loss: 0.5259 - val_accuracy: 0.8108\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5562 - accuracy: 0.7753 - val_loss: 0.5272 - val_accuracy: 0.8041\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5685 - accuracy: 0.7889 - val_loss: 0.5349 - val_accuracy: 0.7973\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5728 - accuracy: 0.7703 - val_loss: 0.5351 - val_accuracy: 0.7973\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6228 - accuracy: 0.7348 - val_loss: 0.5401 - val_accuracy: 0.8041\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5618 - accuracy: 0.7736 - val_loss: 0.5463 - val_accuracy: 0.7770\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5151 - accuracy: 0.8142 - val_loss: 0.5383 - val_accuracy: 0.7838\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.7889 - val_loss: 0.5415 - val_accuracy: 0.7905\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.7365 - val_loss: 0.5392 - val_accuracy: 0.7905\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7787 - val_loss: 0.5254 - val_accuracy: 0.7905\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7686 - val_loss: 0.5218 - val_accuracy: 0.7838\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7804 - val_loss: 0.5395 - val_accuracy: 0.7905\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.7872 - val_loss: 0.5204 - val_accuracy: 0.8108\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7770 - val_loss: 0.5204 - val_accuracy: 0.7905\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7889 - val_loss: 0.5273 - val_accuracy: 0.8108\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7973 - val_loss: 0.5298 - val_accuracy: 0.7905\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.7534 - val_loss: 0.5366 - val_accuracy: 0.7905\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5558 - accuracy: 0.7821 - val_loss: 0.5255 - val_accuracy: 0.7905\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7889 - val_loss: 0.5305 - val_accuracy: 0.7770\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7703 - val_loss: 0.5196 - val_accuracy: 0.7973\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5609 - accuracy: 0.7618 - val_loss: 0.5142 - val_accuracy: 0.7905\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7432 - val_loss: 0.5106 - val_accuracy: 0.8108\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7889 - val_loss: 0.5216 - val_accuracy: 0.7703\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7568 - val_loss: 0.5207 - val_accuracy: 0.7703\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7720 - val_loss: 0.5158 - val_accuracy: 0.7770\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7922 - val_loss: 0.5271 - val_accuracy: 0.7568\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7939 - val_loss: 0.5254 - val_accuracy: 0.7838\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.8057 - val_loss: 0.5378 - val_accuracy: 0.7703\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7736 - val_loss: 0.5357 - val_accuracy: 0.7770\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5387 - accuracy: 0.7922 - val_loss: 0.5421 - val_accuracy: 0.7838\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7753 - val_loss: 0.5294 - val_accuracy: 0.7703\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5622 - accuracy: 0.7787 - val_loss: 0.5312 - val_accuracy: 0.7635\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5644 - accuracy: 0.7686 - val_loss: 0.5289 - val_accuracy: 0.7770\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5402 - accuracy: 0.7855 - val_loss: 0.5294 - val_accuracy: 0.7905\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5234 - accuracy: 0.7990 - val_loss: 0.5300 - val_accuracy: 0.7838\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5448 - accuracy: 0.7770 - val_loss: 0.5296 - val_accuracy: 0.7703\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7990 - val_loss: 0.5243 - val_accuracy: 0.7568\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5380 - accuracy: 0.7872 - val_loss: 0.5279 - val_accuracy: 0.7770\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5495 - accuracy: 0.7618 - val_loss: 0.5315 - val_accuracy: 0.7703\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5532 - accuracy: 0.7905 - val_loss: 0.5160 - val_accuracy: 0.7770\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5712 - accuracy: 0.7720 - val_loss: 0.5098 - val_accuracy: 0.8041\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7584 - val_loss: 0.5167 - val_accuracy: 0.7905\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7872 - val_loss: 0.5227 - val_accuracy: 0.7838\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7855 - val_loss: 0.5162 - val_accuracy: 0.7703\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7922 - val_loss: 0.5037 - val_accuracy: 0.7838\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5344 - accuracy: 0.7838 - val_loss: 0.5051 - val_accuracy: 0.7905\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5354 - accuracy: 0.7990 - val_loss: 0.5141 - val_accuracy: 0.7973\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7855 - val_loss: 0.5243 - val_accuracy: 0.7635\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7736 - val_loss: 0.5171 - val_accuracy: 0.7703\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7838 - val_loss: 0.5079 - val_accuracy: 0.8041\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5619 - accuracy: 0.7551 - val_loss: 0.5067 - val_accuracy: 0.8041\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7787 - val_loss: 0.5162 - val_accuracy: 0.7838\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.8176 - val_loss: 0.5248 - val_accuracy: 0.7905\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7736 - val_loss: 0.5008 - val_accuracy: 0.8041\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7872 - val_loss: 0.5142 - val_accuracy: 0.7973\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.8024 - val_loss: 0.5096 - val_accuracy: 0.7973\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.8041 - val_loss: 0.4976 - val_accuracy: 0.8041\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5525 - accuracy: 0.7720 - val_loss: 0.5000 - val_accuracy: 0.7838\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4939 - accuracy: 0.8091 - val_loss: 0.4985 - val_accuracy: 0.7770\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5095 - accuracy: 0.7990 - val_loss: 0.5115 - val_accuracy: 0.7703\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5687 - accuracy: 0.7517 - val_loss: 0.5147 - val_accuracy: 0.7973\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5333 - accuracy: 0.7753 - val_loss: 0.5167 - val_accuracy: 0.7905\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5630 - accuracy: 0.7753 - val_loss: 0.5179 - val_accuracy: 0.7973\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5422 - accuracy: 0.7838 - val_loss: 0.5041 - val_accuracy: 0.7905\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7855 - val_loss: 0.5150 - val_accuracy: 0.7635\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.7990 - val_loss: 0.5168 - val_accuracy: 0.7838\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7584 - val_loss: 0.5243 - val_accuracy: 0.7770\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7618 - val_loss: 0.5291 - val_accuracy: 0.7838\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7804 - val_loss: 0.5180 - val_accuracy: 0.7905\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.8041 - val_loss: 0.5031 - val_accuracy: 0.7973\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7804 - val_loss: 0.5066 - val_accuracy: 0.7973\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5505 - accuracy: 0.8007 - val_loss: 0.5072 - val_accuracy: 0.7973\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7804 - val_loss: 0.5165 - val_accuracy: 0.7770\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.8091 - val_loss: 0.5071 - val_accuracy: 0.7905\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7990 - val_loss: 0.5178 - val_accuracy: 0.7838\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7669 - val_loss: 0.5030 - val_accuracy: 0.7973\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.8226 - val_loss: 0.5063 - val_accuracy: 0.7973\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5199 - accuracy: 0.8074 - val_loss: 0.5002 - val_accuracy: 0.8041\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.8057 - val_loss: 0.5146 - val_accuracy: 0.7838\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.8091 - val_loss: 0.5091 - val_accuracy: 0.7973\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.8057 - val_loss: 0.5012 - val_accuracy: 0.8108\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7973 - val_loss: 0.5030 - val_accuracy: 0.8176\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.8057 - val_loss: 0.5200 - val_accuracy: 0.8176\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5583 - accuracy: 0.7736 - val_loss: 0.5189 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7956 - val_loss: 0.5146 - val_accuracy: 0.8108\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5322 - accuracy: 0.7804 - val_loss: 0.5200 - val_accuracy: 0.8041\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5167 - accuracy: 0.8091 - val_loss: 0.5153 - val_accuracy: 0.8108\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5092 - accuracy: 0.8159 - val_loss: 0.5138 - val_accuracy: 0.8041\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5419 - accuracy: 0.7568 - val_loss: 0.5200 - val_accuracy: 0.7973\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5067 - accuracy: 0.7635 - val_loss: 0.5150 - val_accuracy: 0.8041\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5177 - accuracy: 0.7821 - val_loss: 0.5185 - val_accuracy: 0.8041\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5284 - accuracy: 0.7855 - val_loss: 0.5131 - val_accuracy: 0.8041\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.7973 - val_loss: 0.5146 - val_accuracy: 0.8041\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.8007 - val_loss: 0.5122 - val_accuracy: 0.8041\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.8074 - val_loss: 0.5147 - val_accuracy: 0.8041\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7922 - val_loss: 0.5214 - val_accuracy: 0.8041\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.7686 - val_loss: 0.5114 - val_accuracy: 0.7973\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7855 - val_loss: 0.5182 - val_accuracy: 0.7905\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.8024 - val_loss: 0.5244 - val_accuracy: 0.7905\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.8243 - val_loss: 0.5150 - val_accuracy: 0.7838\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7973 - val_loss: 0.5213 - val_accuracy: 0.7973\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.8108 - val_loss: 0.5215 - val_accuracy: 0.7905\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7736 - val_loss: 0.5134 - val_accuracy: 0.7905\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5168 - accuracy: 0.7956 - val_loss: 0.5179 - val_accuracy: 0.7905\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7889 - val_loss: 0.5195 - val_accuracy: 0.7905\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7855 - val_loss: 0.5021 - val_accuracy: 0.8041\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5743 - accuracy: 0.7973 - val_loss: 0.5121 - val_accuracy: 0.8108\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5529 - accuracy: 0.7720 - val_loss: 0.5153 - val_accuracy: 0.8041\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7905 - val_loss: 0.5144 - val_accuracy: 0.7973\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7770 - val_loss: 0.5127 - val_accuracy: 0.8041\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7787 - val_loss: 0.5177 - val_accuracy: 0.7973\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5208 - accuracy: 0.7736 - val_loss: 0.5140 - val_accuracy: 0.8041\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.8007 - val_loss: 0.5173 - val_accuracy: 0.7973\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4889 - accuracy: 0.8226 - val_loss: 0.5134 - val_accuracy: 0.7905\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5079 - accuracy: 0.7939 - val_loss: 0.5166 - val_accuracy: 0.7905\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5120 - accuracy: 0.8243 - val_loss: 0.4919 - val_accuracy: 0.8378\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5111 - accuracy: 0.8024 - val_loss: 0.4990 - val_accuracy: 0.7973\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5240 - accuracy: 0.8007 - val_loss: 0.4987 - val_accuracy: 0.7973\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5561 - accuracy: 0.7872 - val_loss: 0.5037 - val_accuracy: 0.7905\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5151 - accuracy: 0.8159 - val_loss: 0.5087 - val_accuracy: 0.7838\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7973 - val_loss: 0.5180 - val_accuracy: 0.7973\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7922 - val_loss: 0.5163 - val_accuracy: 0.7703\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5162 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7905\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7838 - val_loss: 0.5086 - val_accuracy: 0.7838\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.8176 - val_loss: 0.5082 - val_accuracy: 0.8041\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7686 - val_loss: 0.5073 - val_accuracy: 0.8041\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7736 - val_loss: 0.5066 - val_accuracy: 0.8108\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.8074 - val_loss: 0.5121 - val_accuracy: 0.7770\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.8193 - val_loss: 0.4973 - val_accuracy: 0.7905\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7787 - val_loss: 0.5030 - val_accuracy: 0.7770\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.7922 - val_loss: 0.4968 - val_accuracy: 0.7973\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7838 - val_loss: 0.4980 - val_accuracy: 0.7905\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7922 - val_loss: 0.5026 - val_accuracy: 0.7770\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.8057 - val_loss: 0.5072 - val_accuracy: 0.7905\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.8226 - val_loss: 0.5111 - val_accuracy: 0.7838\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7990 - val_loss: 0.5225 - val_accuracy: 0.7838\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7770 - val_loss: 0.5185 - val_accuracy: 0.7770\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7821 - val_loss: 0.5204 - val_accuracy: 0.7703\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7821 - val_loss: 0.4959 - val_accuracy: 0.7973\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5167 - accuracy: 0.8074 - val_loss: 0.5086 - val_accuracy: 0.7838\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5232 - accuracy: 0.7787 - val_loss: 0.5142 - val_accuracy: 0.7838\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5236 - accuracy: 0.7855 - val_loss: 0.5273 - val_accuracy: 0.7905\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5211 - accuracy: 0.7990 - val_loss: 0.5172 - val_accuracy: 0.7973\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5205 - accuracy: 0.7838 - val_loss: 0.5061 - val_accuracy: 0.7973\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4820 - accuracy: 0.8176 - val_loss: 0.5063 - val_accuracy: 0.8041\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5077 - accuracy: 0.8142 - val_loss: 0.5076 - val_accuracy: 0.7905\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4714 - accuracy: 0.8091 - val_loss: 0.5074 - val_accuracy: 0.7905\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.8057 - val_loss: 0.4968 - val_accuracy: 0.7973\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.8007 - val_loss: 0.4943 - val_accuracy: 0.7973\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7990 - val_loss: 0.5029 - val_accuracy: 0.7905\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7838 - val_loss: 0.5062 - val_accuracy: 0.7905\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.8057 - val_loss: 0.5016 - val_accuracy: 0.7973\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.8159 - val_loss: 0.5091 - val_accuracy: 0.7838\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.8277 - val_loss: 0.5302 - val_accuracy: 0.7703\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7804 - val_loss: 0.5163 - val_accuracy: 0.7838\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.8125 - val_loss: 0.5176 - val_accuracy: 0.7905\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7956 - val_loss: 0.5320 - val_accuracy: 0.7770\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7905 - val_loss: 0.5150 - val_accuracy: 0.7973\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7905 - val_loss: 0.5192 - val_accuracy: 0.7973\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.8007 - val_loss: 0.5145 - val_accuracy: 0.7905\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.7973 - val_loss: 0.5195 - val_accuracy: 0.7838\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.8108 - val_loss: 0.5120 - val_accuracy: 0.7973\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.8074 - val_loss: 0.5123 - val_accuracy: 0.7905\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7956 - val_loss: 0.5137 - val_accuracy: 0.7838\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4911 - accuracy: 0.7939 - val_loss: 0.5162 - val_accuracy: 0.7905\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7855 - val_loss: 0.5167 - val_accuracy: 0.7973\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5138 - accuracy: 0.8074 - val_loss: 0.5136 - val_accuracy: 0.7770\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4996 - accuracy: 0.8209 - val_loss: 0.5020 - val_accuracy: 0.7973\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5107 - accuracy: 0.8057 - val_loss: 0.4980 - val_accuracy: 0.7973\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5059 - accuracy: 0.7956 - val_loss: 0.4947 - val_accuracy: 0.8041\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5285 - accuracy: 0.8074 - val_loss: 0.5030 - val_accuracy: 0.7838\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5248 - accuracy: 0.8041 - val_loss: 0.5115 - val_accuracy: 0.8041\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5463 - accuracy: 0.7922 - val_loss: 0.5123 - val_accuracy: 0.7770\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4881 - accuracy: 0.8176 - val_loss: 0.5054 - val_accuracy: 0.7905\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5411 - accuracy: 0.7770 - val_loss: 0.5080 - val_accuracy: 0.7770\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.8125 - val_loss: 0.4996 - val_accuracy: 0.7838\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.8041 - val_loss: 0.4891 - val_accuracy: 0.7973\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.8159 - val_loss: 0.4841 - val_accuracy: 0.8041\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5197 - accuracy: 0.7736 - val_loss: 0.4921 - val_accuracy: 0.8108\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5199 - accuracy: 0.8041 - val_loss: 0.4864 - val_accuracy: 0.7973\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7990 - val_loss: 0.5031 - val_accuracy: 0.7905\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.8007 - val_loss: 0.4923 - val_accuracy: 0.7973\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.8007 - val_loss: 0.4846 - val_accuracy: 0.8176\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4956 - accuracy: 0.8041 - val_loss: 0.4957 - val_accuracy: 0.8041\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7770 - val_loss: 0.5129 - val_accuracy: 0.7770\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.8074 - val_loss: 0.5054 - val_accuracy: 0.7838\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7922 - val_loss: 0.5116 - val_accuracy: 0.7973\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5054 - accuracy: 0.7939 - val_loss: 0.5027 - val_accuracy: 0.8041\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.8057 - val_loss: 0.5215 - val_accuracy: 0.7973\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5164 - accuracy: 0.7922 - val_loss: 0.5250 - val_accuracy: 0.7973\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4975 - accuracy: 0.8041 - val_loss: 0.5119 - val_accuracy: 0.8041\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4975 - accuracy: 0.8159 - val_loss: 0.5078 - val_accuracy: 0.7973\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5051 - accuracy: 0.7939 - val_loss: 0.5210 - val_accuracy: 0.7973\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4809 - accuracy: 0.8159 - val_loss: 0.5113 - val_accuracy: 0.7973\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5444 - accuracy: 0.7736 - val_loss: 0.5081 - val_accuracy: 0.7770\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4774 - accuracy: 0.8209 - val_loss: 0.5019 - val_accuracy: 0.8041\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4851 - accuracy: 0.8378 - val_loss: 0.5038 - val_accuracy: 0.8108\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5345 - accuracy: 0.7804 - val_loss: 0.4993 - val_accuracy: 0.7973\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5197 - accuracy: 0.8108 - val_loss: 0.4978 - val_accuracy: 0.7973\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5134 - accuracy: 0.7990 - val_loss: 0.5025 - val_accuracy: 0.7905\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5036 - accuracy: 0.7872 - val_loss: 0.5041 - val_accuracy: 0.7973\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5056 - accuracy: 0.7804 - val_loss: 0.5052 - val_accuracy: 0.7905\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.8108 - val_loss: 0.5117 - val_accuracy: 0.7838\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.8091 - val_loss: 0.5057 - val_accuracy: 0.7770\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.8057 - val_loss: 0.5097 - val_accuracy: 0.7770\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.8108 - val_loss: 0.4960 - val_accuracy: 0.7905\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7838 - val_loss: 0.4990 - val_accuracy: 0.7838\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5832 - accuracy: 0.7669 - val_loss: 0.5000 - val_accuracy: 0.7838\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.7990 - val_loss: 0.4995 - val_accuracy: 0.7838\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.8277 - val_loss: 0.5048 - val_accuracy: 0.7770\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.8125 - val_loss: 0.4998 - val_accuracy: 0.7838\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7855 - val_loss: 0.4947 - val_accuracy: 0.7838\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.7804 - val_loss: 0.4932 - val_accuracy: 0.7838\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.8074 - val_loss: 0.4914 - val_accuracy: 0.7905\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 0.8328 - val_loss: 0.5002 - val_accuracy: 0.7905\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.8074 - val_loss: 0.5034 - val_accuracy: 0.7770\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5356 - accuracy: 0.7939 - val_loss: 0.4969 - val_accuracy: 0.8041\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.8074 - val_loss: 0.4989 - val_accuracy: 0.8108\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7905 - val_loss: 0.5007 - val_accuracy: 0.7905\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.8091 - val_loss: 0.5120 - val_accuracy: 0.8041\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.8142 - val_loss: 0.5120 - val_accuracy: 0.8041\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.8260 - val_loss: 0.5105 - val_accuracy: 0.8041\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5297 - accuracy: 0.8057 - val_loss: 0.5084 - val_accuracy: 0.7838\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5005 - accuracy: 0.8243 - val_loss: 0.4888 - val_accuracy: 0.8041\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4903 - accuracy: 0.8142 - val_loss: 0.4850 - val_accuracy: 0.8176\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5099 - accuracy: 0.7956 - val_loss: 0.4964 - val_accuracy: 0.7973\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4909 - accuracy: 0.7973 - val_loss: 0.4900 - val_accuracy: 0.7973\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4772 - accuracy: 0.8159 - val_loss: 0.4930 - val_accuracy: 0.7905\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5364 - accuracy: 0.7838 - val_loss: 0.4919 - val_accuracy: 0.8041\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7736 - val_loss: 0.4778 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7872 - val_loss: 0.4858 - val_accuracy: 0.8041\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.8260 - val_loss: 0.4775 - val_accuracy: 0.8108\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8142 - val_loss: 0.4811 - val_accuracy: 0.8243\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.8057 - val_loss: 0.4813 - val_accuracy: 0.8041\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7956 - val_loss: 0.4903 - val_accuracy: 0.7905\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.8142 - val_loss: 0.5059 - val_accuracy: 0.7838\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5580 - accuracy: 0.7770 - val_loss: 0.4899 - val_accuracy: 0.7973\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.8243 - val_loss: 0.4885 - val_accuracy: 0.8108\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5110 - accuracy: 0.8041 - val_loss: 0.4870 - val_accuracy: 0.8041\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5410 - accuracy: 0.7821 - val_loss: 0.4832 - val_accuracy: 0.8108\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.8294 - val_loss: 0.4892 - val_accuracy: 0.8108\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4830 - accuracy: 0.8125 - val_loss: 0.4954 - val_accuracy: 0.7973\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.8226 - val_loss: 0.5168 - val_accuracy: 0.7905\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7905 - val_loss: 0.5267 - val_accuracy: 0.7703\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.7939 - val_loss: 0.5225 - val_accuracy: 0.7703\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7872 - val_loss: 0.5147 - val_accuracy: 0.7703\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5241 - accuracy: 0.7973 - val_loss: 0.5056 - val_accuracy: 0.7770\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.7939 - val_loss: 0.5012 - val_accuracy: 0.7838\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7821 - val_loss: 0.5150 - val_accuracy: 0.7838\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5001 - accuracy: 0.7956 - val_loss: 0.5119 - val_accuracy: 0.7838\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4941 - accuracy: 0.8125 - val_loss: 0.5067 - val_accuracy: 0.7838\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5054 - accuracy: 0.8024 - val_loss: 0.5064 - val_accuracy: 0.7905\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5132 - accuracy: 0.7889 - val_loss: 0.5105 - val_accuracy: 0.7703\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4895 - accuracy: 0.8024 - val_loss: 0.5172 - val_accuracy: 0.7770\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4971 - accuracy: 0.8142 - val_loss: 0.5243 - val_accuracy: 0.7838\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5121 - accuracy: 0.8193 - val_loss: 0.5250 - val_accuracy: 0.7905\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4804 - accuracy: 0.8057 - val_loss: 0.5062 - val_accuracy: 0.7905\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5111 - accuracy: 0.7787 - val_loss: 0.4927 - val_accuracy: 0.8041\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.8091 - val_loss: 0.5103 - val_accuracy: 0.7973\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.8074 - val_loss: 0.5093 - val_accuracy: 0.7838\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5070 - accuracy: 0.8091 - val_loss: 0.4966 - val_accuracy: 0.7973\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.8142 - val_loss: 0.5029 - val_accuracy: 0.8108\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.8091 - val_loss: 0.5046 - val_accuracy: 0.7973\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.7770 - val_loss: 0.4978 - val_accuracy: 0.8041\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4640 - accuracy: 0.8345 - val_loss: 0.4953 - val_accuracy: 0.7973\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5197 - accuracy: 0.7889 - val_loss: 0.4910 - val_accuracy: 0.8041\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.8007 - val_loss: 0.4927 - val_accuracy: 0.7905\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8041 - val_loss: 0.4889 - val_accuracy: 0.8176\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4818 - accuracy: 0.8125 - val_loss: 0.4886 - val_accuracy: 0.8176\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7990 - val_loss: 0.5060 - val_accuracy: 0.8108\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.8142 - val_loss: 0.5055 - val_accuracy: 0.7838\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7838 - val_loss: 0.5158 - val_accuracy: 0.7770\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.8125 - val_loss: 0.5272 - val_accuracy: 0.7770\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.8277 - val_loss: 0.5298 - val_accuracy: 0.7838\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7753 - val_loss: 0.5305 - val_accuracy: 0.7770\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5091 - accuracy: 0.7956 - val_loss: 0.5302 - val_accuracy: 0.7770\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4711 - accuracy: 0.8176 - val_loss: 0.5152 - val_accuracy: 0.7973\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4657 - accuracy: 0.8209 - val_loss: 0.5194 - val_accuracy: 0.8108\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4844 - accuracy: 0.8209 - val_loss: 0.5244 - val_accuracy: 0.7973\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5038 - accuracy: 0.8041 - val_loss: 0.5182 - val_accuracy: 0.7973\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5101 - accuracy: 0.8057 - val_loss: 0.5149 - val_accuracy: 0.7973\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5732 - accuracy: 0.7720 - val_loss: 0.5259 - val_accuracy: 0.7973\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4516 - accuracy: 0.8480 - val_loss: 0.5242 - val_accuracy: 0.7905\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4562 - accuracy: 0.8243 - val_loss: 0.5292 - val_accuracy: 0.7905\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.7956 - val_loss: 0.5230 - val_accuracy: 0.7905\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.7872 - val_loss: 0.5065 - val_accuracy: 0.7905\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7905 - val_loss: 0.5028 - val_accuracy: 0.7905\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.8243 - val_loss: 0.4948 - val_accuracy: 0.8041\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.8007 - val_loss: 0.4833 - val_accuracy: 0.8176\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.7973 - val_loss: 0.4948 - val_accuracy: 0.8108\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8074 - val_loss: 0.5165 - val_accuracy: 0.7838\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7973 - val_loss: 0.5125 - val_accuracy: 0.7770\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.8108 - val_loss: 0.5266 - val_accuracy: 0.7770\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.8024 - val_loss: 0.5151 - val_accuracy: 0.7770\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5158 - accuracy: 0.8125 - val_loss: 0.5072 - val_accuracy: 0.7838\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.8091 - val_loss: 0.4959 - val_accuracy: 0.7905\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7838 - val_loss: 0.5061 - val_accuracy: 0.8108\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.8142 - val_loss: 0.4983 - val_accuracy: 0.7905\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7990 - val_loss: 0.5039 - val_accuracy: 0.7905\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.8209 - val_loss: 0.5001 - val_accuracy: 0.8041\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8108 - val_loss: 0.4940 - val_accuracy: 0.7838\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4876 - accuracy: 0.8209 - val_loss: 0.5013 - val_accuracy: 0.7905\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5024 - accuracy: 0.8176 - val_loss: 0.5011 - val_accuracy: 0.7973\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5072 - accuracy: 0.7922 - val_loss: 0.4926 - val_accuracy: 0.7838\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4740 - accuracy: 0.8260 - val_loss: 0.4963 - val_accuracy: 0.7838\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4897 - accuracy: 0.8091 - val_loss: 0.4899 - val_accuracy: 0.7838\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5140 - accuracy: 0.7956 - val_loss: 0.5015 - val_accuracy: 0.7770\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5268 - accuracy: 0.7838 - val_loss: 0.4934 - val_accuracy: 0.7703\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5086 - accuracy: 0.8176 - val_loss: 0.5033 - val_accuracy: 0.7838\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4941 - accuracy: 0.8209 - val_loss: 0.5082 - val_accuracy: 0.7770\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7855 - val_loss: 0.5117 - val_accuracy: 0.7770\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5156 - accuracy: 0.7922 - val_loss: 0.5109 - val_accuracy: 0.7905\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4986 - accuracy: 0.8193 - val_loss: 0.5032 - val_accuracy: 0.7905\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.8226 - val_loss: 0.5079 - val_accuracy: 0.7973\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7872 - val_loss: 0.5150 - val_accuracy: 0.8041\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4912 - accuracy: 0.7990 - val_loss: 0.5094 - val_accuracy: 0.7973\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8260 - val_loss: 0.5107 - val_accuracy: 0.7905\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.8260 - val_loss: 0.5068 - val_accuracy: 0.7973\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7804 - val_loss: 0.5016 - val_accuracy: 0.7838\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.8074 - val_loss: 0.5107 - val_accuracy: 0.7770\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4818 - accuracy: 0.8294 - val_loss: 0.5139 - val_accuracy: 0.7703\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4886 - accuracy: 0.8057 - val_loss: 0.4950 - val_accuracy: 0.7703\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7855 - val_loss: 0.4992 - val_accuracy: 0.8041\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.8091 - val_loss: 0.4996 - val_accuracy: 0.7905\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.8125 - val_loss: 0.4977 - val_accuracy: 0.7838\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.8041 - val_loss: 0.4954 - val_accuracy: 0.7905\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4851 - accuracy: 0.8193 - val_loss: 0.4851 - val_accuracy: 0.7973\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5056 - accuracy: 0.8074 - val_loss: 0.4970 - val_accuracy: 0.7905\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.8328 - val_loss: 0.4819 - val_accuracy: 0.8243\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.8260 - val_loss: 0.4923 - val_accuracy: 0.7905\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4818 - accuracy: 0.8176 - val_loss: 0.5001 - val_accuracy: 0.8108\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5043 - accuracy: 0.7973 - val_loss: 0.4907 - val_accuracy: 0.8176\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5075 - accuracy: 0.7922 - val_loss: 0.4931 - val_accuracy: 0.7905\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5043 - accuracy: 0.8057 - val_loss: 0.4694 - val_accuracy: 0.8041\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4987 - accuracy: 0.8041 - val_loss: 0.4775 - val_accuracy: 0.8176\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4918 - accuracy: 0.7973 - val_loss: 0.4815 - val_accuracy: 0.8041\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4777 - accuracy: 0.8074 - val_loss: 0.4802 - val_accuracy: 0.7838\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.8193 - val_loss: 0.4868 - val_accuracy: 0.7905\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7956 - val_loss: 0.4910 - val_accuracy: 0.8041\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4601 - accuracy: 0.8311 - val_loss: 0.5080 - val_accuracy: 0.8041\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5091 - accuracy: 0.7990 - val_loss: 0.4989 - val_accuracy: 0.7973\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4830 - accuracy: 0.8057 - val_loss: 0.4964 - val_accuracy: 0.7973\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7905 - val_loss: 0.5052 - val_accuracy: 0.7905\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4939 - accuracy: 0.8209 - val_loss: 0.4853 - val_accuracy: 0.7973\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4469 - accuracy: 0.8361 - val_loss: 0.4912 - val_accuracy: 0.7973\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4608 - accuracy: 0.8294 - val_loss: 0.4924 - val_accuracy: 0.8041\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.8074 - val_loss: 0.4838 - val_accuracy: 0.8041\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.8294 - val_loss: 0.4934 - val_accuracy: 0.8108\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8243 - val_loss: 0.5035 - val_accuracy: 0.8243\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8226 - val_loss: 0.5020 - val_accuracy: 0.7838\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.8142 - val_loss: 0.4952 - val_accuracy: 0.7838\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.8328 - val_loss: 0.4936 - val_accuracy: 0.7838\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5109 - accuracy: 0.7889 - val_loss: 0.4888 - val_accuracy: 0.7973\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7939 - val_loss: 0.4932 - val_accuracy: 0.8108\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.7804 - val_loss: 0.4987 - val_accuracy: 0.8041\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.8024 - val_loss: 0.4986 - val_accuracy: 0.8041\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.7956 - val_loss: 0.4873 - val_accuracy: 0.8108\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5353 - accuracy: 0.7804 - val_loss: 0.4887 - val_accuracy: 0.8108\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4874 - accuracy: 0.8041 - val_loss: 0.4945 - val_accuracy: 0.8041\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5139 - accuracy: 0.8108 - val_loss: 0.4906 - val_accuracy: 0.7973\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4816 - accuracy: 0.8108 - val_loss: 0.4831 - val_accuracy: 0.7973\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5066 - accuracy: 0.8057 - val_loss: 0.4675 - val_accuracy: 0.8311\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4960 - accuracy: 0.8007 - val_loss: 0.4817 - val_accuracy: 0.8041\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.8091 - val_loss: 0.4794 - val_accuracy: 0.8311\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4477 - accuracy: 0.8260 - val_loss: 0.4922 - val_accuracy: 0.8041\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7905 - val_loss: 0.4802 - val_accuracy: 0.8176\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4919 - accuracy: 0.8024 - val_loss: 0.4901 - val_accuracy: 0.7973\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7956 - val_loss: 0.4923 - val_accuracy: 0.7905\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5291 - accuracy: 0.7838 - val_loss: 0.4853 - val_accuracy: 0.7973\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7922 - val_loss: 0.4867 - val_accuracy: 0.7973\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4765 - accuracy: 0.8108 - val_loss: 0.4843 - val_accuracy: 0.8041\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.8311 - val_loss: 0.4866 - val_accuracy: 0.7973\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.8176 - val_loss: 0.4828 - val_accuracy: 0.7973\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7922 - val_loss: 0.5051 - val_accuracy: 0.7770\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4581 - accuracy: 0.8412 - val_loss: 0.4954 - val_accuracy: 0.7905\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.8193 - val_loss: 0.4947 - val_accuracy: 0.7770\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.8024 - val_loss: 0.4766 - val_accuracy: 0.7973\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.8108 - val_loss: 0.4759 - val_accuracy: 0.7973\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.8091 - val_loss: 0.4803 - val_accuracy: 0.7703\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5007 - accuracy: 0.8074 - val_loss: 0.4790 - val_accuracy: 0.7905\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.8311 - val_loss: 0.4853 - val_accuracy: 0.7838\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.8108 - val_loss: 0.5009 - val_accuracy: 0.7905\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8159 - val_loss: 0.4892 - val_accuracy: 0.8041\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4609 - accuracy: 0.8226 - val_loss: 0.4840 - val_accuracy: 0.7905\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5212 - accuracy: 0.8057 - val_loss: 0.4788 - val_accuracy: 0.7905\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5092 - accuracy: 0.7922 - val_loss: 0.4630 - val_accuracy: 0.7973\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7973\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-29c08035a301>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 11ms/step - loss: 2.0043 - accuracy: 0.4882 - val_loss: 1.1505 - val_accuracy: 0.5405\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.8999 - accuracy: 0.5000 - val_loss: 1.1399 - val_accuracy: 0.5541\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6771 - accuracy: 0.5084 - val_loss: 1.1351 - val_accuracy: 0.5608\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6148 - accuracy: 0.5253 - val_loss: 1.1231 - val_accuracy: 0.5608\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5869 - accuracy: 0.4848 - val_loss: 1.1139 - val_accuracy: 0.5541\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 1.4679 - accuracy: 0.4932 - val_loss: 1.1053 - val_accuracy: 0.5811\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3333 - accuracy: 0.5051 - val_loss: 1.1014 - val_accuracy: 0.5743\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2972 - accuracy: 0.5287 - val_loss: 1.0972 - val_accuracy: 0.5743\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.2598 - accuracy: 0.5220 - val_loss: 1.0904 - val_accuracy: 0.5608\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1984 - accuracy: 0.5253 - val_loss: 1.0832 - val_accuracy: 0.5676\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.2066 - accuracy: 0.4916 - val_loss: 1.0764 - val_accuracy: 0.5676\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.1400 - accuracy: 0.5253 - val_loss: 1.0692 - val_accuracy: 0.5676\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.1144 - accuracy: 0.5355 - val_loss: 1.0617 - val_accuracy: 0.5743\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.1155 - accuracy: 0.5034 - val_loss: 1.0546 - val_accuracy: 0.5676\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1030 - accuracy: 0.5253 - val_loss: 1.0474 - val_accuracy: 0.5676\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0691 - accuracy: 0.5068 - val_loss: 1.0388 - val_accuracy: 0.5743\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0548 - accuracy: 0.5270 - val_loss: 1.0298 - val_accuracy: 0.5743\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0443 - accuracy: 0.5304 - val_loss: 1.0216 - val_accuracy: 0.5608\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0335 - accuracy: 0.5422 - val_loss: 1.0128 - val_accuracy: 0.5541\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0264 - accuracy: 0.4949 - val_loss: 1.0045 - val_accuracy: 0.5338\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0032 - accuracy: 0.5236 - val_loss: 0.9954 - val_accuracy: 0.5676\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0045 - accuracy: 0.5304 - val_loss: 0.9868 - val_accuracy: 0.5676\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9913 - accuracy: 0.5321 - val_loss: 0.9780 - val_accuracy: 0.5405\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9862 - accuracy: 0.4966 - val_loss: 0.9690 - val_accuracy: 0.5878\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9700 - accuracy: 0.5253 - val_loss: 0.9599 - val_accuracy: 0.6216\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9617 - accuracy: 0.5236 - val_loss: 0.9508 - val_accuracy: 0.5743\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9546 - accuracy: 0.5270 - val_loss: 0.9418 - val_accuracy: 0.5541\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9406 - accuracy: 0.5253 - val_loss: 0.9319 - val_accuracy: 0.6081\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9315 - accuracy: 0.5405 - val_loss: 0.9228 - val_accuracy: 0.6554\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9271 - accuracy: 0.5152 - val_loss: 0.9141 - val_accuracy: 0.5878\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9117 - accuracy: 0.5355 - val_loss: 0.9039 - val_accuracy: 0.6351\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8981 - accuracy: 0.5490 - val_loss: 0.8952 - val_accuracy: 0.6486\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8974 - accuracy: 0.5135 - val_loss: 0.8864 - val_accuracy: 0.6554\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8887 - accuracy: 0.5253 - val_loss: 0.8775 - val_accuracy: 0.6419\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8779 - accuracy: 0.5186 - val_loss: 0.8691 - val_accuracy: 0.6622\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8675 - accuracy: 0.5405 - val_loss: 0.8597 - val_accuracy: 0.6622\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.8460 - accuracy: 0.5794 - val_loss: 0.8476 - val_accuracy: 0.6689\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8565 - accuracy: 0.5135 - val_loss: 0.8398 - val_accuracy: 0.6622\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8385 - accuracy: 0.5574 - val_loss: 0.8323 - val_accuracy: 0.6892\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.8226 - accuracy: 0.5693 - val_loss: 0.8196 - val_accuracy: 0.7027\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8217 - accuracy: 0.5777 - val_loss: 0.8118 - val_accuracy: 0.6824\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.8079 - accuracy: 0.5811 - val_loss: 0.8047 - val_accuracy: 0.6959\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7979 - accuracy: 0.5929 - val_loss: 0.7937 - val_accuracy: 0.7027\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8044 - accuracy: 0.5676 - val_loss: 0.7868 - val_accuracy: 0.7095\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7923 - accuracy: 0.6064 - val_loss: 0.7762 - val_accuracy: 0.7297\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7778 - accuracy: 0.5997 - val_loss: 0.7586 - val_accuracy: 0.7297\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7804 - accuracy: 0.5845 - val_loss: 0.7462 - val_accuracy: 0.7297\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7699 - accuracy: 0.5794 - val_loss: 0.7325 - val_accuracy: 0.7568\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7699 - accuracy: 0.6014 - val_loss: 0.7196 - val_accuracy: 0.7703\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7468 - accuracy: 0.6233 - val_loss: 0.7097 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7353 - accuracy: 0.6470 - val_loss: 0.6928 - val_accuracy: 0.7432\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7543 - accuracy: 0.6064 - val_loss: 0.6867 - val_accuracy: 0.7432\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7348 - accuracy: 0.6250 - val_loss: 0.6787 - val_accuracy: 0.7365\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7168 - accuracy: 0.6554 - val_loss: 0.6750 - val_accuracy: 0.7297\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.6858 - val_loss: 0.6609 - val_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7161 - accuracy: 0.6470 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7136 - accuracy: 0.6639 - val_loss: 0.6436 - val_accuracy: 0.7568\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.6892 - val_loss: 0.6263 - val_accuracy: 0.7770\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.6959 - val_loss: 0.6191 - val_accuracy: 0.7568\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6867 - accuracy: 0.6655 - val_loss: 0.6170 - val_accuracy: 0.7635\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6812 - accuracy: 0.6926 - val_loss: 0.6141 - val_accuracy: 0.7703\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6715 - accuracy: 0.6943 - val_loss: 0.6004 - val_accuracy: 0.7770\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.6791 - val_loss: 0.5990 - val_accuracy: 0.7635\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.6740 - val_loss: 0.5949 - val_accuracy: 0.7703\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6583 - accuracy: 0.6926 - val_loss: 0.5777 - val_accuracy: 0.7703\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6904 - accuracy: 0.6672 - val_loss: 0.5882 - val_accuracy: 0.7905\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6609 - accuracy: 0.7128 - val_loss: 0.5838 - val_accuracy: 0.7770\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6492 - accuracy: 0.6740 - val_loss: 0.5767 - val_accuracy: 0.7973\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6490 - accuracy: 0.7010 - val_loss: 0.5694 - val_accuracy: 0.7770\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6157 - accuracy: 0.7382 - val_loss: 0.5539 - val_accuracy: 0.7838\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6432 - accuracy: 0.6807 - val_loss: 0.5593 - val_accuracy: 0.7703\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.7061 - val_loss: 0.5471 - val_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6333 - accuracy: 0.7128 - val_loss: 0.5474 - val_accuracy: 0.7770\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6360 - accuracy: 0.7382 - val_loss: 0.5491 - val_accuracy: 0.7905\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6534 - accuracy: 0.6976 - val_loss: 0.5517 - val_accuracy: 0.7905\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6558 - accuracy: 0.6841 - val_loss: 0.5582 - val_accuracy: 0.7905\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6168 - accuracy: 0.7179 - val_loss: 0.5481 - val_accuracy: 0.7973\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7399 - val_loss: 0.5447 - val_accuracy: 0.7905\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7517 - val_loss: 0.5346 - val_accuracy: 0.7973\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.7314 - val_loss: 0.5356 - val_accuracy: 0.8041\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.7331 - val_loss: 0.5232 - val_accuracy: 0.7905\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.7348 - val_loss: 0.5220 - val_accuracy: 0.7973\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7230 - val_loss: 0.5320 - val_accuracy: 0.8108\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.7416 - val_loss: 0.5181 - val_accuracy: 0.8176\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6423 - accuracy: 0.7432 - val_loss: 0.5303 - val_accuracy: 0.8041\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.7432 - val_loss: 0.5341 - val_accuracy: 0.7973\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6062 - accuracy: 0.7382 - val_loss: 0.5197 - val_accuracy: 0.8041\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.7314 - val_loss: 0.5215 - val_accuracy: 0.8041\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7466 - val_loss: 0.5182 - val_accuracy: 0.7973\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5962 - accuracy: 0.7365 - val_loss: 0.5205 - val_accuracy: 0.7905\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6167 - accuracy: 0.7568 - val_loss: 0.5156 - val_accuracy: 0.8176\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6211 - accuracy: 0.7162 - val_loss: 0.5232 - val_accuracy: 0.8108\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6187 - accuracy: 0.7449 - val_loss: 0.5329 - val_accuracy: 0.7973\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6160 - accuracy: 0.7230 - val_loss: 0.5283 - val_accuracy: 0.7973\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5958 - accuracy: 0.7399 - val_loss: 0.5248 - val_accuracy: 0.8108\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6111 - accuracy: 0.7264 - val_loss: 0.5234 - val_accuracy: 0.8243\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5840 - accuracy: 0.7466 - val_loss: 0.5084 - val_accuracy: 0.8311\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5526 - accuracy: 0.7838 - val_loss: 0.4971 - val_accuracy: 0.8176\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7618 - val_loss: 0.4987 - val_accuracy: 0.8176\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7618 - val_loss: 0.5022 - val_accuracy: 0.7973\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5776 - accuracy: 0.7517 - val_loss: 0.5000 - val_accuracy: 0.8108\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5897 - accuracy: 0.7652 - val_loss: 0.4885 - val_accuracy: 0.8378\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5969 - accuracy: 0.7348 - val_loss: 0.4928 - val_accuracy: 0.8311\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5623 - accuracy: 0.7804 - val_loss: 0.4871 - val_accuracy: 0.8378\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.7517 - val_loss: 0.4878 - val_accuracy: 0.8243\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5798 - accuracy: 0.7618 - val_loss: 0.4965 - val_accuracy: 0.8176\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6156 - accuracy: 0.7264 - val_loss: 0.5005 - val_accuracy: 0.8311\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5551 - accuracy: 0.7568 - val_loss: 0.4843 - val_accuracy: 0.8243\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.7584 - val_loss: 0.4839 - val_accuracy: 0.8108\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.7584 - val_loss: 0.4845 - val_accuracy: 0.8108\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5544 - accuracy: 0.7449 - val_loss: 0.4837 - val_accuracy: 0.8311\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7500 - val_loss: 0.4901 - val_accuracy: 0.8176\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6162 - accuracy: 0.7382 - val_loss: 0.4976 - val_accuracy: 0.8176\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.7703 - val_loss: 0.4934 - val_accuracy: 0.8041\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6233 - accuracy: 0.7128 - val_loss: 0.4928 - val_accuracy: 0.8378\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7466 - val_loss: 0.4914 - val_accuracy: 0.8243\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5632 - accuracy: 0.7720 - val_loss: 0.4956 - val_accuracy: 0.8243\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.7584 - val_loss: 0.4961 - val_accuracy: 0.8176\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.7618 - val_loss: 0.4869 - val_accuracy: 0.8108\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5601 - accuracy: 0.7720 - val_loss: 0.4855 - val_accuracy: 0.8041\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5420 - accuracy: 0.7652 - val_loss: 0.4817 - val_accuracy: 0.8108\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5656 - accuracy: 0.7669 - val_loss: 0.4909 - val_accuracy: 0.8041\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6050 - accuracy: 0.7449 - val_loss: 0.5020 - val_accuracy: 0.8041\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5789 - accuracy: 0.7821 - val_loss: 0.4984 - val_accuracy: 0.8041\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5638 - accuracy: 0.7787 - val_loss: 0.4924 - val_accuracy: 0.8041\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.7770 - val_loss: 0.4934 - val_accuracy: 0.8108\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5369 - accuracy: 0.7804 - val_loss: 0.4960 - val_accuracy: 0.7905\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7939 - val_loss: 0.4949 - val_accuracy: 0.8176\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7855 - val_loss: 0.4923 - val_accuracy: 0.7973\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.7500 - val_loss: 0.4935 - val_accuracy: 0.7973\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5842 - accuracy: 0.7736 - val_loss: 0.5001 - val_accuracy: 0.8108\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7551 - val_loss: 0.4979 - val_accuracy: 0.7973\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7669 - val_loss: 0.4937 - val_accuracy: 0.7973\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7720 - val_loss: 0.4863 - val_accuracy: 0.8108\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5907 - accuracy: 0.7584 - val_loss: 0.4877 - val_accuracy: 0.8108\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5975 - accuracy: 0.7601 - val_loss: 0.4849 - val_accuracy: 0.8243\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.8041 - val_loss: 0.4826 - val_accuracy: 0.8176\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5587 - accuracy: 0.7686 - val_loss: 0.4898 - val_accuracy: 0.8176\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.7466 - val_loss: 0.4945 - val_accuracy: 0.8176\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7821 - val_loss: 0.4898 - val_accuracy: 0.8176\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7855 - val_loss: 0.4888 - val_accuracy: 0.8311\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7753 - val_loss: 0.4950 - val_accuracy: 0.8378\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.7686 - val_loss: 0.4848 - val_accuracy: 0.8243\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5478 - accuracy: 0.7720 - val_loss: 0.4884 - val_accuracy: 0.8311\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.7686 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7990 - val_loss: 0.4887 - val_accuracy: 0.8176\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5181 - accuracy: 0.7956 - val_loss: 0.4840 - val_accuracy: 0.8311\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5656 - accuracy: 0.7652 - val_loss: 0.4719 - val_accuracy: 0.8311\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5641 - accuracy: 0.7551 - val_loss: 0.4920 - val_accuracy: 0.8243\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5469 - accuracy: 0.7922 - val_loss: 0.4843 - val_accuracy: 0.8108\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5771 - accuracy: 0.7517 - val_loss: 0.4760 - val_accuracy: 0.8176\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5747 - accuracy: 0.7584 - val_loss: 0.4726 - val_accuracy: 0.8378\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5830 - accuracy: 0.7618 - val_loss: 0.4724 - val_accuracy: 0.8311\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5523 - accuracy: 0.7872 - val_loss: 0.4779 - val_accuracy: 0.8311\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5667 - accuracy: 0.7736 - val_loss: 0.4747 - val_accuracy: 0.8378\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7838 - val_loss: 0.4754 - val_accuracy: 0.8378\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7635 - val_loss: 0.4724 - val_accuracy: 0.8378\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.8007 - val_loss: 0.4696 - val_accuracy: 0.8446\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7753 - val_loss: 0.4542 - val_accuracy: 0.8446\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.7990 - val_loss: 0.4656 - val_accuracy: 0.8514\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7855 - val_loss: 0.4627 - val_accuracy: 0.8446\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5529 - accuracy: 0.7872 - val_loss: 0.4563 - val_accuracy: 0.8581\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7736 - val_loss: 0.4647 - val_accuracy: 0.8446\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5731 - accuracy: 0.7736 - val_loss: 0.4622 - val_accuracy: 0.8446\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7618 - val_loss: 0.4648 - val_accuracy: 0.8311\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.7838 - val_loss: 0.4702 - val_accuracy: 0.8176\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.7416 - val_loss: 0.4664 - val_accuracy: 0.8378\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7568 - val_loss: 0.4784 - val_accuracy: 0.8446\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5689 - accuracy: 0.7753 - val_loss: 0.4581 - val_accuracy: 0.8446\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5452 - accuracy: 0.7686 - val_loss: 0.4586 - val_accuracy: 0.8378\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7753 - val_loss: 0.4516 - val_accuracy: 0.8378\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7753 - val_loss: 0.4553 - val_accuracy: 0.8378\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5700 - accuracy: 0.7720 - val_loss: 0.4581 - val_accuracy: 0.8581\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7922 - val_loss: 0.4507 - val_accuracy: 0.8581\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6052 - accuracy: 0.7365 - val_loss: 0.4574 - val_accuracy: 0.8514\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5466 - accuracy: 0.7889 - val_loss: 0.4502 - val_accuracy: 0.8514\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5169 - accuracy: 0.8125 - val_loss: 0.4561 - val_accuracy: 0.8514\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5441 - accuracy: 0.7821 - val_loss: 0.4560 - val_accuracy: 0.8446\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5234 - accuracy: 0.7686 - val_loss: 0.4596 - val_accuracy: 0.8581\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5566 - accuracy: 0.7635 - val_loss: 0.4532 - val_accuracy: 0.8378\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6137 - accuracy: 0.7365 - val_loss: 0.4702 - val_accuracy: 0.8446\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.7787 - val_loss: 0.4610 - val_accuracy: 0.8514\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.7838 - val_loss: 0.4665 - val_accuracy: 0.8446\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.7939 - val_loss: 0.4672 - val_accuracy: 0.8311\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6097 - accuracy: 0.7399 - val_loss: 0.4808 - val_accuracy: 0.8176\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5451 - accuracy: 0.7804 - val_loss: 0.4834 - val_accuracy: 0.8176\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5757 - accuracy: 0.7584 - val_loss: 0.4763 - val_accuracy: 0.8243\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5580 - accuracy: 0.7889 - val_loss: 0.4668 - val_accuracy: 0.8311\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7889 - val_loss: 0.4719 - val_accuracy: 0.8311\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5925 - accuracy: 0.7416 - val_loss: 0.4700 - val_accuracy: 0.8243\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7804 - val_loss: 0.4640 - val_accuracy: 0.8378\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5683 - accuracy: 0.7855 - val_loss: 0.4725 - val_accuracy: 0.8176\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5450 - accuracy: 0.7568 - val_loss: 0.4736 - val_accuracy: 0.8108\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.7787 - val_loss: 0.4636 - val_accuracy: 0.8176\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7872 - val_loss: 0.4649 - val_accuracy: 0.8243\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7669 - val_loss: 0.4594 - val_accuracy: 0.8243\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7703 - val_loss: 0.4594 - val_accuracy: 0.8514\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.7821 - val_loss: 0.4526 - val_accuracy: 0.8311\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7821 - val_loss: 0.4588 - val_accuracy: 0.8378\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.7855 - val_loss: 0.4748 - val_accuracy: 0.8243\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7905 - val_loss: 0.4616 - val_accuracy: 0.8311\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5388 - accuracy: 0.7804 - val_loss: 0.4594 - val_accuracy: 0.8378\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5666 - accuracy: 0.7551 - val_loss: 0.4696 - val_accuracy: 0.8243\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5552 - accuracy: 0.7889 - val_loss: 0.4684 - val_accuracy: 0.8378\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5489 - accuracy: 0.7635 - val_loss: 0.4686 - val_accuracy: 0.8243\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5435 - accuracy: 0.7652 - val_loss: 0.4549 - val_accuracy: 0.8378\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5737 - accuracy: 0.7720 - val_loss: 0.4632 - val_accuracy: 0.8243\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5564 - accuracy: 0.7534 - val_loss: 0.4567 - val_accuracy: 0.8514\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7990 - val_loss: 0.4550 - val_accuracy: 0.8243\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7855 - val_loss: 0.4582 - val_accuracy: 0.8378\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.8057 - val_loss: 0.4476 - val_accuracy: 0.8378\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7889 - val_loss: 0.4494 - val_accuracy: 0.8446\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.8074 - val_loss: 0.4491 - val_accuracy: 0.8514\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.8209 - val_loss: 0.4579 - val_accuracy: 0.8378\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5702 - accuracy: 0.7753 - val_loss: 0.4396 - val_accuracy: 0.8514\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.8057 - val_loss: 0.4534 - val_accuracy: 0.8378\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5626 - accuracy: 0.7720 - val_loss: 0.4599 - val_accuracy: 0.8243\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7770 - val_loss: 0.4619 - val_accuracy: 0.8243\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.8091 - val_loss: 0.4624 - val_accuracy: 0.8243\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.7821 - val_loss: 0.4472 - val_accuracy: 0.8378\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7770 - val_loss: 0.4503 - val_accuracy: 0.8446\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7601 - val_loss: 0.4471 - val_accuracy: 0.8514\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5064 - accuracy: 0.7990 - val_loss: 0.4435 - val_accuracy: 0.8446\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7838 - val_loss: 0.4379 - val_accuracy: 0.8581\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5417 - accuracy: 0.7973 - val_loss: 0.4372 - val_accuracy: 0.8649\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7838 - val_loss: 0.4513 - val_accuracy: 0.8514\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.8074 - val_loss: 0.4607 - val_accuracy: 0.8378\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7889 - val_loss: 0.4596 - val_accuracy: 0.8446\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5603 - accuracy: 0.7787 - val_loss: 0.4533 - val_accuracy: 0.8514\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5462 - accuracy: 0.7770 - val_loss: 0.4520 - val_accuracy: 0.8514\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5111 - accuracy: 0.8024 - val_loss: 0.4463 - val_accuracy: 0.8581\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5546 - accuracy: 0.7939 - val_loss: 0.4490 - val_accuracy: 0.8581\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5405 - accuracy: 0.7601 - val_loss: 0.4446 - val_accuracy: 0.8581\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5388 - accuracy: 0.7889 - val_loss: 0.4522 - val_accuracy: 0.8446\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5382 - accuracy: 0.7838 - val_loss: 0.4472 - val_accuracy: 0.8514\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7753 - val_loss: 0.4415 - val_accuracy: 0.8581\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7889 - val_loss: 0.4526 - val_accuracy: 0.8581\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7922 - val_loss: 0.4611 - val_accuracy: 0.8446\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5703 - accuracy: 0.7736 - val_loss: 0.4561 - val_accuracy: 0.8514\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.7753 - val_loss: 0.4501 - val_accuracy: 0.8649\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.7973 - val_loss: 0.4640 - val_accuracy: 0.8446\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7905 - val_loss: 0.4534 - val_accuracy: 0.8446\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7618 - val_loss: 0.4661 - val_accuracy: 0.8378\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7990 - val_loss: 0.4624 - val_accuracy: 0.8378\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7956 - val_loss: 0.4531 - val_accuracy: 0.8514\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.8007 - val_loss: 0.4534 - val_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7669 - val_loss: 0.4629 - val_accuracy: 0.8311\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7568 - val_loss: 0.4676 - val_accuracy: 0.8243\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5009 - accuracy: 0.8007 - val_loss: 0.4535 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7973 - val_loss: 0.4623 - val_accuracy: 0.8108\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7889 - val_loss: 0.4631 - val_accuracy: 0.8446\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7973 - val_loss: 0.4568 - val_accuracy: 0.8176\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.8193 - val_loss: 0.4515 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5428 - accuracy: 0.7990 - val_loss: 0.4513 - val_accuracy: 0.8311\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5478 - accuracy: 0.7855 - val_loss: 0.4511 - val_accuracy: 0.8378\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.7973 - val_loss: 0.4444 - val_accuracy: 0.8378\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5401 - accuracy: 0.7973 - val_loss: 0.4357 - val_accuracy: 0.8311\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5519 - accuracy: 0.7905 - val_loss: 0.4436 - val_accuracy: 0.8514\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5664 - accuracy: 0.7669 - val_loss: 0.4562 - val_accuracy: 0.8378\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5468 - accuracy: 0.7855 - val_loss: 0.4644 - val_accuracy: 0.8176\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5195 - accuracy: 0.7990 - val_loss: 0.4568 - val_accuracy: 0.8311\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5049 - accuracy: 0.8041 - val_loss: 0.4557 - val_accuracy: 0.8176\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.8193 - val_loss: 0.4457 - val_accuracy: 0.8378\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5387 - accuracy: 0.8041 - val_loss: 0.4630 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.8074 - val_loss: 0.4494 - val_accuracy: 0.8108\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5310 - accuracy: 0.7568 - val_loss: 0.4474 - val_accuracy: 0.8243\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.8074 - val_loss: 0.4509 - val_accuracy: 0.8041\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5097 - accuracy: 0.8041 - val_loss: 0.4451 - val_accuracy: 0.8176\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.7686 - val_loss: 0.4486 - val_accuracy: 0.8176\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5074 - accuracy: 0.8209 - val_loss: 0.4487 - val_accuracy: 0.8041\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5428 - accuracy: 0.7787 - val_loss: 0.4560 - val_accuracy: 0.8108\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.8024 - val_loss: 0.4439 - val_accuracy: 0.8243\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7872 - val_loss: 0.4450 - val_accuracy: 0.8108\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7939 - val_loss: 0.4376 - val_accuracy: 0.8311\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5567 - accuracy: 0.8074 - val_loss: 0.4540 - val_accuracy: 0.8378\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.8142 - val_loss: 0.4374 - val_accuracy: 0.8243\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7838 - val_loss: 0.4426 - val_accuracy: 0.8311\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7821 - val_loss: 0.4369 - val_accuracy: 0.8581\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5168 - accuracy: 0.7804 - val_loss: 0.4444 - val_accuracy: 0.8311\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5459 - accuracy: 0.7753 - val_loss: 0.4410 - val_accuracy: 0.8446\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.8057 - val_loss: 0.4480 - val_accuracy: 0.8311\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7956 - val_loss: 0.4483 - val_accuracy: 0.8311\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5008 - accuracy: 0.7939 - val_loss: 0.4507 - val_accuracy: 0.8311\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4892 - accuracy: 0.8226 - val_loss: 0.4500 - val_accuracy: 0.8108\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5295 - accuracy: 0.8125 - val_loss: 0.4295 - val_accuracy: 0.8514\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4889 - accuracy: 0.8007 - val_loss: 0.4227 - val_accuracy: 0.8514\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5276 - accuracy: 0.7973 - val_loss: 0.4303 - val_accuracy: 0.8311\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5401 - accuracy: 0.7990 - val_loss: 0.4509 - val_accuracy: 0.8176\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5062 - accuracy: 0.8091 - val_loss: 0.4464 - val_accuracy: 0.8176\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7990 - val_loss: 0.4418 - val_accuracy: 0.8243\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7973 - val_loss: 0.4555 - val_accuracy: 0.8243\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5179 - accuracy: 0.8007 - val_loss: 0.4555 - val_accuracy: 0.8176\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.8176 - val_loss: 0.4540 - val_accuracy: 0.8108\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5540 - accuracy: 0.7736 - val_loss: 0.4722 - val_accuracy: 0.8108\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.8024 - val_loss: 0.4758 - val_accuracy: 0.7973\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7939 - val_loss: 0.4921 - val_accuracy: 0.7973\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.7990 - val_loss: 0.4809 - val_accuracy: 0.8041\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.8514 - val_loss: 0.4794 - val_accuracy: 0.7973\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.7770 - val_loss: 0.4862 - val_accuracy: 0.7973\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.7872 - val_loss: 0.4779 - val_accuracy: 0.8108\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7872 - val_loss: 0.4734 - val_accuracy: 0.8176\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.8108 - val_loss: 0.4720 - val_accuracy: 0.8108\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.8125 - val_loss: 0.4724 - val_accuracy: 0.8108\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7922 - val_loss: 0.4689 - val_accuracy: 0.8041\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7466 - val_loss: 0.4890 - val_accuracy: 0.7973\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.8209 - val_loss: 0.4831 - val_accuracy: 0.8041\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5418 - accuracy: 0.7889 - val_loss: 0.4791 - val_accuracy: 0.7973\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7973 - val_loss: 0.4694 - val_accuracy: 0.8108\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5653 - accuracy: 0.7736 - val_loss: 0.4696 - val_accuracy: 0.8041\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5337 - accuracy: 0.7990 - val_loss: 0.4701 - val_accuracy: 0.8243\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5151 - accuracy: 0.7838 - val_loss: 0.4531 - val_accuracy: 0.8176\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5192 - accuracy: 0.7855 - val_loss: 0.4584 - val_accuracy: 0.8176\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4858 - accuracy: 0.8024 - val_loss: 0.4518 - val_accuracy: 0.8243\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5008 - accuracy: 0.7973 - val_loss: 0.4559 - val_accuracy: 0.8378\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4800 - accuracy: 0.8159 - val_loss: 0.4742 - val_accuracy: 0.7973\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5210 - accuracy: 0.8091 - val_loss: 0.4759 - val_accuracy: 0.7973\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7872 - val_loss: 0.4765 - val_accuracy: 0.8041\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7821 - val_loss: 0.4576 - val_accuracy: 0.8041\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5506 - accuracy: 0.7787 - val_loss: 0.4769 - val_accuracy: 0.7973\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4676 - accuracy: 0.8176 - val_loss: 0.4709 - val_accuracy: 0.7973\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5125 - accuracy: 0.8074 - val_loss: 0.4733 - val_accuracy: 0.8108\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7889 - val_loss: 0.4688 - val_accuracy: 0.7905\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.8024 - val_loss: 0.4636 - val_accuracy: 0.8041\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.8125 - val_loss: 0.4628 - val_accuracy: 0.8176\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7939 - val_loss: 0.4648 - val_accuracy: 0.8108\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5113 - accuracy: 0.7973 - val_loss: 0.4680 - val_accuracy: 0.8108\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4943 - accuracy: 0.7956 - val_loss: 0.4609 - val_accuracy: 0.8108\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.7872 - val_loss: 0.4628 - val_accuracy: 0.7905\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5149 - accuracy: 0.7787 - val_loss: 0.4600 - val_accuracy: 0.8108\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7922 - val_loss: 0.4536 - val_accuracy: 0.8041\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7568 - val_loss: 0.4599 - val_accuracy: 0.8041\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4889 - accuracy: 0.8209 - val_loss: 0.4644 - val_accuracy: 0.8041\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5635 - accuracy: 0.7736 - val_loss: 0.4689 - val_accuracy: 0.7905\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.8007 - val_loss: 0.4634 - val_accuracy: 0.7973\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.8193 - val_loss: 0.4648 - val_accuracy: 0.7973\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4983 - accuracy: 0.7990 - val_loss: 0.4620 - val_accuracy: 0.7973\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5302 - accuracy: 0.8091 - val_loss: 0.4712 - val_accuracy: 0.7905\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5572 - accuracy: 0.7821 - val_loss: 0.4757 - val_accuracy: 0.7973\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4851 - accuracy: 0.7905 - val_loss: 0.4687 - val_accuracy: 0.7838\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5522 - accuracy: 0.7838 - val_loss: 0.4734 - val_accuracy: 0.7838\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5438 - accuracy: 0.7872 - val_loss: 0.4706 - val_accuracy: 0.7905\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4921 - accuracy: 0.8041 - val_loss: 0.4716 - val_accuracy: 0.7905\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7838 - val_loss: 0.4723 - val_accuracy: 0.7905\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.7872 - val_loss: 0.4624 - val_accuracy: 0.7973\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5007 - accuracy: 0.7973 - val_loss: 0.4562 - val_accuracy: 0.8108\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.8159 - val_loss: 0.4642 - val_accuracy: 0.7905\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4961 - accuracy: 0.8209 - val_loss: 0.4709 - val_accuracy: 0.7838\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5283 - accuracy: 0.8024 - val_loss: 0.4586 - val_accuracy: 0.7973\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.8294 - val_loss: 0.4555 - val_accuracy: 0.7973\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.7922 - val_loss: 0.4637 - val_accuracy: 0.8041\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5127 - accuracy: 0.7990 - val_loss: 0.4824 - val_accuracy: 0.7905\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7838 - val_loss: 0.4700 - val_accuracy: 0.7973\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4853 - accuracy: 0.8159 - val_loss: 0.4609 - val_accuracy: 0.7973\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.8074 - val_loss: 0.4508 - val_accuracy: 0.8041\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7922 - val_loss: 0.4518 - val_accuracy: 0.8176\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.7973 - val_loss: 0.4509 - val_accuracy: 0.8108\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7905 - val_loss: 0.4492 - val_accuracy: 0.8176\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5168 - accuracy: 0.8057 - val_loss: 0.4522 - val_accuracy: 0.8243\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4766 - accuracy: 0.8260 - val_loss: 0.4325 - val_accuracy: 0.8108\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.8074 - val_loss: 0.4556 - val_accuracy: 0.8041\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.7720 - val_loss: 0.4408 - val_accuracy: 0.8176\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7990 - val_loss: 0.4466 - val_accuracy: 0.8176\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5388 - accuracy: 0.7686 - val_loss: 0.4484 - val_accuracy: 0.8108\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4999 - accuracy: 0.8125 - val_loss: 0.4470 - val_accuracy: 0.8108\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4832 - accuracy: 0.8294 - val_loss: 0.4458 - val_accuracy: 0.8108\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5097 - accuracy: 0.8057 - val_loss: 0.4555 - val_accuracy: 0.8176\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5575 - accuracy: 0.7787 - val_loss: 0.4452 - val_accuracy: 0.8108\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4943 - accuracy: 0.7889 - val_loss: 0.4434 - val_accuracy: 0.8041\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5167 - accuracy: 0.7838 - val_loss: 0.4283 - val_accuracy: 0.8311\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.8007 - val_loss: 0.4326 - val_accuracy: 0.8378\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.8108 - val_loss: 0.4533 - val_accuracy: 0.8108\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.7855 - val_loss: 0.4421 - val_accuracy: 0.8041\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.8074 - val_loss: 0.4488 - val_accuracy: 0.7973\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8125 - val_loss: 0.4355 - val_accuracy: 0.8176\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.8074 - val_loss: 0.4425 - val_accuracy: 0.8243\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.8260 - val_loss: 0.4448 - val_accuracy: 0.8243\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4885 - accuracy: 0.8209 - val_loss: 0.4416 - val_accuracy: 0.8311\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7990 - val_loss: 0.4450 - val_accuracy: 0.8243\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4519 - accuracy: 0.8209 - val_loss: 0.4451 - val_accuracy: 0.8041\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.8041 - val_loss: 0.4471 - val_accuracy: 0.7973\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5139 - accuracy: 0.8024 - val_loss: 0.4627 - val_accuracy: 0.8108\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4843 - accuracy: 0.8260 - val_loss: 0.4504 - val_accuracy: 0.8108\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.7720 - val_loss: 0.4534 - val_accuracy: 0.8041\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5222 - accuracy: 0.7872 - val_loss: 0.4516 - val_accuracy: 0.8176\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.8091 - val_loss: 0.4464 - val_accuracy: 0.8176\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5160 - accuracy: 0.8176 - val_loss: 0.4533 - val_accuracy: 0.7905\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8091 - val_loss: 0.4492 - val_accuracy: 0.8176\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.8074 - val_loss: 0.4487 - val_accuracy: 0.8176\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5167 - accuracy: 0.7720 - val_loss: 0.4467 - val_accuracy: 0.8243\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4806 - accuracy: 0.8193 - val_loss: 0.4390 - val_accuracy: 0.8176\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5085 - accuracy: 0.7905 - val_loss: 0.4475 - val_accuracy: 0.8108\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5245 - accuracy: 0.8024 - val_loss: 0.4443 - val_accuracy: 0.8108\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5079 - accuracy: 0.8091 - val_loss: 0.4367 - val_accuracy: 0.8176\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5276 - accuracy: 0.7990 - val_loss: 0.4381 - val_accuracy: 0.8311\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4758 - accuracy: 0.8226 - val_loss: 0.4388 - val_accuracy: 0.8311\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4944 - accuracy: 0.7990 - val_loss: 0.4333 - val_accuracy: 0.8176\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7889 - val_loss: 0.4296 - val_accuracy: 0.8311\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5299 - accuracy: 0.7956 - val_loss: 0.4335 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4745 - accuracy: 0.8108 - val_loss: 0.4400 - val_accuracy: 0.8378\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.8226 - val_loss: 0.4374 - val_accuracy: 0.8311\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5140 - accuracy: 0.7872 - val_loss: 0.4351 - val_accuracy: 0.8311\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8108 - val_loss: 0.4364 - val_accuracy: 0.8311\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.8176 - val_loss: 0.4460 - val_accuracy: 0.8378\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.7872 - val_loss: 0.4392 - val_accuracy: 0.8378\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5652 - accuracy: 0.7889 - val_loss: 0.4444 - val_accuracy: 0.8243\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.7990 - val_loss: 0.4456 - val_accuracy: 0.8243\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4832 - accuracy: 0.8159 - val_loss: 0.4439 - val_accuracy: 0.8176\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5371 - accuracy: 0.7956 - val_loss: 0.4437 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8074 - val_loss: 0.4444 - val_accuracy: 0.8378\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8074 - val_loss: 0.4300 - val_accuracy: 0.8446\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.7905 - val_loss: 0.4299 - val_accuracy: 0.8378\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.7821 - val_loss: 0.4237 - val_accuracy: 0.8514\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.7939 - val_loss: 0.4292 - val_accuracy: 0.8446\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.8142 - val_loss: 0.4290 - val_accuracy: 0.8446\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5074 - accuracy: 0.8074 - val_loss: 0.4403 - val_accuracy: 0.8243\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5348 - accuracy: 0.7939 - val_loss: 0.4385 - val_accuracy: 0.8311\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4894 - accuracy: 0.8209 - val_loss: 0.4295 - val_accuracy: 0.8446\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4775 - accuracy: 0.8328 - val_loss: 0.4309 - val_accuracy: 0.8581\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5108 - accuracy: 0.7855 - val_loss: 0.4365 - val_accuracy: 0.8446\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4829 - accuracy: 0.8057 - val_loss: 0.4328 - val_accuracy: 0.8378\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4596 - accuracy: 0.8328 - val_loss: 0.4461 - val_accuracy: 0.8378\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5193 - accuracy: 0.8007 - val_loss: 0.4498 - val_accuracy: 0.8243\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.8024 - val_loss: 0.4561 - val_accuracy: 0.8311\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5279 - accuracy: 0.7956 - val_loss: 0.4518 - val_accuracy: 0.8243\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5058 - accuracy: 0.7922 - val_loss: 0.4359 - val_accuracy: 0.8514\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.8176 - val_loss: 0.4406 - val_accuracy: 0.8378\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.7872 - val_loss: 0.4380 - val_accuracy: 0.8378\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4999 - accuracy: 0.7973 - val_loss: 0.4499 - val_accuracy: 0.8311\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.7855 - val_loss: 0.4522 - val_accuracy: 0.8176\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4815 - accuracy: 0.8041 - val_loss: 0.4451 - val_accuracy: 0.8311\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5725 - accuracy: 0.7770 - val_loss: 0.4577 - val_accuracy: 0.8108\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5470 - accuracy: 0.8024 - val_loss: 0.4439 - val_accuracy: 0.8108\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5041 - accuracy: 0.8007 - val_loss: 0.4494 - val_accuracy: 0.8041\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4967 - accuracy: 0.8091 - val_loss: 0.4449 - val_accuracy: 0.8108\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7939 - val_loss: 0.4631 - val_accuracy: 0.8041\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.8041 - val_loss: 0.4587 - val_accuracy: 0.8243\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7973 - val_loss: 0.4499 - val_accuracy: 0.8176\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4985 - accuracy: 0.8125 - val_loss: 0.4460 - val_accuracy: 0.8176\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5474 - accuracy: 0.7753 - val_loss: 0.4461 - val_accuracy: 0.8176\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4690 - accuracy: 0.8277 - val_loss: 0.4457 - val_accuracy: 0.8243\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5156 - accuracy: 0.8091 - val_loss: 0.4474 - val_accuracy: 0.8243\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4660 - accuracy: 0.8193 - val_loss: 0.4505 - val_accuracy: 0.8108\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5422 - accuracy: 0.7889 - val_loss: 0.4539 - val_accuracy: 0.7973\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4934 - accuracy: 0.8057 - val_loss: 0.4502 - val_accuracy: 0.8176\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5341 - accuracy: 0.7990 - val_loss: 0.4509 - val_accuracy: 0.8041\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5073 - accuracy: 0.8007 - val_loss: 0.4487 - val_accuracy: 0.8243\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5228 - accuracy: 0.7855 - val_loss: 0.4562 - val_accuracy: 0.8176\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4988 - accuracy: 0.8074 - val_loss: 0.4472 - val_accuracy: 0.8243\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5373 - accuracy: 0.7939 - val_loss: 0.4461 - val_accuracy: 0.8378\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5215 - accuracy: 0.8074 - val_loss: 0.4456 - val_accuracy: 0.8446\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.8142 - val_loss: 0.4367 - val_accuracy: 0.8311\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8361 - val_loss: 0.4374 - val_accuracy: 0.8243\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.7939 - val_loss: 0.4364 - val_accuracy: 0.8514\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.8024 - val_loss: 0.4368 - val_accuracy: 0.8514\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4927 - accuracy: 0.8108 - val_loss: 0.4430 - val_accuracy: 0.8311\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4846 - accuracy: 0.7905 - val_loss: 0.4390 - val_accuracy: 0.8378\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5119 - accuracy: 0.8024 - val_loss: 0.4415 - val_accuracy: 0.8446\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5256 - accuracy: 0.7905 - val_loss: 0.4362 - val_accuracy: 0.8446\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7855 - val_loss: 0.4451 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.8226 - val_loss: 0.4362 - val_accuracy: 0.8581\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5081 - accuracy: 0.7753 - val_loss: 0.4349 - val_accuracy: 0.8243\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5136 - accuracy: 0.8125 - val_loss: 0.4398 - val_accuracy: 0.8311\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4989 - accuracy: 0.7889 - val_loss: 0.4332 - val_accuracy: 0.8581\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.7905 - val_loss: 0.4318 - val_accuracy: 0.8581\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5437 - accuracy: 0.7973 - val_loss: 0.4306 - val_accuracy: 0.8514\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5334 - accuracy: 0.7939 - val_loss: 0.4364 - val_accuracy: 0.8514\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4974 - accuracy: 0.7956 - val_loss: 0.4389 - val_accuracy: 0.8581\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7939 - val_loss: 0.4392 - val_accuracy: 0.8446\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5830 - accuracy: 0.7432 - val_loss: 0.4393 - val_accuracy: 0.8581\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5232 - accuracy: 0.8159 - val_loss: 0.4392 - val_accuracy: 0.8649\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5181 - accuracy: 0.7821 - val_loss: 0.4370 - val_accuracy: 0.8716\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5288 - accuracy: 0.8057 - val_loss: 0.4385 - val_accuracy: 0.8581\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5166 - accuracy: 0.7922 - val_loss: 0.4461 - val_accuracy: 0.8378\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4987 - accuracy: 0.8125 - val_loss: 0.4506 - val_accuracy: 0.8446\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4858 - accuracy: 0.8041 - val_loss: 0.4471 - val_accuracy: 0.8311\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4734 - accuracy: 0.8159 - val_loss: 0.4617 - val_accuracy: 0.8041\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5311 - accuracy: 0.7838 - val_loss: 0.4646 - val_accuracy: 0.8176\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7939 - val_loss: 0.4496 - val_accuracy: 0.8446\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.8074 - val_loss: 0.4480 - val_accuracy: 0.8378\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.8125 - val_loss: 0.4417 - val_accuracy: 0.8311\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4803 - accuracy: 0.8209 - val_loss: 0.4441 - val_accuracy: 0.8311\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4831 - accuracy: 0.8176 - val_loss: 0.4502 - val_accuracy: 0.8243\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.7905 - val_loss: 0.4671 - val_accuracy: 0.8243\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.8260 - val_loss: 0.4605 - val_accuracy: 0.8243\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.8024 - val_loss: 0.4519 - val_accuracy: 0.8311\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.8125 - val_loss: 0.4528 - val_accuracy: 0.8243\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5129 - accuracy: 0.8108 - val_loss: 0.4496 - val_accuracy: 0.8446\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.8125 - val_loss: 0.4521 - val_accuracy: 0.8378\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5148 - accuracy: 0.7889 - val_loss: 0.4501 - val_accuracy: 0.8581\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.8091 - val_loss: 0.4496 - val_accuracy: 0.8378\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.8159 - val_loss: 0.4458 - val_accuracy: 0.8243\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4809 - accuracy: 0.8108 - val_loss: 0.4522 - val_accuracy: 0.8176\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.8074 - val_loss: 0.4459 - val_accuracy: 0.8176\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.8091 - val_loss: 0.4422 - val_accuracy: 0.8243\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5241 - accuracy: 0.7652 - val_loss: 0.4502 - val_accuracy: 0.8311\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4876 - accuracy: 0.8074 - val_loss: 0.4471 - val_accuracy: 0.8378\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4760 - accuracy: 0.8345 - val_loss: 0.4514 - val_accuracy: 0.8243\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4830 - accuracy: 0.8024 - val_loss: 0.4594 - val_accuracy: 0.8176\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4964 - accuracy: 0.8057 - val_loss: 0.4446 - val_accuracy: 0.8176\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5015 - accuracy: 0.8024 - val_loss: 0.4500 - val_accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-29c08035a301>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 5s 11ms/step - loss: 2.1080 - accuracy: 0.4730 - val_loss: 1.2397 - val_accuracy: 0.4595\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 2.0951 - accuracy: 0.4797 - val_loss: 1.2689 - val_accuracy: 0.4797\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.7819 - accuracy: 0.5422 - val_loss: 1.2585 - val_accuracy: 0.4865\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.7666 - accuracy: 0.5236 - val_loss: 1.2527 - val_accuracy: 0.4730\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6262 - accuracy: 0.4814 - val_loss: 1.2290 - val_accuracy: 0.4730\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.5189 - accuracy: 0.4899 - val_loss: 1.1945 - val_accuracy: 0.5000\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4614 - accuracy: 0.4899 - val_loss: 1.1743 - val_accuracy: 0.5068\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3514 - accuracy: 0.5186 - val_loss: 1.1485 - val_accuracy: 0.5000\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3487 - accuracy: 0.5321 - val_loss: 1.1358 - val_accuracy: 0.4932\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2531 - accuracy: 0.5203 - val_loss: 1.1219 - val_accuracy: 0.5000\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2938 - accuracy: 0.4882 - val_loss: 1.1076 - val_accuracy: 0.5270\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1853 - accuracy: 0.5304 - val_loss: 1.0975 - val_accuracy: 0.5405\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1989 - accuracy: 0.5169 - val_loss: 1.0923 - val_accuracy: 0.4865\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1295 - accuracy: 0.5574 - val_loss: 1.0811 - val_accuracy: 0.5000\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1607 - accuracy: 0.5355 - val_loss: 1.0681 - val_accuracy: 0.5608\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1078 - accuracy: 0.5034 - val_loss: 1.0574 - val_accuracy: 0.5878\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1079 - accuracy: 0.5034 - val_loss: 1.0514 - val_accuracy: 0.5676\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0780 - accuracy: 0.5186 - val_loss: 1.0440 - val_accuracy: 0.5135\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0610 - accuracy: 0.5203 - val_loss: 1.0331 - val_accuracy: 0.6081\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0478 - accuracy: 0.5304 - val_loss: 1.0244 - val_accuracy: 0.5946\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0395 - accuracy: 0.5101 - val_loss: 1.0180 - val_accuracy: 0.5541\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0190 - accuracy: 0.5456 - val_loss: 1.0075 - val_accuracy: 0.6014\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 1.0036 - accuracy: 0.5338 - val_loss: 1.0010 - val_accuracy: 0.4932\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0079 - accuracy: 0.5304 - val_loss: 0.9897 - val_accuracy: 0.6149\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0017 - accuracy: 0.5422 - val_loss: 0.9826 - val_accuracy: 0.5068\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9705 - accuracy: 0.5490 - val_loss: 0.9686 - val_accuracy: 0.6081\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9754 - accuracy: 0.5372 - val_loss: 0.9605 - val_accuracy: 0.6081\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9596 - accuracy: 0.5456 - val_loss: 0.9509 - val_accuracy: 0.6351\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9504 - accuracy: 0.5372 - val_loss: 0.9415 - val_accuracy: 0.6554\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.5693 - val_loss: 0.9322 - val_accuracy: 0.6351\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9499 - accuracy: 0.5186 - val_loss: 0.9270 - val_accuracy: 0.6149\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9280 - accuracy: 0.5372 - val_loss: 0.9148 - val_accuracy: 0.6419\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9247 - accuracy: 0.5270 - val_loss: 0.9059 - val_accuracy: 0.6689\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9071 - accuracy: 0.5608 - val_loss: 0.8975 - val_accuracy: 0.6351\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9009 - accuracy: 0.5490 - val_loss: 0.8891 - val_accuracy: 0.6149\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8826 - accuracy: 0.5709 - val_loss: 0.8745 - val_accuracy: 0.6757\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8864 - accuracy: 0.5676 - val_loss: 0.8658 - val_accuracy: 0.6351\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8716 - accuracy: 0.5591 - val_loss: 0.8595 - val_accuracy: 0.6351\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8685 - accuracy: 0.5287 - val_loss: 0.8445 - val_accuracy: 0.6689\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8449 - accuracy: 0.5777 - val_loss: 0.8275 - val_accuracy: 0.6689\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8464 - accuracy: 0.5709 - val_loss: 0.8160 - val_accuracy: 0.6689\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8378 - accuracy: 0.5726 - val_loss: 0.8071 - val_accuracy: 0.7027\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.5743 - val_loss: 0.7915 - val_accuracy: 0.7095\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8222 - accuracy: 0.5574 - val_loss: 0.7828 - val_accuracy: 0.7027\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7973 - accuracy: 0.6166 - val_loss: 0.7676 - val_accuracy: 0.6892\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.8155 - accuracy: 0.5861 - val_loss: 0.7628 - val_accuracy: 0.7027\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7884 - accuracy: 0.6267 - val_loss: 0.7434 - val_accuracy: 0.7230\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7880 - accuracy: 0.5912 - val_loss: 0.7346 - val_accuracy: 0.7095\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7779 - accuracy: 0.6081 - val_loss: 0.7250 - val_accuracy: 0.7027\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7798 - accuracy: 0.6182 - val_loss: 0.7199 - val_accuracy: 0.7095\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7571 - accuracy: 0.6250 - val_loss: 0.7089 - val_accuracy: 0.7095\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7438 - accuracy: 0.6537 - val_loss: 0.6986 - val_accuracy: 0.7027\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7282 - accuracy: 0.6689 - val_loss: 0.6825 - val_accuracy: 0.7365\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7231 - accuracy: 0.6453 - val_loss: 0.6545 - val_accuracy: 0.7568\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7341 - accuracy: 0.6571 - val_loss: 0.6548 - val_accuracy: 0.7365\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.6791 - val_loss: 0.6259 - val_accuracy: 0.7703\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7135 - accuracy: 0.6639 - val_loss: 0.6224 - val_accuracy: 0.7905\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7019 - accuracy: 0.6639 - val_loss: 0.6268 - val_accuracy: 0.7905\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7108 - accuracy: 0.6672 - val_loss: 0.6217 - val_accuracy: 0.7905\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7078 - accuracy: 0.6655 - val_loss: 0.6156 - val_accuracy: 0.7905\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.6875 - val_loss: 0.6035 - val_accuracy: 0.8041\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.6926 - val_loss: 0.5994 - val_accuracy: 0.8108\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.6588 - val_loss: 0.5968 - val_accuracy: 0.7838\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6632 - accuracy: 0.6926 - val_loss: 0.5849 - val_accuracy: 0.7635\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.6622 - val_loss: 0.5758 - val_accuracy: 0.7973\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.6976 - val_loss: 0.5715 - val_accuracy: 0.8176\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.6959 - val_loss: 0.5682 - val_accuracy: 0.8378\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6697 - accuracy: 0.6774 - val_loss: 0.5568 - val_accuracy: 0.8243\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.6824 - val_loss: 0.5499 - val_accuracy: 0.8378\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.7213 - val_loss: 0.5461 - val_accuracy: 0.8243\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.6976 - val_loss: 0.5473 - val_accuracy: 0.8243\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6569 - accuracy: 0.7145 - val_loss: 0.5488 - val_accuracy: 0.8176\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6425 - accuracy: 0.7044 - val_loss: 0.5280 - val_accuracy: 0.8378\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6559 - accuracy: 0.7078 - val_loss: 0.5274 - val_accuracy: 0.8514\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6555 - accuracy: 0.6841 - val_loss: 0.5281 - val_accuracy: 0.8514\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6379 - accuracy: 0.7111 - val_loss: 0.5267 - val_accuracy: 0.8311\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6472 - accuracy: 0.6858 - val_loss: 0.5195 - val_accuracy: 0.8243\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6532 - accuracy: 0.7078 - val_loss: 0.5285 - val_accuracy: 0.8446\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.7399 - val_loss: 0.5212 - val_accuracy: 0.8446\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6082 - accuracy: 0.7348 - val_loss: 0.5043 - val_accuracy: 0.8514\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6070 - accuracy: 0.7162 - val_loss: 0.4983 - val_accuracy: 0.8581\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.7095 - val_loss: 0.4952 - val_accuracy: 0.8243\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6409 - accuracy: 0.6909 - val_loss: 0.4869 - val_accuracy: 0.8378\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6295 - accuracy: 0.7247 - val_loss: 0.4841 - val_accuracy: 0.8446\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.7652 - val_loss: 0.4697 - val_accuracy: 0.8446\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.7483 - val_loss: 0.4760 - val_accuracy: 0.8311\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5976 - accuracy: 0.7449 - val_loss: 0.4885 - val_accuracy: 0.8108\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.7652 - val_loss: 0.4880 - val_accuracy: 0.8041\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.7280 - val_loss: 0.4637 - val_accuracy: 0.8581\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.7196 - val_loss: 0.4721 - val_accuracy: 0.8581\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6158 - accuracy: 0.7297 - val_loss: 0.4725 - val_accuracy: 0.8514\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6117 - accuracy: 0.7027 - val_loss: 0.4699 - val_accuracy: 0.8581\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6402 - accuracy: 0.7179 - val_loss: 0.4886 - val_accuracy: 0.8311\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6976 - val_loss: 0.4983 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5988 - accuracy: 0.7551 - val_loss: 0.4871 - val_accuracy: 0.8446\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5682 - accuracy: 0.7517 - val_loss: 0.4787 - val_accuracy: 0.8514\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.7247 - val_loss: 0.4694 - val_accuracy: 0.8446\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.7348 - val_loss: 0.4803 - val_accuracy: 0.8446\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5944 - accuracy: 0.7382 - val_loss: 0.4781 - val_accuracy: 0.8581\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5854 - accuracy: 0.7534 - val_loss: 0.4673 - val_accuracy: 0.8514\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5974 - accuracy: 0.7483 - val_loss: 0.4704 - val_accuracy: 0.8581\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6108 - accuracy: 0.7500 - val_loss: 0.4623 - val_accuracy: 0.8716\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5872 - accuracy: 0.7399 - val_loss: 0.4518 - val_accuracy: 0.8649\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5739 - accuracy: 0.7669 - val_loss: 0.4550 - val_accuracy: 0.8514\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5973 - accuracy: 0.7382 - val_loss: 0.4455 - val_accuracy: 0.8784\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.7483 - val_loss: 0.4400 - val_accuracy: 0.8581\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6414 - accuracy: 0.7314 - val_loss: 0.4523 - val_accuracy: 0.8649\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7297 - val_loss: 0.4658 - val_accuracy: 0.8514\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.7416 - val_loss: 0.4709 - val_accuracy: 0.8649\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.7517 - val_loss: 0.4794 - val_accuracy: 0.8311\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6013 - accuracy: 0.7466 - val_loss: 0.4706 - val_accuracy: 0.8514\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.7449 - val_loss: 0.4622 - val_accuracy: 0.8446\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5858 - accuracy: 0.7399 - val_loss: 0.4675 - val_accuracy: 0.8176\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.7652 - val_loss: 0.4548 - val_accuracy: 0.8378\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.7483 - val_loss: 0.4374 - val_accuracy: 0.8784\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.7297 - val_loss: 0.4522 - val_accuracy: 0.8649\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.7432 - val_loss: 0.4654 - val_accuracy: 0.8446\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7568 - val_loss: 0.4372 - val_accuracy: 0.8581\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.7551 - val_loss: 0.4318 - val_accuracy: 0.8581\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5967 - accuracy: 0.7635 - val_loss: 0.4485 - val_accuracy: 0.8378\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5823 - accuracy: 0.7466 - val_loss: 0.4372 - val_accuracy: 0.8649\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5916 - accuracy: 0.7517 - val_loss: 0.4328 - val_accuracy: 0.8649\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5941 - accuracy: 0.7382 - val_loss: 0.4502 - val_accuracy: 0.8581\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5991 - accuracy: 0.7483 - val_loss: 0.4517 - val_accuracy: 0.8514\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.7432 - val_loss: 0.4388 - val_accuracy: 0.8649\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5984 - accuracy: 0.7399 - val_loss: 0.4352 - val_accuracy: 0.8716\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5658 - accuracy: 0.7432 - val_loss: 0.4245 - val_accuracy: 0.8716\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5845 - accuracy: 0.7416 - val_loss: 0.4286 - val_accuracy: 0.8784\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5413 - accuracy: 0.7905 - val_loss: 0.4198 - val_accuracy: 0.8919\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5645 - accuracy: 0.7720 - val_loss: 0.4189 - val_accuracy: 0.8649\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5635 - accuracy: 0.7618 - val_loss: 0.4335 - val_accuracy: 0.8581\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5480 - accuracy: 0.7669 - val_loss: 0.4224 - val_accuracy: 0.8581\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5679 - accuracy: 0.7770 - val_loss: 0.4229 - val_accuracy: 0.8581\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7449 - val_loss: 0.4203 - val_accuracy: 0.8378\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7601 - val_loss: 0.4179 - val_accuracy: 0.8581\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7584 - val_loss: 0.4012 - val_accuracy: 0.8649\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.3956 - val_accuracy: 0.8851\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5644 - accuracy: 0.7635 - val_loss: 0.4066 - val_accuracy: 0.8784\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.7720 - val_loss: 0.4194 - val_accuracy: 0.8649\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5605 - accuracy: 0.7466 - val_loss: 0.4114 - val_accuracy: 0.8784\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.7618 - val_loss: 0.4092 - val_accuracy: 0.8649\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5824 - accuracy: 0.7534 - val_loss: 0.4185 - val_accuracy: 0.8446\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7652 - val_loss: 0.4163 - val_accuracy: 0.8581\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7500 - val_loss: 0.4228 - val_accuracy: 0.8581\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5578 - accuracy: 0.7686 - val_loss: 0.4195 - val_accuracy: 0.8649\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7416 - val_loss: 0.4201 - val_accuracy: 0.8784\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5812 - accuracy: 0.7551 - val_loss: 0.4339 - val_accuracy: 0.8649\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.7568 - val_loss: 0.4333 - val_accuracy: 0.8514\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5582 - accuracy: 0.7838 - val_loss: 0.4238 - val_accuracy: 0.8716\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7618 - val_loss: 0.4189 - val_accuracy: 0.8851\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.8041 - val_loss: 0.4201 - val_accuracy: 0.8581\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5736 - accuracy: 0.7736 - val_loss: 0.4255 - val_accuracy: 0.8716\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7787 - val_loss: 0.4208 - val_accuracy: 0.8716\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7635 - val_loss: 0.4216 - val_accuracy: 0.8716\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5857 - accuracy: 0.7449 - val_loss: 0.4051 - val_accuracy: 0.8851\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5676 - accuracy: 0.7787 - val_loss: 0.4036 - val_accuracy: 0.8919\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5736 - accuracy: 0.7618 - val_loss: 0.3972 - val_accuracy: 0.8986\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5399 - accuracy: 0.7787 - val_loss: 0.4073 - val_accuracy: 0.8716\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5432 - accuracy: 0.7821 - val_loss: 0.4004 - val_accuracy: 0.8784\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5473 - accuracy: 0.7736 - val_loss: 0.4003 - val_accuracy: 0.9054\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5723 - accuracy: 0.7534 - val_loss: 0.4049 - val_accuracy: 0.8851\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5525 - accuracy: 0.7889 - val_loss: 0.4096 - val_accuracy: 0.8716\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.7601 - val_loss: 0.4139 - val_accuracy: 0.8784\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7584 - val_loss: 0.4163 - val_accuracy: 0.8784\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7922 - val_loss: 0.4113 - val_accuracy: 0.8716\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5771 - accuracy: 0.7432 - val_loss: 0.4187 - val_accuracy: 0.8716\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7838 - val_loss: 0.4185 - val_accuracy: 0.8649\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5420 - accuracy: 0.7872 - val_loss: 0.4082 - val_accuracy: 0.8784\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7855 - val_loss: 0.3997 - val_accuracy: 0.8784\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5540 - accuracy: 0.7601 - val_loss: 0.4037 - val_accuracy: 0.8649\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5661 - accuracy: 0.7568 - val_loss: 0.4065 - val_accuracy: 0.8851\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.8159 - val_loss: 0.3988 - val_accuracy: 0.8784\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7838 - val_loss: 0.3964 - val_accuracy: 0.8784\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7889 - val_loss: 0.3937 - val_accuracy: 0.8716\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5796 - accuracy: 0.7703 - val_loss: 0.4156 - val_accuracy: 0.8784\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6032 - accuracy: 0.7601 - val_loss: 0.4197 - val_accuracy: 0.8919\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5592 - accuracy: 0.7584 - val_loss: 0.4129 - val_accuracy: 0.8851\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7635 - val_loss: 0.4178 - val_accuracy: 0.8716\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5761 - accuracy: 0.7686 - val_loss: 0.4110 - val_accuracy: 0.8784\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7635 - val_loss: 0.4087 - val_accuracy: 0.8784\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7618 - val_loss: 0.4159 - val_accuracy: 0.8649\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7753 - val_loss: 0.4082 - val_accuracy: 0.8716\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5421 - accuracy: 0.7838 - val_loss: 0.3940 - val_accuracy: 0.8919\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5564 - accuracy: 0.7736 - val_loss: 0.3983 - val_accuracy: 0.8986\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5515 - accuracy: 0.7652 - val_loss: 0.3935 - val_accuracy: 0.8919\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5138 - accuracy: 0.7939 - val_loss: 0.3883 - val_accuracy: 0.9054\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5608 - accuracy: 0.7652 - val_loss: 0.3929 - val_accuracy: 0.8919\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5535 - accuracy: 0.7804 - val_loss: 0.3818 - val_accuracy: 0.8986\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5461 - accuracy: 0.7838 - val_loss: 0.3852 - val_accuracy: 0.8784\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5628 - accuracy: 0.7787 - val_loss: 0.3939 - val_accuracy: 0.8851\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7905 - val_loss: 0.3939 - val_accuracy: 0.8986\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5563 - accuracy: 0.7821 - val_loss: 0.3974 - val_accuracy: 0.8986\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7770 - val_loss: 0.4007 - val_accuracy: 0.8919\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5438 - accuracy: 0.7872 - val_loss: 0.3991 - val_accuracy: 0.8919\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.7568 - val_loss: 0.3879 - val_accuracy: 0.8919\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.7736 - val_loss: 0.3851 - val_accuracy: 0.9054\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7973 - val_loss: 0.4092 - val_accuracy: 0.8851\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7956 - val_loss: 0.4088 - val_accuracy: 0.8784\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.8024 - val_loss: 0.3846 - val_accuracy: 0.8986\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5922 - accuracy: 0.7720 - val_loss: 0.3947 - val_accuracy: 0.8986\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5550 - accuracy: 0.7669 - val_loss: 0.4070 - val_accuracy: 0.8919\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7855 - val_loss: 0.3901 - val_accuracy: 0.8851\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7990 - val_loss: 0.3970 - val_accuracy: 0.9054\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7703 - val_loss: 0.3993 - val_accuracy: 0.8986\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7855 - val_loss: 0.4068 - val_accuracy: 0.8851\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7872 - val_loss: 0.3887 - val_accuracy: 0.9189\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.8074 - val_loss: 0.3894 - val_accuracy: 0.8986\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7770 - val_loss: 0.3877 - val_accuracy: 0.8986\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.7821 - val_loss: 0.3892 - val_accuracy: 0.8784\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7889 - val_loss: 0.4015 - val_accuracy: 0.8716\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.7483 - val_loss: 0.4123 - val_accuracy: 0.8851\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5554 - accuracy: 0.7669 - val_loss: 0.4004 - val_accuracy: 0.8919\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5512 - accuracy: 0.7889 - val_loss: 0.3951 - val_accuracy: 0.8919\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4998 - accuracy: 0.7922 - val_loss: 0.3890 - val_accuracy: 0.8986\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5096 - accuracy: 0.8091 - val_loss: 0.3833 - val_accuracy: 0.8716\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5206 - accuracy: 0.7956 - val_loss: 0.3848 - val_accuracy: 0.8851\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5405 - accuracy: 0.7872 - val_loss: 0.3951 - val_accuracy: 0.8716\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5832 - accuracy: 0.7838 - val_loss: 0.3927 - val_accuracy: 0.8986\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5221 - accuracy: 0.7990 - val_loss: 0.3893 - val_accuracy: 0.8919\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.8024 - val_loss: 0.3861 - val_accuracy: 0.8919\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5691 - accuracy: 0.7483 - val_loss: 0.3909 - val_accuracy: 0.8919\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7686 - val_loss: 0.3853 - val_accuracy: 0.8986\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7855 - val_loss: 0.3939 - val_accuracy: 0.8649\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.8108 - val_loss: 0.3802 - val_accuracy: 0.8784\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5195 - accuracy: 0.7872 - val_loss: 0.3814 - val_accuracy: 0.8784\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.8057 - val_loss: 0.3963 - val_accuracy: 0.8649\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7855 - val_loss: 0.3959 - val_accuracy: 0.8784\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5362 - accuracy: 0.7770 - val_loss: 0.3762 - val_accuracy: 0.8784\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.7669 - val_loss: 0.3716 - val_accuracy: 0.8851\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.8260 - val_loss: 0.3853 - val_accuracy: 0.8649\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7922 - val_loss: 0.3786 - val_accuracy: 0.8649\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7922 - val_loss: 0.3694 - val_accuracy: 0.8919\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7889 - val_loss: 0.3736 - val_accuracy: 0.8716\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.7956 - val_loss: 0.3781 - val_accuracy: 0.8851\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.7635 - val_loss: 0.3790 - val_accuracy: 0.9054\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.8024 - val_loss: 0.3906 - val_accuracy: 0.8986\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7652 - val_loss: 0.3901 - val_accuracy: 0.8851\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7753 - val_loss: 0.3982 - val_accuracy: 0.8851\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.7889 - val_loss: 0.4000 - val_accuracy: 0.8851\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.8024 - val_loss: 0.3915 - val_accuracy: 0.8716\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5703 - accuracy: 0.7601 - val_loss: 0.3926 - val_accuracy: 0.8851\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5648 - accuracy: 0.7753 - val_loss: 0.4007 - val_accuracy: 0.8716\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5325 - accuracy: 0.7838 - val_loss: 0.3983 - val_accuracy: 0.8649\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5620 - accuracy: 0.7922 - val_loss: 0.4078 - val_accuracy: 0.8581\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5181 - accuracy: 0.7838 - val_loss: 0.3949 - val_accuracy: 0.8716\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5208 - accuracy: 0.8159 - val_loss: 0.3830 - val_accuracy: 0.8716\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7889 - val_loss: 0.3820 - val_accuracy: 0.8649\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7821 - val_loss: 0.3827 - val_accuracy: 0.8649\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7922 - val_loss: 0.3845 - val_accuracy: 0.8716\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5098 - accuracy: 0.8142 - val_loss: 0.3827 - val_accuracy: 0.8514\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.8024 - val_loss: 0.3862 - val_accuracy: 0.8649\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.8024 - val_loss: 0.3881 - val_accuracy: 0.8716\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7821 - val_loss: 0.3799 - val_accuracy: 0.8514\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.7990 - val_loss: 0.3759 - val_accuracy: 0.8581\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.8007 - val_loss: 0.3647 - val_accuracy: 0.8784\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.8074 - val_loss: 0.3697 - val_accuracy: 0.8851\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7990 - val_loss: 0.3817 - val_accuracy: 0.8919\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7973 - val_loss: 0.3848 - val_accuracy: 0.8716\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7889 - val_loss: 0.3808 - val_accuracy: 0.8851\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5049 - accuracy: 0.8074 - val_loss: 0.3819 - val_accuracy: 0.8784\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7855 - val_loss: 0.3815 - val_accuracy: 0.8716\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8125 - val_loss: 0.3907 - val_accuracy: 0.8716\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7889 - val_loss: 0.3828 - val_accuracy: 0.8649\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7804 - val_loss: 0.3945 - val_accuracy: 0.8649\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7736 - val_loss: 0.3957 - val_accuracy: 0.8716\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7821 - val_loss: 0.3961 - val_accuracy: 0.8649\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.8091 - val_loss: 0.3892 - val_accuracy: 0.8784\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4861 - accuracy: 0.7905 - val_loss: 0.3797 - val_accuracy: 0.8784\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5507 - accuracy: 0.8074 - val_loss: 0.3779 - val_accuracy: 0.8784\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5317 - accuracy: 0.7821 - val_loss: 0.3799 - val_accuracy: 0.8649\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5587 - accuracy: 0.7787 - val_loss: 0.3835 - val_accuracy: 0.8784\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5097 - accuracy: 0.7922 - val_loss: 0.3901 - val_accuracy: 0.8784\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5089 - accuracy: 0.8074 - val_loss: 0.4009 - val_accuracy: 0.8649\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5106 - accuracy: 0.8125 - val_loss: 0.3803 - val_accuracy: 0.8581\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5124 - accuracy: 0.7720 - val_loss: 0.3724 - val_accuracy: 0.8851\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7821 - val_loss: 0.3817 - val_accuracy: 0.8649\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.8024 - val_loss: 0.3834 - val_accuracy: 0.8649\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7872 - val_loss: 0.3801 - val_accuracy: 0.8649\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.7838 - val_loss: 0.3809 - val_accuracy: 0.8716\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.8159 - val_loss: 0.3851 - val_accuracy: 0.8716\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.7821 - val_loss: 0.3830 - val_accuracy: 0.8784\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5490 - accuracy: 0.7889 - val_loss: 0.3895 - val_accuracy: 0.8851\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.8091 - val_loss: 0.3820 - val_accuracy: 0.8851\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.7922 - val_loss: 0.3822 - val_accuracy: 0.8784\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.8159 - val_loss: 0.3827 - val_accuracy: 0.8716\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7905 - val_loss: 0.3757 - val_accuracy: 0.8649\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5392 - accuracy: 0.7855 - val_loss: 0.3783 - val_accuracy: 0.8716\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7669 - val_loss: 0.3747 - val_accuracy: 0.8851\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5301 - accuracy: 0.7703 - val_loss: 0.3817 - val_accuracy: 0.8784\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5117 - accuracy: 0.7872 - val_loss: 0.3865 - val_accuracy: 0.8649\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7872 - val_loss: 0.3794 - val_accuracy: 0.8649\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7889 - val_loss: 0.3774 - val_accuracy: 0.8649\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5018 - accuracy: 0.8142 - val_loss: 0.3754 - val_accuracy: 0.8784\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.7939 - val_loss: 0.3812 - val_accuracy: 0.8716\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4758 - accuracy: 0.8311 - val_loss: 0.3822 - val_accuracy: 0.8649\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5553 - accuracy: 0.7753 - val_loss: 0.3772 - val_accuracy: 0.8716\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5005 - accuracy: 0.8294 - val_loss: 0.3729 - val_accuracy: 0.8716\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5149 - accuracy: 0.8193 - val_loss: 0.3823 - val_accuracy: 0.8784\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5004 - accuracy: 0.8091 - val_loss: 0.3794 - val_accuracy: 0.8851\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4769 - accuracy: 0.8125 - val_loss: 0.3776 - val_accuracy: 0.8784\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4925 - accuracy: 0.8328 - val_loss: 0.3732 - val_accuracy: 0.8784\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5332 - accuracy: 0.7939 - val_loss: 0.3785 - val_accuracy: 0.8716\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5225 - accuracy: 0.8142 - val_loss: 0.3864 - val_accuracy: 0.8784\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7736 - val_loss: 0.4021 - val_accuracy: 0.8649\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4855 - accuracy: 0.8057 - val_loss: 0.3968 - val_accuracy: 0.8784\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5272 - accuracy: 0.8024 - val_loss: 0.3993 - val_accuracy: 0.8649\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5577 - accuracy: 0.7939 - val_loss: 0.3959 - val_accuracy: 0.8716\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7889 - val_loss: 0.3910 - val_accuracy: 0.8784\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5505 - accuracy: 0.7939 - val_loss: 0.3845 - val_accuracy: 0.8784\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5095 - accuracy: 0.7939 - val_loss: 0.3859 - val_accuracy: 0.8716\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.7551 - val_loss: 0.3867 - val_accuracy: 0.8716\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7855 - val_loss: 0.3757 - val_accuracy: 0.8716\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7939 - val_loss: 0.3828 - val_accuracy: 0.8784\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7973 - val_loss: 0.3867 - val_accuracy: 0.8716\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7703 - val_loss: 0.3718 - val_accuracy: 0.8716\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7956 - val_loss: 0.3732 - val_accuracy: 0.8716\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.7804 - val_loss: 0.3681 - val_accuracy: 0.8784\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7939 - val_loss: 0.3688 - val_accuracy: 0.8919\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.8057 - val_loss: 0.3659 - val_accuracy: 0.8784\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5184 - accuracy: 0.8041 - val_loss: 0.3728 - val_accuracy: 0.8784\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.8159 - val_loss: 0.3685 - val_accuracy: 0.8784\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.8159 - val_loss: 0.3664 - val_accuracy: 0.8784\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4923 - accuracy: 0.8108 - val_loss: 0.3721 - val_accuracy: 0.8649\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5177 - accuracy: 0.8108 - val_loss: 0.3813 - val_accuracy: 0.8649\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5069 - accuracy: 0.8024 - val_loss: 0.3835 - val_accuracy: 0.8581\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5542 - accuracy: 0.7787 - val_loss: 0.3959 - val_accuracy: 0.8581\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4892 - accuracy: 0.8193 - val_loss: 0.3858 - val_accuracy: 0.8649\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5242 - accuracy: 0.7804 - val_loss: 0.3855 - val_accuracy: 0.8581\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5179 - accuracy: 0.8057 - val_loss: 0.3868 - val_accuracy: 0.8649\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5230 - accuracy: 0.7855 - val_loss: 0.3847 - val_accuracy: 0.8716\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7821 - val_loss: 0.3797 - val_accuracy: 0.8784\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7973 - val_loss: 0.3818 - val_accuracy: 0.8716\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.8260 - val_loss: 0.3853 - val_accuracy: 0.8716\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.8142 - val_loss: 0.3852 - val_accuracy: 0.8649\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.8074 - val_loss: 0.3887 - val_accuracy: 0.8649\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.8176 - val_loss: 0.3803 - val_accuracy: 0.8716\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7568 - val_loss: 0.3862 - val_accuracy: 0.8851\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5021 - accuracy: 0.8108 - val_loss: 0.3789 - val_accuracy: 0.8716\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5197 - accuracy: 0.7770 - val_loss: 0.3721 - val_accuracy: 0.8784\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.7838 - val_loss: 0.3721 - val_accuracy: 0.8919\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5331 - accuracy: 0.7838 - val_loss: 0.3790 - val_accuracy: 0.8851\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4924 - accuracy: 0.7990 - val_loss: 0.3733 - val_accuracy: 0.8851\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5282 - accuracy: 0.8108 - val_loss: 0.3839 - val_accuracy: 0.8919\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5123 - accuracy: 0.7889 - val_loss: 0.3700 - val_accuracy: 0.8986\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.8193 - val_loss: 0.3632 - val_accuracy: 0.8716\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5194 - accuracy: 0.8091 - val_loss: 0.3735 - val_accuracy: 0.8851\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8176 - val_loss: 0.3759 - val_accuracy: 0.8716\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4925 - accuracy: 0.8057 - val_loss: 0.3765 - val_accuracy: 0.8716\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5278 - accuracy: 0.7956 - val_loss: 0.3736 - val_accuracy: 0.8784\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4971 - accuracy: 0.8125 - val_loss: 0.3796 - val_accuracy: 0.8581\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5273 - accuracy: 0.7922 - val_loss: 0.3794 - val_accuracy: 0.8716\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5179 - accuracy: 0.7821 - val_loss: 0.3773 - val_accuracy: 0.8716\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5066 - accuracy: 0.8108 - val_loss: 0.3675 - val_accuracy: 0.8716\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4997 - accuracy: 0.8007 - val_loss: 0.3692 - val_accuracy: 0.8784\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5123 - accuracy: 0.7973 - val_loss: 0.3708 - val_accuracy: 0.8851\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5334 - accuracy: 0.7889 - val_loss: 0.3727 - val_accuracy: 0.8716\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4901 - accuracy: 0.8176 - val_loss: 0.3783 - val_accuracy: 0.8649\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5168 - accuracy: 0.8311 - val_loss: 0.3775 - val_accuracy: 0.8649\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5118 - accuracy: 0.8007 - val_loss: 0.3561 - val_accuracy: 0.8716\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.8159 - val_loss: 0.3659 - val_accuracy: 0.8716\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.8041 - val_loss: 0.3732 - val_accuracy: 0.8649\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.8024 - val_loss: 0.3731 - val_accuracy: 0.8784\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5406 - accuracy: 0.7956 - val_loss: 0.3701 - val_accuracy: 0.8784\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.8057 - val_loss: 0.3717 - val_accuracy: 0.8716\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7703 - val_loss: 0.3815 - val_accuracy: 0.8784\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.8277 - val_loss: 0.3637 - val_accuracy: 0.8716\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7821 - val_loss: 0.3732 - val_accuracy: 0.8649\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.8057 - val_loss: 0.3791 - val_accuracy: 0.8649\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.7855 - val_loss: 0.3661 - val_accuracy: 0.8784\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.8328 - val_loss: 0.3593 - val_accuracy: 0.8716\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.8108 - val_loss: 0.3681 - val_accuracy: 0.8784\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.8142 - val_loss: 0.3630 - val_accuracy: 0.8784\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.8294 - val_loss: 0.3531 - val_accuracy: 0.8649\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5400 - accuracy: 0.7905 - val_loss: 0.3602 - val_accuracy: 0.8784\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.8057 - val_loss: 0.3713 - val_accuracy: 0.8716\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7720 - val_loss: 0.3661 - val_accuracy: 0.8784\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5222 - accuracy: 0.7905 - val_loss: 0.3775 - val_accuracy: 0.8784\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5273 - accuracy: 0.7872 - val_loss: 0.3880 - val_accuracy: 0.8716\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5109 - accuracy: 0.8057 - val_loss: 0.3796 - val_accuracy: 0.8784\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5171 - accuracy: 0.8007 - val_loss: 0.3790 - val_accuracy: 0.8851\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5460 - accuracy: 0.7855 - val_loss: 0.3782 - val_accuracy: 0.8649\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5189 - accuracy: 0.7872 - val_loss: 0.3716 - val_accuracy: 0.8784\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5259 - accuracy: 0.8108 - val_loss: 0.3705 - val_accuracy: 0.8851\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5161 - accuracy: 0.7939 - val_loss: 0.3706 - val_accuracy: 0.8784\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5443 - accuracy: 0.7905 - val_loss: 0.3812 - val_accuracy: 0.8784\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.7990 - val_loss: 0.3819 - val_accuracy: 0.8716\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.8091 - val_loss: 0.3812 - val_accuracy: 0.8716\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.7990 - val_loss: 0.3775 - val_accuracy: 0.8784\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.8108 - val_loss: 0.3718 - val_accuracy: 0.8581\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5603 - accuracy: 0.7618 - val_loss: 0.3763 - val_accuracy: 0.8446\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7990 - val_loss: 0.3714 - val_accuracy: 0.8716\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7973 - val_loss: 0.3755 - val_accuracy: 0.8716\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4939 - accuracy: 0.8243 - val_loss: 0.3727 - val_accuracy: 0.8784\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.8041 - val_loss: 0.3729 - val_accuracy: 0.8716\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5451 - accuracy: 0.8057 - val_loss: 0.3917 - val_accuracy: 0.8716\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.8007 - val_loss: 0.3743 - val_accuracy: 0.8784\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.8159 - val_loss: 0.3726 - val_accuracy: 0.8784\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5210 - accuracy: 0.8041 - val_loss: 0.3694 - val_accuracy: 0.8649\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.8277 - val_loss: 0.3652 - val_accuracy: 0.8716\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4786 - accuracy: 0.8243 - val_loss: 0.3588 - val_accuracy: 0.8851\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4726 - accuracy: 0.7956 - val_loss: 0.3675 - val_accuracy: 0.8851\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7838 - val_loss: 0.3794 - val_accuracy: 0.8919\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5598 - accuracy: 0.7838 - val_loss: 0.3869 - val_accuracy: 0.8784\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.8091 - val_loss: 0.3835 - val_accuracy: 0.8716\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5269 - accuracy: 0.8024 - val_loss: 0.3723 - val_accuracy: 0.8919\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5195 - accuracy: 0.7939 - val_loss: 0.3798 - val_accuracy: 0.8716\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5145 - accuracy: 0.8108 - val_loss: 0.3854 - val_accuracy: 0.8716\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5119 - accuracy: 0.8024 - val_loss: 0.3742 - val_accuracy: 0.8716\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5103 - accuracy: 0.8176 - val_loss: 0.3794 - val_accuracy: 0.8649\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5081 - accuracy: 0.8176 - val_loss: 0.3732 - val_accuracy: 0.8784\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5479 - accuracy: 0.7905 - val_loss: 0.3801 - val_accuracy: 0.8784\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5275 - accuracy: 0.7838 - val_loss: 0.3727 - val_accuracy: 0.8716\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5234 - accuracy: 0.7905 - val_loss: 0.3759 - val_accuracy: 0.8716\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5246 - accuracy: 0.7922 - val_loss: 0.3709 - val_accuracy: 0.8784\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4933 - accuracy: 0.7889 - val_loss: 0.3692 - val_accuracy: 0.8716\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.7872 - val_loss: 0.3734 - val_accuracy: 0.8784\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.8226 - val_loss: 0.3748 - val_accuracy: 0.8784\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.8041 - val_loss: 0.3748 - val_accuracy: 0.8784\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.8294 - val_loss: 0.3655 - val_accuracy: 0.8716\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.8091 - val_loss: 0.3664 - val_accuracy: 0.8784\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.8041 - val_loss: 0.3714 - val_accuracy: 0.8784\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5410 - accuracy: 0.7889 - val_loss: 0.3689 - val_accuracy: 0.8919\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5570 - accuracy: 0.7922 - val_loss: 0.3792 - val_accuracy: 0.8851\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4884 - accuracy: 0.8328 - val_loss: 0.3729 - val_accuracy: 0.8851\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5228 - accuracy: 0.8041 - val_loss: 0.3667 - val_accuracy: 0.8851\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.8125 - val_loss: 0.3690 - val_accuracy: 0.8716\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.8345 - val_loss: 0.3630 - val_accuracy: 0.8784\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.8074 - val_loss: 0.3672 - val_accuracy: 0.8581\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.8091 - val_loss: 0.3673 - val_accuracy: 0.8716\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.8193 - val_loss: 0.3630 - val_accuracy: 0.8649\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7956 - val_loss: 0.3680 - val_accuracy: 0.8716\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.8024 - val_loss: 0.3790 - val_accuracy: 0.8919\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4771 - accuracy: 0.8159 - val_loss: 0.3719 - val_accuracy: 0.8581\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4578 - accuracy: 0.8041 - val_loss: 0.3686 - val_accuracy: 0.8514\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5168 - accuracy: 0.8007 - val_loss: 0.3769 - val_accuracy: 0.8581\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4855 - accuracy: 0.8361 - val_loss: 0.3846 - val_accuracy: 0.8446\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4812 - accuracy: 0.8361 - val_loss: 0.3720 - val_accuracy: 0.8581\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5095 - accuracy: 0.7973 - val_loss: 0.3815 - val_accuracy: 0.8649\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4817 - accuracy: 0.8159 - val_loss: 0.3960 - val_accuracy: 0.8514\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.8007 - val_loss: 0.4009 - val_accuracy: 0.8446\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5398 - accuracy: 0.8142 - val_loss: 0.3980 - val_accuracy: 0.8514\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.8091 - val_loss: 0.3923 - val_accuracy: 0.8649\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5134 - accuracy: 0.7990 - val_loss: 0.3853 - val_accuracy: 0.8851\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5383 - accuracy: 0.7787 - val_loss: 0.3836 - val_accuracy: 0.8784\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5260 - accuracy: 0.7838 - val_loss: 0.3802 - val_accuracy: 0.8919\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5070 - accuracy: 0.8142 - val_loss: 0.3753 - val_accuracy: 0.8986\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.8142 - val_loss: 0.3748 - val_accuracy: 0.8784\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4947 - accuracy: 0.8074 - val_loss: 0.3833 - val_accuracy: 0.8784\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5033 - accuracy: 0.8074 - val_loss: 0.3682 - val_accuracy: 0.8851\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7939 - val_loss: 0.3782 - val_accuracy: 0.8784\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.8108 - val_loss: 0.3809 - val_accuracy: 0.8784\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5004 - accuracy: 0.8024 - val_loss: 0.3656 - val_accuracy: 0.8986\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.8057 - val_loss: 0.3621 - val_accuracy: 0.8919\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.8159 - val_loss: 0.3631 - val_accuracy: 0.8919\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.8193 - val_loss: 0.3655 - val_accuracy: 0.8851\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.8226 - val_loss: 0.3649 - val_accuracy: 0.8986\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4967 - accuracy: 0.8395 - val_loss: 0.3693 - val_accuracy: 0.8919\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.8041 - val_loss: 0.3752 - val_accuracy: 0.8784\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4828 - accuracy: 0.8193 - val_loss: 0.3683 - val_accuracy: 0.8851\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4563 - accuracy: 0.8345 - val_loss: 0.3820 - val_accuracy: 0.8649\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4762 - accuracy: 0.8260 - val_loss: 0.3713 - val_accuracy: 0.8851\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4693 - accuracy: 0.8142 - val_loss: 0.3728 - val_accuracy: 0.8784\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.7956 - val_loss: 0.3914 - val_accuracy: 0.8649\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5020 - accuracy: 0.7939 - val_loss: 0.3913 - val_accuracy: 0.8784\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4984 - accuracy: 0.8108 - val_loss: 0.3977 - val_accuracy: 0.8716\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4672 - accuracy: 0.8209 - val_loss: 0.3950 - val_accuracy: 0.8784\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5338 - accuracy: 0.8007 - val_loss: 0.3828 - val_accuracy: 0.8716\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5274 - accuracy: 0.7939 - val_loss: 0.3813 - val_accuracy: 0.8851\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.8007 - val_loss: 0.3813 - val_accuracy: 0.8784\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7889 - val_loss: 0.3917 - val_accuracy: 0.8581\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.8193 - val_loss: 0.3854 - val_accuracy: 0.8784\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4929 - accuracy: 0.8041 - val_loss: 0.3708 - val_accuracy: 0.8851\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7922 - val_loss: 0.3667 - val_accuracy: 0.8919\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5647 - accuracy: 0.7736 - val_loss: 0.3701 - val_accuracy: 0.9054\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.8125 - val_loss: 0.3695 - val_accuracy: 0.8919\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5056 - accuracy: 0.8007 - val_loss: 0.3742 - val_accuracy: 0.8851\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5112 - accuracy: 0.8007 - val_loss: 0.3892 - val_accuracy: 0.8716\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.8024 - val_loss: 0.3953 - val_accuracy: 0.8784\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5068 - accuracy: 0.7821 - val_loss: 0.3902 - val_accuracy: 0.8649\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.8091 - val_loss: 0.3794 - val_accuracy: 0.8919\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4746 - accuracy: 0.8328 - val_loss: 0.3814 - val_accuracy: 0.8851\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.8024 - val_loss: 0.3891 - val_accuracy: 0.8784\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7872 - val_loss: 0.3822 - val_accuracy: 0.8784\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5016 - accuracy: 0.8024 - val_loss: 0.3762 - val_accuracy: 0.8716\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5147 - accuracy: 0.8041 - val_loss: 0.3753 - val_accuracy: 0.8716\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.8125 - val_loss: 0.3751 - val_accuracy: 0.8716\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4893 - accuracy: 0.8057 - val_loss: 0.3786 - val_accuracy: 0.8784\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4895 - accuracy: 0.8226 - val_loss: 0.3835 - val_accuracy: 0.8784\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5094 - accuracy: 0.8074 - val_loss: 0.3853 - val_accuracy: 0.8716\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5332 - accuracy: 0.7568 - val_loss: 0.3834 - val_accuracy: 0.8784\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4872 - accuracy: 0.8024 - val_loss: 0.3735 - val_accuracy: 0.8784\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5039 - accuracy: 0.8108 - val_loss: 0.3671 - val_accuracy: 0.8919\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5191 - accuracy: 0.7939 - val_loss: 0.3820 - val_accuracy: 0.8919\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4862 - accuracy: 0.8361 - val_loss: 0.3880 - val_accuracy: 0.8851\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7990 - val_loss: 0.3942 - val_accuracy: 0.8716\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4919 - accuracy: 0.7855 - val_loss: 0.3905 - val_accuracy: 0.8716\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.8226 - val_loss: 0.3920 - val_accuracy: 0.8784\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.8294 - val_loss: 0.3772 - val_accuracy: 0.8851\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5497 - accuracy: 0.7635 - val_loss: 0.3753 - val_accuracy: 0.8851\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.8091 - val_loss: 0.3670 - val_accuracy: 0.8851\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8851\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-29c08035a301>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 4s 11ms/step - loss: 1.5273 - accuracy: 0.5084 - val_loss: 1.1373 - val_accuracy: 0.5338\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4679 - accuracy: 0.4983 - val_loss: 1.1355 - val_accuracy: 0.5068\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4089 - accuracy: 0.4747 - val_loss: 1.1292 - val_accuracy: 0.4932\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2425 - accuracy: 0.5152 - val_loss: 1.1187 - val_accuracy: 0.4797\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2385 - accuracy: 0.5152 - val_loss: 1.1021 - val_accuracy: 0.4797\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.1640 - accuracy: 0.5051 - val_loss: 1.0875 - val_accuracy: 0.4865\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.1713 - accuracy: 0.5338 - val_loss: 1.0725 - val_accuracy: 0.4932\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0923 - accuracy: 0.5270 - val_loss: 1.0593 - val_accuracy: 0.4865\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0810 - accuracy: 0.5304 - val_loss: 1.0449 - val_accuracy: 0.4865\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0466 - accuracy: 0.5220 - val_loss: 1.0320 - val_accuracy: 0.4865\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0466 - accuracy: 0.5152 - val_loss: 1.0190 - val_accuracy: 0.4797\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0248 - accuracy: 0.5253 - val_loss: 1.0067 - val_accuracy: 0.5068\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0029 - accuracy: 0.5490 - val_loss: 0.9963 - val_accuracy: 0.5000\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9811 - accuracy: 0.5726 - val_loss: 0.9844 - val_accuracy: 0.4932\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9770 - accuracy: 0.5389 - val_loss: 0.9728 - val_accuracy: 0.4865\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9667 - accuracy: 0.5389 - val_loss: 0.9614 - val_accuracy: 0.4865\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9540 - accuracy: 0.5439 - val_loss: 0.9493 - val_accuracy: 0.4932\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9514 - accuracy: 0.5084 - val_loss: 0.9386 - val_accuracy: 0.4865\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9357 - accuracy: 0.5253 - val_loss: 0.9291 - val_accuracy: 0.5000\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9278 - accuracy: 0.5051 - val_loss: 0.9176 - val_accuracy: 0.5000\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9153 - accuracy: 0.5253 - val_loss: 0.9060 - val_accuracy: 0.5811\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9045 - accuracy: 0.5152 - val_loss: 0.8965 - val_accuracy: 0.4932\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8858 - accuracy: 0.5524 - val_loss: 0.8854 - val_accuracy: 0.5270\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8823 - accuracy: 0.5355 - val_loss: 0.8756 - val_accuracy: 0.5473\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8731 - accuracy: 0.5456 - val_loss: 0.8655 - val_accuracy: 0.5135\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8653 - accuracy: 0.5236 - val_loss: 0.8582 - val_accuracy: 0.5270\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8557 - accuracy: 0.5321 - val_loss: 0.8489 - val_accuracy: 0.5203\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8415 - accuracy: 0.5557 - val_loss: 0.8397 - val_accuracy: 0.5338\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8396 - accuracy: 0.5355 - val_loss: 0.8313 - val_accuracy: 0.5473\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8219 - accuracy: 0.5642 - val_loss: 0.8210 - val_accuracy: 0.6486\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8173 - accuracy: 0.5608 - val_loss: 0.8080 - val_accuracy: 0.6892\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8086 - accuracy: 0.5625 - val_loss: 0.7986 - val_accuracy: 0.7095\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8016 - accuracy: 0.5861 - val_loss: 0.7862 - val_accuracy: 0.6959\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7916 - accuracy: 0.5777 - val_loss: 0.7737 - val_accuracy: 0.6959\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7748 - accuracy: 0.6250 - val_loss: 0.7569 - val_accuracy: 0.7162\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7803 - accuracy: 0.5659 - val_loss: 0.7466 - val_accuracy: 0.7770\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7810 - accuracy: 0.5760 - val_loss: 0.7362 - val_accuracy: 0.7770\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7514 - accuracy: 0.6267 - val_loss: 0.7155 - val_accuracy: 0.7770\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7555 - accuracy: 0.6064 - val_loss: 0.7061 - val_accuracy: 0.7905\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7497 - accuracy: 0.6503 - val_loss: 0.6996 - val_accuracy: 0.8041\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7388 - accuracy: 0.6672 - val_loss: 0.6858 - val_accuracy: 0.7568\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7202 - accuracy: 0.6419 - val_loss: 0.6635 - val_accuracy: 0.7838\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7327 - accuracy: 0.6199 - val_loss: 0.6623 - val_accuracy: 0.8041\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7202 - accuracy: 0.6334 - val_loss: 0.6639 - val_accuracy: 0.7973\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7127 - accuracy: 0.6689 - val_loss: 0.6571 - val_accuracy: 0.7230\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.6858 - val_loss: 0.6299 - val_accuracy: 0.7838\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.7095 - val_loss: 0.6217 - val_accuracy: 0.7905\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.6706 - val_loss: 0.6140 - val_accuracy: 0.7838\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.6824 - val_loss: 0.6000 - val_accuracy: 0.8041\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6956 - accuracy: 0.6706 - val_loss: 0.6036 - val_accuracy: 0.7973\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6800 - accuracy: 0.6976 - val_loss: 0.5966 - val_accuracy: 0.8041\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.6959 - val_loss: 0.5849 - val_accuracy: 0.7973\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6553 - accuracy: 0.7078 - val_loss: 0.5756 - val_accuracy: 0.7770\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6483 - accuracy: 0.7128 - val_loss: 0.5648 - val_accuracy: 0.7905\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.7162 - val_loss: 0.5738 - val_accuracy: 0.7905\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.7027 - val_loss: 0.5727 - val_accuracy: 0.7770\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6539 - accuracy: 0.6959 - val_loss: 0.5631 - val_accuracy: 0.7905\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6833 - accuracy: 0.6824 - val_loss: 0.5721 - val_accuracy: 0.8108\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6722 - accuracy: 0.6993 - val_loss: 0.5816 - val_accuracy: 0.8108\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6439 - accuracy: 0.7179 - val_loss: 0.5640 - val_accuracy: 0.7905\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6354 - accuracy: 0.7247 - val_loss: 0.5573 - val_accuracy: 0.7838\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6323 - accuracy: 0.7264 - val_loss: 0.5483 - val_accuracy: 0.7973\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6633 - accuracy: 0.6976 - val_loss: 0.5528 - val_accuracy: 0.7973\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6385 - accuracy: 0.7179 - val_loss: 0.5505 - val_accuracy: 0.8041\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6018 - accuracy: 0.7399 - val_loss: 0.5373 - val_accuracy: 0.7905\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6475 - accuracy: 0.7213 - val_loss: 0.5405 - val_accuracy: 0.7838\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6231 - accuracy: 0.7213 - val_loss: 0.5286 - val_accuracy: 0.7838\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6245 - accuracy: 0.7297 - val_loss: 0.5181 - val_accuracy: 0.8176\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6015 - accuracy: 0.7314 - val_loss: 0.5018 - val_accuracy: 0.8176\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6144 - accuracy: 0.7331 - val_loss: 0.4994 - val_accuracy: 0.8176\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.7179 - val_loss: 0.5082 - val_accuracy: 0.8243\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6671 - accuracy: 0.7179 - val_loss: 0.5191 - val_accuracy: 0.8243\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.7500 - val_loss: 0.5137 - val_accuracy: 0.8243\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6375 - accuracy: 0.7044 - val_loss: 0.5210 - val_accuracy: 0.8108\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6223 - accuracy: 0.7162 - val_loss: 0.5167 - val_accuracy: 0.8176\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6308 - accuracy: 0.7196 - val_loss: 0.5186 - val_accuracy: 0.8041\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6229 - accuracy: 0.7213 - val_loss: 0.5174 - val_accuracy: 0.7905\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.7247 - val_loss: 0.5150 - val_accuracy: 0.8108\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.7399 - val_loss: 0.5132 - val_accuracy: 0.8041\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.7111 - val_loss: 0.5192 - val_accuracy: 0.8311\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.7382 - val_loss: 0.5115 - val_accuracy: 0.8176\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6039 - accuracy: 0.7348 - val_loss: 0.5045 - val_accuracy: 0.8176\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.7247 - val_loss: 0.4940 - val_accuracy: 0.8243\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6298 - accuracy: 0.7416 - val_loss: 0.4976 - val_accuracy: 0.8108\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.7095 - val_loss: 0.4970 - val_accuracy: 0.8243\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5584 - accuracy: 0.7889 - val_loss: 0.4854 - val_accuracy: 0.8378\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6149 - accuracy: 0.7534 - val_loss: 0.4949 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6087 - accuracy: 0.7314 - val_loss: 0.4924 - val_accuracy: 0.8176\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7432 - val_loss: 0.4818 - val_accuracy: 0.8446\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5889 - accuracy: 0.7534 - val_loss: 0.4860 - val_accuracy: 0.8446\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6236 - accuracy: 0.7280 - val_loss: 0.4817 - val_accuracy: 0.8378\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5999 - accuracy: 0.7601 - val_loss: 0.4861 - val_accuracy: 0.8243\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5898 - accuracy: 0.7331 - val_loss: 0.4873 - val_accuracy: 0.8446\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5697 - accuracy: 0.7584 - val_loss: 0.4748 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6023 - accuracy: 0.7601 - val_loss: 0.4699 - val_accuracy: 0.8378\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5703 - accuracy: 0.7534 - val_loss: 0.4587 - val_accuracy: 0.8378\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5901 - accuracy: 0.7331 - val_loss: 0.4678 - val_accuracy: 0.8378\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6037 - accuracy: 0.7500 - val_loss: 0.4664 - val_accuracy: 0.8378\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6209 - accuracy: 0.7449 - val_loss: 0.4650 - val_accuracy: 0.8446\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5977 - accuracy: 0.7365 - val_loss: 0.4665 - val_accuracy: 0.8378\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6345 - accuracy: 0.7213 - val_loss: 0.4701 - val_accuracy: 0.8378\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5723 - accuracy: 0.7601 - val_loss: 0.4626 - val_accuracy: 0.8581\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5854 - accuracy: 0.7635 - val_loss: 0.4542 - val_accuracy: 0.8581\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.7635 - val_loss: 0.4534 - val_accuracy: 0.8514\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6061 - accuracy: 0.7348 - val_loss: 0.4593 - val_accuracy: 0.8514\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.7551 - val_loss: 0.4596 - val_accuracy: 0.8514\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.7551 - val_loss: 0.4597 - val_accuracy: 0.8514\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7568 - val_loss: 0.4557 - val_accuracy: 0.8446\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.7770 - val_loss: 0.4562 - val_accuracy: 0.8311\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7584 - val_loss: 0.4417 - val_accuracy: 0.8446\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.7703 - val_loss: 0.4344 - val_accuracy: 0.8581\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5681 - accuracy: 0.7669 - val_loss: 0.4502 - val_accuracy: 0.8446\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.7534 - val_loss: 0.4463 - val_accuracy: 0.8649\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6059 - accuracy: 0.7331 - val_loss: 0.4467 - val_accuracy: 0.8446\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6082 - accuracy: 0.7466 - val_loss: 0.4504 - val_accuracy: 0.8716\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.7601 - val_loss: 0.4536 - val_accuracy: 0.8311\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5932 - accuracy: 0.7500 - val_loss: 0.4546 - val_accuracy: 0.8581\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5665 - accuracy: 0.7584 - val_loss: 0.4451 - val_accuracy: 0.8649\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6024 - accuracy: 0.7551 - val_loss: 0.4476 - val_accuracy: 0.8581\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5869 - accuracy: 0.7568 - val_loss: 0.4459 - val_accuracy: 0.8581\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5575 - accuracy: 0.7787 - val_loss: 0.4337 - val_accuracy: 0.8581\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5661 - accuracy: 0.7753 - val_loss: 0.4313 - val_accuracy: 0.8851\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5907 - accuracy: 0.7568 - val_loss: 0.4410 - val_accuracy: 0.8784\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5916 - accuracy: 0.7601 - val_loss: 0.4423 - val_accuracy: 0.8581\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7720 - val_loss: 0.4440 - val_accuracy: 0.8378\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7534 - val_loss: 0.4315 - val_accuracy: 0.8514\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7787 - val_loss: 0.4323 - val_accuracy: 0.8514\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7601 - val_loss: 0.4233 - val_accuracy: 0.8581\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.7686 - val_loss: 0.4147 - val_accuracy: 0.8581\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6242 - accuracy: 0.7280 - val_loss: 0.4296 - val_accuracy: 0.8446\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7787 - val_loss: 0.4201 - val_accuracy: 0.8649\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7787 - val_loss: 0.4127 - val_accuracy: 0.8851\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.7686 - val_loss: 0.4174 - val_accuracy: 0.8784\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7703 - val_loss: 0.4147 - val_accuracy: 0.8784\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5758 - accuracy: 0.7720 - val_loss: 0.4183 - val_accuracy: 0.8649\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5911 - accuracy: 0.7618 - val_loss: 0.4216 - val_accuracy: 0.8581\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7584 - val_loss: 0.4205 - val_accuracy: 0.8649\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.7753 - val_loss: 0.4241 - val_accuracy: 0.8784\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5691 - accuracy: 0.7770 - val_loss: 0.4275 - val_accuracy: 0.8649\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5507 - accuracy: 0.7939 - val_loss: 0.4214 - val_accuracy: 0.8784\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.7770 - val_loss: 0.4265 - val_accuracy: 0.8649\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.4283 - val_accuracy: 0.8851\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5739 - accuracy: 0.7568 - val_loss: 0.4243 - val_accuracy: 0.8784\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5615 - accuracy: 0.7584 - val_loss: 0.4179 - val_accuracy: 0.8649\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.7584 - val_loss: 0.4242 - val_accuracy: 0.8784\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5820 - accuracy: 0.7601 - val_loss: 0.4196 - val_accuracy: 0.8851\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5748 - accuracy: 0.7720 - val_loss: 0.4151 - val_accuracy: 0.8784\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5570 - accuracy: 0.7618 - val_loss: 0.4141 - val_accuracy: 0.8649\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5661 - accuracy: 0.7601 - val_loss: 0.4276 - val_accuracy: 0.8649\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5475 - accuracy: 0.8024 - val_loss: 0.4253 - val_accuracy: 0.8716\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5722 - accuracy: 0.7720 - val_loss: 0.4064 - val_accuracy: 0.8919\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5659 - accuracy: 0.7855 - val_loss: 0.4095 - val_accuracy: 0.8851\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5733 - accuracy: 0.7348 - val_loss: 0.4159 - val_accuracy: 0.8581\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7753 - val_loss: 0.4055 - val_accuracy: 0.8581\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.7517 - val_loss: 0.4057 - val_accuracy: 0.8649\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.7821 - val_loss: 0.4007 - val_accuracy: 0.8919\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7601 - val_loss: 0.4059 - val_accuracy: 0.8649\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7872 - val_loss: 0.3875 - val_accuracy: 0.8919\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5319 - accuracy: 0.8007 - val_loss: 0.3802 - val_accuracy: 0.8649\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7770 - val_loss: 0.3817 - val_accuracy: 0.8784\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6150 - accuracy: 0.7348 - val_loss: 0.4020 - val_accuracy: 0.8784\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.7686 - val_loss: 0.4117 - val_accuracy: 0.8716\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7956 - val_loss: 0.4142 - val_accuracy: 0.8851\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5764 - accuracy: 0.7618 - val_loss: 0.4123 - val_accuracy: 0.8919\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5377 - accuracy: 0.7939 - val_loss: 0.4033 - val_accuracy: 0.8784\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7855 - val_loss: 0.3951 - val_accuracy: 0.8851\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5501 - accuracy: 0.7905 - val_loss: 0.3959 - val_accuracy: 0.8851\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7534 - val_loss: 0.3877 - val_accuracy: 0.9054\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.8074 - val_loss: 0.3969 - val_accuracy: 0.8716\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7753 - val_loss: 0.4008 - val_accuracy: 0.8919\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7399 - val_loss: 0.4068 - val_accuracy: 0.8716\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7686 - val_loss: 0.4164 - val_accuracy: 0.8581\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.7635 - val_loss: 0.3994 - val_accuracy: 0.8784\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5662 - accuracy: 0.7618 - val_loss: 0.4047 - val_accuracy: 0.8716\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5735 - accuracy: 0.7686 - val_loss: 0.4186 - val_accuracy: 0.8581\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5717 - accuracy: 0.7736 - val_loss: 0.4118 - val_accuracy: 0.8784\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5690 - accuracy: 0.7736 - val_loss: 0.4089 - val_accuracy: 0.8784\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5436 - accuracy: 0.7855 - val_loss: 0.4080 - val_accuracy: 0.8784\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5522 - accuracy: 0.7804 - val_loss: 0.4062 - val_accuracy: 0.8716\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6124 - accuracy: 0.7449 - val_loss: 0.4323 - val_accuracy: 0.8784\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7736 - val_loss: 0.4089 - val_accuracy: 0.8784\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7787 - val_loss: 0.4183 - val_accuracy: 0.8649\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7753 - val_loss: 0.4189 - val_accuracy: 0.8649\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7922 - val_loss: 0.4021 - val_accuracy: 0.8784\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5518 - accuracy: 0.8007 - val_loss: 0.4139 - val_accuracy: 0.8919\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7787 - val_loss: 0.4014 - val_accuracy: 0.8784\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.7736 - val_loss: 0.4065 - val_accuracy: 0.8784\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5255 - accuracy: 0.7804 - val_loss: 0.4025 - val_accuracy: 0.8851\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7973 - val_loss: 0.4013 - val_accuracy: 0.8851\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.7736 - val_loss: 0.4008 - val_accuracy: 0.8851\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7889 - val_loss: 0.3987 - val_accuracy: 0.8716\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.7432 - val_loss: 0.4071 - val_accuracy: 0.8716\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5794 - accuracy: 0.7466 - val_loss: 0.4059 - val_accuracy: 0.8784\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7804 - val_loss: 0.3974 - val_accuracy: 0.8716\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7889 - val_loss: 0.4004 - val_accuracy: 0.8851\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7939 - val_loss: 0.3943 - val_accuracy: 0.8919\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5644 - accuracy: 0.7804 - val_loss: 0.3945 - val_accuracy: 0.8919\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7973 - val_loss: 0.4004 - val_accuracy: 0.8784\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.7517 - val_loss: 0.4022 - val_accuracy: 0.8784\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7889 - val_loss: 0.4089 - val_accuracy: 0.8716\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5678 - accuracy: 0.7686 - val_loss: 0.4087 - val_accuracy: 0.8851\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5718 - accuracy: 0.7770 - val_loss: 0.4064 - val_accuracy: 0.8784\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5351 - accuracy: 0.8074 - val_loss: 0.3928 - val_accuracy: 0.8851\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5105 - accuracy: 0.7973 - val_loss: 0.3856 - val_accuracy: 0.8851\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5478 - accuracy: 0.7534 - val_loss: 0.3936 - val_accuracy: 0.8851\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5347 - accuracy: 0.7905 - val_loss: 0.3888 - val_accuracy: 0.8649\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5374 - accuracy: 0.7770 - val_loss: 0.4044 - val_accuracy: 0.8649\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.7736 - val_loss: 0.3956 - val_accuracy: 0.8649\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5752 - accuracy: 0.7618 - val_loss: 0.4027 - val_accuracy: 0.8784\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5473 - accuracy: 0.7787 - val_loss: 0.4021 - val_accuracy: 0.8784\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7939 - val_loss: 0.3987 - val_accuracy: 0.8581\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.7601 - val_loss: 0.3998 - val_accuracy: 0.8784\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7855 - val_loss: 0.3947 - val_accuracy: 0.8784\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5525 - accuracy: 0.7990 - val_loss: 0.3831 - val_accuracy: 0.8716\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7736 - val_loss: 0.3882 - val_accuracy: 0.8851\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.8125 - val_loss: 0.3912 - val_accuracy: 0.8784\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5579 - accuracy: 0.7990 - val_loss: 0.3924 - val_accuracy: 0.8716\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.8041 - val_loss: 0.3931 - val_accuracy: 0.8784\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7889 - val_loss: 0.3966 - val_accuracy: 0.8919\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5540 - accuracy: 0.7787 - val_loss: 0.3977 - val_accuracy: 0.8851\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.7922 - val_loss: 0.3980 - val_accuracy: 0.8581\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.7804 - val_loss: 0.4012 - val_accuracy: 0.8716\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7635 - val_loss: 0.4009 - val_accuracy: 0.8784\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5478 - accuracy: 0.7601 - val_loss: 0.4034 - val_accuracy: 0.8514\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7973 - val_loss: 0.3956 - val_accuracy: 0.8716\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.8108 - val_loss: 0.4021 - val_accuracy: 0.8581\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.8091 - val_loss: 0.3906 - val_accuracy: 0.8514\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5011 - accuracy: 0.7939 - val_loss: 0.3875 - val_accuracy: 0.8446\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5182 - accuracy: 0.8057 - val_loss: 0.4126 - val_accuracy: 0.8581\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5675 - accuracy: 0.7736 - val_loss: 0.3975 - val_accuracy: 0.8581\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5596 - accuracy: 0.7652 - val_loss: 0.3957 - val_accuracy: 0.8784\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5490 - accuracy: 0.7770 - val_loss: 0.3941 - val_accuracy: 0.8649\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5605 - accuracy: 0.7534 - val_loss: 0.3937 - val_accuracy: 0.8649\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5483 - accuracy: 0.7753 - val_loss: 0.3972 - val_accuracy: 0.8581\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7855 - val_loss: 0.4005 - val_accuracy: 0.8514\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5330 - accuracy: 0.7838 - val_loss: 0.3983 - val_accuracy: 0.8716\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5738 - accuracy: 0.7956 - val_loss: 0.3995 - val_accuracy: 0.8446\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.7855 - val_loss: 0.3891 - val_accuracy: 0.8649\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5643 - accuracy: 0.7686 - val_loss: 0.3957 - val_accuracy: 0.8581\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5706 - accuracy: 0.7568 - val_loss: 0.4052 - val_accuracy: 0.8784\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.8024 - val_loss: 0.3857 - val_accuracy: 0.8851\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7601 - val_loss: 0.3779 - val_accuracy: 0.8986\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.8007 - val_loss: 0.3791 - val_accuracy: 0.9054\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7990 - val_loss: 0.3682 - val_accuracy: 0.9054\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5585 - accuracy: 0.7686 - val_loss: 0.3732 - val_accuracy: 0.9122\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7973 - val_loss: 0.3777 - val_accuracy: 0.8986\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5598 - accuracy: 0.7787 - val_loss: 0.3926 - val_accuracy: 0.8851\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7821 - val_loss: 0.3850 - val_accuracy: 0.8986\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5298 - accuracy: 0.7939 - val_loss: 0.3856 - val_accuracy: 0.8851\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.8024 - val_loss: 0.3795 - val_accuracy: 0.8919\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5180 - accuracy: 0.8074 - val_loss: 0.3721 - val_accuracy: 0.8986\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5476 - accuracy: 0.7753 - val_loss: 0.3747 - val_accuracy: 0.8986\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.8024 - val_loss: 0.3661 - val_accuracy: 0.8919\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.8024 - val_loss: 0.3707 - val_accuracy: 0.8986\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5612 - accuracy: 0.7568 - val_loss: 0.3874 - val_accuracy: 0.8986\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5435 - accuracy: 0.7973 - val_loss: 0.3972 - val_accuracy: 0.8851\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5242 - accuracy: 0.7720 - val_loss: 0.4030 - val_accuracy: 0.8514\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4837 - accuracy: 0.8311 - val_loss: 0.3819 - val_accuracy: 0.9054\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5122 - accuracy: 0.8007 - val_loss: 0.3821 - val_accuracy: 0.8919\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5143 - accuracy: 0.8091 - val_loss: 0.3753 - val_accuracy: 0.8919\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5291 - accuracy: 0.7990 - val_loss: 0.3761 - val_accuracy: 0.8716\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.7973 - val_loss: 0.3830 - val_accuracy: 0.8784\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7939 - val_loss: 0.3903 - val_accuracy: 0.8514\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7939 - val_loss: 0.3935 - val_accuracy: 0.8514\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5550 - accuracy: 0.7787 - val_loss: 0.3779 - val_accuracy: 0.8716\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7905 - val_loss: 0.3803 - val_accuracy: 0.8716\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7787 - val_loss: 0.3866 - val_accuracy: 0.8919\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7855 - val_loss: 0.3970 - val_accuracy: 0.8851\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.8057 - val_loss: 0.3901 - val_accuracy: 0.8784\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7939 - val_loss: 0.3899 - val_accuracy: 0.8716\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.8074 - val_loss: 0.3852 - val_accuracy: 0.8784\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5490 - accuracy: 0.7753 - val_loss: 0.3936 - val_accuracy: 0.8716\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7720 - val_loss: 0.3977 - val_accuracy: 0.8784\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5482 - accuracy: 0.7855 - val_loss: 0.3879 - val_accuracy: 0.8851\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.8091 - val_loss: 0.3759 - val_accuracy: 0.8851\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7939 - val_loss: 0.3756 - val_accuracy: 0.8919\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7905 - val_loss: 0.3811 - val_accuracy: 0.8649\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.8125 - val_loss: 0.3829 - val_accuracy: 0.8784\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7770 - val_loss: 0.3869 - val_accuracy: 0.8514\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.7838 - val_loss: 0.4047 - val_accuracy: 0.8649\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7973 - val_loss: 0.3891 - val_accuracy: 0.8851\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5223 - accuracy: 0.7990 - val_loss: 0.3903 - val_accuracy: 0.8851\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5130 - accuracy: 0.8057 - val_loss: 0.3947 - val_accuracy: 0.8581\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5541 - accuracy: 0.7753 - val_loss: 0.3972 - val_accuracy: 0.8581\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5519 - accuracy: 0.7703 - val_loss: 0.4062 - val_accuracy: 0.8716\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5620 - accuracy: 0.7770 - val_loss: 0.4040 - val_accuracy: 0.8716\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5265 - accuracy: 0.7838 - val_loss: 0.3960 - val_accuracy: 0.8716\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5369 - accuracy: 0.8091 - val_loss: 0.4049 - val_accuracy: 0.8514\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5260 - accuracy: 0.7973 - val_loss: 0.4001 - val_accuracy: 0.8716\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5408 - accuracy: 0.7618 - val_loss: 0.3918 - val_accuracy: 0.8784\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7990 - val_loss: 0.3901 - val_accuracy: 0.8649\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5337 - accuracy: 0.7956 - val_loss: 0.3859 - val_accuracy: 0.8784\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7956 - val_loss: 0.3842 - val_accuracy: 0.8716\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.7787 - val_loss: 0.3818 - val_accuracy: 0.8649\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.7753 - val_loss: 0.3828 - val_accuracy: 0.8851\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5395 - accuracy: 0.7720 - val_loss: 0.3963 - val_accuracy: 0.8919\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.8176 - val_loss: 0.3838 - val_accuracy: 0.8851\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5003 - accuracy: 0.8091 - val_loss: 0.3665 - val_accuracy: 0.8986\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5445 - accuracy: 0.7736 - val_loss: 0.3734 - val_accuracy: 0.8986\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.8007 - val_loss: 0.3702 - val_accuracy: 0.8851\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.8142 - val_loss: 0.3632 - val_accuracy: 0.8986\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.8108 - val_loss: 0.3779 - val_accuracy: 0.8581\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5122 - accuracy: 0.7922 - val_loss: 0.3756 - val_accuracy: 0.8784\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5299 - accuracy: 0.7872 - val_loss: 0.3686 - val_accuracy: 0.8986\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.8041 - val_loss: 0.3662 - val_accuracy: 0.8986\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7669 - val_loss: 0.3719 - val_accuracy: 0.8851\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.8091 - val_loss: 0.3825 - val_accuracy: 0.9122\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7787 - val_loss: 0.3810 - val_accuracy: 0.8919\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5031 - accuracy: 0.8142 - val_loss: 0.3749 - val_accuracy: 0.8986\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5325 - accuracy: 0.7872 - val_loss: 0.3700 - val_accuracy: 0.8851\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5516 - accuracy: 0.7770 - val_loss: 0.3821 - val_accuracy: 0.8919\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5169 - accuracy: 0.7872 - val_loss: 0.3744 - val_accuracy: 0.9054\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5243 - accuracy: 0.7956 - val_loss: 0.3728 - val_accuracy: 0.9054\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5854 - accuracy: 0.7652 - val_loss: 0.3974 - val_accuracy: 0.8919\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5348 - accuracy: 0.7787 - val_loss: 0.3971 - val_accuracy: 0.8716\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5370 - accuracy: 0.7703 - val_loss: 0.3917 - val_accuracy: 0.8784\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5231 - accuracy: 0.7855 - val_loss: 0.3867 - val_accuracy: 0.8851\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7736 - val_loss: 0.3941 - val_accuracy: 0.8649\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7736 - val_loss: 0.4075 - val_accuracy: 0.8581\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.8074 - val_loss: 0.3950 - val_accuracy: 0.8716\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.8091 - val_loss: 0.3882 - val_accuracy: 0.8784\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.8024 - val_loss: 0.3804 - val_accuracy: 0.8919\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7905 - val_loss: 0.3871 - val_accuracy: 0.9054\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7669 - val_loss: 0.3816 - val_accuracy: 0.8919\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7889 - val_loss: 0.3829 - val_accuracy: 0.8784\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5294 - accuracy: 0.7838 - val_loss: 0.3923 - val_accuracy: 0.8784\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5099 - accuracy: 0.8057 - val_loss: 0.3858 - val_accuracy: 0.8784\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5278 - accuracy: 0.7939 - val_loss: 0.3946 - val_accuracy: 0.8784\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.7956 - val_loss: 0.3911 - val_accuracy: 0.8851\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5462 - accuracy: 0.7838 - val_loss: 0.3957 - val_accuracy: 0.8581\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.7939 - val_loss: 0.3846 - val_accuracy: 0.8784\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.8057 - val_loss: 0.3817 - val_accuracy: 0.8716\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.7855 - val_loss: 0.3863 - val_accuracy: 0.8716\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7720 - val_loss: 0.3908 - val_accuracy: 0.8784\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.8243 - val_loss: 0.3828 - val_accuracy: 0.8784\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.8007 - val_loss: 0.3808 - val_accuracy: 0.8851\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7990 - val_loss: 0.3825 - val_accuracy: 0.8716\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5539 - accuracy: 0.7770 - val_loss: 0.3849 - val_accuracy: 0.8581\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5369 - accuracy: 0.8041 - val_loss: 0.3913 - val_accuracy: 0.8716\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5429 - accuracy: 0.7635 - val_loss: 0.3915 - val_accuracy: 0.8649\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5688 - accuracy: 0.7686 - val_loss: 0.4155 - val_accuracy: 0.8446\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4821 - accuracy: 0.8311 - val_loss: 0.3907 - val_accuracy: 0.8446\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5147 - accuracy: 0.7720 - val_loss: 0.3798 - val_accuracy: 0.8784\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4602 - accuracy: 0.8311 - val_loss: 0.3855 - val_accuracy: 0.8649\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5239 - accuracy: 0.8057 - val_loss: 0.3927 - val_accuracy: 0.8514\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5367 - accuracy: 0.7821 - val_loss: 0.3910 - val_accuracy: 0.8649\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.7990 - val_loss: 0.3904 - val_accuracy: 0.8784\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.8463 - val_loss: 0.3776 - val_accuracy: 0.8851\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.8041 - val_loss: 0.3889 - val_accuracy: 0.8649\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.7889 - val_loss: 0.3893 - val_accuracy: 0.8784\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7956 - val_loss: 0.4020 - val_accuracy: 0.8716\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5294 - accuracy: 0.7956 - val_loss: 0.4028 - val_accuracy: 0.8446\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5519 - accuracy: 0.7889 - val_loss: 0.3933 - val_accuracy: 0.8716\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5336 - accuracy: 0.8024 - val_loss: 0.3953 - val_accuracy: 0.8716\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.8007 - val_loss: 0.3856 - val_accuracy: 0.8581\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.8091 - val_loss: 0.3949 - val_accuracy: 0.8514\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5536 - accuracy: 0.7669 - val_loss: 0.3906 - val_accuracy: 0.8919\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4986 - accuracy: 0.8074 - val_loss: 0.3946 - val_accuracy: 0.8784\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7872 - val_loss: 0.3985 - val_accuracy: 0.8581\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.8159 - val_loss: 0.3981 - val_accuracy: 0.8716\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7939 - val_loss: 0.3906 - val_accuracy: 0.8716\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.8159 - val_loss: 0.3857 - val_accuracy: 0.8784\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7669 - val_loss: 0.3818 - val_accuracy: 0.8716\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7703 - val_loss: 0.3839 - val_accuracy: 0.8649\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.8142 - val_loss: 0.3876 - val_accuracy: 0.8716\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7922 - val_loss: 0.3966 - val_accuracy: 0.8784\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5295 - accuracy: 0.7720 - val_loss: 0.3895 - val_accuracy: 0.8649\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5135 - accuracy: 0.7956 - val_loss: 0.3923 - val_accuracy: 0.8716\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4827 - accuracy: 0.8057 - val_loss: 0.3788 - val_accuracy: 0.8851\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4809 - accuracy: 0.8108 - val_loss: 0.3806 - val_accuracy: 0.8716\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5300 - accuracy: 0.7872 - val_loss: 0.3742 - val_accuracy: 0.8851\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5482 - accuracy: 0.7635 - val_loss: 0.3748 - val_accuracy: 0.8986\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5315 - accuracy: 0.7804 - val_loss: 0.3798 - val_accuracy: 0.8649\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5025 - accuracy: 0.8159 - val_loss: 0.3790 - val_accuracy: 0.8716\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.7922 - val_loss: 0.3766 - val_accuracy: 0.8716\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.8007 - val_loss: 0.3762 - val_accuracy: 0.8716\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5397 - accuracy: 0.7736 - val_loss: 0.3844 - val_accuracy: 0.8716\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5452 - accuracy: 0.7872 - val_loss: 0.3838 - val_accuracy: 0.8716\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.8074 - val_loss: 0.3860 - val_accuracy: 0.8851\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5134 - accuracy: 0.7838 - val_loss: 0.3864 - val_accuracy: 0.8716\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7905 - val_loss: 0.3974 - val_accuracy: 0.8581\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.7821 - val_loss: 0.3786 - val_accuracy: 0.8851\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.8041 - val_loss: 0.3780 - val_accuracy: 0.8851\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4999 - accuracy: 0.8226 - val_loss: 0.3830 - val_accuracy: 0.8784\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.8057 - val_loss: 0.3802 - val_accuracy: 0.8784\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5136 - accuracy: 0.8108 - val_loss: 0.3765 - val_accuracy: 0.8649\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5202 - accuracy: 0.7939 - val_loss: 0.3823 - val_accuracy: 0.8581\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5473 - accuracy: 0.7922 - val_loss: 0.3831 - val_accuracy: 0.8649\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.8125 - val_loss: 0.3866 - val_accuracy: 0.8649\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4990 - accuracy: 0.8024 - val_loss: 0.3759 - val_accuracy: 0.8716\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7973 - val_loss: 0.3816 - val_accuracy: 0.8784\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4922 - accuracy: 0.7939 - val_loss: 0.3814 - val_accuracy: 0.8784\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5320 - accuracy: 0.7939 - val_loss: 0.3679 - val_accuracy: 0.8649\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5472 - accuracy: 0.7736 - val_loss: 0.3690 - val_accuracy: 0.8649\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5303 - accuracy: 0.7838 - val_loss: 0.3741 - val_accuracy: 0.8784\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5181 - accuracy: 0.7804 - val_loss: 0.3766 - val_accuracy: 0.8784\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4995 - accuracy: 0.7973 - val_loss: 0.3841 - val_accuracy: 0.8784\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5443 - accuracy: 0.7804 - val_loss: 0.3752 - val_accuracy: 0.8986\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5068 - accuracy: 0.8125 - val_loss: 0.3778 - val_accuracy: 0.8784\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5022 - accuracy: 0.8041 - val_loss: 0.3747 - val_accuracy: 0.8851\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5244 - accuracy: 0.8007 - val_loss: 0.3753 - val_accuracy: 0.8986\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.8176 - val_loss: 0.3741 - val_accuracy: 0.8784\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.8159 - val_loss: 0.3774 - val_accuracy: 0.8919\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5131 - accuracy: 0.7905 - val_loss: 0.3874 - val_accuracy: 0.8514\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5153 - accuracy: 0.7889 - val_loss: 0.3679 - val_accuracy: 0.8851\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7990 - val_loss: 0.3760 - val_accuracy: 0.8649\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5242 - accuracy: 0.7973 - val_loss: 0.3784 - val_accuracy: 0.8649\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.8226 - val_loss: 0.3804 - val_accuracy: 0.8649\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4525 - accuracy: 0.8345 - val_loss: 0.3783 - val_accuracy: 0.8581\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7889 - val_loss: 0.3734 - val_accuracy: 0.8716\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4980 - accuracy: 0.8226 - val_loss: 0.3690 - val_accuracy: 0.8649\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4843 - accuracy: 0.8125 - val_loss: 0.3644 - val_accuracy: 0.8851\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.8125 - val_loss: 0.3689 - val_accuracy: 0.8649\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.8176 - val_loss: 0.3771 - val_accuracy: 0.8514\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.8041 - val_loss: 0.3722 - val_accuracy: 0.8649\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7973 - val_loss: 0.3911 - val_accuracy: 0.8581\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.8074 - val_loss: 0.3883 - val_accuracy: 0.8446\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4528 - accuracy: 0.8226 - val_loss: 0.3792 - val_accuracy: 0.8581\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.8057 - val_loss: 0.3906 - val_accuracy: 0.8514\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5190 - accuracy: 0.8159 - val_loss: 0.3907 - val_accuracy: 0.8514\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5314 - accuracy: 0.7770 - val_loss: 0.4008 - val_accuracy: 0.8514\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5065 - accuracy: 0.8057 - val_loss: 0.3837 - val_accuracy: 0.8851\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5425 - accuracy: 0.7838 - val_loss: 0.3864 - val_accuracy: 0.8784\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5620 - accuracy: 0.7669 - val_loss: 0.3876 - val_accuracy: 0.8851\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5222 - accuracy: 0.7838 - val_loss: 0.3904 - val_accuracy: 0.8986\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5199 - accuracy: 0.8108 - val_loss: 0.3845 - val_accuracy: 0.8784\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5163 - accuracy: 0.7770 - val_loss: 0.3818 - val_accuracy: 0.8986\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4979 - accuracy: 0.8007 - val_loss: 0.3841 - val_accuracy: 0.8851\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5190 - accuracy: 0.7889 - val_loss: 0.3893 - val_accuracy: 0.8581\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.8260 - val_loss: 0.3879 - val_accuracy: 0.8784\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7838 - val_loss: 0.4018 - val_accuracy: 0.8311\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.8125 - val_loss: 0.3893 - val_accuracy: 0.8716\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5084 - accuracy: 0.8108 - val_loss: 0.3829 - val_accuracy: 0.8581\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4898 - accuracy: 0.8125 - val_loss: 0.3854 - val_accuracy: 0.8581\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4909 - accuracy: 0.8041 - val_loss: 0.3764 - val_accuracy: 0.8716\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.8125 - val_loss: 0.3849 - val_accuracy: 0.8581\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7973 - val_loss: 0.3965 - val_accuracy: 0.8716\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4659 - accuracy: 0.8209 - val_loss: 0.4039 - val_accuracy: 0.8581\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.8209 - val_loss: 0.4045 - val_accuracy: 0.8446\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.8142 - val_loss: 0.3867 - val_accuracy: 0.8581\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7922 - val_loss: 0.4031 - val_accuracy: 0.8581\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.7939 - val_loss: 0.4008 - val_accuracy: 0.8649\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5209 - accuracy: 0.7787 - val_loss: 0.3927 - val_accuracy: 0.8581\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5001 - accuracy: 0.8108 - val_loss: 0.3890 - val_accuracy: 0.8446\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.7956 - val_loss: 0.3890 - val_accuracy: 0.8649\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8057 - val_loss: 0.3845 - val_accuracy: 0.8514\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.8142 - val_loss: 0.3883 - val_accuracy: 0.8514\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7821 - val_loss: 0.3930 - val_accuracy: 0.8446\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5073 - accuracy: 0.7939 - val_loss: 0.3892 - val_accuracy: 0.8649\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5452 - accuracy: 0.7753 - val_loss: 0.3803 - val_accuracy: 0.8784\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5131 - accuracy: 0.7973 - val_loss: 0.3856 - val_accuracy: 0.8581\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5153 - accuracy: 0.7973 - val_loss: 0.3736 - val_accuracy: 0.8716\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4899 - accuracy: 0.8091 - val_loss: 0.3668 - val_accuracy: 0.8649\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5081 - accuracy: 0.8091 - val_loss: 0.3750 - val_accuracy: 0.8784\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4955 - accuracy: 0.7990 - val_loss: 0.3722 - val_accuracy: 0.8716\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5091 - accuracy: 0.7990 - val_loss: 0.3720 - val_accuracy: 0.8649\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5031 - accuracy: 0.8193 - val_loss: 0.3725 - val_accuracy: 0.8649\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.7956 - val_loss: 0.3750 - val_accuracy: 0.8514\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.8193 - val_loss: 0.3697 - val_accuracy: 0.8581\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4669 - accuracy: 0.8142 - val_loss: 0.3619 - val_accuracy: 0.8649\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5071 - accuracy: 0.8007 - val_loss: 0.3629 - val_accuracy: 0.8784\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4994 - accuracy: 0.8260 - val_loss: 0.3757 - val_accuracy: 0.8716\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5088 - accuracy: 0.8024 - val_loss: 0.3777 - val_accuracy: 0.8649\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5032 - accuracy: 0.7990 - val_loss: 0.3787 - val_accuracy: 0.8446\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4854 - accuracy: 0.8125 - val_loss: 0.3798 - val_accuracy: 0.8649\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5300 - accuracy: 0.7720 - val_loss: 0.3975 - val_accuracy: 0.8581\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5243 - accuracy: 0.7618 - val_loss: 0.3935 - val_accuracy: 0.8784\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.7889 - val_loss: 0.3905 - val_accuracy: 0.8446\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4769 - accuracy: 0.8125 - val_loss: 0.3831 - val_accuracy: 0.8514\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4992 - accuracy: 0.8074 - val_loss: 0.3872 - val_accuracy: 0.8716\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4697 - accuracy: 0.8159 - val_loss: 0.3893 - val_accuracy: 0.8716\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5761 - accuracy: 0.7601 - val_loss: 0.3894 - val_accuracy: 0.8581\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4642 - accuracy: 0.8311 - val_loss: 0.3781 - val_accuracy: 0.8514\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5399 - accuracy: 0.7855 - val_loss: 0.3828 - val_accuracy: 0.8649\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5131 - accuracy: 0.8041 - val_loss: 0.3806 - val_accuracy: 0.8378\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4941 - accuracy: 0.8074 - val_loss: 0.3793 - val_accuracy: 0.8446\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4948 - accuracy: 0.7990 - val_loss: 0.3787 - val_accuracy: 0.8649\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5526 - accuracy: 0.7889 - val_loss: 0.3791 - val_accuracy: 0.8716\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4710 - accuracy: 0.8108 - val_loss: 0.3810 - val_accuracy: 0.8446\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5629 - accuracy: 0.7821 - val_loss: 0.3910 - val_accuracy: 0.8446\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4999 - accuracy: 0.8108 - val_loss: 0.3805 - val_accuracy: 0.8311\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5161 - accuracy: 0.8193 - val_loss: 0.3765 - val_accuracy: 0.8378\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5067 - accuracy: 0.7855 - val_loss: 0.3826 - val_accuracy: 0.8581\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.8074 - val_loss: 0.3679 - val_accuracy: 0.8649\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.8074 - val_loss: 0.3675 - val_accuracy: 0.8581\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5124 - accuracy: 0.8041 - val_loss: 0.3774 - val_accuracy: 0.8311\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5173 - accuracy: 0.7939 - val_loss: 0.3764 - val_accuracy: 0.8311\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4862 - accuracy: 0.7990 - val_loss: 0.3806 - val_accuracy: 0.8243\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4859 - accuracy: 0.8024 - val_loss: 0.3793 - val_accuracy: 0.8446\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.7821 - val_loss: 0.3885 - val_accuracy: 0.8378\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5210 - accuracy: 0.7973 - val_loss: 0.3808 - val_accuracy: 0.8581\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5159 - accuracy: 0.7905 - val_loss: 0.3855 - val_accuracy: 0.8716\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5418 - accuracy: 0.7787 - val_loss: 0.3865 - val_accuracy: 0.8784\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.7889 - val_loss: 0.3925 - val_accuracy: 0.8784\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.7872 - val_loss: 0.3931 - val_accuracy: 0.8784\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.7720 - val_loss: 0.3914 - val_accuracy: 0.8851\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.8024 - val_loss: 0.3868 - val_accuracy: 0.8784\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4708 - accuracy: 0.8024 - val_loss: 0.3805 - val_accuracy: 0.8716\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5002 - accuracy: 0.8057 - val_loss: 0.3823 - val_accuracy: 0.8784\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5137 - accuracy: 0.8007 - val_loss: 0.3944 - val_accuracy: 0.8378\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8378\n",
            "5/5 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-29c08035a301>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8175675868988037, 0.7972972989082336, 0.8243243098258972, 0.8851351141929626, 0.837837815284729]\n",
            "Accuracy: 0.83\n",
            "Sensitivity: 0.8252\n",
            "Specificity: 0.8365\n",
            "MCC: 0.6643\n",
            "Precision: 0.8457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn')\n",
        "model.save_weights('acp_mhcnn_weights')"
      ],
      "metadata": {
        "id": "i-ySuIJePlfJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn.keras')"
      ],
      "metadata": {
        "id": "sUnKQ39Oql-p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/acp_mhcnn.zip /content/acp_mhcnn"
      ],
      "metadata": {
        "id": "TCPrPTFlq03j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4035aee8-0dcb-4d8d-efe2-17eb2c13a5ec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/acp_mhcnn/ (stored 0%)\n",
            "  adding: content/acp_mhcnn/keras_metadata.pb (deflated 93%)\n",
            "  adding: content/acp_mhcnn/assets/ (stored 0%)\n",
            "  adding: content/acp_mhcnn/fingerprint.pb (stored 0%)\n",
            "  adding: content/acp_mhcnn/variables/ (stored 0%)\n",
            "  adding: content/acp_mhcnn/variables/variables.data-00000-of-00001 (deflated 30%)\n",
            "  adding: content/acp_mhcnn/variables/variables.index (deflated 71%)\n",
            "  adding: content/acp_mhcnn/saved_model.pb (deflated 90%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('acp_mhcnn_weights.h5')"
      ],
      "metadata": {
        "id": "t1YZag2MrItN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Network()\n",
        "discriminator.load_weights('./acp_mhcnn_weights.h5')"
      ],
      "metadata": {
        "id": "TwWTbybNIxbS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkTpxUpTJDkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}