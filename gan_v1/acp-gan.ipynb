{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 00:34:25.275913: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 15, 20)\n",
      "(376, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical as labelEncoding \n",
    "\n",
    "T = 15 # terminus_length\n",
    "\n",
    "X1 = np.load('bpf-740.npy')\n",
    "\n",
    "\n",
    "X1 = X1[:376,:T,:]\n",
    "\n",
    "\n",
    "Y  = [1 for _ in range(376)]\n",
    "\n",
    "Y = labelEncoding(Y, dtype=int)\n",
    "\n",
    "print(X1.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 15, 20)\n",
      "(15, 20)\n",
      "[[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 00:34:40.393223: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 00:34:40.395189: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)\n",
    "print(X1[0].shape)\n",
    "print(X1[0])\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF-2.11.0.\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Networks:\n",
    "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
    "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
    "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
    "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
    "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
    "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
    "from tensorflow.keras.models import (Sequential, Model)\n",
    "\n",
    "# Core:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Performance:\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
    "\n",
    "#Utilities:\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
    "from tensorflow.keras.utils import plot_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    ### Head-1:\n",
    "    input1 = Input(shape=X1[0].shape)\n",
    "\n",
    "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate=0.80)(x)\n",
    "\n",
    "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate=0.70)(x)\n",
    "\n",
    "    head1 = Flatten()(x)\n",
    "\n",
    "    # merge\n",
    "    merge = Concatenate()([head1])\n",
    "\n",
    "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dropout(rate=0.70)(output)\n",
    "\n",
    "    output = Dense(units=2, activation='softmax')(output)\n",
    "\n",
    "    return Model(inputs=[input1], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/homayoun/anaconda3/envs/acp-proj/lib/python3.10/site-packages/Bio/SubsMat/__init__.py:126: BiopythonDeprecationWarning: Bio.SubsMat has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.substitution_matrices as a replacement, and contact the Biopython developers if you still need the Bio.SubsMat module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import ProtParam\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio.SubsMat import MatrixInfo\n",
    "\n",
    "\n",
    "# Function to convert binary profile feature to amino acid sequence\n",
    "def bpf_to_sequence(binary_profile_feature):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVBZX\"\n",
    "    sequence = \"\"\n",
    "    for row in binary_profile_feature:\n",
    "        index = row.argmax()\n",
    "        sequence += amino_acids[index]\n",
    "    return sequence\n",
    "\n",
    "def seq_to_blosum(sequence):\n",
    "    blosum62 = MatrixInfo.blosum62\n",
    "    sequence = sequence.upper()\n",
    "    length = len(sequence)\n",
    "    blosum_matrix = []\n",
    "    for aa1 in sequence:\n",
    "        row = []\n",
    "        for aa2 in sequence:\n",
    "            if (aa1, aa2) in blosum62:\n",
    "                row.append(blosum62[(aa1, aa2)])\n",
    "            else:\n",
    "                row.append(blosum62[(aa2, aa1)])\n",
    "        blosum_matrix.append(row)\n",
    "    return blosum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpf_to_sequence(binary_profile_feature):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVBZX\"\n",
    "    sequence = \"\"\n",
    "    for row in binary_profile_feature:\n",
    "        i = 0\n",
    "        for item in row:\n",
    "            i += 1\n",
    "            if item.numpy() == 1:\n",
    "                sequence += amino_acids[i]\n",
    "    return sequence\n",
    "\n",
    "def seq_to_blosum(sequence):\n",
    "    blosum62 = MatrixInfo.blosum62\n",
    "    sequence = sequence.upper()\n",
    "    length = len(sequence)\n",
    "    blosum_matrix = []\n",
    "    for aa1 in sequence:\n",
    "        row = []\n",
    "        for aa2 in sequence:\n",
    "            if (aa1, aa2) in blosum62:\n",
    "                row.append(blosum62[(aa1, aa2)])\n",
    "            else:\n",
    "                row.append(blosum62[(aa2, aa1)])\n",
    "        blosum_matrix.append(row[:20])\n",
    "    return blosum_matrix\n",
    "\n",
    "def bpf_to_blosum_layer(seqs_bpf):\n",
    "    seqs_blosum = []\n",
    "    for bpf in seqs_bpf:\n",
    "        str_seq = bpf_to_sequence(bpf)\n",
    "        seqs_blosum.append(seq_to_blosum(str_seq))\n",
    "\n",
    "    print(seqs_blosum)\n",
    "    return seqs_blosum\n",
    "\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(25 * 20, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((25, 20)))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    # model = Sequential([\n",
    "    #     layers.Input(shape=(latent_dim,)),\n",
    "    #     layers.Dense(128, activation='relu'),\n",
    "    #     layers.Dense(256, activation='relu'),\n",
    "    #     layers.Dense(output_shape[0] * output_shape[1], activation='sigmoid'),\n",
    "    #     layers.Reshape(output_shape),\n",
    "    #     layers.Lambda(lambda x: tf.one_hot(tf.argmax(x, axis=-1), depth=output_shape[1])),\n",
    "    #     layers.Lambda(lambda x: tf.cast(x, dtype=tf.int32)),\n",
    "    # ])\n",
    "\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 25, 20), dtype=float32, numpy=\n",
       "array([[[0.5632561 , 0.59868664, 0.5302857 , 0.4743488 , 0.466737  ,\n",
       "         0.34883004, 0.42490128, 0.45570356, 0.5157759 , 0.43227735,\n",
       "         0.5345773 , 0.53017   , 0.64453214, 0.60913026, 0.46206757,\n",
       "         0.59450036, 0.60547906, 0.41075704, 0.4612134 , 0.64958704],\n",
       "        [0.537805  , 0.6134808 , 0.43480632, 0.45223516, 0.4935239 ,\n",
       "         0.617118  , 0.5539922 , 0.42951494, 0.4734365 , 0.71595275,\n",
       "         0.5659221 , 0.48000106, 0.5486674 , 0.3749019 , 0.591867  ,\n",
       "         0.62894344, 0.45892832, 0.619879  , 0.6292353 , 0.48482794],\n",
       "        [0.53032124, 0.54135466, 0.3992784 , 0.45691356, 0.42348823,\n",
       "         0.54346764, 0.40301245, 0.635292  , 0.6087729 , 0.48971877,\n",
       "         0.47702965, 0.5066979 , 0.5937844 , 0.5010254 , 0.5070725 ,\n",
       "         0.5717561 , 0.46633738, 0.6082328 , 0.35570124, 0.56770587],\n",
       "        [0.6369611 , 0.59157073, 0.5317608 , 0.4725489 , 0.49271443,\n",
       "         0.47108024, 0.59768707, 0.44858932, 0.45782515, 0.49494466,\n",
       "         0.57994056, 0.35180202, 0.47132036, 0.4592281 , 0.36732674,\n",
       "         0.49115255, 0.6138004 , 0.50672954, 0.52174014, 0.47360408],\n",
       "        [0.42082226, 0.5125797 , 0.5526031 , 0.45360133, 0.56814724,\n",
       "         0.5229271 , 0.5039524 , 0.57862085, 0.47160608, 0.4709144 ,\n",
       "         0.6072395 , 0.5470592 , 0.51424235, 0.5252361 , 0.40051222,\n",
       "         0.51819575, 0.48854074, 0.82447743, 0.56098866, 0.5264544 ],\n",
       "        [0.49841863, 0.5028127 , 0.36960194, 0.5840161 , 0.43222636,\n",
       "         0.5007068 , 0.32115257, 0.41898236, 0.33645752, 0.38380316,\n",
       "         0.40746388, 0.4990832 , 0.6100872 , 0.674903  , 0.40538457,\n",
       "         0.3543002 , 0.59845465, 0.4564681 , 0.537721  , 0.50083834],\n",
       "        [0.3912813 , 0.39472452, 0.5046474 , 0.4484664 , 0.49701405,\n",
       "         0.5286421 , 0.43904173, 0.6260346 , 0.5616287 , 0.47369802,\n",
       "         0.41097775, 0.6115197 , 0.5134689 , 0.4278293 , 0.4636939 ,\n",
       "         0.51445615, 0.70206356, 0.55609417, 0.61629766, 0.45321146],\n",
       "        [0.5863406 , 0.46648175, 0.42441568, 0.4919764 , 0.4959527 ,\n",
       "         0.465902  , 0.36896023, 0.36375785, 0.5889167 , 0.49319157,\n",
       "         0.66812956, 0.57424176, 0.61841196, 0.45448568, 0.47345334,\n",
       "         0.40066934, 0.50413185, 0.60676587, 0.40778083, 0.33923313],\n",
       "        [0.7112836 , 0.60965824, 0.49784568, 0.47735953, 0.55040544,\n",
       "         0.4424915 , 0.5898765 , 0.54020023, 0.56582254, 0.53610647,\n",
       "         0.5450102 , 0.47109148, 0.3578824 , 0.5247636 , 0.4990171 ,\n",
       "         0.5764655 , 0.53731287, 0.35276726, 0.3557826 , 0.4015928 ],\n",
       "        [0.64256036, 0.4896566 , 0.46265003, 0.48222244, 0.49864477,\n",
       "         0.39627954, 0.5905513 , 0.36817077, 0.51081145, 0.41932535,\n",
       "         0.49378797, 0.47229204, 0.6162217 , 0.39105657, 0.5398227 ,\n",
       "         0.58271855, 0.59069926, 0.43777537, 0.4934003 , 0.46687406],\n",
       "        [0.46124348, 0.5344869 , 0.48327878, 0.4042351 , 0.3340699 ,\n",
       "         0.5914652 , 0.43056256, 0.4127807 , 0.5295739 , 0.37097043,\n",
       "         0.5240537 , 0.47016862, 0.6004283 , 0.5098288 , 0.5604418 ,\n",
       "         0.40581325, 0.5908707 , 0.58932984, 0.6195788 , 0.3792247 ],\n",
       "        [0.45518708, 0.5889336 , 0.46505192, 0.5714427 , 0.68321383,\n",
       "         0.6720154 , 0.41510603, 0.57455623, 0.5409162 , 0.548153  ,\n",
       "         0.5390374 , 0.52004606, 0.6748459 , 0.43839025, 0.53355026,\n",
       "         0.5309828 , 0.4717491 , 0.48626292, 0.35866132, 0.45777673],\n",
       "        [0.5923278 , 0.61996967, 0.4735989 , 0.39184234, 0.39894697,\n",
       "         0.49086076, 0.49544093, 0.31450346, 0.5042115 , 0.3629669 ,\n",
       "         0.53031546, 0.568874  , 0.38695785, 0.56075865, 0.36140665,\n",
       "         0.41226256, 0.5205934 , 0.3631995 , 0.63866806, 0.47437742],\n",
       "        [0.3946607 , 0.55861807, 0.5527723 , 0.34876394, 0.5898647 ,\n",
       "         0.45919818, 0.5454816 , 0.28067496, 0.54585284, 0.43201703,\n",
       "         0.4761513 , 0.48884997, 0.5922862 , 0.38428596, 0.5561365 ,\n",
       "         0.36284325, 0.53859663, 0.4681099 , 0.5015347 , 0.42434758],\n",
       "        [0.5194189 , 0.4329214 , 0.46655664, 0.56464815, 0.5848903 ,\n",
       "         0.35290432, 0.41964462, 0.34618407, 0.5745133 , 0.45398304,\n",
       "         0.44883272, 0.56316364, 0.4282105 , 0.49059346, 0.65012574,\n",
       "         0.34384498, 0.48531884, 0.4936599 , 0.67067856, 0.6106674 ],\n",
       "        [0.63287646, 0.51188016, 0.53632206, 0.56232446, 0.6102647 ,\n",
       "         0.47195512, 0.49970347, 0.21727474, 0.34672523, 0.6415298 ,\n",
       "         0.47545585, 0.59462124, 0.5574194 , 0.27317208, 0.40569898,\n",
       "         0.72101355, 0.33163127, 0.4285013 , 0.32214448, 0.4382827 ],\n",
       "        [0.5569171 , 0.53819793, 0.6179107 , 0.5179952 , 0.73131865,\n",
       "         0.5079637 , 0.5900413 , 0.5929095 , 0.3536464 , 0.51202714,\n",
       "         0.30071127, 0.4619118 , 0.6409752 , 0.36170077, 0.5613048 ,\n",
       "         0.37300956, 0.5942439 , 0.36298576, 0.52213144, 0.38891327],\n",
       "        [0.4917145 , 0.44212666, 0.47958395, 0.67175883, 0.5941214 ,\n",
       "         0.53478867, 0.66468984, 0.6059653 , 0.5011896 , 0.48950094,\n",
       "         0.37251997, 0.43577504, 0.5511393 , 0.43692684, 0.4609504 ,\n",
       "         0.61078614, 0.6207413 , 0.49068007, 0.48351744, 0.5524459 ],\n",
       "        [0.40558642, 0.425589  , 0.37945   , 0.4261701 , 0.4278523 ,\n",
       "         0.49271312, 0.5013326 , 0.5126914 , 0.48966038, 0.455408  ,\n",
       "         0.43255493, 0.6159064 , 0.6516576 , 0.6250127 , 0.5987097 ,\n",
       "         0.4783478 , 0.45444667, 0.4858587 , 0.3478233 , 0.43632385],\n",
       "        [0.3839767 , 0.55149555, 0.35306257, 0.5699877 , 0.45664045,\n",
       "         0.53611726, 0.45621446, 0.46948633, 0.50504214, 0.47525093,\n",
       "         0.39959136, 0.5896552 , 0.70164174, 0.36069387, 0.47026634,\n",
       "         0.5387232 , 0.52659386, 0.4377902 , 0.47233564, 0.4548302 ],\n",
       "        [0.4866249 , 0.37721974, 0.43232772, 0.3394277 , 0.56352377,\n",
       "         0.6764758 , 0.54964733, 0.5061035 , 0.5104227 , 0.62545455,\n",
       "         0.39587635, 0.5175916 , 0.5764502 , 0.4250666 , 0.5557697 ,\n",
       "         0.399095  , 0.38405582, 0.53217727, 0.43513367, 0.4958466 ],\n",
       "        [0.5219496 , 0.56215835, 0.44841576, 0.46947894, 0.5133626 ,\n",
       "         0.47150877, 0.48937264, 0.53298855, 0.34168997, 0.54739845,\n",
       "         0.33506364, 0.39632457, 0.42123923, 0.5398249 , 0.48511007,\n",
       "         0.6202747 , 0.54714483, 0.52744704, 0.5688368 , 0.55657053],\n",
       "        [0.3937551 , 0.47098544, 0.5807195 , 0.5680055 , 0.612023  ,\n",
       "         0.5118247 , 0.399018  , 0.38052654, 0.5561237 , 0.49113604,\n",
       "         0.44289145, 0.43319938, 0.40562624, 0.62182826, 0.34762043,\n",
       "         0.44320947, 0.43303818, 0.42570382, 0.64257956, 0.4407714 ],\n",
       "        [0.6616223 , 0.50559425, 0.56019163, 0.54616445, 0.56227934,\n",
       "         0.49087456, 0.576504  , 0.5556002 , 0.317355  , 0.5000027 ,\n",
       "         0.51678544, 0.6079344 , 0.5418276 , 0.5845235 , 0.45361894,\n",
       "         0.40466684, 0.45926383, 0.6667951 , 0.50705194, 0.5476741 ],\n",
       "        [0.46703827, 0.6515716 , 0.5794923 , 0.65475345, 0.6714707 ,\n",
       "         0.46615475, 0.48654297, 0.4943525 , 0.426295  , 0.46925914,\n",
       "         0.48512524, 0.45385662, 0.29648018, 0.48662335, 0.5258452 ,\n",
       "         0.4266489 , 0.56365174, 0.4544968 , 0.4599996 , 0.44426596]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "latent_dim = 100  # Dimensionality of the latent space\n",
    "batch_size = 1\n",
    "output_shape = (25, 20)  # Desired output shape of the matrix\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "generated_matrix = generator(noise, training=False)\n",
    "\n",
    "generated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.load_weights('./acp_mhcnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 269ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30780783, 0.6921922 ],\n",
       "       [0.17504199, 0.824958  ],\n",
       "       [0.31832418, 0.68167585],\n",
       "       [0.18360284, 0.81639713],\n",
       "       [0.19149974, 0.80850023]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = discriminator.predict([X1[:5,:,:]])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "[[9.9999869e-01 1.3249029e-06]\n",
      " [9.9999928e-01 7.0653169e-07]\n",
      " [9.9999964e-01 3.3815178e-07]\n",
      " [9.9999905e-01 8.9603759e-07]\n",
      " [9.9999952e-01 4.7471184e-07]]\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([5, 100])\n",
    "fake_seqs = generator(noise, training=False)\n",
    "\n",
    "prediction = discriminator.predict([fake_seqs[:,:15,:]])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# def generator_loss(disc_output):\n",
    "#     batch_size = tf.shape(disc_output)[0]\n",
    "#     num_classes = tf.shape(disc_output)[1]\n",
    "#     desired_output = tf.concat([tf.zeros((batch_size, 1)), tf.ones((batch_size, num_classes - 1))], axis=1)\n",
    "    \n",
    "#     # Define binary cross entropy loss\n",
    "#     bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss = bce(desired_output, disc_output)\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[9.9999881e-01 1.1870885e-06]\n",
      " [9.9999774e-01 2.2686256e-06]\n",
      " [9.9999976e-01 2.6769021e-07]\n",
      " [9.9999809e-01 1.9313168e-06]\n",
      " [9.9999905e-01 9.4836673e-07]]\n",
      "[[0.30780783 0.6921922 ]\n",
      " [0.17504199 0.824958  ]\n",
      " [0.31832418 0.68167585]\n",
      " [0.18360284 0.81639713]\n",
      " [0.19149974 0.80850023]]\n",
      "tf.Tensor(6.8207464, shape=(), dtype=float32)\n",
      "tf.Tensor(7.706738, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([5, 100])\n",
    "fake_seqs = generator(noise, training=False)\n",
    "\n",
    "fake_prediction = discriminator.predict([fake_seqs[:,:15,:]])\n",
    "real_prediction = discriminator.predict([X1[:5]])\n",
    "print(fake_prediction)\n",
    "print(real_prediction)\n",
    "\n",
    "# disc_loss = discriminator_loss(Y[:5], real_prediction)\n",
    "gen_loss = generator_loss(fake_prediction)\n",
    "print(gen_loss)\n",
    "disc_loss = discriminator_loss(real_prediction, fake_prediction)\n",
    "print(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 500\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(peptides):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_bpf = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(peptides, training=True)\n",
    "      fake_output = discriminator(generated_bpf[:,:15,:], training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    print(gen_loss)\n",
    "    print(disc_loss)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "def train(epochs):\n",
    "  for epoch in range(epochs):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for seq_batch in dataset:\n",
    "      train_step(seq_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Time for epoch 1 is 8.748155117034912 sec\n",
      "Time for epoch 2 is 1.1100022792816162 sec\n",
      "Time for epoch 3 is 1.315201997756958 sec\n",
      "Time for epoch 4 is 0.8880801200866699 sec\n",
      "Time for epoch 5 is 0.7214643955230713 sec\n",
      "Time for epoch 6 is 0.8460509777069092 sec\n",
      "Time for epoch 7 is 1.2163808345794678 sec\n",
      "Time for epoch 8 is 1.182375192642212 sec\n",
      "Time for epoch 9 is 1.1970548629760742 sec\n",
      "Time for epoch 10 is 0.9175777435302734 sec\n",
      "Time for epoch 11 is 1.0940961837768555 sec\n",
      "Time for epoch 12 is 1.2876603603363037 sec\n",
      "Time for epoch 13 is 1.2435963153839111 sec\n",
      "Time for epoch 14 is 1.1411387920379639 sec\n",
      "Time for epoch 15 is 1.2384791374206543 sec\n",
      "Time for epoch 16 is 1.0840225219726562 sec\n",
      "Time for epoch 17 is 0.977283239364624 sec\n",
      "Time for epoch 18 is 0.8858296871185303 sec\n",
      "Time for epoch 19 is 0.9531545639038086 sec\n",
      "Time for epoch 20 is 0.8948516845703125 sec\n",
      "Time for epoch 21 is 0.9093008041381836 sec\n",
      "Time for epoch 22 is 0.8372509479522705 sec\n",
      "Time for epoch 23 is 1.0103659629821777 sec\n",
      "Time for epoch 24 is 1.2217507362365723 sec\n",
      "Time for epoch 25 is 1.4410090446472168 sec\n",
      "Time for epoch 26 is 1.4583842754364014 sec\n",
      "Time for epoch 27 is 1.273259162902832 sec\n",
      "Time for epoch 28 is 1.5292789936065674 sec\n",
      "Time for epoch 29 is 1.6818344593048096 sec\n",
      "Time for epoch 30 is 1.4247617721557617 sec\n",
      "Time for epoch 31 is 1.2878787517547607 sec\n",
      "Time for epoch 32 is 1.258470058441162 sec\n",
      "Time for epoch 33 is 1.510603904724121 sec\n",
      "Time for epoch 34 is 1.3271887302398682 sec\n",
      "Time for epoch 35 is 1.1706364154815674 sec\n",
      "Time for epoch 36 is 1.5132238864898682 sec\n",
      "Time for epoch 37 is 1.3398101329803467 sec\n",
      "Time for epoch 38 is 1.2209255695343018 sec\n",
      "Time for epoch 39 is 1.4586822986602783 sec\n",
      "Time for epoch 40 is 1.221956729888916 sec\n",
      "Time for epoch 41 is 0.9033656120300293 sec\n",
      "Time for epoch 42 is 1.023289680480957 sec\n",
      "Time for epoch 43 is 1.425579309463501 sec\n",
      "Time for epoch 44 is 0.8003048896789551 sec\n",
      "Time for epoch 45 is 1.3420944213867188 sec\n",
      "Time for epoch 46 is 1.1705031394958496 sec\n",
      "Time for epoch 47 is 1.084303617477417 sec\n",
      "Time for epoch 48 is 1.302727460861206 sec\n",
      "Time for epoch 49 is 0.810631275177002 sec\n",
      "Time for epoch 50 is 0.5843863487243652 sec\n"
     ]
    }
   ],
   "source": [
    "train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2180667, shape=(), dtype=float32)\n",
      "[<tf.Tensor: shape=(100, 256), dtype=float32, numpy=\n",
      "array([[-1.2657368e-02,  6.9917133e-03,  6.0670548e-03, ...,\n",
      "        -1.6835192e-02, -4.7025052e-03,  2.5047136e-03],\n",
      "       [ 2.3169793e-02, -4.2005438e-02,  7.3910793e-03, ...,\n",
      "         8.0881245e-02, -1.2484933e-01,  3.0256495e-02],\n",
      "       [-1.0271495e-02,  4.4948120e-02,  2.8028844e-03, ...,\n",
      "        -2.5511788e-02,  4.2048875e-02,  1.0373569e-02],\n",
      "       ...,\n",
      "       [ 1.2098706e-02, -7.9551907e-03, -9.0531558e-03, ...,\n",
      "         5.4907920e-03,  4.2967238e-02, -4.0880926e-03],\n",
      "       [ 7.1380506e-03,  1.9250286e-04, -2.9733729e-02, ...,\n",
      "        -6.7231312e-02,  2.4482787e-01, -3.6508486e-02],\n",
      "       [ 1.7665628e-02, -1.6757061e-03, -1.1706840e-02, ...,\n",
      "         1.1587529e-02,  5.1152870e-02, -2.5116103e-03]], dtype=float32)>, <tf.Tensor: shape=(256,), dtype=float32, numpy=\n",
      "array([ 3.22254561e-02, -1.07854285e-04,  1.18630454e-02,  1.24601424e-02,\n",
      "        3.22683118e-02,  2.62602209e-03, -3.98315676e-02,  3.18201706e-02,\n",
      "        1.10595012e-02,  4.18192620e-04, -2.28847284e-02,  2.47162748e-02,\n",
      "        1.33909630e-02,  1.48169613e-02,  2.49564112e-03,  6.83031627e-04,\n",
      "        2.99267657e-03, -3.76935080e-02, -1.97861139e-02, -6.66271569e-03,\n",
      "       -2.54430361e-02, -1.94956716e-02, -2.21205037e-02,  1.48694478e-02,\n",
      "        2.87001617e-02,  6.39854046e-03,  5.24147600e-03,  1.80405490e-02,\n",
      "       -2.50719972e-02,  1.31873146e-03,  3.53077278e-02, -3.30165476e-02,\n",
      "        2.30591632e-02, -2.87290309e-02,  1.51233571e-02, -1.06157432e-03,\n",
      "        3.44563946e-02,  5.91313699e-03, -1.02158654e-02,  7.75778294e-03,\n",
      "       -1.31743578e-02, -1.10910917e-02, -1.49255218e-02,  5.21096680e-03,\n",
      "        3.45671102e-02,  6.16636798e-02, -1.50075543e-03,  2.43637022e-02,\n",
      "        2.50119511e-02,  1.78414937e-02, -1.53782601e-02, -4.85074818e-02,\n",
      "       -1.21472050e-02,  5.31387888e-03, -1.12194065e-02,  7.57974107e-03,\n",
      "        1.58813186e-02,  1.05118304e-02,  1.46687953e-02,  1.34699261e-02,\n",
      "        1.37355737e-02, -4.36438806e-03, -1.08811613e-02,  2.58822404e-02,\n",
      "        1.77821238e-03,  3.06268260e-02, -8.58257897e-03, -7.15134991e-03,\n",
      "        2.31469162e-02, -1.03070028e-02, -1.69576164e-02,  1.69672556e-02,\n",
      "        7.60354800e-03, -2.40754147e-04, -2.45545581e-02,  1.86469071e-02,\n",
      "        2.35093813e-02,  5.71814878e-03, -1.57003216e-02,  6.17166283e-04,\n",
      "       -7.93217029e-03,  4.54013348e-02,  2.50215065e-02,  1.66799724e-02,\n",
      "        2.70219296e-02, -1.90101266e-02, -2.09156517e-02, -1.43412808e-02,\n",
      "        1.26283672e-02,  4.22127172e-02, -1.05631173e-01, -1.62472297e-02,\n",
      "        1.71871635e-03, -8.83063301e-03,  8.92831085e-05,  2.77473722e-02,\n",
      "        6.43368065e-03,  6.40166504e-03, -8.21468048e-03, -4.12313975e-02,\n",
      "        1.35696791e-02,  5.54058962e-02, -1.89626613e-03, -1.30103752e-02,\n",
      "       -5.09006009e-02,  1.79105848e-02, -3.58247794e-02, -1.10600258e-05,\n",
      "        7.67813204e-03, -6.71884138e-03,  3.16516049e-02,  6.76782336e-03,\n",
      "       -7.19798356e-03,  3.60260252e-03, -2.58361630e-04,  1.00727640e-02,\n",
      "        3.43903527e-02,  9.94696049e-04, -8.10168404e-03,  6.92930957e-03,\n",
      "        3.93292494e-03,  4.68736922e-04,  6.12980314e-03, -1.32392747e-02,\n",
      "       -2.61282525e-03, -6.37541786e-02,  2.58371718e-02, -2.46908870e-02,\n",
      "        1.67150740e-02, -2.13511605e-02,  5.23320772e-03,  2.25597452e-02,\n",
      "        9.34210140e-03,  6.05526753e-03,  3.95524688e-02, -3.12679657e-03,\n",
      "       -1.67590268e-02, -1.20246345e-02, -2.54117195e-02,  1.62075069e-02,\n",
      "       -2.28849519e-02, -1.34216277e-02, -5.79017401e-03, -3.93312462e-02,\n",
      "       -7.57665038e-02, -2.62703598e-02, -1.03048224e-03, -6.23594895e-02,\n",
      "       -4.42541437e-03,  1.24908565e-02, -1.41445594e-02,  8.39501247e-03,\n",
      "       -1.51949590e-02, -7.19963983e-02, -2.43823137e-02, -6.44667819e-03,\n",
      "       -7.97433779e-04,  3.84769663e-02, -2.10121721e-02, -9.84633714e-03,\n",
      "       -9.13766387e-04,  2.93308608e-02,  1.12170586e-02,  5.30265011e-02,\n",
      "       -1.02312723e-02, -5.58103144e-04, -1.24203907e-02,  2.64826510e-03,\n",
      "       -1.74193531e-02, -5.06692566e-02, -5.65763097e-03,  7.90123045e-02,\n",
      "       -1.29007073e-02, -2.68647950e-02, -3.37008853e-03,  3.01754046e-02,\n",
      "        2.77893916e-02, -1.06145116e-02,  1.12808151e-02, -1.58398449e-02,\n",
      "       -7.82373920e-03, -1.53184282e-02,  1.29065746e-02, -1.21006900e-02,\n",
      "        4.17481083e-03, -2.48493198e-02,  2.75082490e-03, -1.28561361e-02,\n",
      "       -3.67025323e-02, -3.26587409e-02, -3.40375938e-02, -3.16049205e-04,\n",
      "        9.29349917e-04,  1.81288458e-02,  3.70930918e-02,  1.17937429e-02,\n",
      "       -5.32885035e-03,  1.27871707e-02, -5.61465649e-03, -1.94562059e-02,\n",
      "       -3.50174420e-02,  2.09155083e-02,  1.17918868e-02,  2.00039688e-02,\n",
      "       -8.89218785e-03,  1.02424566e-02, -3.42346169e-02, -3.95650789e-03,\n",
      "        1.10918395e-02,  2.62072813e-02, -3.23969201e-04, -2.32949834e-02,\n",
      "        9.90880188e-03,  3.31172608e-02, -2.93008015e-02,  2.16008071e-03,\n",
      "        1.02229863e-02, -1.81205161e-02, -3.14794928e-02, -8.45825113e-03,\n",
      "        7.35285878e-03,  4.90030684e-02,  8.74888431e-03, -8.40316061e-03,\n",
      "       -1.29691781e-02, -4.15024301e-03,  4.83571514e-02,  3.70872393e-02,\n",
      "        1.32142939e-03, -1.55017863e-03,  1.57705531e-03, -2.76010651e-02,\n",
      "        1.33475792e-02,  1.31356781e-02, -3.83354840e-03,  3.61020565e-02,\n",
      "        4.23956243e-03, -3.35712247e-02, -4.68566408e-03,  5.43386750e-02,\n",
      "        7.58869722e-02, -1.89401880e-02,  7.18094362e-03,  8.43862910e-03,\n",
      "       -3.86060141e-02, -9.92165599e-03,  7.55740190e-03, -4.13570516e-02,\n",
      "       -3.47392187e-02,  2.82638299e-04, -6.95477985e-03,  2.53067887e-03,\n",
      "        1.06972661e-02,  3.38747613e-02, -2.08751466e-02, -1.04860887e-02],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(256,), dtype=float32, numpy=\n",
      "array([ 0.01078976, -0.00036635,  0.00976787,  0.00157787,  0.03334669,\n",
      "       -0.0010784 , -0.02575889,  0.00993653,  0.00478241,  0.00149976,\n",
      "       -0.00549329,  0.00839586, -0.00086933,  0.00594248,  0.00150948,\n",
      "        0.0007763 ,  0.00109164, -0.02348798, -0.02182518, -0.01262438,\n",
      "       -0.02192532,  0.00740998, -0.01170222,  0.00070834,  0.00794045,\n",
      "       -0.00093692, -0.00745309,  0.01739877, -0.01200768, -0.00186051,\n",
      "        0.00647024, -0.01686222,  0.01590923,  0.00228821,  0.00118865,\n",
      "       -0.00175873,  0.01741111,  0.00161216, -0.00775273,  0.0123821 ,\n",
      "        0.00626308,  0.01013425, -0.01001316, -0.0110839 ,  0.01686349,\n",
      "        0.02618681, -0.00074145,  0.00823388,  0.00616906,  0.01116924,\n",
      "       -0.01335858, -0.02242854, -0.00648039,  0.00692348, -0.00402339,\n",
      "        0.00216262,  0.01470539,  0.00090351,  0.00746009,  0.00734745,\n",
      "       -0.00459906,  0.00072813, -0.00565586,  0.00970357, -0.00112373,\n",
      "        0.00561402, -0.00313604, -0.00418336,  0.01121596, -0.00863404,\n",
      "       -0.00516722,  0.0038457 ,  0.00163351,  0.00463318, -0.02869449,\n",
      "        0.00968959,  0.00868138, -0.00502101,  0.01118358,  0.00119315,\n",
      "       -0.00014463,  0.01694422,  0.01279329,  0.00762554,  0.01753564,\n",
      "       -0.01529921, -0.0029032 , -0.00502781,  0.01364067, -0.00068362,\n",
      "       -0.03470331, -0.0095933 ,  0.00282719, -0.01951659, -0.00639058,\n",
      "        0.02004847,  0.00538079, -0.00374563, -0.00246153, -0.01142772,\n",
      "        0.02607013,  0.01582109, -0.00076615, -0.00866293, -0.01759311,\n",
      "        0.00591262, -0.02659737,  0.00045572,  0.00501784, -0.00033686,\n",
      "        0.01048165, -0.00638714, -0.00454561,  0.00120966,  0.01299075,\n",
      "        0.00432759,  0.01346392, -0.00316942, -0.00332576,  0.00459148,\n",
      "        0.00065222, -0.0030853 , -0.00369749,  0.00120342,  0.00664367,\n",
      "       -0.03602191,  0.01639188, -0.00817403,  0.01211592, -0.02419192,\n",
      "        0.01325194,  0.0097187 ,  0.00320531, -0.01390856,  0.01301583,\n",
      "       -0.00124363, -0.00756411, -0.00772679, -0.01206989,  0.00769095,\n",
      "        0.00747969, -0.01496725, -0.00514608, -0.01362624, -0.01811224,\n",
      "        0.00916288, -0.01550549, -0.031599  , -0.00057042,  0.00758852,\n",
      "       -0.00714871,  0.00676844, -0.01435557, -0.02140775, -0.00649803,\n",
      "       -0.00325545, -0.01498671,  0.0169242 , -0.01173497, -0.00855473,\n",
      "       -0.00426306, -0.00121903,  0.010894  ,  0.03552172, -0.00636291,\n",
      "       -0.00214908, -0.00422479, -0.00261479, -0.01152748, -0.0173159 ,\n",
      "       -0.00429304,  0.02468395, -0.0084909 , -0.0283195 , -0.00745343,\n",
      "        0.01770658,  0.01824044,  0.00223312,  0.00593372, -0.0082936 ,\n",
      "       -0.00428902, -0.00200996,  0.00557101, -0.00653941, -0.00171331,\n",
      "       -0.01357294,  0.0030423 ,  0.00709373, -0.01518793, -0.00971945,\n",
      "       -0.01733088, -0.00472027,  0.0020802 ,  0.00929252,  0.01584489,\n",
      "       -0.00592864, -0.00113845,  0.00546164, -0.00450415, -0.01063597,\n",
      "       -0.01636971,  0.00475926,  0.00891804,  0.0094822 , -0.01004938,\n",
      "        0.00378974, -0.01755582, -0.00422239,  0.00460147,  0.00926844,\n",
      "       -0.00155064, -0.00840622,  0.00659286,  0.00250849, -0.020669  ,\n",
      "        0.00018905,  0.00288407, -0.01377416, -0.01773532, -0.00095992,\n",
      "        0.0060001 ,  0.024865  ,  0.00261393, -0.00652397, -0.00303768,\n",
      "       -0.00103877,  0.00946241,  0.02455963,  0.00152863, -0.00818483,\n",
      "       -0.00120731, -0.02067062, -0.00502122,  0.00726838,  0.00499996,\n",
      "        0.01974204,  0.00255877, -0.01933213, -0.00199143,  0.01380123,\n",
      "        0.02249917, -0.00926815,  0.00195317,  0.00173753, -0.01593843,\n",
      "       -0.00068253,  0.00763028, -0.02659019, -0.01895529, -0.00506548,\n",
      "       -0.02314686,  0.00156483,  0.00676344,  0.00578064, -0.00781996,\n",
      "        0.00558699], dtype=float32)>, <tf.Tensor: shape=(256, 512), dtype=float32, numpy=\n",
      "array([[ 0.05073941, -0.00042163,  0.00183105, ..., -0.01438133,\n",
      "         0.00058433, -0.00052199],\n",
      "       [ 0.01673364,  0.00523864,  0.00862729, ..., -0.00737211,\n",
      "        -0.00645356, -0.00067101],\n",
      "       [-0.01433879,  0.0036102 , -0.00489187, ...,  0.00562409,\n",
      "        -0.00719128, -0.00146616],\n",
      "       ...,\n",
      "       [-0.08944815,  0.01849815,  0.00756599, ...,  0.01948215,\n",
      "        -0.00064826,  0.00715604],\n",
      "       [-0.07069428,  0.01010158, -0.00530315, ...,  0.01960197,\n",
      "        -0.00092491,  0.00370408],\n",
      "       [ 0.00721562,  0.01027082, -0.00788911, ..., -0.00061088,\n",
      "        -0.00305113,  0.00188325]], dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
      "array([-3.7252903e-09, -3.7252903e-09, -1.1641532e-09, -9.3132257e-10,\n",
      "       -2.3283064e-10, -7.5669959e-10,  4.6566129e-10, -2.3283064e-09,\n",
      "       -1.8626451e-09,  3.4924597e-10, -1.8626451e-09, -4.6566129e-10,\n",
      "       -9.3132257e-10, -1.8626451e-09, -2.3283064e-10,  1.8626451e-09,\n",
      "       -4.6566129e-10, -9.3132257e-10,  1.8626451e-09,  1.8626451e-09,\n",
      "        4.6566129e-10,  0.0000000e+00,  4.6566129e-10, -3.4924597e-09,\n",
      "       -2.2118911e-09,  3.7252903e-09,  4.6566129e-10, -3.7834980e-10,\n",
      "        2.3283064e-10, -2.3283064e-09,  0.0000000e+00, -9.3132257e-10,\n",
      "       -3.0267984e-09,  4.6566129e-10, -9.3132257e-10, -5.8207661e-10,\n",
      "       -1.1641532e-10,  0.0000000e+00, -2.3283064e-09, -9.3132257e-10,\n",
      "        1.5716068e-09, -4.6566129e-10,  0.0000000e+00,  6.5192580e-09,\n",
      "        0.0000000e+00, -4.6566129e-10,  9.3132257e-10, -2.7939677e-09,\n",
      "        1.1641532e-10,  4.6566129e-10,  0.0000000e+00,  0.0000000e+00,\n",
      "       -2.7939677e-09,  9.3132257e-10, -1.1641532e-10, -1.0477379e-09,\n",
      "       -4.6566129e-10,  9.3132257e-10, -3.2596290e-09,  3.4924597e-10,\n",
      "       -1.8626451e-09,  0.0000000e+00, -4.6566129e-10,  2.3283064e-10,\n",
      "       -5.8207661e-10,  2.3283064e-10,  6.9849193e-10,  6.9849193e-10,\n",
      "        1.8626451e-09,  0.0000000e+00,  4.6566129e-10,  9.3132257e-10,\n",
      "        4.6566129e-10,  0.0000000e+00,  3.4924597e-10, -8.1490725e-10,\n",
      "       -1.8626451e-09,  9.3132257e-10,  4.6566129e-10, -9.3132257e-10,\n",
      "        7.5669959e-10, -4.6566129e-10, -1.8626451e-09,  2.3283064e-10,\n",
      "       -1.8626451e-09,  9.3132257e-10, -9.3132257e-10,  0.0000000e+00,\n",
      "        0.0000000e+00, -2.3283064e-10, -1.1641532e-10,  0.0000000e+00,\n",
      "        1.9208528e-09, -1.8626451e-09, -1.8626451e-09,  1.3969839e-09,\n",
      "        0.0000000e+00,  9.3132257e-10, -3.9581209e-09,  0.0000000e+00,\n",
      "        3.7252903e-09, -4.6566129e-10,  0.0000000e+00,  4.6566129e-10,\n",
      "        2.5611371e-09, -2.3283064e-10,  4.6566129e-10, -9.3132257e-10,\n",
      "        9.3132257e-10,  5.8207661e-09,  2.3283064e-10, -9.3132257e-10,\n",
      "        0.0000000e+00,  1.1641532e-09, -7.2177500e-09, -1.8626451e-09,\n",
      "        1.8626451e-09,  4.8894435e-09, -2.7939677e-09, -2.3283064e-10,\n",
      "       -2.0954758e-09,  2.3283064e-10, -9.3132257e-10,  0.0000000e+00,\n",
      "       -3.7252903e-09, -1.8626451e-09,  0.0000000e+00, -3.4924597e-10,\n",
      "        4.1909516e-09, -2.3283064e-10, -1.8626451e-09,  1.8626451e-09,\n",
      "        0.0000000e+00,  4.6566129e-10,  0.0000000e+00, -9.3132257e-10,\n",
      "        0.0000000e+00,  0.0000000e+00, -8.1490725e-10,  3.7252903e-09,\n",
      "        4.6566129e-10, -5.8207661e-10,  1.1641532e-09, -9.3132257e-10,\n",
      "        1.8626451e-09,  0.0000000e+00, -9.3132257e-10, -2.7939677e-09,\n",
      "        3.2596290e-09, -7.4505806e-09, -9.3132257e-10,  4.6566129e-10,\n",
      "       -7.4505806e-09, -9.3132257e-09, -9.3132257e-10, -1.8626451e-09,\n",
      "        9.3132257e-10,  1.8626451e-09,  1.1175871e-08, -1.3969839e-08,\n",
      "       -1.7462298e-10,  0.0000000e+00, -3.7252903e-09,  1.8626451e-09,\n",
      "        0.0000000e+00, -1.3969839e-09, -9.3132257e-10,  1.8626451e-08,\n",
      "        0.0000000e+00,  1.8626451e-09,  1.8626451e-09, -1.1641532e-09,\n",
      "        3.7252903e-09, -6.9849193e-10,  1.8626451e-09,  0.0000000e+00,\n",
      "       -9.3132257e-10,  2.7939677e-09,  1.5133992e-09, -4.6566129e-10,\n",
      "        0.0000000e+00, -2.3283064e-09,  9.3132257e-10, -9.3132257e-10,\n",
      "       -5.5879354e-09,  9.3132257e-10, -3.9581209e-09,  0.0000000e+00,\n",
      "        1.8626451e-09, -4.6566129e-10, -1.8626451e-09, -1.3969839e-09,\n",
      "        1.1641532e-10, -5.5879354e-09,  8.1490725e-10,  8.1490725e-10,\n",
      "        5.5879354e-09, -1.8626451e-09, -4.1909516e-09, -3.7252903e-09,\n",
      "       -1.2805685e-09, -2.3283064e-10,  1.3969839e-09, -3.4924597e-10,\n",
      "       -2.0954758e-09, -1.1641532e-10, -8.7311491e-10,  5.5879354e-09,\n",
      "        9.3132257e-10,  1.1641532e-09,  1.3969839e-09,  4.6566129e-10,\n",
      "        0.0000000e+00,  2.7939677e-09,  9.3132257e-10,  1.4901161e-08,\n",
      "        0.0000000e+00, -9.3132257e-10,  4.6566129e-10, -2.7939677e-09,\n",
      "       -1.8626451e-09, -1.3969839e-09, -4.6566129e-10,  1.1641532e-09,\n",
      "        2.7939677e-09, -3.4924597e-09,  0.0000000e+00,  2.3283064e-10,\n",
      "        0.0000000e+00, -1.3969839e-09, -5.1222742e-09,  2.3283064e-10,\n",
      "       -1.3969839e-09,  0.0000000e+00,  9.3132257e-10,  0.0000000e+00,\n",
      "       -4.6566129e-09, -2.3283064e-10,  4.6566129e-10, -9.3132257e-10,\n",
      "        2.7939677e-09,  0.0000000e+00,  9.3132257e-10,  4.6566129e-10,\n",
      "        0.0000000e+00,  2.0954758e-09, -3.7252903e-09, -2.3283064e-10,\n",
      "        1.8626451e-09,  3.7252903e-09,  0.0000000e+00,  3.4924597e-10,\n",
      "       -6.9849193e-10, -8.1490725e-10, -3.2596290e-09,  3.7252903e-09,\n",
      "        2.9103830e-10, -1.8626451e-09,  0.0000000e+00,  1.8626451e-09,\n",
      "       -9.3132257e-10, -4.6566129e-09,  4.6566129e-10,  0.0000000e+00,\n",
      "        1.1641532e-09,  1.1641532e-10,  3.2014214e-10,  1.8626451e-09,\n",
      "        0.0000000e+00,  2.3283064e-10,  2.7939677e-09, -4.6566129e-10,\n",
      "        0.0000000e+00,  0.0000000e+00,  4.6566129e-10,  9.3132257e-10,\n",
      "       -2.3283064e-09, -6.4028427e-10,  4.6566129e-10,  4.6566129e-10,\n",
      "        6.9849193e-10,  0.0000000e+00, -1.8626451e-09, -7.4505806e-09,\n",
      "        1.1641532e-09, -1.3969839e-09,  1.3969839e-09, -1.3969839e-09,\n",
      "        4.0745363e-10, -3.7252903e-09,  4.6566129e-10, -9.3132257e-10,\n",
      "       -4.6566129e-10,  1.8626451e-09,  1.8626451e-09, -2.3283064e-10,\n",
      "        0.0000000e+00, -1.1641532e-10, -2.7939677e-09,  9.3132257e-10,\n",
      "        2.6193447e-10,  0.0000000e+00,  0.0000000e+00, -9.3132257e-10,\n",
      "        1.0477379e-09, -4.6566129e-10, -4.6566129e-10, -1.4551915e-09,\n",
      "        0.0000000e+00, -2.7939677e-09,  4.6566129e-10,  7.4505806e-09,\n",
      "        1.7462298e-10, -4.6566129e-10,  0.0000000e+00,  0.0000000e+00,\n",
      "        0.0000000e+00,  0.0000000e+00, -2.3283064e-10,  9.3132257e-10,\n",
      "       -1.1641532e-09, -1.8626451e-09, -4.6566129e-10, -6.9849193e-10,\n",
      "        0.0000000e+00,  0.0000000e+00,  3.7252903e-09, -4.6566129e-10,\n",
      "        1.8626451e-09,  1.1641532e-10,  2.7939677e-09,  1.8626451e-09,\n",
      "       -9.3132257e-10,  3.4924597e-10, -1.3969839e-09, -1.3969839e-09,\n",
      "       -1.3969839e-09, -3.2596290e-09,  9.3132257e-10,  0.0000000e+00,\n",
      "        9.3132257e-10, -2.9103830e-11, -1.8626451e-09, -2.7939677e-09,\n",
      "        9.3132257e-10,  2.3283064e-10, -3.2014214e-10, -4.6566129e-10,\n",
      "        1.8626451e-09, -1.1641532e-09, -2.0954758e-09, -1.3969839e-09,\n",
      "        0.0000000e+00, -2.3283064e-10,  2.3283064e-10,  3.4924597e-10,\n",
      "        0.0000000e+00, -9.3132257e-10, -1.8626451e-09, -1.8626451e-09,\n",
      "        9.3132257e-10, -4.6566129e-10, -9.3132257e-10, -4.6566129e-10,\n",
      "       -3.2596290e-09, -1.5133992e-09,  2.3283064e-09,  2.3283064e-10,\n",
      "        1.1059456e-09, -2.3283064e-10, -9.3132257e-10, -3.7252903e-09,\n",
      "        3.7252903e-09,  3.0267984e-09,  5.1222742e-09, -9.3132257e-10,\n",
      "       -2.7939677e-09,  4.1909516e-09, -3.0267984e-09, -2.3283064e-10,\n",
      "       -2.3283064e-10, -4.6566129e-10, -4.6566129e-10, -4.6566129e-10,\n",
      "       -1.8626451e-09,  0.0000000e+00, -9.3132257e-10, -4.6566129e-10,\n",
      "        9.3132257e-10, -1.8626451e-09,  1.8626451e-09, -2.3283064e-10,\n",
      "        0.0000000e+00, -9.3132257e-10,  0.0000000e+00,  3.2596290e-09,\n",
      "        0.0000000e+00,  1.8626451e-09,  0.0000000e+00,  4.6566129e-10,\n",
      "       -2.3283064e-09, -1.4901161e-08,  4.6566129e-10,  2.5611371e-09,\n",
      "        1.6298145e-09,  2.3283064e-10, -3.4924597e-10, -1.8626451e-09,\n",
      "        1.1641532e-10,  4.6566129e-10,  2.3283064e-10, -1.2805685e-09,\n",
      "       -6.9849193e-10,  0.0000000e+00, -1.3969839e-09, -1.3969839e-09,\n",
      "        2.3283064e-10, -7.4505806e-09,  4.6566129e-10, -4.6566129e-10,\n",
      "       -6.9849193e-10, -9.3132257e-10, -1.8626451e-09, -7.4505806e-09,\n",
      "       -4.6566129e-10, -2.7939677e-09, -6.9849193e-10,  4.1909516e-09,\n",
      "       -1.3969839e-09,  2.3283064e-09,  1.1641532e-09,  3.4924597e-10,\n",
      "        5.8207661e-10, -4.6566129e-10,  0.0000000e+00, -1.3969839e-09,\n",
      "        0.0000000e+00, -4.0745363e-10,  0.0000000e+00, -4.0745363e-10,\n",
      "        1.3969839e-09,  3.2014214e-09,  9.3132257e-10, -2.3283064e-09,\n",
      "        2.3283064e-10, -9.3132257e-10, -3.7252903e-09, -2.3283064e-10,\n",
      "        6.9849193e-10, -1.8626451e-09, -1.1641532e-10, -6.9849193e-10,\n",
      "        1.8626451e-09,  4.0745363e-10,  9.3132257e-10,  2.9103830e-10,\n",
      "       -9.3132257e-10, -1.8626451e-09, -9.3132257e-10,  5.8207661e-10,\n",
      "        9.3132257e-10, -6.5192580e-09,  0.0000000e+00,  1.3969839e-09,\n",
      "       -9.3132257e-10,  3.4924597e-10, -2.3283064e-10,  9.3132257e-10,\n",
      "       -1.8626451e-09,  5.8207661e-11, -1.3969839e-09,  4.6566129e-10,\n",
      "        0.0000000e+00,  0.0000000e+00, -2.3283064e-10, -1.8626451e-09,\n",
      "       -9.3132257e-10,  4.6566129e-10, -2.3283064e-10, -4.6566129e-10,\n",
      "       -4.6566129e-10,  9.3132257e-10,  5.5879354e-09, -3.7252903e-09,\n",
      "       -2.5611371e-09,  1.8626451e-09, -1.1641532e-09,  1.3969839e-09,\n",
      "        2.7939677e-09,  1.8626451e-09,  4.6566129e-09,  2.5611371e-09,\n",
      "        1.8626451e-09, -6.9849193e-10,  8.1490725e-10, -2.7939677e-09,\n",
      "        9.3132257e-10, -1.7462298e-10,  4.6566129e-10, -6.5192580e-09,\n",
      "       -4.6566129e-10,  4.6566129e-10, -1.6298145e-09, -1.3969839e-09,\n",
      "       -7.4505806e-09, -1.1641532e-10, -7.4505806e-09, -6.9849193e-10,\n",
      "       -1.8626451e-09, -4.6566129e-10, -3.4924597e-10, -1.6298145e-09],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
      "array([-3.66327865e-03,  1.91377960e-02, -4.97935852e-03, -2.72344303e-04,\n",
      "        3.61191249e-03,  7.70065701e-04,  2.66022864e-03, -5.80952782e-03,\n",
      "        6.30801951e-04, -1.00483093e-02, -4.10109237e-02, -3.79955373e-03,\n",
      "       -3.01516545e-03, -2.45907493e-02, -6.77816570e-03,  2.08804123e-02,\n",
      "       -1.81087782e-03,  7.52590876e-03,  1.96199920e-02, -6.65484881e-03,\n",
      "        5.65638170e-02,  6.35293021e-04, -5.26902266e-03, -8.74761306e-03,\n",
      "       -2.10338514e-02, -1.71701740e-02, -4.14399803e-03,  5.61285019e-03,\n",
      "        9.75895394e-03, -8.11464712e-03, -1.74939458e-03,  1.82742272e-02,\n",
      "       -9.73836612e-03, -4.66214772e-03, -6.37616729e-03,  1.23081543e-02,\n",
      "       -1.18628284e-02,  1.53221479e-02, -2.21983367e-03,  2.66614463e-02,\n",
      "        8.25321116e-03,  6.54372294e-03, -1.96702313e-03,  2.91141612e-03,\n",
      "       -1.95205361e-02, -9.78925172e-03,  3.04524391e-03,  1.11496383e-02,\n",
      "        1.01469355e-02, -2.48011295e-02,  9.51264426e-03, -1.25599271e-02,\n",
      "        1.78222377e-02,  4.27150130e-02,  4.24938602e-03, -4.55084071e-03,\n",
      "        3.34998243e-03,  6.63124956e-03,  1.31528331e-02, -7.71501940e-03,\n",
      "        1.63373463e-02,  8.45284294e-03, -1.11353176e-03, -5.06465789e-03,\n",
      "        1.06976833e-02,  2.58880970e-03,  7.13456050e-03, -1.03552071e-02,\n",
      "       -9.56426468e-03,  8.64844769e-05, -9.23617929e-03,  5.99342771e-03,\n",
      "        2.77745130e-04, -5.73841017e-03,  3.99199687e-03, -3.75269260e-03,\n",
      "        4.85057123e-02,  7.11077685e-03,  1.11093400e-02, -2.30183266e-03,\n",
      "        1.70471966e-02,  7.16272416e-03,  1.56745203e-02,  8.96201562e-03,\n",
      "        1.29765458e-02, -2.49553705e-03,  3.51309706e-03,  8.24588444e-03,\n",
      "       -1.18543496e-02, -3.18220467e-03,  1.14882207e-02, -1.82535325e-03,\n",
      "       -5.56242559e-03, -2.72929855e-03,  2.25274321e-02, -8.97478126e-03,\n",
      "        3.99781484e-03, -2.06393171e-02, -3.92314338e-04, -1.81675628e-02,\n",
      "        2.09553018e-02,  1.91858469e-03, -1.10019455e-02, -1.13299796e-02,\n",
      "        1.54061802e-02, -9.30002891e-03, -1.34129878e-02,  2.71931570e-03,\n",
      "        2.29097262e-04, -5.52059002e-02, -4.40248242e-03,  3.60332727e-02,\n",
      "       -4.87112533e-03, -6.62977435e-03,  6.18526293e-03, -7.59399962e-03,\n",
      "       -6.12744130e-03, -1.86018012e-02, -2.64753792e-02, -7.10650021e-03,\n",
      "        4.14925441e-03,  7.85378274e-03,  5.27378730e-03,  6.16485626e-03,\n",
      "        2.63029113e-02,  2.21434073e-03, -3.67258355e-04,  3.12354800e-08,\n",
      "       -2.48647071e-02, -2.65395641e-03,  3.75316129e-04,  7.98815582e-03,\n",
      "       -1.31625058e-02,  1.88661907e-02, -1.79241523e-02, -3.24237905e-03,\n",
      "       -6.86631771e-03,  3.80876288e-03,  3.16744251e-03,  1.13997646e-02,\n",
      "       -3.52199981e-03,  2.46665510e-03,  5.67233983e-05, -5.89230680e-04,\n",
      "       -1.73654989e-03,  3.41439503e-03, -3.18490155e-02, -9.71330504e-04,\n",
      "       -1.11804893e-02, -5.06115751e-03, -1.46680176e-02, -5.80839021e-03,\n",
      "        3.32825966e-02,  3.07180379e-02, -6.97084516e-03, -7.32580572e-03,\n",
      "       -3.73687572e-03, -2.74010357e-02, -2.18366310e-02, -1.55607294e-02,\n",
      "       -1.11868652e-03, -1.26035372e-02,  2.07017213e-02, -1.59172434e-02,\n",
      "       -1.33607176e-03,  8.28475691e-03, -1.13658502e-03, -2.23295800e-02,\n",
      "       -1.90264713e-02, -7.09847827e-03,  3.50930616e-02, -9.64374840e-03,\n",
      "       -9.69888736e-03, -6.45068428e-03,  2.94596935e-03,  2.77609136e-02,\n",
      "        3.61814983e-02, -7.79663352e-03, -3.60043091e-03, -2.68416572e-03,\n",
      "        1.73998866e-02,  3.40387002e-02, -1.43598579e-02, -7.45925214e-03,\n",
      "       -1.53811127e-02,  7.02690938e-03, -1.32254763e-02,  2.48968625e-03,\n",
      "       -1.74335875e-02,  7.65310833e-03,  1.58849452e-03,  4.92790993e-03,\n",
      "       -4.59661940e-03,  2.28651389e-02, -4.13145684e-03,  1.05291111e-02,\n",
      "       -1.63791794e-02, -2.50467844e-02,  4.46133455e-03,  1.42848948e-02,\n",
      "        1.85460714e-03, -7.47613423e-03, -3.58599937e-03,  3.59431491e-03,\n",
      "        6.93490263e-03, -3.74803273e-03, -1.82324357e-03,  3.21515836e-02,\n",
      "       -3.48078855e-03,  3.15027758e-02,  1.02232443e-02,  1.78496912e-02,\n",
      "        5.65783028e-03,  1.27870338e-02,  5.57105057e-03, -2.64476389e-02,\n",
      "       -3.41490051e-03,  1.41869485e-02, -8.11930746e-03,  1.10222520e-02,\n",
      "        3.73423956e-02,  1.25244651e-02, -4.09941655e-03, -4.56698705e-03,\n",
      "       -3.09637450e-02,  1.62448548e-02,  4.76478459e-03,  1.75544387e-03,\n",
      "       -2.15990352e-03,  1.93410013e-02, -4.66080848e-03,  2.24417518e-03,\n",
      "       -9.41891037e-03, -1.12055708e-02,  1.44102024e-02,  5.23707597e-04,\n",
      "       -1.49950283e-02,  1.20009584e-02, -5.24798036e-03,  5.69581473e-03,\n",
      "        5.29545965e-03,  2.25825403e-02,  3.56638408e-03,  2.20052321e-02,\n",
      "       -4.18252283e-04,  1.50239863e-03,  7.68521149e-03,  2.44826265e-03,\n",
      "       -2.57216059e-02,  9.98754147e-03,  1.12248445e-02, -3.34523036e-03,\n",
      "        8.01487919e-03,  1.05551276e-02, -1.09254420e-02,  1.71022099e-02,\n",
      "        3.21952044e-03, -7.88461231e-03, -7.55948899e-03,  1.14837131e-02,\n",
      "       -1.00667058e-02,  1.29457647e-02,  8.42197100e-04,  1.23847602e-02,\n",
      "       -5.83980512e-03,  1.08737200e-02, -1.49707473e-03, -2.73661073e-02,\n",
      "        5.59040392e-03, -2.92168371e-03,  1.81410909e-02,  2.94124521e-02,\n",
      "       -1.35689592e-02,  1.34842200e-02, -1.40486583e-02,  8.44568852e-03,\n",
      "       -2.27487758e-02, -5.68714784e-03,  1.82231376e-03,  2.65722309e-04,\n",
      "        3.20212953e-02, -5.03590656e-03,  1.56136407e-02, -3.96931573e-04,\n",
      "       -7.85827078e-03,  1.02865808e-02,  1.49962734e-02,  8.74265842e-03,\n",
      "       -9.44073871e-03, -2.26263218e-02, -2.94755399e-03,  8.32378026e-03,\n",
      "        1.49898557e-02, -2.42565200e-02, -1.45216836e-02,  9.80835524e-04,\n",
      "        3.67929302e-02, -2.53953622e-03,  7.68085476e-03,  1.08266883e-02,\n",
      "       -7.47648394e-03, -1.09490147e-02,  2.73024081e-03, -1.61269978e-02,\n",
      "        4.17539291e-03, -1.05075557e-02, -3.12615186e-04, -1.59098802e-03,\n",
      "        1.88044943e-02,  1.32331317e-02, -3.16852471e-04, -2.07639169e-02,\n",
      "       -8.91926582e-04,  1.99084375e-02,  3.08129354e-03, -1.23002669e-02,\n",
      "       -6.39896374e-03, -9.35877860e-03,  6.67018397e-03, -1.67318955e-02,\n",
      "       -1.55330021e-02,  4.59372029e-02, -3.60655278e-04, -4.05931845e-03,\n",
      "        3.14822309e-02,  1.03274863e-02,  1.25600789e-02,  5.83071727e-03,\n",
      "        7.63078360e-03, -1.34357682e-03, -2.08728225e-03,  1.11221650e-03,\n",
      "        7.86752719e-03, -7.92358362e-04, -1.53852673e-02,  3.81005295e-02,\n",
      "        4.70700860e-03, -9.46263783e-03, -6.72856951e-03,  1.23735532e-04,\n",
      "        1.54969189e-02,  5.23326267e-03, -1.59242656e-02,  3.00870370e-02,\n",
      "        6.47024391e-03, -5.70151163e-03, -4.58077760e-03,  4.43989458e-03,\n",
      "       -1.86148304e-02,  8.24442599e-04,  6.47543371e-03, -7.63466395e-03,\n",
      "       -2.40116064e-02,  5.57358842e-03, -9.68094915e-03,  6.97632181e-03,\n",
      "       -2.73264805e-03, -9.29091405e-03,  1.87567975e-02,  4.55715321e-03,\n",
      "       -2.03821505e-03,  5.59995230e-03,  9.46200080e-03, -9.18791536e-03,\n",
      "       -2.59429775e-03,  6.49914844e-03,  1.40441479e-02, -6.05177367e-03,\n",
      "        6.88131340e-03, -3.75899207e-03, -9.64757462e-04,  1.98463947e-02,\n",
      "       -1.05492529e-02,  1.15772253e-02,  9.89643764e-03,  1.04899239e-02,\n",
      "        1.13281654e-03,  1.28976330e-02,  1.02271242e-02,  7.13244267e-03,\n",
      "        4.40316508e-03,  3.23918299e-03, -4.40213969e-03, -3.39153153e-03,\n",
      "       -2.11341549e-02, -9.51169617e-03, -5.10349171e-03, -1.39217805e-02,\n",
      "       -5.15755266e-04,  1.12158572e-02, -1.31710283e-02,  4.65737598e-04,\n",
      "       -1.23912636e-02, -1.57218159e-03, -4.38275654e-03,  1.72874536e-02,\n",
      "        5.25791338e-03,  6.12552650e-03,  9.41252511e-04,  2.29396448e-02,\n",
      "       -8.83537903e-03, -2.02853922e-02, -9.70466342e-03, -2.08306424e-02,\n",
      "       -9.21040121e-03, -3.73106124e-03, -5.57121122e-03,  6.49098493e-03,\n",
      "       -7.29151955e-03,  1.53725240e-02, -9.78057738e-04, -1.36395581e-02,\n",
      "        4.60333936e-03,  6.36447920e-04, -3.97008890e-03, -1.92158911e-02,\n",
      "        4.04833723e-03, -1.21824844e-02,  5.55310724e-03,  1.30395964e-02,\n",
      "       -1.69467193e-03, -8.88989214e-03,  1.04625300e-02, -8.09442252e-03,\n",
      "        5.48371440e-03, -2.21787696e-03, -8.98308959e-03,  1.44748657e-03,\n",
      "       -3.47140129e-03,  1.30617339e-02,  1.59424567e-03, -6.42425474e-03,\n",
      "       -1.24893535e-03, -3.84197221e-04, -1.71421841e-02, -1.09595768e-02,\n",
      "        2.74957903e-03, -5.40169858e-05, -1.56151801e-02, -4.88424813e-03,\n",
      "       -2.18633637e-02,  1.76661648e-02,  6.34758733e-03, -1.74749997e-02,\n",
      "        1.12152314e-02,  2.82900520e-02,  1.57102142e-02,  1.02494340e-02,\n",
      "        8.41120817e-03, -1.10105518e-02,  6.18760381e-03,  6.47976296e-03,\n",
      "       -3.30300839e-03,  1.46607182e-03,  1.95790529e-02, -3.73477023e-03,\n",
      "       -8.31233710e-03,  1.67913400e-02,  5.51347667e-03, -1.35687215e-03,\n",
      "        1.85085684e-02, -4.63530943e-02,  3.53333238e-03,  7.87527766e-04,\n",
      "        1.07207056e-02, -1.03811957e-02, -1.01691193e-03,  4.62962361e-03,\n",
      "       -7.87386578e-03, -5.12279046e-04,  3.21928822e-02,  3.55949881e-03,\n",
      "       -2.18696590e-03,  7.41685927e-03, -6.41196733e-03,  1.49922189e-03,\n",
      "       -1.22684073e-02, -1.41173496e-03, -3.99179902e-04,  1.66307352e-02,\n",
      "        3.70589318e-03,  9.68872663e-03, -3.31593566e-02,  1.30285565e-02,\n",
      "       -2.45012739e-03,  3.19166202e-03,  7.65589438e-03,  1.72285107e-03,\n",
      "        1.76050495e-02, -1.60316695e-02,  1.02451502e-03,  1.20894723e-02,\n",
      "       -1.36436736e-02, -3.22068995e-03, -5.76440850e-03,  8.83252360e-03,\n",
      "       -2.04876885e-02,  7.61716533e-03,  2.48572417e-02,  2.15934757e-02,\n",
      "       -9.70074907e-03, -9.57019441e-03,  8.50946922e-03, -1.95562770e-03,\n",
      "        2.00543702e-02, -2.92080780e-03,  1.35664102e-02, -1.26081835e-02,\n",
      "        2.13305745e-03,  4.43433272e-03, -2.00145831e-03, -2.53105797e-02],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
      "array([-7.52056716e-03,  2.95322500e-02,  8.88354983e-03, -1.01940511e-02,\n",
      "       -9.50285466e-05,  3.49627039e-03,  3.31885135e-03,  1.89000263e-03,\n",
      "        3.26949265e-03, -8.89320858e-03, -2.44320221e-02, -3.15649877e-03,\n",
      "       -1.16437552e-02, -2.51969155e-02, -4.77987109e-03,  1.11473594e-02,\n",
      "       -5.50909946e-03,  9.78475250e-03,  9.92205553e-03,  4.27046325e-03,\n",
      "        2.80505884e-02, -1.92671793e-03, -5.76386601e-03, -9.64865740e-03,\n",
      "       -4.62671742e-03, -1.09700430e-02,  1.34484433e-02,  9.99472849e-03,\n",
      "       -2.85296235e-03, -8.93435813e-03, -8.75301659e-03,  1.50293969e-02,\n",
      "        5.35296556e-03, -1.02588199e-02,  1.54919818e-03, -1.88932987e-03,\n",
      "        3.39694717e-03,  7.13873236e-03, -8.92844331e-03,  1.99633744e-02,\n",
      "        1.99577641e-02,  7.71520101e-03,  3.00496444e-03,  1.74777061e-02,\n",
      "       -1.14587722e-02, -6.33324729e-03, -6.26449659e-03,  2.12948266e-02,\n",
      "       -9.42667597e-04, -1.85460541e-02,  1.39667755e-02, -1.18253548e-02,\n",
      "        1.12416102e-02,  1.58095472e-02, -1.26841397e-03, -1.32879727e-02,\n",
      "        2.20938073e-03,  1.16886599e-02,  9.61224921e-03, -1.73764070e-03,\n",
      "        1.34771252e-02,  4.28809179e-03,  2.70294957e-04,  1.90062413e-03,\n",
      "        4.31722868e-03, -6.74352981e-04,  2.85967533e-03,  1.45976776e-02,\n",
      "       -7.93232117e-03,  7.68389972e-03, -2.40671774e-03,  1.06106019e-02,\n",
      "        2.39465764e-04, -1.17264586e-02,  5.88584924e-03,  1.12378178e-02,\n",
      "        2.45641414e-02, -2.42137024e-03,  8.40663724e-03, -3.37802502e-03,\n",
      "        2.86402809e-03, -2.93394690e-03,  2.20326241e-02,  6.05311571e-03,\n",
      "        1.74186006e-02, -1.23868734e-02,  1.63511522e-02,  1.99514208e-03,\n",
      "       -9.77671007e-04,  1.64765562e-03,  1.22928275e-02, -7.75357895e-03,\n",
      "       -6.36578072e-03,  1.16248848e-03,  1.65737327e-02,  2.48209178e-03,\n",
      "        6.07037544e-03, -7.27411453e-03, -6.56010304e-03, -8.39590840e-03,\n",
      "        1.12335589e-02,  8.37054290e-03, -9.17986408e-03, -6.77841762e-03,\n",
      "        1.47956843e-02, -6.54960610e-03, -9.27143171e-03, -5.13835019e-03,\n",
      "        6.98950328e-03, -2.26216838e-02,  7.16389809e-03,  1.91959962e-02,\n",
      "       -4.58447915e-03, -6.99676201e-03,  4.40764613e-03,  4.39847074e-03,\n",
      "        8.37584771e-03, -1.23097654e-02, -1.93669107e-02, -7.78026413e-03,\n",
      "       -7.40722846e-03,  8.95454548e-03, -2.45473231e-03,  7.63501273e-03,\n",
      "        1.70796998e-02, -1.29344333e-02, -4.45820065e-03, -9.67907603e-04,\n",
      "       -1.04868067e-02,  3.08421347e-03,  3.18219862e-03,  5.81499189e-03,\n",
      "       -5.67022990e-03,  1.53270708e-02,  1.85260200e-03,  4.21725493e-03,\n",
      "       -7.64117436e-03, -8.28815345e-03,  7.95013551e-03,  1.08236801e-02,\n",
      "        7.46815931e-05,  2.40228279e-03,  9.75832343e-03, -3.26241716e-03,\n",
      "       -1.01645114e-02,  2.87849479e-03, -1.27929300e-02,  8.48009065e-03,\n",
      "        1.19995605e-03,  1.36479177e-03, -1.18865864e-03, -5.67454798e-03,\n",
      "        2.86512859e-02,  3.48107480e-02,  6.92637404e-05, -9.79422592e-03,\n",
      "       -1.16107762e-02, -1.88597403e-02, -1.61844194e-02, -1.50640951e-02,\n",
      "       -3.66686634e-03,  1.68068428e-03,  1.67142991e-02, -2.54428536e-02,\n",
      "       -1.18154217e-03,  1.24714486e-02,  6.99591544e-03, -1.93638597e-02,\n",
      "       -1.72201619e-02, -1.20744184e-02,  1.24253752e-02, -5.62097132e-03,\n",
      "       -2.36374401e-02, -5.35788620e-03,  7.27944402e-03,  1.59788337e-02,\n",
      "        1.84009373e-02, -8.21825769e-03,  3.04228440e-03,  4.03079297e-03,\n",
      "        8.09107069e-03,  1.62086207e-02, -1.15499543e-02,  4.87291021e-04,\n",
      "       -1.85574926e-02, -1.72506887e-02, -1.59338638e-02,  5.23463544e-03,\n",
      "       -5.66937029e-03,  5.07529778e-03, -4.06232243e-03,  2.31014006e-02,\n",
      "       -3.30588990e-03,  2.43987795e-03,  1.34125147e-02, -2.10917136e-03,\n",
      "       -1.38479527e-02, -1.45779401e-02,  1.18675875e-02,  1.64564010e-02,\n",
      "        8.96797050e-03, -8.08017142e-03, -3.68040404e-03,  6.56225206e-03,\n",
      "        1.09474850e-03, -5.63891558e-03, -3.93397734e-03,  2.66370233e-02,\n",
      "        1.46917664e-02,  1.64754800e-02,  9.28140152e-03,  1.29771261e-02,\n",
      "        1.62224297e-03, -1.02844723e-02,  1.35692209e-02, -4.52265181e-02,\n",
      "       -2.02524336e-03,  9.21924133e-03, -4.69304528e-03,  3.60889290e-03,\n",
      "        1.66986957e-02, -4.58628079e-03, -4.95739281e-03, -1.27188570e-04,\n",
      "       -2.36384310e-02,  6.90389099e-03,  8.00446793e-03,  4.89778933e-04,\n",
      "       -3.81916063e-03,  6.37126388e-03, -1.69536304e-02, -2.75642890e-03,\n",
      "       -1.86532480e-03, -2.78879027e-03,  1.06028914e-02, -5.54492418e-03,\n",
      "       -5.41354623e-03,  9.36537236e-03, -1.16084507e-02,  9.59872792e-04,\n",
      "        3.66446562e-03,  1.24362260e-02, -1.03372068e-03,  6.31102873e-03,\n",
      "        7.05659296e-03,  8.35810229e-03,  7.60429865e-03,  2.82529835e-03,\n",
      "       -1.56261455e-02,  4.76408331e-03, -1.60556426e-03,  6.71829330e-05,\n",
      "        8.90370179e-03,  4.74033179e-04, -1.49897505e-02,  1.14075243e-02,\n",
      "        7.16505339e-03, -9.53249261e-03, -7.39648100e-03, -2.41015339e-04,\n",
      "       -4.56976751e-03,  9.20725614e-03,  3.89800407e-03,  3.60176503e-03,\n",
      "        4.40346869e-03,  8.93275905e-03, -7.68800266e-03, -1.87136717e-02,\n",
      "       -2.06734706e-03,  5.94225526e-03,  1.02321217e-02,  1.64822713e-02,\n",
      "       -1.18251294e-02,  1.79398358e-02, -1.37277795e-02,  9.93941538e-03,\n",
      "       -8.81992467e-03, -2.97977566e-03, -1.48374867e-03, -7.85241276e-03,\n",
      "        1.87224038e-02, -3.78656900e-03, -4.36063390e-03, -1.09008141e-02,\n",
      "       -1.35928914e-02,  1.29054999e-02,  1.54390298e-02,  2.35978160e-02,\n",
      "       -9.39365197e-03, -1.50595987e-02,  1.38926436e-03,  1.39577407e-02,\n",
      "        1.04681551e-02, -2.19376646e-02, -2.15977076e-02,  3.99733102e-03,\n",
      "        1.92546323e-02,  2.21745402e-04, -1.09007619e-02,  7.31403008e-03,\n",
      "       -1.91385066e-03,  4.12796857e-04,  3.67454207e-03, -1.11037423e-03,\n",
      "        1.11521187e-03, -2.57487106e-03,  1.13020814e-03,  2.05852184e-03,\n",
      "        1.44521566e-02,  5.36153140e-03, -1.56494416e-03,  2.88686901e-03,\n",
      "       -2.00588931e-03,  1.34142274e-02,  1.69584830e-03, -5.52679738e-03,\n",
      "       -5.83940465e-03, -8.04939587e-03,  1.48610044e-02, -8.85787420e-03,\n",
      "       -6.14023628e-03,  2.63628382e-02,  1.23567705e-03, -3.13027087e-03,\n",
      "        1.26702171e-02, -1.68826408e-03,  6.32256595e-03,  2.19129887e-03,\n",
      "        4.09349939e-03, -6.56773336e-03, -4.52024862e-03, -2.07578279e-02,\n",
      "        4.11839364e-03, -1.40514318e-03, -4.98642633e-03,  2.12330222e-02,\n",
      "        7.02033332e-03, -1.18124261e-02, -3.66475643e-03,  4.57540341e-03,\n",
      "       -2.48198863e-03,  5.42882364e-03,  2.25638365e-03,  1.71419717e-02,\n",
      "        1.15103470e-02,  3.33229103e-03,  3.91915115e-03,  6.50545955e-03,\n",
      "       -6.67376816e-03, -5.69418212e-03,  1.30118784e-02,  1.27419243e-02,\n",
      "       -1.67114120e-02,  1.30296340e-02, -1.34574454e-02,  1.58207491e-03,\n",
      "       -5.37543278e-03, -8.81726015e-03,  7.02604931e-03, -5.59661491e-03,\n",
      "        3.29343067e-03,  8.65769014e-03,  7.81496428e-03, -8.65970924e-03,\n",
      "        2.20484124e-03,  1.18862838e-02, -2.78314750e-04, -8.63937894e-05,\n",
      "        8.76916572e-03, -1.52348988e-02,  6.18912606e-03,  1.58819128e-02,\n",
      "       -2.65851300e-02,  1.58134885e-02,  6.96081342e-03,  1.21490378e-02,\n",
      "        1.32446538e-03,  1.26915071e-02,  6.24547992e-03,  1.26643628e-02,\n",
      "        3.64438957e-03,  6.00939710e-03, -7.23338162e-04, -4.15077712e-03,\n",
      "       -2.26045735e-02, -8.31778906e-03,  6.80320151e-03, -1.82513823e-03,\n",
      "       -6.75520580e-03,  8.45481269e-03, -6.12277398e-03,  5.38635114e-03,\n",
      "       -6.03886507e-03,  6.46866765e-03,  5.79710933e-04,  1.48333218e-02,\n",
      "       -1.39812939e-04,  3.48104024e-03,  8.58263695e-04,  1.31477155e-02,\n",
      "       -2.79744640e-02, -7.43839424e-04, -1.47489589e-02, -1.68874655e-02,\n",
      "       -8.52827821e-03, -8.58248957e-03, -8.93939007e-03, -9.96638089e-04,\n",
      "       -2.99699651e-03,  3.32958740e-03, -2.47272151e-03, -2.59950403e-02,\n",
      "       -3.64961335e-04,  4.90065804e-03, -6.03861874e-03, -9.22275893e-03,\n",
      "       -1.02829165e-03, -5.73148904e-03, -5.00579644e-03,  4.72434564e-03,\n",
      "       -7.72312237e-03, -1.22633390e-02, -4.69574193e-03,  3.00784782e-03,\n",
      "        6.66107005e-03,  1.29222469e-02, -1.68364786e-03,  9.66003817e-03,\n",
      "       -1.07474737e-02,  4.84519592e-03, -6.77668210e-03, -6.16526976e-03,\n",
      "       -4.05363366e-03, -3.62585043e-03, -2.14220062e-02, -1.52456965e-02,\n",
      "        7.19478820e-03, -1.35729951e-03, -8.97702854e-03, -4.88012377e-03,\n",
      "       -4.45744675e-03,  1.24235302e-02,  7.47911399e-04, -1.61065497e-02,\n",
      "       -1.17914262e-03,  2.57672407e-02,  4.84059518e-03, -7.94648018e-04,\n",
      "        4.88476036e-03,  1.11302454e-03, -1.81548356e-03,  4.88472544e-03,\n",
      "        4.04147338e-03,  6.45885151e-03,  1.33895073e-02, -1.13025876e-02,\n",
      "       -1.24056963e-02,  1.18099498e-02, -2.36443197e-03, -9.02867690e-03,\n",
      "        8.48348066e-03, -1.76307969e-02, -4.56959242e-03,  4.86754160e-03,\n",
      "        1.29808737e-02, -4.23139986e-03,  2.83403532e-03,  2.00866032e-02,\n",
      "        3.41780251e-03, -7.32794963e-03,  1.32597405e-02,  5.20261470e-03,\n",
      "        4.01646271e-03,  9.72679933e-04, -6.58577960e-03,  1.31995939e-02,\n",
      "        3.41762300e-03,  9.56047885e-03, -5.07002231e-03,  1.53265167e-02,\n",
      "        1.65059371e-03,  9.35756601e-03, -1.84807833e-02,  2.23641358e-02,\n",
      "       -1.17408149e-02,  1.05778631e-02,  1.41765596e-02,  2.25386303e-03,\n",
      "        1.80684533e-02, -1.75255015e-02,  1.26102082e-02,  3.51251382e-03,\n",
      "       -1.00841373e-02, -7.92881567e-03, -4.63357661e-03,  1.27502996e-02,\n",
      "       -1.16467541e-02, -1.80975348e-03,  2.73995101e-02,  6.38546795e-03,\n",
      "       -8.49696156e-03, -1.02304155e-02, -1.33301667e-03, -7.76599674e-03,\n",
      "        1.33502390e-02,  2.04280880e-03,  5.00973873e-03, -8.29430576e-03,\n",
      "        7.57055962e-03,  2.76603829e-03, -3.10098520e-04, -1.14411674e-02],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(512, 500), dtype=float32, numpy=\n",
      "array([[-3.7378658e-02, -3.0285910e-02, -1.4386959e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-3.5187241e-02, -3.6660764e-02, -3.7223842e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [ 5.9299781e-03,  1.2785681e-02,  1.4741530e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       ...,\n",
      "       [ 5.7866586e-05,  1.0403169e-02,  2.3820980e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-6.7064628e-02, -7.7184387e-02, -8.3170794e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "       [-2.4151057e-02, -9.5662242e-03,  1.1368391e-02, ...,\n",
      "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: shape=(500,), dtype=float32, numpy=\n",
      "array([-4.99066412e-02, -4.74145785e-02, -3.71197537e-02, -8.23702756e-03,\n",
      "       -2.58415118e-02, -8.84139463e-02,  2.57330341e-03, -1.09303100e-02,\n",
      "        7.22775469e-03,  2.27390099e-02,  2.16083843e-02,  8.02773237e-03,\n",
      "        4.15038504e-02,  2.91379392e-02,  2.90624611e-02, -1.09635079e-02,\n",
      "        1.08238878e-02,  2.58155018e-02, -7.66509678e-04, -2.51325686e-02,\n",
      "        5.07612191e-02, -6.01510815e-02,  8.98054056e-03, -2.91945878e-03,\n",
      "       -3.30536664e-02,  1.51138697e-02, -4.34775231e-03,  2.42396910e-03,\n",
      "        1.19853951e-02,  1.17619615e-02,  8.74983333e-03, -1.07794255e-02,\n",
      "       -6.18866086e-03,  9.23806243e-03,  2.09853351e-02, -1.69991590e-02,\n",
      "       -4.46197111e-03, -1.00177173e-02,  1.43639697e-02,  1.80459861e-02,\n",
      "        1.08449925e-02, -4.62815464e-02,  2.30944473e-02,  2.45593116e-02,\n",
      "       -3.71112451e-02, -1.43942181e-02, -3.03594451e-02, -2.35662386e-02,\n",
      "       -4.67171613e-03,  2.73457952e-02,  1.63221564e-02, -1.80341583e-03,\n",
      "       -3.63314152e-02,  5.16401939e-02,  5.25006279e-02, -4.73408699e-02,\n",
      "        1.06747262e-02, -9.45694745e-03,  2.43809950e-02, -1.71628371e-02,\n",
      "        2.84083863e-03, -1.62069388e-02, -2.07447484e-02, -8.63511022e-03,\n",
      "       -5.88646391e-03, -1.84765123e-02,  3.88214830e-03,  1.72237977e-02,\n",
      "       -2.78516207e-03,  2.45255344e-02,  7.85337761e-03, -1.09675471e-02,\n",
      "        1.44062517e-02,  1.52699761e-02,  2.14509517e-02,  6.59781974e-04,\n",
      "        2.35777721e-02,  4.80674673e-03,  2.01698020e-02, -2.18981784e-03,\n",
      "        1.10696368e-02, -1.69317964e-02,  1.03825238e-04,  4.32639755e-03,\n",
      "       -2.98444852e-02, -7.93232210e-03,  9.87442909e-04,  6.48471713e-03,\n",
      "       -1.01554412e-02,  2.18268633e-02,  1.31632127e-02,  1.31628895e-03,\n",
      "       -3.18038673e-03,  7.78469024e-03,  2.12203115e-02, -3.64818261e-03,\n",
      "        9.97307058e-03,  1.39680300e-02,  1.22571606e-02, -1.34408195e-02,\n",
      "        1.67188123e-02,  5.26920427e-03, -6.45147078e-03,  7.65819149e-03,\n",
      "        5.07025933e-03, -1.74334068e-02, -1.75304827e-04, -1.12799471e-02,\n",
      "        2.07419638e-02, -5.94127038e-03, -2.30758712e-02,  4.62821219e-03,\n",
      "       -3.98624036e-03,  2.61998270e-03,  4.91241552e-03, -1.29670845e-02,\n",
      "       -3.07963206e-03,  5.64331654e-03,  1.00110332e-02,  2.45901458e-02,\n",
      "        1.60195194e-02, -1.44336019e-02,  8.18043016e-03,  8.81880149e-03,\n",
      "       -7.22604617e-03, -1.76441520e-02, -1.57928504e-02,  3.59542901e-03,\n",
      "       -7.12879002e-04,  6.85765967e-03, -5.19854203e-03, -4.94867912e-04,\n",
      "        1.89324026e-03,  6.19595265e-03,  8.45337054e-04,  6.91553438e-03,\n",
      "       -7.97936320e-03,  6.36176392e-03, -1.17315222e-02, -8.05448275e-03,\n",
      "       -1.27850217e-03,  2.39406619e-03,  5.92802465e-03,  3.73685081e-03,\n",
      "        7.45134195e-03,  6.44404115e-03,  8.33009277e-03, -2.44808663e-03,\n",
      "        7.19585549e-03,  4.74590296e-03,  1.20227644e-02, -8.20544199e-04,\n",
      "       -1.46648623e-02, -1.54006411e-03, -3.07619246e-03, -1.94263011e-02,\n",
      "       -8.51089973e-03,  2.25830416e-04,  1.24415737e-02,  3.47044133e-03,\n",
      "       -4.46709059e-03,  1.14215985e-02,  4.34789248e-03,  1.31927738e-02,\n",
      "        1.66265257e-02,  1.01345442e-02, -5.80127444e-03,  2.13859952e-04,\n",
      "        7.81807932e-04, -2.13752408e-02,  1.08782912e-03,  1.92259122e-02,\n",
      "        6.78674458e-03,  6.51664427e-03, -3.69815528e-02,  5.12226485e-04,\n",
      "       -3.44337896e-03, -9.97680798e-03, -2.65033040e-02, -3.80257773e-03,\n",
      "       -1.83763299e-02, -7.85980374e-03,  4.15681629e-04,  1.28405439e-02,\n",
      "       -1.22850584e-02,  2.02489458e-02,  2.53821397e-03, -2.09559361e-03,\n",
      "       -5.22285700e-03,  2.52761645e-04,  1.34648150e-03, -6.88366406e-03,\n",
      "        1.61752161e-02,  4.52722795e-03, -1.31934350e-02,  1.70420371e-02,\n",
      "       -3.21313331e-04, -1.62591711e-02, -1.77463740e-02, -1.35870771e-02,\n",
      "       -8.77070520e-03,  1.50151923e-02, -1.12991687e-02, -1.34131154e-02,\n",
      "        2.53326669e-02,  1.76188126e-02,  9.48747154e-03,  6.78547472e-03,\n",
      "        1.07152723e-02, -2.06716619e-02, -4.83775046e-03, -8.85590166e-03,\n",
      "       -3.52611160e-03, -2.54216082e-02, -1.17838178e-02,  5.06209722e-03,\n",
      "       -1.12164440e-02, -2.04569250e-02,  1.31737953e-03,  1.94010548e-02,\n",
      "        3.23518319e-03,  2.02142745e-02, -7.00970506e-03, -1.38818268e-02,\n",
      "        2.01890375e-02,  2.77191401e-02, -3.31756612e-03,  9.52289067e-03,\n",
      "        8.30192119e-04, -2.57740729e-02, -1.00323074e-02,  1.23088565e-02,\n",
      "       -1.71152380e-04, -3.00545730e-02, -2.81488001e-02, -1.17050449e-03,\n",
      "       -1.07221585e-02, -1.47798937e-02, -2.04190821e-03,  1.66240167e-02,\n",
      "       -2.22689519e-03,  4.63558547e-03,  7.81985838e-03, -8.94055702e-05,\n",
      "        5.30462619e-03,  1.13499966e-02, -1.31714446e-02, -6.41521346e-03,\n",
      "       -5.14448481e-03, -2.34826608e-03, -4.86794306e-04,  6.60648849e-03,\n",
      "        6.56019105e-03, -8.31228681e-05, -1.15826344e-02,  3.93067114e-03,\n",
      "       -4.65900963e-03,  2.04144744e-05, -1.93980113e-02, -5.31729823e-03,\n",
      "       -2.04193294e-02,  2.38615461e-02, -8.75015557e-03, -6.91796420e-03,\n",
      "        5.13799256e-03,  5.07803820e-03,  1.22948261e-02, -7.39125814e-03,\n",
      "       -1.31878688e-03, -1.85045134e-02,  4.57272952e-04,  1.18822441e-03,\n",
      "        1.43351331e-02, -1.87896863e-02, -1.93548054e-02,  9.29064211e-03,\n",
      "       -1.30436989e-03, -7.99932983e-03, -2.12043617e-02,  6.54774671e-03,\n",
      "       -2.84864986e-03,  1.10342465e-02, -6.79792464e-03, -1.38431014e-02,\n",
      "       -2.93564284e-03,  6.09593699e-03, -4.90376679e-03,  4.23257588e-05,\n",
      "        4.29669395e-03, -1.22140376e-02, -2.59195035e-03, -2.62298970e-04,\n",
      "        1.12061407e-02, -1.57210771e-02, -1.69215165e-02,  8.99949484e-03,\n",
      "       -4.17506741e-03, -9.04940441e-03, -1.34445876e-02,  5.06343273e-03,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([5, 100])\n",
    "#, tf.GradientTape() as disc_tape\n",
    "peptides = X1[:5, :15, :]\n",
    "with tf.GradientTape() as gen_tape:\n",
    "    generated_bpf = generator(noise, training=True)\n",
    "\n",
    "    # real_output = discriminator(peptides, training=True)\n",
    "    fake_output = discriminator(generated_bpf[:,:15,:], training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    # disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "    print(gen_loss)\n",
    "    # print(disc_loss)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    # gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    print(gradients_of_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([100, 100])\n",
    "\n",
    "generated_bpf = generator(noise, training=True)\n",
    "\n",
    "fake_output = discriminator(generated_bpf[:,:15,:], training=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for key, output in enumerate(fake_output):\n",
    "    if output[1] > 0.25:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "print(correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
