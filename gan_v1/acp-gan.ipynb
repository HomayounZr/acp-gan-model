{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 15, 20)\n",
      "(376, 2)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical as labelEncoding \n",
    "\n",
    "T = 15 # terminus_length\n",
    "\n",
    "X1 = np.load('bpf-740.npy')\n",
    "\n",
    "\n",
    "X1 = X1[:376,:T,:]\n",
    "\n",
    "\n",
    "Y  = [1 for _ in range(376)]\n",
    "\n",
    "Y = labelEncoding(Y, dtype=int)\n",
    "\n",
    "print(X1.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 15, 20)\n",
      "(15, 20)\n",
      "[[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape)\n",
    "print(X1[0].shape)\n",
    "print(X1[0])\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF-2.11.0.\n"
     ]
    }
   ],
   "source": [
    "# Deep Neural Networks:\n",
    "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
    "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
    "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
    "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
    "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
    "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
    "from tensorflow.keras.models import (Sequential, Model)\n",
    "\n",
    "# Core:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Performance:\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
    "\n",
    "#Utilities:\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
    "from tensorflow.keras.utils import plot_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    ### Head-1:\n",
    "    input1 = Input(shape=X1[0].shape)\n",
    "\n",
    "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate=0.80)(x)\n",
    "\n",
    "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate=0.70)(x)\n",
    "\n",
    "    head1 = Flatten()(x)\n",
    "\n",
    "    # merge\n",
    "    merge = Concatenate()([head1])\n",
    "\n",
    "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Dropout(rate=0.70)(output)\n",
    "\n",
    "    output = Dense(units=2, activation='softmax')(output)\n",
    "\n",
    "    return Model(inputs=[input1], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import ProtParam\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio.SubsMat import MatrixInfo\n",
    "\n",
    "\n",
    "# Function to convert binary profile feature to amino acid sequence\n",
    "def bpf_to_sequence(binary_profile_feature):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVBZX\"\n",
    "    sequence = \"\"\n",
    "    for row in binary_profile_feature:\n",
    "        index = row.argmax()\n",
    "        sequence += amino_acids[index]\n",
    "    return sequence\n",
    "\n",
    "def seq_to_blosum(sequence):\n",
    "    blosum62 = MatrixInfo.blosum62\n",
    "    sequence = sequence.upper()\n",
    "    length = len(sequence)\n",
    "    blosum_matrix = []\n",
    "    for aa1 in sequence:\n",
    "        row = []\n",
    "        for aa2 in sequence:\n",
    "            if (aa1, aa2) in blosum62:\n",
    "                row.append(blosum62[(aa1, aa2)])\n",
    "            else:\n",
    "                row.append(blosum62[(aa2, aa1)])\n",
    "        blosum_matrix.append(row)\n",
    "    return blosum_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpf_to_sequence(binary_profile_feature):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVBZX\"\n",
    "    sequence = \"\"\n",
    "    for row in binary_profile_feature:\n",
    "        i = 0\n",
    "        for item in row:\n",
    "            i += 1\n",
    "            if item.numpy() == 1:\n",
    "                sequence += amino_acids[i]\n",
    "    return sequence\n",
    "\n",
    "def seq_to_blosum(sequence):\n",
    "    blosum62 = MatrixInfo.blosum62\n",
    "    sequence = sequence.upper()\n",
    "    length = len(sequence)\n",
    "    blosum_matrix = []\n",
    "    for aa1 in sequence:\n",
    "        row = []\n",
    "        for aa2 in sequence:\n",
    "            if (aa1, aa2) in blosum62:\n",
    "                row.append(blosum62[(aa1, aa2)])\n",
    "            else:\n",
    "                row.append(blosum62[(aa2, aa1)])\n",
    "        blosum_matrix.append(row[:20])\n",
    "    return blosum_matrix\n",
    "\n",
    "def bpf_to_blosum_layer(seqs_bpf):\n",
    "    seqs_blosum = []\n",
    "    for bpf in seqs_bpf:\n",
    "        str_seq = bpf_to_sequence(bpf)\n",
    "        seqs_blosum.append(seq_to_blosum(str_seq))\n",
    "\n",
    "    print(seqs_blosum)\n",
    "    return seqs_blosum\n",
    "\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(512))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Dense(25 * 20, activation='sigmoid'))\n",
    "    model.add(layers.Reshape((25, 20)))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    # model = Sequential([\n",
    "    #     layers.Input(shape=(latent_dim,)),\n",
    "    #     layers.Dense(128, activation='relu'),\n",
    "    #     layers.Dense(256, activation='relu'),\n",
    "    #     layers.Dense(output_shape[0] * output_shape[1], activation='sigmoid'),\n",
    "    #     layers.Reshape(output_shape),\n",
    "    #     layers.Lambda(lambda x: tf.one_hot(tf.argmax(x, axis=-1), depth=output_shape[1])),\n",
    "    #     layers.Lambda(lambda x: tf.cast(x, dtype=tf.int32)),\n",
    "    # ])\n",
    "\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 25, 20), dtype=float32, numpy=\n",
       "array([[[0.4177503 , 0.5410225 , 0.5191743 , 0.4092115 , 0.5264865 ,\n",
       "         0.5068796 , 0.4981922 , 0.3752302 , 0.39406362, 0.375696  ,\n",
       "         0.65833527, 0.48286122, 0.5388575 , 0.47444177, 0.5417432 ,\n",
       "         0.49155676, 0.6065807 , 0.6115332 , 0.5164627 , 0.47408876],\n",
       "        [0.2792052 , 0.56848186, 0.5060081 , 0.68393797, 0.46552604,\n",
       "         0.57585406, 0.6001385 , 0.41196012, 0.4627222 , 0.41055036,\n",
       "         0.50699484, 0.37217724, 0.43834338, 0.53974426, 0.5383152 ,\n",
       "         0.7316912 , 0.39973783, 0.4404458 , 0.49866048, 0.38269988],\n",
       "        [0.42645922, 0.4642695 , 0.53303045, 0.4519937 , 0.38793388,\n",
       "         0.6316519 , 0.64925116, 0.61246985, 0.5330645 , 0.54738283,\n",
       "         0.42506808, 0.3343812 , 0.37869853, 0.5177621 , 0.43524584,\n",
       "         0.40246683, 0.63195807, 0.5087882 , 0.5352669 , 0.4144797 ],\n",
       "        [0.43680716, 0.51767695, 0.579431  , 0.49107927, 0.4525455 ,\n",
       "         0.48567742, 0.67157775, 0.5889723 , 0.6918545 , 0.35402474,\n",
       "         0.4320611 , 0.56230175, 0.48169786, 0.5542422 , 0.60491705,\n",
       "         0.583387  , 0.49935177, 0.51596   , 0.44680044, 0.40532413],\n",
       "        [0.5800585 , 0.39162108, 0.6379141 , 0.636021  , 0.5711161 ,\n",
       "         0.52939606, 0.40151355, 0.58981127, 0.5204453 , 0.39794457,\n",
       "         0.3732738 , 0.5616886 , 0.49438307, 0.5492675 , 0.66320145,\n",
       "         0.6648245 , 0.5497147 , 0.2893894 , 0.3749573 , 0.37898684],\n",
       "        [0.4119329 , 0.5948683 , 0.58721256, 0.500094  , 0.51996326,\n",
       "         0.42568743, 0.5117315 , 0.6258497 , 0.32671568, 0.49922454,\n",
       "         0.51157683, 0.51056397, 0.55431294, 0.34342283, 0.51367193,\n",
       "         0.53796816, 0.33629233, 0.4985199 , 0.51353264, 0.5132087 ],\n",
       "        [0.61627984, 0.5725196 , 0.589338  , 0.39824572, 0.53253865,\n",
       "         0.5183209 , 0.44886947, 0.45918468, 0.43090448, 0.46988475,\n",
       "         0.55144036, 0.512817  , 0.46548012, 0.38024965, 0.49966463,\n",
       "         0.440896  , 0.48829716, 0.56326914, 0.49304175, 0.39257783],\n",
       "        [0.5217668 , 0.5814874 , 0.60354793, 0.5799614 , 0.5074763 ,\n",
       "         0.29864663, 0.4617209 , 0.5011538 , 0.49735063, 0.6405516 ,\n",
       "         0.33288306, 0.43154007, 0.58895576, 0.49961647, 0.4996231 ,\n",
       "         0.5745697 , 0.5743403 , 0.48017818, 0.5091054 , 0.5077528 ],\n",
       "        [0.5323726 , 0.5288374 , 0.57270736, 0.54010135, 0.39901644,\n",
       "         0.6609804 , 0.47176838, 0.36182263, 0.48455986, 0.30495   ,\n",
       "         0.47732818, 0.50653857, 0.5937973 , 0.58245504, 0.6406576 ,\n",
       "         0.5692734 , 0.4190933 , 0.5347062 , 0.51399344, 0.41747838],\n",
       "        [0.31031418, 0.58279705, 0.47056785, 0.32339928, 0.34115922,\n",
       "         0.52388316, 0.6537027 , 0.33469993, 0.6898302 , 0.5966637 ,\n",
       "         0.56728935, 0.6944238 , 0.5863519 , 0.568067  , 0.65080035,\n",
       "         0.5563755 , 0.43011242, 0.4136753 , 0.37107915, 0.44577906],\n",
       "        [0.5609617 , 0.38395733, 0.3806572 , 0.5016608 , 0.2205279 ,\n",
       "         0.5620709 , 0.4465285 , 0.5236519 , 0.5350862 , 0.5612433 ,\n",
       "         0.49357367, 0.4802217 , 0.51706105, 0.58388454, 0.39365035,\n",
       "         0.6117424 , 0.45876288, 0.5804772 , 0.5495658 , 0.4137435 ],\n",
       "        [0.5453042 , 0.4700579 , 0.36563066, 0.5770425 , 0.5438201 ,\n",
       "         0.5916899 , 0.63917756, 0.6667451 , 0.5629491 , 0.589085  ,\n",
       "         0.36717802, 0.4917992 , 0.6423454 , 0.28409496, 0.45379242,\n",
       "         0.3682374 , 0.60636765, 0.4589178 , 0.52585524, 0.59163266],\n",
       "        [0.48483673, 0.6576443 , 0.60587656, 0.45571464, 0.5141961 ,\n",
       "         0.6398878 , 0.61098033, 0.5068225 , 0.518372  , 0.42431936,\n",
       "         0.5177066 , 0.42539617, 0.49061504, 0.6366472 , 0.6934106 ,\n",
       "         0.780742  , 0.3431367 , 0.5554117 , 0.5120959 , 0.47549003],\n",
       "        [0.339988  , 0.5533225 , 0.46067658, 0.5319909 , 0.39785534,\n",
       "         0.6499433 , 0.5332961 , 0.5297191 , 0.44787362, 0.3575218 ,\n",
       "         0.6671046 , 0.4042155 , 0.5965668 , 0.5073763 , 0.6848831 ,\n",
       "         0.5526749 , 0.5620346 , 0.43793344, 0.42373756, 0.5381464 ],\n",
       "        [0.30032492, 0.3979459 , 0.46108612, 0.53296417, 0.49691457,\n",
       "         0.5161865 , 0.4914359 , 0.57904834, 0.39544   , 0.57307965,\n",
       "         0.54049796, 0.59586483, 0.3552164 , 0.47122088, 0.6365081 ,\n",
       "         0.7225189 , 0.34596336, 0.5203128 , 0.59590054, 0.5762569 ],\n",
       "        [0.47956055, 0.3989634 , 0.566424  , 0.6968403 , 0.46475413,\n",
       "         0.34397104, 0.49801785, 0.35590667, 0.63082117, 0.45503384,\n",
       "         0.51161605, 0.42947534, 0.39669204, 0.5792107 , 0.46452674,\n",
       "         0.48336756, 0.5081293 , 0.44977072, 0.61438555, 0.63350445],\n",
       "        [0.57560444, 0.39730564, 0.56347746, 0.5411563 , 0.43339744,\n",
       "         0.5632797 , 0.55576724, 0.6068932 , 0.6443641 , 0.574918  ,\n",
       "         0.5447356 , 0.50335664, 0.63288313, 0.50020295, 0.29874408,\n",
       "         0.40970394, 0.57470167, 0.47019818, 0.43360466, 0.49258307],\n",
       "        [0.5293763 , 0.47414958, 0.59005976, 0.59156394, 0.5659602 ,\n",
       "         0.5341347 , 0.57752156, 0.64139074, 0.514756  , 0.37985462,\n",
       "         0.5537211 , 0.5045424 , 0.5926171 , 0.37538812, 0.45710328,\n",
       "         0.6186156 , 0.54074913, 0.6211656 , 0.5592011 , 0.50992423],\n",
       "        [0.5440795 , 0.6090874 , 0.5905977 , 0.51699996, 0.6044404 ,\n",
       "         0.5482602 , 0.3775832 , 0.5210913 , 0.34495315, 0.47072217,\n",
       "         0.39419675, 0.3359156 , 0.4228821 , 0.454981  , 0.6226642 ,\n",
       "         0.44211736, 0.48733518, 0.6406805 , 0.48063356, 0.43800506],\n",
       "        [0.27665922, 0.54733187, 0.6265475 , 0.38250926, 0.65209645,\n",
       "         0.5553986 , 0.59030664, 0.6344079 , 0.5172867 , 0.49055156,\n",
       "         0.46005386, 0.5574546 , 0.44080305, 0.40865314, 0.5133207 ,\n",
       "         0.38116035, 0.47016594, 0.48057252, 0.5701241 , 0.55850905],\n",
       "        [0.5862613 , 0.5090769 , 0.336832  , 0.611925  , 0.43972442,\n",
       "         0.69726574, 0.5743218 , 0.42558515, 0.63701755, 0.40395033,\n",
       "         0.4704594 , 0.44347936, 0.68351936, 0.3876629 , 0.55274   ,\n",
       "         0.610655  , 0.42162085, 0.7037585 , 0.36419976, 0.29520077],\n",
       "        [0.5666572 , 0.6014589 , 0.61395967, 0.32712278, 0.31229487,\n",
       "         0.5188499 , 0.41627574, 0.52583003, 0.17359863, 0.49245283,\n",
       "         0.5200361 , 0.48063144, 0.6034213 , 0.34237823, 0.62547827,\n",
       "         0.40887097, 0.51064265, 0.436803  , 0.33810577, 0.49691296],\n",
       "        [0.5004259 , 0.64079314, 0.58271325, 0.50800675, 0.5452599 ,\n",
       "         0.4907215 , 0.46563682, 0.4535418 , 0.5980164 , 0.52221   ,\n",
       "         0.60979867, 0.38832822, 0.29870892, 0.5701223 , 0.5208683 ,\n",
       "         0.40811297, 0.5381428 , 0.5216844 , 0.4946477 , 0.50303936],\n",
       "        [0.5647153 , 0.36648044, 0.4139351 , 0.42788166, 0.49757957,\n",
       "         0.5585371 , 0.52101505, 0.4337949 , 0.48220947, 0.4239038 ,\n",
       "         0.54323035, 0.5632566 , 0.48076475, 0.51696736, 0.30067432,\n",
       "         0.58717275, 0.5911236 , 0.43821153, 0.5046216 , 0.57872874],\n",
       "        [0.52650744, 0.41742674, 0.4013235 , 0.61158246, 0.50721335,\n",
       "         0.46111616, 0.5280341 , 0.5410182 , 0.65209526, 0.3901971 ,\n",
       "         0.61515564, 0.2763237 , 0.49757257, 0.47669536, 0.45418954,\n",
       "         0.45449325, 0.65099245, 0.62266135, 0.6355042 , 0.48211107]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "latent_dim = 100  # Dimensionality of the latent space\n",
    "batch_size = 1\n",
    "output_shape = (25, 20)  # Desired output shape of the matrix\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "generated_matrix = generator(noise, training=False)\n",
    "\n",
    "generated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.load_weights('./acp_mhcnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3078078 , 0.6921922 ],\n",
       "       [0.17504196, 0.824958  ],\n",
       "       [0.31832415, 0.6816759 ],\n",
       "       [0.18360282, 0.81639725],\n",
       "       [0.19149974, 0.80850023]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = discriminator.predict([X1[:5,:,:]])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "[[9.9999666e-01 3.3694214e-06]\n",
      " [9.9999964e-01 3.4618466e-07]\n",
      " [9.9999976e-01 2.8348268e-07]\n",
      " ...\n",
      " [9.9999976e-01 2.2222730e-07]\n",
      " [9.9999964e-01 3.9724043e-07]\n",
      " [9.9999952e-01 4.9980542e-07]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([1000, 100])\n",
    "fake_seqs = generator(noise, training=False)\n",
    "\n",
    "prediction = discriminator.predict([fake_seqs[:,:15,:]])\n",
    "print(prediction)\n",
    "\n",
    "over50 = 0\n",
    "over25 = 0\n",
    "over40 = 0\n",
    "total = 0\n",
    "for key, output in enumerate(prediction):\n",
    "    if output[1] > 0.25:\n",
    "        over25 += 1\n",
    "    if output[1] > 0.4:\n",
    "        over40 += 1\n",
    "    if output[1] > 0.5:\n",
    "        over50 += 1\n",
    "    total += 1\n",
    "\n",
    "print(over25 / total)\n",
    "print(over40 / total)\n",
    "print(over50 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# def generator_loss(disc_output):\n",
    "#     batch_size = tf.shape(disc_output)[0]\n",
    "#     num_classes = tf.shape(disc_output)[1]\n",
    "#     desired_output = tf.concat([tf.zeros((batch_size, 1)), tf.ones((batch_size, num_classes - 1))], axis=1)\n",
    "    \n",
    "#     # Define binary cross entropy loss\n",
    "#     bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss = bce(desired_output, disc_output)\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[9.9999940e-01 5.4496769e-07]\n",
      " [9.9999738e-01 2.6562680e-06]\n",
      " [9.9999702e-01 3.0341221e-06]\n",
      " [9.9999964e-01 4.0852419e-07]\n",
      " [9.9999952e-01 5.0236633e-07]]\n",
      "[[0.3078078  0.6921922 ]\n",
      " [0.17504196 0.824958  ]\n",
      " [0.31832415 0.6816759 ]\n",
      " [0.18360282 0.81639725]\n",
      " [0.19149974 0.80850023]]\n",
      "tf.Tensor(6.8543024, shape=(), dtype=float32)\n",
      "tf.Tensor(7.7417684, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([5, 100])\n",
    "fake_seqs = generator(noise, training=False)\n",
    "\n",
    "fake_prediction = discriminator.predict([fake_seqs[:,:15,:]])\n",
    "real_prediction = discriminator.predict([X1[:5]])\n",
    "print(fake_prediction)\n",
    "print(real_prediction)\n",
    "\n",
    "# disc_loss = discriminator_loss(Y[:5], real_prediction)\n",
    "gen_loss = generator_loss(fake_prediction)\n",
    "print(gen_loss)\n",
    "disc_loss = discriminator_loss(real_prediction, fake_prediction)\n",
    "print(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "EPOCHS = 500\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(peptides):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_bpf = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(peptides, training=True)\n",
    "      fake_output = discriminator(generated_bpf[:,:15,:], training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    print(gen_loss)\n",
    "    print(disc_loss)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "def train(epochs):\n",
    "  for epoch in range(epochs):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for seq_batch in dataset:\n",
    "      train_step(seq_batch)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Time for epoch 1 is 5.514289855957031 sec\n",
      "Time for epoch 2 is 0.855933427810669 sec\n",
      "Time for epoch 3 is 1.1011767387390137 sec\n",
      "Time for epoch 4 is 1.3729007244110107 sec\n",
      "Time for epoch 5 is 1.252692461013794 sec\n",
      "Time for epoch 6 is 1.2778620719909668 sec\n",
      "Time for epoch 7 is 1.208526611328125 sec\n",
      "Time for epoch 8 is 1.6376838684082031 sec\n",
      "Time for epoch 9 is 1.9902801513671875 sec\n",
      "Time for epoch 10 is 1.2782330513000488 sec\n",
      "Time for epoch 11 is 1.476546287536621 sec\n",
      "Time for epoch 12 is 1.4736523628234863 sec\n",
      "Time for epoch 13 is 1.51523756980896 sec\n",
      "Time for epoch 14 is 1.186385154724121 sec\n",
      "Time for epoch 15 is 1.3547885417938232 sec\n",
      "Time for epoch 16 is 1.5234668254852295 sec\n",
      "Time for epoch 17 is 1.2951395511627197 sec\n",
      "Time for epoch 18 is 1.3324706554412842 sec\n",
      "Time for epoch 19 is 0.9472980499267578 sec\n",
      "Time for epoch 20 is 1.1968653202056885 sec\n",
      "Time for epoch 21 is 1.1204783916473389 sec\n",
      "Time for epoch 22 is 1.225245475769043 sec\n",
      "Time for epoch 23 is 1.0929052829742432 sec\n",
      "Time for epoch 24 is 1.0489721298217773 sec\n",
      "Time for epoch 25 is 1.1253366470336914 sec\n",
      "Time for epoch 26 is 1.5425686836242676 sec\n",
      "Time for epoch 27 is 1.5761404037475586 sec\n",
      "Time for epoch 28 is 1.397937297821045 sec\n",
      "Time for epoch 29 is 1.3873717784881592 sec\n",
      "Time for epoch 30 is 0.9072751998901367 sec\n",
      "Time for epoch 31 is 0.8285441398620605 sec\n",
      "Time for epoch 32 is 0.5176401138305664 sec\n",
      "Time for epoch 33 is 0.7661435604095459 sec\n",
      "Time for epoch 34 is 0.662651777267456 sec\n",
      "Time for epoch 35 is 0.5276491641998291 sec\n",
      "Time for epoch 36 is 0.23912644386291504 sec\n",
      "Time for epoch 37 is 0.2849996089935303 sec\n",
      "Time for epoch 38 is 0.4716196060180664 sec\n",
      "Time for epoch 39 is 0.4601926803588867 sec\n",
      "Time for epoch 40 is 0.5378115177154541 sec\n",
      "Time for epoch 41 is 0.830693244934082 sec\n",
      "Time for epoch 42 is 0.7047948837280273 sec\n",
      "Time for epoch 43 is 0.5875566005706787 sec\n",
      "Time for epoch 44 is 0.5217180252075195 sec\n",
      "Time for epoch 45 is 0.5346889495849609 sec\n",
      "Time for epoch 46 is 0.5038373470306396 sec\n",
      "Time for epoch 47 is 0.5410990715026855 sec\n",
      "Time for epoch 48 is 0.5419435501098633 sec\n",
      "Time for epoch 49 is 0.6053872108459473 sec\n",
      "Time for epoch 50 is 0.44319987297058105 sec\n",
      "Time for epoch 51 is 0.5681195259094238 sec\n",
      "Time for epoch 52 is 0.6112406253814697 sec\n",
      "Time for epoch 53 is 0.5354318618774414 sec\n",
      "Time for epoch 54 is 0.42446064949035645 sec\n",
      "Time for epoch 55 is 0.4513263702392578 sec\n",
      "Time for epoch 56 is 0.5222797393798828 sec\n",
      "Time for epoch 57 is 0.26799941062927246 sec\n",
      "Time for epoch 58 is 0.4026634693145752 sec\n",
      "Time for epoch 59 is 0.48807454109191895 sec\n",
      "Time for epoch 60 is 0.6061196327209473 sec\n",
      "Time for epoch 61 is 0.6687073707580566 sec\n",
      "Time for epoch 62 is 0.8142461776733398 sec\n",
      "Time for epoch 63 is 0.630650520324707 sec\n",
      "Time for epoch 64 is 0.775153398513794 sec\n",
      "Time for epoch 65 is 0.3562333583831787 sec\n",
      "Time for epoch 66 is 0.29814767837524414 sec\n",
      "Time for epoch 67 is 0.27813243865966797 sec\n",
      "Time for epoch 68 is 0.3986814022064209 sec\n",
      "Time for epoch 69 is 0.45224952697753906 sec\n",
      "Time for epoch 70 is 0.4432051181793213 sec\n",
      "Time for epoch 71 is 0.6363518238067627 sec\n",
      "Time for epoch 72 is 0.2470552921295166 sec\n",
      "Time for epoch 73 is 0.6464567184448242 sec\n",
      "Time for epoch 74 is 0.5616953372955322 sec\n",
      "Time for epoch 75 is 0.6814377307891846 sec\n",
      "Time for epoch 76 is 0.44947290420532227 sec\n",
      "Time for epoch 77 is 0.5310261249542236 sec\n",
      "Time for epoch 78 is 0.41470980644226074 sec\n",
      "Time for epoch 79 is 0.5213322639465332 sec\n",
      "Time for epoch 80 is 0.4836764335632324 sec\n",
      "Time for epoch 81 is 0.5831115245819092 sec\n",
      "Time for epoch 82 is 0.6343247890472412 sec\n",
      "Time for epoch 83 is 0.49953651428222656 sec\n",
      "Time for epoch 84 is 0.5346674919128418 sec\n",
      "Time for epoch 85 is 0.5895075798034668 sec\n",
      "Time for epoch 86 is 0.6361215114593506 sec\n",
      "Time for epoch 87 is 0.5731334686279297 sec\n",
      "Time for epoch 88 is 0.5924246311187744 sec\n",
      "Time for epoch 89 is 0.5215771198272705 sec\n",
      "Time for epoch 90 is 0.33324122428894043 sec\n",
      "Time for epoch 91 is 0.42227959632873535 sec\n",
      "Time for epoch 92 is 0.6082990169525146 sec\n",
      "Time for epoch 93 is 0.4740571975708008 sec\n",
      "Time for epoch 94 is 0.3335380554199219 sec\n",
      "Time for epoch 95 is 0.16870856285095215 sec\n",
      "Time for epoch 96 is 0.26856040954589844 sec\n",
      "Time for epoch 97 is 0.35938501358032227 sec\n",
      "Time for epoch 98 is 0.4576082229614258 sec\n",
      "Time for epoch 99 is 0.4430098533630371 sec\n",
      "Time for epoch 100 is 0.3716411590576172 sec\n",
      "Time for epoch 101 is 0.3646416664123535 sec\n",
      "Time for epoch 102 is 0.48177075386047363 sec\n",
      "Time for epoch 103 is 0.31145215034484863 sec\n",
      "Time for epoch 104 is 0.30788183212280273 sec\n",
      "Time for epoch 105 is 0.4083843231201172 sec\n",
      "Time for epoch 106 is 0.30217480659484863 sec\n",
      "Time for epoch 107 is 0.2870199680328369 sec\n",
      "Time for epoch 108 is 0.33228611946105957 sec\n",
      "Time for epoch 109 is 0.4145679473876953 sec\n",
      "Time for epoch 110 is 0.4322822093963623 sec\n",
      "Time for epoch 111 is 0.3461291790008545 sec\n",
      "Time for epoch 112 is 0.24716782569885254 sec\n",
      "Time for epoch 113 is 0.30321669578552246 sec\n",
      "Time for epoch 114 is 0.5273573398590088 sec\n",
      "Time for epoch 115 is 0.6244621276855469 sec\n",
      "Time for epoch 116 is 0.4536468982696533 sec\n",
      "Time for epoch 117 is 0.5364811420440674 sec\n",
      "Time for epoch 118 is 0.6961431503295898 sec\n",
      "Time for epoch 119 is 1.0363519191741943 sec\n",
      "Time for epoch 120 is 1.4305031299591064 sec\n",
      "Time for epoch 121 is 1.029322862625122 sec\n",
      "Time for epoch 122 is 1.295356273651123 sec\n",
      "Time for epoch 123 is 0.38729429244995117 sec\n",
      "Time for epoch 124 is 0.6826260089874268 sec\n",
      "Time for epoch 125 is 0.7715859413146973 sec\n",
      "Time for epoch 126 is 0.8635430335998535 sec\n",
      "Time for epoch 127 is 1.0091547966003418 sec\n",
      "Time for epoch 128 is 1.1395225524902344 sec\n",
      "Time for epoch 129 is 0.6905481815338135 sec\n",
      "Time for epoch 130 is 0.5665712356567383 sec\n",
      "Time for epoch 131 is 0.4202992916107178 sec\n",
      "Time for epoch 132 is 0.5515580177307129 sec\n",
      "Time for epoch 133 is 0.43461155891418457 sec\n",
      "Time for epoch 134 is 0.32429933547973633 sec\n",
      "Time for epoch 135 is 0.3079371452331543 sec\n",
      "Time for epoch 136 is 0.3742833137512207 sec\n",
      "Time for epoch 137 is 0.5532963275909424 sec\n",
      "Time for epoch 138 is 0.5409040451049805 sec\n",
      "Time for epoch 139 is 0.4791371822357178 sec\n",
      "Time for epoch 140 is 0.5473692417144775 sec\n",
      "Time for epoch 141 is 0.46546387672424316 sec\n",
      "Time for epoch 142 is 0.3141779899597168 sec\n",
      "Time for epoch 143 is 0.21462106704711914 sec\n",
      "Time for epoch 144 is 0.4883730411529541 sec\n",
      "Time for epoch 145 is 0.5891902446746826 sec\n",
      "Time for epoch 146 is 0.49358296394348145 sec\n",
      "Time for epoch 147 is 0.6041059494018555 sec\n",
      "Time for epoch 148 is 0.5835244655609131 sec\n",
      "Time for epoch 149 is 0.610048770904541 sec\n",
      "Time for epoch 150 is 0.6101944446563721 sec\n",
      "Time for epoch 151 is 0.510800838470459 sec\n",
      "Time for epoch 152 is 0.37133216857910156 sec\n",
      "Time for epoch 153 is 0.2373807430267334 sec\n",
      "Time for epoch 154 is 0.514962911605835 sec\n",
      "Time for epoch 155 is 0.5783510208129883 sec\n",
      "Time for epoch 156 is 0.5059752464294434 sec\n",
      "Time for epoch 157 is 0.4646487236022949 sec\n",
      "Time for epoch 158 is 0.4617598056793213 sec\n",
      "Time for epoch 159 is 0.5462696552276611 sec\n",
      "Time for epoch 160 is 0.4880201816558838 sec\n",
      "Time for epoch 161 is 0.43673014640808105 sec\n",
      "Time for epoch 162 is 0.4742851257324219 sec\n",
      "Time for epoch 163 is 0.4328498840332031 sec\n",
      "Time for epoch 164 is 0.5219428539276123 sec\n",
      "Time for epoch 165 is 0.5939769744873047 sec\n",
      "Time for epoch 166 is 0.45967817306518555 sec\n",
      "Time for epoch 167 is 0.4029886722564697 sec\n",
      "Time for epoch 168 is 0.5133323669433594 sec\n",
      "Time for epoch 169 is 0.45122575759887695 sec\n",
      "Time for epoch 170 is 0.4024810791015625 sec\n",
      "Time for epoch 171 is 0.37894463539123535 sec\n",
      "Time for epoch 172 is 0.33284497261047363 sec\n",
      "Time for epoch 173 is 0.4045522212982178 sec\n",
      "Time for epoch 174 is 0.5158305168151855 sec\n",
      "Time for epoch 175 is 0.44733166694641113 sec\n",
      "Time for epoch 176 is 0.5857009887695312 sec\n",
      "Time for epoch 177 is 0.5545766353607178 sec\n",
      "Time for epoch 178 is 0.523944616317749 sec\n",
      "Time for epoch 179 is 0.5269174575805664 sec\n",
      "Time for epoch 180 is 0.6581215858459473 sec\n",
      "Time for epoch 181 is 0.6525883674621582 sec\n",
      "Time for epoch 182 is 0.7514948844909668 sec\n",
      "Time for epoch 183 is 0.6413054466247559 sec\n",
      "Time for epoch 184 is 0.5464086532592773 sec\n",
      "Time for epoch 185 is 0.5861899852752686 sec\n",
      "Time for epoch 186 is 0.5089073181152344 sec\n",
      "Time for epoch 187 is 0.47763991355895996 sec\n",
      "Time for epoch 188 is 0.4302709102630615 sec\n",
      "Time for epoch 189 is 0.4837949275970459 sec\n",
      "Time for epoch 190 is 0.49744272232055664 sec\n",
      "Time for epoch 191 is 0.5960004329681396 sec\n",
      "Time for epoch 192 is 0.4812042713165283 sec\n",
      "Time for epoch 193 is 0.44818544387817383 sec\n",
      "Time for epoch 194 is 0.36206674575805664 sec\n",
      "Time for epoch 195 is 0.5217680931091309 sec\n",
      "Time for epoch 196 is 0.49060821533203125 sec\n",
      "Time for epoch 197 is 0.39951562881469727 sec\n",
      "Time for epoch 198 is 0.3265552520751953 sec\n",
      "Time for epoch 199 is 0.3592031002044678 sec\n",
      "Time for epoch 200 is 0.4218323230743408 sec\n",
      "Time for epoch 201 is 0.3715479373931885 sec\n",
      "Time for epoch 202 is 0.6001174449920654 sec\n",
      "Time for epoch 203 is 0.5455868244171143 sec\n",
      "Time for epoch 204 is 0.535567045211792 sec\n",
      "Time for epoch 205 is 0.5530855655670166 sec\n",
      "Time for epoch 206 is 0.5115342140197754 sec\n",
      "Time for epoch 207 is 0.6405913829803467 sec\n",
      "Time for epoch 208 is 0.6163771152496338 sec\n",
      "Time for epoch 209 is 0.719139814376831 sec\n",
      "Time for epoch 210 is 0.6898207664489746 sec\n",
      "Time for epoch 211 is 0.5340330600738525 sec\n",
      "Time for epoch 212 is 0.5497071743011475 sec\n",
      "Time for epoch 213 is 0.42842936515808105 sec\n",
      "Time for epoch 214 is 0.44392943382263184 sec\n",
      "Time for epoch 215 is 0.4396061897277832 sec\n",
      "Time for epoch 216 is 0.5125141143798828 sec\n",
      "Time for epoch 217 is 0.39098501205444336 sec\n",
      "Time for epoch 218 is 0.5013613700866699 sec\n",
      "Time for epoch 219 is 0.5772078037261963 sec\n",
      "Time for epoch 220 is 0.4385499954223633 sec\n",
      "Time for epoch 221 is 0.32905101776123047 sec\n",
      "Time for epoch 222 is 0.4531266689300537 sec\n",
      "Time for epoch 223 is 0.3830831050872803 sec\n",
      "Time for epoch 224 is 0.2990880012512207 sec\n",
      "Time for epoch 225 is 0.40359973907470703 sec\n",
      "Time for epoch 226 is 0.5034589767456055 sec\n",
      "Time for epoch 227 is 0.4283273220062256 sec\n",
      "Time for epoch 228 is 0.38121771812438965 sec\n",
      "Time for epoch 229 is 0.3817942142486572 sec\n",
      "Time for epoch 230 is 0.5470056533813477 sec\n",
      "Time for epoch 231 is 0.4473445415496826 sec\n",
      "Time for epoch 232 is 0.6331851482391357 sec\n",
      "Time for epoch 233 is 0.5311753749847412 sec\n",
      "Time for epoch 234 is 0.3650650978088379 sec\n",
      "Time for epoch 235 is 0.4880640506744385 sec\n",
      "Time for epoch 236 is 0.4335215091705322 sec\n",
      "Time for epoch 237 is 0.5910439491271973 sec\n",
      "Time for epoch 238 is 0.323711633682251 sec\n",
      "Time for epoch 239 is 0.2649552822113037 sec\n",
      "Time for epoch 240 is 0.46158313751220703 sec\n",
      "Time for epoch 241 is 0.3477060794830322 sec\n",
      "Time for epoch 242 is 0.5564670562744141 sec\n",
      "Time for epoch 243 is 0.4889965057373047 sec\n",
      "Time for epoch 244 is 0.6412665843963623 sec\n",
      "Time for epoch 245 is 0.5165510177612305 sec\n",
      "Time for epoch 246 is 0.5635116100311279 sec\n",
      "Time for epoch 247 is 0.5763425827026367 sec\n",
      "Time for epoch 248 is 0.5673480033874512 sec\n",
      "Time for epoch 249 is 0.4616892337799072 sec\n",
      "Time for epoch 250 is 0.4405031204223633 sec\n",
      "Time for epoch 251 is 0.3461754322052002 sec\n",
      "Time for epoch 252 is 0.33762383460998535 sec\n",
      "Time for epoch 253 is 0.4870026111602783 sec\n",
      "Time for epoch 254 is 0.568190336227417 sec\n",
      "Time for epoch 255 is 0.7267968654632568 sec\n",
      "Time for epoch 256 is 0.7135426998138428 sec\n",
      "Time for epoch 257 is 0.39380383491516113 sec\n",
      "Time for epoch 258 is 0.6346585750579834 sec\n",
      "Time for epoch 259 is 0.44696736335754395 sec\n",
      "Time for epoch 260 is 0.48143458366394043 sec\n",
      "Time for epoch 261 is 0.4063076972961426 sec\n",
      "Time for epoch 262 is 0.2939426898956299 sec\n",
      "Time for epoch 263 is 0.3394138813018799 sec\n",
      "Time for epoch 264 is 0.26759886741638184 sec\n",
      "Time for epoch 265 is 0.2712571620941162 sec\n",
      "Time for epoch 266 is 0.3050844669342041 sec\n",
      "Time for epoch 267 is 0.27579689025878906 sec\n",
      "Time for epoch 268 is 0.25438976287841797 sec\n",
      "Time for epoch 269 is 0.5131709575653076 sec\n",
      "Time for epoch 270 is 0.6027719974517822 sec\n",
      "Time for epoch 271 is 0.34267497062683105 sec\n",
      "Time for epoch 272 is 0.4481539726257324 sec\n",
      "Time for epoch 273 is 0.48384690284729004 sec\n",
      "Time for epoch 274 is 0.4090726375579834 sec\n",
      "Time for epoch 275 is 0.6649653911590576 sec\n",
      "Time for epoch 276 is 0.5696475505828857 sec\n",
      "Time for epoch 277 is 0.6084325313568115 sec\n",
      "Time for epoch 278 is 0.4124882221221924 sec\n",
      "Time for epoch 279 is 0.3901546001434326 sec\n",
      "Time for epoch 280 is 0.31414270401000977 sec\n",
      "Time for epoch 281 is 0.43899989128112793 sec\n",
      "Time for epoch 282 is 0.5890133380889893 sec\n",
      "Time for epoch 283 is 0.4529714584350586 sec\n",
      "Time for epoch 284 is 0.3946969509124756 sec\n",
      "Time for epoch 285 is 0.3578157424926758 sec\n",
      "Time for epoch 286 is 0.3618638515472412 sec\n",
      "Time for epoch 287 is 0.46579670906066895 sec\n",
      "Time for epoch 288 is 0.4311854839324951 sec\n",
      "Time for epoch 289 is 0.7100133895874023 sec\n",
      "Time for epoch 290 is 0.686488151550293 sec\n",
      "Time for epoch 291 is 0.6702795028686523 sec\n",
      "Time for epoch 292 is 0.5940847396850586 sec\n",
      "Time for epoch 293 is 0.3078951835632324 sec\n",
      "Time for epoch 294 is 0.30101752281188965 sec\n",
      "Time for epoch 295 is 0.456524133682251 sec\n",
      "Time for epoch 296 is 0.41777777671813965 sec\n",
      "Time for epoch 297 is 0.5467469692230225 sec\n",
      "Time for epoch 298 is 0.3668854236602783 sec\n",
      "Time for epoch 299 is 0.33786439895629883 sec\n",
      "Time for epoch 300 is 0.4507629871368408 sec\n",
      "Time for epoch 301 is 0.3060464859008789 sec\n",
      "Time for epoch 302 is 0.3392298221588135 sec\n",
      "Time for epoch 303 is 0.4234335422515869 sec\n",
      "Time for epoch 304 is 0.2426760196685791 sec\n",
      "Time for epoch 305 is 0.26197052001953125 sec\n",
      "Time for epoch 306 is 0.5077362060546875 sec\n",
      "Time for epoch 307 is 0.5562644004821777 sec\n",
      "Time for epoch 308 is 0.5480358600616455 sec\n",
      "Time for epoch 309 is 0.6070201396942139 sec\n",
      "Time for epoch 310 is 0.5947732925415039 sec\n",
      "Time for epoch 311 is 0.32714414596557617 sec\n",
      "Time for epoch 312 is 0.3560962677001953 sec\n",
      "Time for epoch 313 is 0.4472928047180176 sec\n",
      "Time for epoch 314 is 0.45365285873413086 sec\n",
      "Time for epoch 315 is 0.3864905834197998 sec\n",
      "Time for epoch 316 is 0.2610466480255127 sec\n",
      "Time for epoch 317 is 0.29979491233825684 sec\n",
      "Time for epoch 318 is 0.46350526809692383 sec\n",
      "Time for epoch 319 is 0.5175378322601318 sec\n",
      "Time for epoch 320 is 0.4597902297973633 sec\n",
      "Time for epoch 321 is 0.5339746475219727 sec\n",
      "Time for epoch 322 is 0.5782871246337891 sec\n",
      "Time for epoch 323 is 0.6290607452392578 sec\n",
      "Time for epoch 324 is 0.6070210933685303 sec\n",
      "Time for epoch 325 is 0.7919626235961914 sec\n",
      "Time for epoch 326 is 0.7840399742126465 sec\n",
      "Time for epoch 327 is 0.765873908996582 sec\n",
      "Time for epoch 328 is 0.7021021842956543 sec\n",
      "Time for epoch 329 is 0.6461429595947266 sec\n",
      "Time for epoch 330 is 0.7178332805633545 sec\n",
      "Time for epoch 331 is 0.4360983371734619 sec\n",
      "Time for epoch 332 is 0.40634989738464355 sec\n",
      "Time for epoch 333 is 0.439755916595459 sec\n",
      "Time for epoch 334 is 0.5391113758087158 sec\n",
      "Time for epoch 335 is 0.5181519985198975 sec\n",
      "Time for epoch 336 is 0.5853927135467529 sec\n",
      "Time for epoch 337 is 0.3643338680267334 sec\n",
      "Time for epoch 338 is 0.46027183532714844 sec\n",
      "Time for epoch 339 is 0.29058218002319336 sec\n",
      "Time for epoch 340 is 0.5449426174163818 sec\n",
      "Time for epoch 341 is 0.6185150146484375 sec\n",
      "Time for epoch 342 is 0.5960538387298584 sec\n",
      "Time for epoch 343 is 0.46589016914367676 sec\n",
      "Time for epoch 344 is 0.33935117721557617 sec\n",
      "Time for epoch 345 is 0.5580182075500488 sec\n",
      "Time for epoch 346 is 0.5508999824523926 sec\n",
      "Time for epoch 347 is 0.6320955753326416 sec\n",
      "Time for epoch 348 is 0.6329882144927979 sec\n",
      "Time for epoch 349 is 0.5014102458953857 sec\n",
      "Time for epoch 350 is 0.6165361404418945 sec\n",
      "Time for epoch 351 is 0.6279065608978271 sec\n",
      "Time for epoch 352 is 0.593998908996582 sec\n",
      "Time for epoch 353 is 0.6345968246459961 sec\n",
      "Time for epoch 354 is 0.5247740745544434 sec\n",
      "Time for epoch 355 is 0.605776309967041 sec\n",
      "Time for epoch 356 is 0.5238463878631592 sec\n",
      "Time for epoch 357 is 0.5528788566589355 sec\n",
      "Time for epoch 358 is 0.48980116844177246 sec\n",
      "Time for epoch 359 is 0.6458566188812256 sec\n",
      "Time for epoch 360 is 0.6424453258514404 sec\n",
      "Time for epoch 361 is 0.7063710689544678 sec\n",
      "Time for epoch 362 is 0.4937131404876709 sec\n",
      "Time for epoch 363 is 0.5061929225921631 sec\n",
      "Time for epoch 364 is 0.4896247386932373 sec\n",
      "Time for epoch 365 is 0.5119729042053223 sec\n",
      "Time for epoch 366 is 0.43380141258239746 sec\n",
      "Time for epoch 367 is 0.5904669761657715 sec\n",
      "Time for epoch 368 is 0.9538021087646484 sec\n",
      "Time for epoch 369 is 0.7343754768371582 sec\n",
      "Time for epoch 370 is 0.7143588066101074 sec\n",
      "Time for epoch 371 is 0.7833297252655029 sec\n",
      "Time for epoch 372 is 0.7879374027252197 sec\n",
      "Time for epoch 373 is 0.805849552154541 sec\n",
      "Time for epoch 374 is 0.7497727870941162 sec\n",
      "Time for epoch 375 is 1.0179810523986816 sec\n",
      "Time for epoch 376 is 1.0667920112609863 sec\n",
      "Time for epoch 377 is 0.5357096195220947 sec\n",
      "Time for epoch 378 is 0.6083705425262451 sec\n",
      "Time for epoch 379 is 0.40323519706726074 sec\n",
      "Time for epoch 380 is 0.6614751815795898 sec\n",
      "Time for epoch 381 is 0.7266404628753662 sec\n",
      "Time for epoch 382 is 0.6196343898773193 sec\n",
      "Time for epoch 383 is 0.7196099758148193 sec\n",
      "Time for epoch 384 is 0.5250325202941895 sec\n",
      "Time for epoch 385 is 0.45843935012817383 sec\n",
      "Time for epoch 386 is 0.4676175117492676 sec\n",
      "Time for epoch 387 is 0.5310583114624023 sec\n",
      "Time for epoch 388 is 0.5535378456115723 sec\n",
      "Time for epoch 389 is 0.5138599872589111 sec\n",
      "Time for epoch 390 is 0.5381443500518799 sec\n",
      "Time for epoch 391 is 0.40436434745788574 sec\n",
      "Time for epoch 392 is 0.46845054626464844 sec\n",
      "Time for epoch 393 is 0.5166382789611816 sec\n",
      "Time for epoch 394 is 0.5834157466888428 sec\n",
      "Time for epoch 395 is 0.38924288749694824 sec\n",
      "Time for epoch 396 is 0.3699455261230469 sec\n",
      "Time for epoch 397 is 0.4376204013824463 sec\n",
      "Time for epoch 398 is 0.39217185974121094 sec\n",
      "Time for epoch 399 is 0.2208261489868164 sec\n",
      "Time for epoch 400 is 0.5947494506835938 sec\n",
      "Time for epoch 401 is 0.5152804851531982 sec\n",
      "Time for epoch 402 is 0.5719914436340332 sec\n",
      "Time for epoch 403 is 0.47742199897766113 sec\n",
      "Time for epoch 404 is 0.6253423690795898 sec\n",
      "Time for epoch 405 is 0.832282543182373 sec\n",
      "Time for epoch 406 is 0.3735935688018799 sec\n",
      "Time for epoch 407 is 0.4560086727142334 sec\n",
      "Time for epoch 408 is 0.5105361938476562 sec\n",
      "Time for epoch 409 is 0.5530519485473633 sec\n",
      "Time for epoch 410 is 0.4954092502593994 sec\n",
      "Time for epoch 411 is 0.40717506408691406 sec\n",
      "Time for epoch 412 is 0.6007936000823975 sec\n",
      "Time for epoch 413 is 0.527026891708374 sec\n",
      "Time for epoch 414 is 0.4440779685974121 sec\n",
      "Time for epoch 415 is 0.6353247165679932 sec\n",
      "Time for epoch 416 is 0.40822744369506836 sec\n",
      "Time for epoch 417 is 0.5443105697631836 sec\n",
      "Time for epoch 418 is 0.6577651500701904 sec\n",
      "Time for epoch 419 is 0.5062501430511475 sec\n",
      "Time for epoch 420 is 0.4768359661102295 sec\n",
      "Time for epoch 421 is 0.39257383346557617 sec\n",
      "Time for epoch 422 is 0.29500579833984375 sec\n",
      "Time for epoch 423 is 0.2699239253997803 sec\n",
      "Time for epoch 424 is 0.6227753162384033 sec\n",
      "Time for epoch 425 is 0.5409691333770752 sec\n",
      "Time for epoch 426 is 0.6342484951019287 sec\n",
      "Time for epoch 427 is 0.6809401512145996 sec\n",
      "Time for epoch 428 is 0.9504964351654053 sec\n",
      "Time for epoch 429 is 0.8837690353393555 sec\n",
      "Time for epoch 430 is 0.7207257747650146 sec\n",
      "Time for epoch 431 is 0.6789371967315674 sec\n",
      "Time for epoch 432 is 0.3326406478881836 sec\n",
      "Time for epoch 433 is 0.29616737365722656 sec\n",
      "Time for epoch 434 is 0.6477823257446289 sec\n",
      "Time for epoch 435 is 0.6350114345550537 sec\n",
      "Time for epoch 436 is 0.6324014663696289 sec\n",
      "Time for epoch 437 is 0.35770201683044434 sec\n",
      "Time for epoch 438 is 0.24736499786376953 sec\n",
      "Time for epoch 439 is 0.29631733894348145 sec\n",
      "Time for epoch 440 is 0.6151762008666992 sec\n",
      "Time for epoch 441 is 0.6001639366149902 sec\n",
      "Time for epoch 442 is 0.41541147232055664 sec\n",
      "Time for epoch 443 is 0.4171421527862549 sec\n",
      "Time for epoch 444 is 0.35774970054626465 sec\n",
      "Time for epoch 445 is 0.5560665130615234 sec\n",
      "Time for epoch 446 is 0.540168046951294 sec\n",
      "Time for epoch 447 is 0.46709513664245605 sec\n",
      "Time for epoch 448 is 0.5862278938293457 sec\n",
      "Time for epoch 449 is 0.5670990943908691 sec\n",
      "Time for epoch 450 is 0.46839356422424316 sec\n",
      "Time for epoch 451 is 0.5012385845184326 sec\n",
      "Time for epoch 452 is 0.4994618892669678 sec\n",
      "Time for epoch 453 is 0.7125914096832275 sec\n",
      "Time for epoch 454 is 0.7922427654266357 sec\n",
      "Time for epoch 455 is 0.655104398727417 sec\n",
      "Time for epoch 456 is 0.6340250968933105 sec\n",
      "Time for epoch 457 is 0.7388882637023926 sec\n",
      "Time for epoch 458 is 0.6314399242401123 sec\n",
      "Time for epoch 459 is 0.7369575500488281 sec\n",
      "Time for epoch 460 is 0.7730922698974609 sec\n",
      "Time for epoch 461 is 0.5420584678649902 sec\n",
      "Time for epoch 462 is 0.42346954345703125 sec\n",
      "Time for epoch 463 is 0.618363618850708 sec\n",
      "Time for epoch 464 is 0.4003608226776123 sec\n",
      "Time for epoch 465 is 0.3923816680908203 sec\n",
      "Time for epoch 466 is 0.5389032363891602 sec\n",
      "Time for epoch 467 is 0.5430195331573486 sec\n",
      "Time for epoch 468 is 0.5469889640808105 sec\n",
      "Time for epoch 469 is 0.7479500770568848 sec\n",
      "Time for epoch 470 is 0.627152681350708 sec\n",
      "Time for epoch 471 is 0.6424863338470459 sec\n",
      "Time for epoch 472 is 0.6737468242645264 sec\n",
      "Time for epoch 473 is 0.6275153160095215 sec\n",
      "Time for epoch 474 is 0.6564760208129883 sec\n",
      "Time for epoch 475 is 0.5190677642822266 sec\n",
      "Time for epoch 476 is 0.5050299167633057 sec\n",
      "Time for epoch 477 is 0.4794490337371826 sec\n",
      "Time for epoch 478 is 0.441591739654541 sec\n",
      "Time for epoch 479 is 0.47431278228759766 sec\n",
      "Time for epoch 480 is 0.5518405437469482 sec\n",
      "Time for epoch 481 is 0.7498748302459717 sec\n",
      "Time for epoch 482 is 0.42112159729003906 sec\n",
      "Time for epoch 483 is 0.54974365234375 sec\n",
      "Time for epoch 484 is 0.5506947040557861 sec\n",
      "Time for epoch 485 is 0.6278557777404785 sec\n",
      "Time for epoch 486 is 0.5539195537567139 sec\n",
      "Time for epoch 487 is 0.56516432762146 sec\n",
      "Time for epoch 488 is 0.5558679103851318 sec\n",
      "Time for epoch 489 is 0.2874906063079834 sec\n",
      "Time for epoch 490 is 0.20515847206115723 sec\n",
      "Time for epoch 491 is 0.2764894962310791 sec\n",
      "Time for epoch 492 is 0.33569908142089844 sec\n",
      "Time for epoch 493 is 0.42363810539245605 sec\n",
      "Time for epoch 494 is 0.23864269256591797 sec\n",
      "Time for epoch 495 is 0.19388246536254883 sec\n",
      "Time for epoch 496 is 0.22470498085021973 sec\n",
      "Time for epoch 497 is 0.4459712505340576 sec\n",
      "Time for epoch 498 is 0.4755384922027588 sec\n",
      "Time for epoch 499 is 0.3724250793457031 sec\n",
      "Time for epoch 500 is 0.3765268325805664 sec\n"
     ]
    }
   ],
   "source": [
    "train(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step\n",
      "[[0.5454503  0.45454973]\n",
      " [0.47031873 0.52968127]\n",
      " [0.54570436 0.45429558]\n",
      " ...\n",
      " [0.49318314 0.50681686]\n",
      " [0.5340632  0.46593684]\n",
      " [0.49426886 0.50573117]]\n",
      "1.0\n",
      "0.993\n",
      "0.139\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([1000, 100])\n",
    "fake_seqs = generator(noise, training=False)\n",
    "\n",
    "prediction = discriminator.predict([fake_seqs[:,:15,:]])\n",
    "print(prediction)\n",
    "\n",
    "over50 = 0\n",
    "over25 = 0\n",
    "over40 = 0\n",
    "total = 0\n",
    "for key, output in enumerate(prediction):\n",
    "    if output[1] > 0.25:\n",
    "        over25 += 1\n",
    "    if output[1] > 0.4:\n",
    "        over40 += 1\n",
    "    if output[1] > 0.5:\n",
    "        over50 += 1\n",
    "    total += 1\n",
    "\n",
    "print(over25 / total)\n",
    "print(over40 / total)\n",
    "print(over50 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
