{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NCx8Mc7DwG",
        "outputId": "38130e6d-f18b-4810-c55f-f9cd2b5801a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "4Ievu6ie7KcN",
        "outputId": "e1fba08c-3461-460d-d194-bbad3bbae0ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5f41e563-5022-405c-b4b8-2676d83420cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5f41e563-5022-405c-b4b8-2676d83420cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bits-740.npy to bits-740.npy\n",
            "Saving blosum-740.npy to blosum-740.npy\n",
            "Saving bpf-740.npy to bpf-740.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Neural Networks:\n",
        "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
        "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
        "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
        "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
        "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
        "from tensorflow.keras.models import (Sequential, Model)\n",
        "\n",
        "# Core:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import interp\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Performance:\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
        "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
        "\n",
        "#Utilities:\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
        "from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "#end-import\n",
        "\n",
        "def lossPlot(results):\n",
        "    plt.title(label='Loss: Training and Validation')\n",
        "    plt.plot(results.history['loss'], label='Training Loss')\n",
        "    plt.plot(results.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def accuracyPlot(results):\n",
        "    plt.title(label='Accuracy: Training and Validation')\n",
        "    plt.plot(results.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def rocPlot(TPR, meanFPR):\n",
        "    plt.plot([0,1], [0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "    meanTPR = np.mean(TPR, axis=0)\n",
        "    meanAUC = auc(meanFPR, meanTPR)\n",
        "    plt.plot(meanFPR, meanTPR, color='blue',\n",
        "            label=r'Mean ROC (AUC = %0.2f )' % (meanAUC),lw=2, alpha=1)\n",
        "\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('ROC-740.png')\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "T = 15 # terminus_length\n",
        "\n",
        "X1 = np.load('bpf-740.npy')\n",
        "X2 = np.load('bits-740.npy')\n",
        "X3 = np.load('blosum-740.npy')\n",
        "\n",
        "\n",
        "X1 = X1[:,0:T,:]\n",
        "X2 = X2[:,0:T,:]\n",
        "X3 = X3[:,0:T,:]\n",
        "\n",
        "\n",
        "Y  = [1 for _ in range(376)]\n",
        "Y += [0 for _ in range(364)]\n",
        "\n",
        "Y = labelEncoding(Y, dtype=int)\n",
        "\n",
        "\n",
        "print(X1.shape)\n",
        "print(X2.shape)\n",
        "print(X3.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "### Model-740\n",
        "\n",
        "def Network():\n",
        "    ### Head-1:\n",
        "    input1 = Input(shape=X1[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.80)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-2:\n",
        "    input2 = Input(shape=X2[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-3:\n",
        "    input3 = Input(shape=X3[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu',)(input3)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head3 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # merge\n",
        "    merge = Concatenate()([head1, head2, head3])\n",
        "\n",
        "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(rate=0.70)(output)\n",
        "\n",
        "    output = Dense(units=2, activation='softmax')(output)\n",
        "\n",
        "    return Model(inputs=[input1, input2, input3], outputs=[output])\n",
        "#end-def\n",
        "\n",
        "model = Network()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model-740.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "setEpochNumber     = 500     # Performed-welled in epoch 600.\n",
        "setBatchSizeNumber = 8\n",
        "####################################################\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=101)\n",
        "\n",
        "Accuracy = []\n",
        "Sensitivity = []\n",
        "Specificity = []\n",
        "Precision = []\n",
        "MCC = []\n",
        "\n",
        "# ROC Curve:\n",
        "fig1 = plt.figure(figsize=[12,12])\n",
        "\n",
        "TPR = []\n",
        "meanFPR = np.linspace(0, 1, 100)\n",
        "\n",
        "i = 1\n",
        "\n",
        "# CM = np.array([\n",
        "#      [0, 0],\n",
        "#      [0, 0],\n",
        "# ], dtype=int)\n",
        "\n",
        "for train, test in cv.split(Y):\n",
        "\n",
        "    # Compile Model:\n",
        "    model = Network()\n",
        "    model.compile(optimizer=Adam(lr=0.005),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Run Model:\n",
        "    results = model.fit(x=[X1[train,:,:], X2[train,:,:], X3[train,:,:]],\n",
        "                        y=Y[train,:],\n",
        "                        validation_data=([X1[test,:,:], X2[test,:,:], X3[test,:,:],], Y[test,:]),\n",
        "                        batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "                        verbose=1,\n",
        "                        callbacks=[])\n",
        "\n",
        "    # Evaluate the Model:\n",
        "    accuracy = model.evaluate(x=[X1[test,:,:], X2[test,:,:], X3[test,:,:]], y=Y[test,:])\n",
        "    Accuracy.append(accuracy[1])\n",
        "\n",
        "    # Performance Metices:\n",
        "    Yactual = Y[test,:].argmax(axis=1)\n",
        "    Yp = model.predict([X1[test,:,:], X2[test,:,:], X3[test,:,:]])\n",
        "    v = Yp\n",
        "    Yp = Yp.argmax(axis=1)\n",
        "\n",
        "    CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "    TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "    MCC.append(matthews_corrcoef(y_true=Yactual, y_pred=Yp))\n",
        "    Sensitivity.append( TP / (TP + FN) )\n",
        "    Specificity.append( TN / (TN + FP) )\n",
        "    Precision.append(precision_score(y_true=Yactual, y_pred=Yp))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(Yactual, v[:,1])\n",
        "    TPR.append(interp(meanFPR, fpr, tpr))\n",
        "    rocauc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, rocauc))\n",
        "    i= i+1\n",
        "\n",
        "    # # Performance Plot\n",
        "    # print('#################################################')\n",
        "    # print('Fold\\'s Accuracy: {:.2f}'.format(accuracy[1]*100.0))\n",
        "    # lossPlot(results)\n",
        "    # accuracyPlot(results)\n",
        "    # print('#################################################')\n",
        "\n",
        "#end-for\n",
        "\n",
        "rocPlot(TPR, meanFPR)\n",
        "\n",
        "print(Accuracy)\n",
        "print('Accuracy: {:.2f}'.format(np.sum(Accuracy)/5.0))\n",
        "print('Sensitivity: {0:.4f}'.format(np.sum(Sensitivity)/5.00))\n",
        "print('Specificity: {0:.4f}'.format(np.sum(Specificity)/5.00))\n",
        "print('MCC: {0:.4f}'.format(np.sum(MCC)/5.00))\n",
        "print('Precision: {0:.4f}'.format(np.sum(Precision)/5.00))"
      ],
      "metadata": {
        "id": "_o28L8jW7KnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cbdd10e5-10ed-4c7f-bc02-8e239bbc09f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're using TF-2.15.0.\n",
            "(740, 15, 20)\n",
            "(740, 15, 31)\n",
            "(740, 15, 20)\n",
            "(740, 2)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 15, 31)]             0         []                            \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 15, 20)]             0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 15, 10)               810       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 15, 10)               1250      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 15, 10)               810       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 15, 10)               40        ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 15, 10)               40        ['conv1d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 15, 10)               40        ['conv1d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 15, 10)               0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 15, 10)               0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 15, 10)               0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 15, 8)                248       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 15, 8)                248       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 15, 8)                248       ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 15, 8)                32        ['conv1d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 15, 8)                32        ['conv1d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 15, 8)                32        ['conv1d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 15, 8)                0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 15, 8)                0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 15, 8)                0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 120)                  0         ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 120)                  0         ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 120)                  0         ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 360)                  0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]',           \n",
            "                                                                     'flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 8)                    2888      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 8)                    32        ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 8)                    0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 2)                    18        ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6768 (26.44 KB)\n",
            "Trainable params: 6644 (25.95 KB)\n",
            "Non-trainable params: 124 (496.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 6s 17ms/step - loss: 2.1764 - accuracy: 0.4730 - val_loss: 1.4118 - val_accuracy: 0.5338\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 2.1154 - accuracy: 0.5068 - val_loss: 1.4691 - val_accuracy: 0.5405\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.8443 - accuracy: 0.5270 - val_loss: 1.4510 - val_accuracy: 0.5338\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.7793 - accuracy: 0.5084 - val_loss: 1.3899 - val_accuracy: 0.5405\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.6844 - accuracy: 0.5270 - val_loss: 1.3544 - val_accuracy: 0.5541\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6367 - accuracy: 0.5084 - val_loss: 1.3285 - val_accuracy: 0.5608\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5103 - accuracy: 0.5253 - val_loss: 1.3115 - val_accuracy: 0.5608\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4791 - accuracy: 0.5338 - val_loss: 1.2884 - val_accuracy: 0.5676\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.4083 - accuracy: 0.5220 - val_loss: 1.2641 - val_accuracy: 0.5946\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3403 - accuracy: 0.5389 - val_loss: 1.2451 - val_accuracy: 0.6014\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3357 - accuracy: 0.5270 - val_loss: 1.2340 - val_accuracy: 0.5946\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3259 - accuracy: 0.5270 - val_loss: 1.2256 - val_accuracy: 0.5878\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2928 - accuracy: 0.5118 - val_loss: 1.2120 - val_accuracy: 0.5878\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.2403 - accuracy: 0.5321 - val_loss: 1.1968 - val_accuracy: 0.5878\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2258 - accuracy: 0.5389 - val_loss: 1.1796 - val_accuracy: 0.5878\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1952 - accuracy: 0.5557 - val_loss: 1.1634 - val_accuracy: 0.5946\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1991 - accuracy: 0.5574 - val_loss: 1.1503 - val_accuracy: 0.6081\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1654 - accuracy: 0.5828 - val_loss: 1.1351 - val_accuracy: 0.6014\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1581 - accuracy: 0.5389 - val_loss: 1.1190 - val_accuracy: 0.6014\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1449 - accuracy: 0.5405 - val_loss: 1.1058 - val_accuracy: 0.6081\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0995 - accuracy: 0.6064 - val_loss: 1.0844 - val_accuracy: 0.6351\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1002 - accuracy: 0.5676 - val_loss: 1.0661 - val_accuracy: 0.6486\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0617 - accuracy: 0.6081 - val_loss: 1.0515 - val_accuracy: 0.6419\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0661 - accuracy: 0.5878 - val_loss: 1.0395 - val_accuracy: 0.6284\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.0491 - accuracy: 0.5929 - val_loss: 1.0270 - val_accuracy: 0.6419\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0462 - accuracy: 0.5693 - val_loss: 1.0150 - val_accuracy: 0.6486\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0199 - accuracy: 0.6115 - val_loss: 0.9994 - val_accuracy: 0.6419\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.9988 - accuracy: 0.6199 - val_loss: 0.9821 - val_accuracy: 0.6419\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.9856 - accuracy: 0.5997 - val_loss: 0.9697 - val_accuracy: 0.6419\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.9554 - accuracy: 0.6318 - val_loss: 0.9491 - val_accuracy: 0.6486\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9590 - accuracy: 0.6402 - val_loss: 0.9350 - val_accuracy: 0.6486\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9424 - accuracy: 0.6132 - val_loss: 0.9208 - val_accuracy: 0.6554\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9185 - accuracy: 0.6267 - val_loss: 0.8991 - val_accuracy: 0.6757\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9238 - accuracy: 0.6284 - val_loss: 0.8888 - val_accuracy: 0.6892\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8978 - accuracy: 0.6385 - val_loss: 0.8797 - val_accuracy: 0.6824\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8885 - accuracy: 0.6216 - val_loss: 0.8657 - val_accuracy: 0.6824\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8605 - accuracy: 0.6453 - val_loss: 0.8415 - val_accuracy: 0.7297\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8725 - accuracy: 0.6436 - val_loss: 0.8392 - val_accuracy: 0.7027\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8453 - accuracy: 0.6588 - val_loss: 0.8283 - val_accuracy: 0.6824\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8359 - accuracy: 0.6655 - val_loss: 0.8215 - val_accuracy: 0.6892\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8138 - accuracy: 0.6723 - val_loss: 0.8105 - val_accuracy: 0.6757\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8118 - accuracy: 0.6774 - val_loss: 0.7942 - val_accuracy: 0.7095\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7996 - accuracy: 0.6943 - val_loss: 0.7888 - val_accuracy: 0.7162\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7869 - accuracy: 0.6875 - val_loss: 0.7571 - val_accuracy: 0.7365\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8008 - accuracy: 0.6470 - val_loss: 0.7503 - val_accuracy: 0.7297\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7856 - accuracy: 0.6588 - val_loss: 0.7318 - val_accuracy: 0.7432\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7700 - accuracy: 0.6807 - val_loss: 0.7303 - val_accuracy: 0.7365\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7583 - accuracy: 0.6824 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7345 - accuracy: 0.7061 - val_loss: 0.7113 - val_accuracy: 0.7365\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7608 - accuracy: 0.6723 - val_loss: 0.7131 - val_accuracy: 0.7432\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7364 - accuracy: 0.6926 - val_loss: 0.6923 - val_accuracy: 0.7635\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.7358 - accuracy: 0.6807 - val_loss: 0.6841 - val_accuracy: 0.7770\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7065 - accuracy: 0.7247 - val_loss: 0.6802 - val_accuracy: 0.7365\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7185 - accuracy: 0.7078 - val_loss: 0.6603 - val_accuracy: 0.7770\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6806 - accuracy: 0.7247 - val_loss: 0.6552 - val_accuracy: 0.7703\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7300 - accuracy: 0.6858 - val_loss: 0.6425 - val_accuracy: 0.7838\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6884 - accuracy: 0.7095 - val_loss: 0.6463 - val_accuracy: 0.7703\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6711 - accuracy: 0.7128 - val_loss: 0.6432 - val_accuracy: 0.7703\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.7111 - val_loss: 0.6410 - val_accuracy: 0.7770\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6690 - accuracy: 0.7297 - val_loss: 0.6414 - val_accuracy: 0.7568\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6829 - accuracy: 0.7162 - val_loss: 0.6246 - val_accuracy: 0.7905\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.7196 - val_loss: 0.6317 - val_accuracy: 0.7905\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.7365 - val_loss: 0.6203 - val_accuracy: 0.7838\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6739 - accuracy: 0.7264 - val_loss: 0.6098 - val_accuracy: 0.7838\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.7213 - val_loss: 0.6052 - val_accuracy: 0.7905\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6613 - accuracy: 0.7179 - val_loss: 0.6018 - val_accuracy: 0.7973\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6645 - accuracy: 0.7584 - val_loss: 0.5965 - val_accuracy: 0.7973\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.7382 - val_loss: 0.6006 - val_accuracy: 0.7973\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.7264 - val_loss: 0.6000 - val_accuracy: 0.7838\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6333 - accuracy: 0.7449 - val_loss: 0.6007 - val_accuracy: 0.7973\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.7821 - val_loss: 0.5907 - val_accuracy: 0.7905\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6817 - accuracy: 0.7247 - val_loss: 0.5993 - val_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6506 - accuracy: 0.7399 - val_loss: 0.5995 - val_accuracy: 0.7973\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6095 - accuracy: 0.7703 - val_loss: 0.5974 - val_accuracy: 0.7770\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.7753 - val_loss: 0.5787 - val_accuracy: 0.8041\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6321 - accuracy: 0.7584 - val_loss: 0.5848 - val_accuracy: 0.7838\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.7280 - val_loss: 0.5985 - val_accuracy: 0.7770\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6239 - accuracy: 0.7247 - val_loss: 0.5831 - val_accuracy: 0.7973\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6441 - accuracy: 0.7348 - val_loss: 0.5760 - val_accuracy: 0.7973\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6220 - accuracy: 0.7686 - val_loss: 0.5727 - val_accuracy: 0.7770\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6380 - accuracy: 0.7264 - val_loss: 0.5721 - val_accuracy: 0.8041\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6139 - accuracy: 0.7568 - val_loss: 0.5688 - val_accuracy: 0.7973\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6167 - accuracy: 0.7534 - val_loss: 0.5736 - val_accuracy: 0.8108\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6285 - accuracy: 0.7601 - val_loss: 0.5682 - val_accuracy: 0.8108\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5942 - accuracy: 0.7416 - val_loss: 0.5555 - val_accuracy: 0.8108\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.7534 - val_loss: 0.5525 - val_accuracy: 0.8243\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.7500 - val_loss: 0.5551 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6335 - accuracy: 0.7382 - val_loss: 0.5477 - val_accuracy: 0.8176\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.7483 - val_loss: 0.5376 - val_accuracy: 0.8176\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5977 - accuracy: 0.7720 - val_loss: 0.5374 - val_accuracy: 0.8243\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5943 - accuracy: 0.7517 - val_loss: 0.5245 - val_accuracy: 0.8243\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5751 - accuracy: 0.7635 - val_loss: 0.5249 - val_accuracy: 0.8378\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5818 - accuracy: 0.7787 - val_loss: 0.5298 - val_accuracy: 0.8243\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5803 - accuracy: 0.7703 - val_loss: 0.5254 - val_accuracy: 0.8311\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5737 - accuracy: 0.7855 - val_loss: 0.5329 - val_accuracy: 0.8311\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6054 - accuracy: 0.7584 - val_loss: 0.5375 - val_accuracy: 0.8108\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5542 - accuracy: 0.7821 - val_loss: 0.5396 - val_accuracy: 0.8108\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5850 - accuracy: 0.7551 - val_loss: 0.5371 - val_accuracy: 0.8243\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7770 - val_loss: 0.5310 - val_accuracy: 0.8041\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.7551 - val_loss: 0.5242 - val_accuracy: 0.8311\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6195 - accuracy: 0.7466 - val_loss: 0.5279 - val_accuracy: 0.8041\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.7416 - val_loss: 0.5350 - val_accuracy: 0.8108\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5985 - accuracy: 0.7432 - val_loss: 0.5267 - val_accuracy: 0.8176\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6074 - accuracy: 0.7568 - val_loss: 0.5256 - val_accuracy: 0.7905\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5925 - accuracy: 0.7517 - val_loss: 0.5232 - val_accuracy: 0.8311\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6001 - accuracy: 0.7652 - val_loss: 0.5234 - val_accuracy: 0.8378\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5971 - accuracy: 0.7500 - val_loss: 0.5247 - val_accuracy: 0.8176\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5766 - accuracy: 0.8024 - val_loss: 0.5195 - val_accuracy: 0.8243\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6019 - accuracy: 0.7720 - val_loss: 0.5252 - val_accuracy: 0.8311\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6039 - accuracy: 0.7483 - val_loss: 0.5271 - val_accuracy: 0.7973\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7466 - val_loss: 0.5316 - val_accuracy: 0.8176\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7618 - val_loss: 0.5254 - val_accuracy: 0.8378\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5863 - accuracy: 0.7584 - val_loss: 0.5259 - val_accuracy: 0.8176\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5763 - accuracy: 0.7736 - val_loss: 0.5283 - val_accuracy: 0.8108\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5662 - accuracy: 0.7736 - val_loss: 0.5165 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5774 - accuracy: 0.7618 - val_loss: 0.5209 - val_accuracy: 0.8243\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5781 - accuracy: 0.7787 - val_loss: 0.5325 - val_accuracy: 0.8176\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5897 - accuracy: 0.7584 - val_loss: 0.5329 - val_accuracy: 0.8378\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7956 - val_loss: 0.5252 - val_accuracy: 0.8243\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5592 - accuracy: 0.7804 - val_loss: 0.5447 - val_accuracy: 0.7905\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7872 - val_loss: 0.5277 - val_accuracy: 0.8108\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7838 - val_loss: 0.5283 - val_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.8007 - val_loss: 0.5182 - val_accuracy: 0.8108\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6094 - accuracy: 0.7568 - val_loss: 0.5414 - val_accuracy: 0.8041\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.7905 - val_loss: 0.5331 - val_accuracy: 0.8243\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5721 - accuracy: 0.7770 - val_loss: 0.5285 - val_accuracy: 0.8243\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5503 - accuracy: 0.8041 - val_loss: 0.5237 - val_accuracy: 0.8378\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.8108\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5817 - accuracy: 0.7618 - val_loss: 0.5302 - val_accuracy: 0.8108\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5580 - accuracy: 0.7787 - val_loss: 0.5238 - val_accuracy: 0.8311\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5552 - accuracy: 0.7838 - val_loss: 0.5154 - val_accuracy: 0.8108\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5680 - accuracy: 0.7990 - val_loss: 0.5237 - val_accuracy: 0.7973\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5554 - accuracy: 0.7872 - val_loss: 0.5203 - val_accuracy: 0.8041\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5691 - accuracy: 0.7889 - val_loss: 0.5144 - val_accuracy: 0.8176\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5780 - accuracy: 0.7669 - val_loss: 0.5215 - val_accuracy: 0.8176\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7736 - val_loss: 0.5396 - val_accuracy: 0.7973\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.7669 - val_loss: 0.5340 - val_accuracy: 0.8108\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.8041 - val_loss: 0.5272 - val_accuracy: 0.8041\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5838 - accuracy: 0.7584 - val_loss: 0.5273 - val_accuracy: 0.8176\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5455 - accuracy: 0.7753 - val_loss: 0.5296 - val_accuracy: 0.8176\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.7939 - val_loss: 0.5254 - val_accuracy: 0.8041\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5402 - accuracy: 0.7889 - val_loss: 0.5220 - val_accuracy: 0.8108\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.8108 - val_loss: 0.5136 - val_accuracy: 0.8041\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5566 - accuracy: 0.7838 - val_loss: 0.5032 - val_accuracy: 0.8041\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5684 - accuracy: 0.7855 - val_loss: 0.5091 - val_accuracy: 0.8108\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5481 - accuracy: 0.7821 - val_loss: 0.5204 - val_accuracy: 0.8041\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.7686 - val_loss: 0.5191 - val_accuracy: 0.8041\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.8125 - val_loss: 0.5053 - val_accuracy: 0.8243\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7736 - val_loss: 0.5080 - val_accuracy: 0.8108\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7872 - val_loss: 0.5107 - val_accuracy: 0.8108\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5682 - accuracy: 0.7703 - val_loss: 0.5075 - val_accuracy: 0.8041\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7838 - val_loss: 0.5131 - val_accuracy: 0.7973\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5495 - accuracy: 0.7990 - val_loss: 0.5061 - val_accuracy: 0.8243\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4963 - accuracy: 0.8007 - val_loss: 0.4935 - val_accuracy: 0.8378\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5224 - accuracy: 0.8108 - val_loss: 0.4912 - val_accuracy: 0.8311\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5737 - accuracy: 0.7770 - val_loss: 0.5017 - val_accuracy: 0.8041\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5593 - accuracy: 0.7973 - val_loss: 0.4986 - val_accuracy: 0.8041\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5409 - accuracy: 0.7922 - val_loss: 0.4947 - val_accuracy: 0.8243\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7753 - val_loss: 0.4960 - val_accuracy: 0.8176\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5793 - accuracy: 0.7635 - val_loss: 0.5021 - val_accuracy: 0.8243\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5610 - accuracy: 0.7669 - val_loss: 0.5062 - val_accuracy: 0.8176\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5783 - accuracy: 0.7939 - val_loss: 0.5016 - val_accuracy: 0.8446\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7889 - val_loss: 0.4965 - val_accuracy: 0.8378\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7922 - val_loss: 0.5083 - val_accuracy: 0.8176\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7787 - val_loss: 0.5048 - val_accuracy: 0.8176\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5644 - accuracy: 0.7838 - val_loss: 0.5075 - val_accuracy: 0.8176\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.7855 - val_loss: 0.4938 - val_accuracy: 0.8176\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7787 - val_loss: 0.4957 - val_accuracy: 0.8176\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7990 - val_loss: 0.4943 - val_accuracy: 0.8176\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5010 - accuracy: 0.8193 - val_loss: 0.4888 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7973 - val_loss: 0.5028 - val_accuracy: 0.8108\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5528 - accuracy: 0.7736 - val_loss: 0.5081 - val_accuracy: 0.8176\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5181 - accuracy: 0.7939 - val_loss: 0.5069 - val_accuracy: 0.8176\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.7905 - val_loss: 0.5117 - val_accuracy: 0.8041\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.7821 - val_loss: 0.5068 - val_accuracy: 0.8108\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5237 - accuracy: 0.7872 - val_loss: 0.5084 - val_accuracy: 0.8311\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.7889 - val_loss: 0.5086 - val_accuracy: 0.8176\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.8243 - val_loss: 0.5054 - val_accuracy: 0.8176\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5550 - accuracy: 0.7872 - val_loss: 0.5145 - val_accuracy: 0.8108\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4787 - accuracy: 0.8378 - val_loss: 0.5037 - val_accuracy: 0.8176\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5601 - accuracy: 0.7804 - val_loss: 0.4907 - val_accuracy: 0.8514\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5211 - accuracy: 0.8057 - val_loss: 0.4876 - val_accuracy: 0.8446\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5034 - accuracy: 0.8057 - val_loss: 0.4932 - val_accuracy: 0.8311\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5211 - accuracy: 0.8142 - val_loss: 0.4857 - val_accuracy: 0.8446\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5604 - accuracy: 0.7838 - val_loss: 0.4946 - val_accuracy: 0.8176\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5544 - accuracy: 0.7956 - val_loss: 0.4843 - val_accuracy: 0.8243\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5663 - accuracy: 0.7787 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5011 - accuracy: 0.8311 - val_loss: 0.4823 - val_accuracy: 0.8446\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.7905 - val_loss: 0.4833 - val_accuracy: 0.8378\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7736 - val_loss: 0.5011 - val_accuracy: 0.8243\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6050 - accuracy: 0.7551 - val_loss: 0.5058 - val_accuracy: 0.8243\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 0.7753 - val_loss: 0.5084 - val_accuracy: 0.8311\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.8057 - val_loss: 0.5047 - val_accuracy: 0.8378\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7821 - val_loss: 0.4960 - val_accuracy: 0.8378\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7872 - val_loss: 0.4865 - val_accuracy: 0.8311\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5577 - accuracy: 0.7838 - val_loss: 0.5009 - val_accuracy: 0.8041\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5909 - accuracy: 0.7736 - val_loss: 0.5034 - val_accuracy: 0.8176\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7922 - val_loss: 0.5077 - val_accuracy: 0.8243\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.8108 - val_loss: 0.5164 - val_accuracy: 0.8176\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.8057 - val_loss: 0.5144 - val_accuracy: 0.8311\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7770 - val_loss: 0.5198 - val_accuracy: 0.8108\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7753 - val_loss: 0.5193 - val_accuracy: 0.8176\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.7905 - val_loss: 0.5065 - val_accuracy: 0.8176\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5364 - accuracy: 0.7990 - val_loss: 0.5102 - val_accuracy: 0.8176\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5786 - accuracy: 0.7855 - val_loss: 0.5045 - val_accuracy: 0.8176\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5647 - accuracy: 0.7956 - val_loss: 0.4986 - val_accuracy: 0.8243\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5478 - accuracy: 0.8024 - val_loss: 0.4974 - val_accuracy: 0.8176\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5189 - accuracy: 0.7922 - val_loss: 0.4907 - val_accuracy: 0.8446\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5973 - accuracy: 0.7720 - val_loss: 0.5065 - val_accuracy: 0.8243\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5495 - accuracy: 0.7922 - val_loss: 0.5000 - val_accuracy: 0.8311\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5523 - accuracy: 0.7939 - val_loss: 0.4936 - val_accuracy: 0.8311\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5875 - accuracy: 0.7669 - val_loss: 0.5019 - val_accuracy: 0.8243\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.7669 - val_loss: 0.4894 - val_accuracy: 0.8243\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7787 - val_loss: 0.4912 - val_accuracy: 0.8243\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5800 - accuracy: 0.7787 - val_loss: 0.4982 - val_accuracy: 0.8378\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5480 - accuracy: 0.7635 - val_loss: 0.4900 - val_accuracy: 0.8311\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5500 - accuracy: 0.7720 - val_loss: 0.4985 - val_accuracy: 0.8378\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5418 - accuracy: 0.7720 - val_loss: 0.4952 - val_accuracy: 0.8446\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.8159 - val_loss: 0.4953 - val_accuracy: 0.8446\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7973 - val_loss: 0.4917 - val_accuracy: 0.8446\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.8007 - val_loss: 0.4846 - val_accuracy: 0.8041\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5525 - accuracy: 0.7973 - val_loss: 0.4963 - val_accuracy: 0.7973\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5558 - accuracy: 0.7855 - val_loss: 0.4954 - val_accuracy: 0.8514\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5249 - accuracy: 0.8226 - val_loss: 0.4924 - val_accuracy: 0.8243\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7990 - val_loss: 0.5014 - val_accuracy: 0.8243\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5650 - accuracy: 0.7905 - val_loss: 0.4954 - val_accuracy: 0.8176\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7973 - val_loss: 0.4933 - val_accuracy: 0.8108\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5511 - accuracy: 0.8007 - val_loss: 0.4907 - val_accuracy: 0.8176\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5284 - accuracy: 0.7922 - val_loss: 0.4898 - val_accuracy: 0.8041\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5177 - accuracy: 0.7804 - val_loss: 0.4815 - val_accuracy: 0.8243\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5327 - accuracy: 0.7821 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5403 - accuracy: 0.7956 - val_loss: 0.4893 - val_accuracy: 0.8243\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4925 - accuracy: 0.8345 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5323 - accuracy: 0.8057 - val_loss: 0.4884 - val_accuracy: 0.8243\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.8041 - val_loss: 0.4858 - val_accuracy: 0.8378\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5752 - accuracy: 0.7736 - val_loss: 0.4881 - val_accuracy: 0.8378\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.7990 - val_loss: 0.4949 - val_accuracy: 0.8311\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5401 - accuracy: 0.7905 - val_loss: 0.4908 - val_accuracy: 0.8378\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5652 - accuracy: 0.7872 - val_loss: 0.4893 - val_accuracy: 0.8243\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5090 - accuracy: 0.8226 - val_loss: 0.4962 - val_accuracy: 0.8243\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7703 - val_loss: 0.4998 - val_accuracy: 0.8311\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5353 - accuracy: 0.8024 - val_loss: 0.4884 - val_accuracy: 0.8243\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5605 - accuracy: 0.7804 - val_loss: 0.4897 - val_accuracy: 0.8243\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5344 - accuracy: 0.7855 - val_loss: 0.4894 - val_accuracy: 0.8176\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.8243 - val_loss: 0.4885 - val_accuracy: 0.8243\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.7703 - val_loss: 0.4974 - val_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5434 - accuracy: 0.7889 - val_loss: 0.4910 - val_accuracy: 0.8378\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5277 - accuracy: 0.8091 - val_loss: 0.4882 - val_accuracy: 0.8176\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5380 - accuracy: 0.7855 - val_loss: 0.4951 - val_accuracy: 0.7905\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5006 - accuracy: 0.8277 - val_loss: 0.4849 - val_accuracy: 0.8108\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5651 - accuracy: 0.7703 - val_loss: 0.4905 - val_accuracy: 0.8108\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5155 - accuracy: 0.8226 - val_loss: 0.4926 - val_accuracy: 0.8108\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.8091 - val_loss: 0.4877 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5091 - accuracy: 0.8024 - val_loss: 0.4800 - val_accuracy: 0.8243\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4908 - accuracy: 0.8159 - val_loss: 0.4772 - val_accuracy: 0.8446\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5130 - accuracy: 0.8159 - val_loss: 0.4874 - val_accuracy: 0.8581\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.8226 - val_loss: 0.4997 - val_accuracy: 0.8446\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4843 - accuracy: 0.8277 - val_loss: 0.5052 - val_accuracy: 0.8378\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4967 - accuracy: 0.8024 - val_loss: 0.5044 - val_accuracy: 0.8378\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5187 - accuracy: 0.8074 - val_loss: 0.5052 - val_accuracy: 0.8378\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5179 - accuracy: 0.7956 - val_loss: 0.5017 - val_accuracy: 0.8378\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5346 - accuracy: 0.8007 - val_loss: 0.4934 - val_accuracy: 0.8243\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.8209 - val_loss: 0.5002 - val_accuracy: 0.8108\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5178 - accuracy: 0.8226 - val_loss: 0.5018 - val_accuracy: 0.8176\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.8159 - val_loss: 0.5055 - val_accuracy: 0.8108\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.8057 - val_loss: 0.5010 - val_accuracy: 0.8311\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5072 - accuracy: 0.8226 - val_loss: 0.5002 - val_accuracy: 0.8311\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.8345 - val_loss: 0.4848 - val_accuracy: 0.8311\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5106 - accuracy: 0.8125 - val_loss: 0.4875 - val_accuracy: 0.8446\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4829 - accuracy: 0.8311 - val_loss: 0.4872 - val_accuracy: 0.8243\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.8057 - val_loss: 0.4785 - val_accuracy: 0.8378\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5263 - accuracy: 0.7855 - val_loss: 0.4784 - val_accuracy: 0.8446\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7990 - val_loss: 0.4756 - val_accuracy: 0.8378\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5728 - accuracy: 0.7905 - val_loss: 0.4753 - val_accuracy: 0.8176\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.8395 - val_loss: 0.4706 - val_accuracy: 0.8243\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.8024 - val_loss: 0.4799 - val_accuracy: 0.8446\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5512 - accuracy: 0.7855 - val_loss: 0.4792 - val_accuracy: 0.8378\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.7973 - val_loss: 0.4859 - val_accuracy: 0.8176\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5261 - accuracy: 0.7821 - val_loss: 0.4815 - val_accuracy: 0.8243\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4853 - accuracy: 0.8226 - val_loss: 0.4838 - val_accuracy: 0.8176\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4901 - accuracy: 0.8074 - val_loss: 0.4809 - val_accuracy: 0.8378\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5227 - accuracy: 0.8024 - val_loss: 0.4808 - val_accuracy: 0.8176\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.8294 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5096 - accuracy: 0.8007 - val_loss: 0.4911 - val_accuracy: 0.8243\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5476 - accuracy: 0.7973 - val_loss: 0.4930 - val_accuracy: 0.8243\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8074 - val_loss: 0.4859 - val_accuracy: 0.8108\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5209 - accuracy: 0.8057 - val_loss: 0.4821 - val_accuracy: 0.8176\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5121 - accuracy: 0.8041 - val_loss: 0.4797 - val_accuracy: 0.8378\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4742 - accuracy: 0.8530 - val_loss: 0.4837 - val_accuracy: 0.8243\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5083 - accuracy: 0.8074 - val_loss: 0.4860 - val_accuracy: 0.8176\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5653 - accuracy: 0.7855 - val_loss: 0.4888 - val_accuracy: 0.8243\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.8108 - val_loss: 0.4898 - val_accuracy: 0.8378\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5720 - accuracy: 0.7922 - val_loss: 0.4846 - val_accuracy: 0.8243\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5123 - accuracy: 0.8243 - val_loss: 0.4893 - val_accuracy: 0.8311\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.7973 - val_loss: 0.4917 - val_accuracy: 0.8311\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.8193 - val_loss: 0.4912 - val_accuracy: 0.8311\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8311 - val_loss: 0.4918 - val_accuracy: 0.8176\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.8041 - val_loss: 0.4837 - val_accuracy: 0.8311\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.8159 - val_loss: 0.4816 - val_accuracy: 0.8311\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5240 - accuracy: 0.7905 - val_loss: 0.4849 - val_accuracy: 0.8446\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5352 - accuracy: 0.7855 - val_loss: 0.4758 - val_accuracy: 0.8446\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5422 - accuracy: 0.7922 - val_loss: 0.4767 - val_accuracy: 0.8176\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5576 - accuracy: 0.7922 - val_loss: 0.4724 - val_accuracy: 0.8378\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.8007 - val_loss: 0.4754 - val_accuracy: 0.8378\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5474 - accuracy: 0.8108 - val_loss: 0.4780 - val_accuracy: 0.8446\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5400 - accuracy: 0.8007 - val_loss: 0.4741 - val_accuracy: 0.8311\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5268 - accuracy: 0.7956 - val_loss: 0.4716 - val_accuracy: 0.8581\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5210 - accuracy: 0.8176 - val_loss: 0.4695 - val_accuracy: 0.8378\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5063 - accuracy: 0.8007 - val_loss: 0.4719 - val_accuracy: 0.8446\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5313 - accuracy: 0.7838 - val_loss: 0.4848 - val_accuracy: 0.8243\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7838 - val_loss: 0.4836 - val_accuracy: 0.8311\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5059 - accuracy: 0.7973 - val_loss: 0.4820 - val_accuracy: 0.8378\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.8091 - val_loss: 0.4880 - val_accuracy: 0.8378\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.8193 - val_loss: 0.4945 - val_accuracy: 0.8311\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7990 - val_loss: 0.4850 - val_accuracy: 0.8446\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5288 - accuracy: 0.7838 - val_loss: 0.4916 - val_accuracy: 0.8446\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.8243 - val_loss: 0.4925 - val_accuracy: 0.8446\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5865 - accuracy: 0.7736 - val_loss: 0.4974 - val_accuracy: 0.8311\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5000 - accuracy: 0.8209 - val_loss: 0.5006 - val_accuracy: 0.8243\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4885 - accuracy: 0.8260 - val_loss: 0.4987 - val_accuracy: 0.8243\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8125 - val_loss: 0.4905 - val_accuracy: 0.8446\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.8057 - val_loss: 0.4860 - val_accuracy: 0.8378\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4899 - accuracy: 0.8125 - val_loss: 0.4846 - val_accuracy: 0.8446\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.8125 - val_loss: 0.4823 - val_accuracy: 0.8446\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7939 - val_loss: 0.4781 - val_accuracy: 0.8514\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.8193 - val_loss: 0.4940 - val_accuracy: 0.8243\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.7905 - val_loss: 0.4818 - val_accuracy: 0.8446\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8074 - val_loss: 0.4703 - val_accuracy: 0.8378\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.8091 - val_loss: 0.4729 - val_accuracy: 0.8311\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5262 - accuracy: 0.8125 - val_loss: 0.4761 - val_accuracy: 0.8378\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5354 - accuracy: 0.8057 - val_loss: 0.4783 - val_accuracy: 0.8446\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5199 - accuracy: 0.8057 - val_loss: 0.4740 - val_accuracy: 0.8311\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4997 - accuracy: 0.8243 - val_loss: 0.4702 - val_accuracy: 0.8514\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5038 - accuracy: 0.8074 - val_loss: 0.4733 - val_accuracy: 0.8649\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5067 - accuracy: 0.7990 - val_loss: 0.4707 - val_accuracy: 0.8581\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.8041 - val_loss: 0.4642 - val_accuracy: 0.8514\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.8007 - val_loss: 0.4658 - val_accuracy: 0.8378\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5122 - accuracy: 0.8209 - val_loss: 0.4645 - val_accuracy: 0.8649\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5331 - accuracy: 0.7922 - val_loss: 0.4677 - val_accuracy: 0.8446\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5142 - accuracy: 0.8193 - val_loss: 0.4659 - val_accuracy: 0.8514\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5457 - accuracy: 0.7956 - val_loss: 0.4800 - val_accuracy: 0.8446\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5550 - accuracy: 0.8041 - val_loss: 0.4932 - val_accuracy: 0.8446\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5340 - accuracy: 0.8041 - val_loss: 0.4947 - val_accuracy: 0.8243\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.7990 - val_loss: 0.4970 - val_accuracy: 0.8311\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4753 - accuracy: 0.8361 - val_loss: 0.4899 - val_accuracy: 0.8176\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4675 - accuracy: 0.8260 - val_loss: 0.4784 - val_accuracy: 0.8514\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.8243 - val_loss: 0.4739 - val_accuracy: 0.8514\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4910 - accuracy: 0.8243 - val_loss: 0.4734 - val_accuracy: 0.8378\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5532 - accuracy: 0.7905 - val_loss: 0.4751 - val_accuracy: 0.8378\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.7618 - val_loss: 0.4750 - val_accuracy: 0.8514\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.8176 - val_loss: 0.4780 - val_accuracy: 0.8514\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.7889 - val_loss: 0.4753 - val_accuracy: 0.8378\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.8243 - val_loss: 0.4755 - val_accuracy: 0.8378\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5432 - accuracy: 0.7652 - val_loss: 0.4856 - val_accuracy: 0.8378\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5086 - accuracy: 0.8159 - val_loss: 0.4818 - val_accuracy: 0.8446\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5103 - accuracy: 0.8260 - val_loss: 0.4780 - val_accuracy: 0.8378\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5023 - accuracy: 0.8159 - val_loss: 0.4841 - val_accuracy: 0.8311\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5765 - accuracy: 0.7753 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5531 - accuracy: 0.7939 - val_loss: 0.4941 - val_accuracy: 0.8243\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5221 - accuracy: 0.7990 - val_loss: 0.4874 - val_accuracy: 0.8243\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4913 - accuracy: 0.8345 - val_loss: 0.4804 - val_accuracy: 0.8243\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4687 - accuracy: 0.8446 - val_loss: 0.4806 - val_accuracy: 0.8311\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5494 - accuracy: 0.8041 - val_loss: 0.4839 - val_accuracy: 0.8243\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4771 - accuracy: 0.8243 - val_loss: 0.4915 - val_accuracy: 0.8176\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.8412 - val_loss: 0.4845 - val_accuracy: 0.8108\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5021 - accuracy: 0.8294 - val_loss: 0.4887 - val_accuracy: 0.8243\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5043 - accuracy: 0.7956 - val_loss: 0.4863 - val_accuracy: 0.8176\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5082 - accuracy: 0.8057 - val_loss: 0.4940 - val_accuracy: 0.8176\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5051 - accuracy: 0.8226 - val_loss: 0.4823 - val_accuracy: 0.8176\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6011 - accuracy: 0.7652 - val_loss: 0.4854 - val_accuracy: 0.8378\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7905 - val_loss: 0.4887 - val_accuracy: 0.8243\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.8159 - val_loss: 0.4829 - val_accuracy: 0.8378\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5407 - accuracy: 0.8159 - val_loss: 0.4866 - val_accuracy: 0.8514\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5290 - accuracy: 0.8041 - val_loss: 0.4842 - val_accuracy: 0.8311\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5317 - accuracy: 0.8193 - val_loss: 0.4931 - val_accuracy: 0.8378\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5155 - accuracy: 0.7922 - val_loss: 0.4932 - val_accuracy: 0.8311\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5207 - accuracy: 0.8108 - val_loss: 0.4889 - val_accuracy: 0.8311\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5282 - accuracy: 0.8243 - val_loss: 0.4874 - val_accuracy: 0.8378\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5089 - accuracy: 0.7973 - val_loss: 0.4885 - val_accuracy: 0.8514\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4841 - accuracy: 0.8345 - val_loss: 0.4917 - val_accuracy: 0.8243\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5137 - accuracy: 0.8125 - val_loss: 0.4895 - val_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5268 - accuracy: 0.7973 - val_loss: 0.4831 - val_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5383 - accuracy: 0.8041 - val_loss: 0.4730 - val_accuracy: 0.8378\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5569 - accuracy: 0.8007 - val_loss: 0.4747 - val_accuracy: 0.8378\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8294 - val_loss: 0.4878 - val_accuracy: 0.8378\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.8142 - val_loss: 0.4865 - val_accuracy: 0.8311\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5129 - accuracy: 0.8277 - val_loss: 0.4825 - val_accuracy: 0.8378\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5004 - accuracy: 0.8142 - val_loss: 0.4832 - val_accuracy: 0.8108\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.8260 - val_loss: 0.4847 - val_accuracy: 0.8311\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5077 - accuracy: 0.8125 - val_loss: 0.4763 - val_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5292 - accuracy: 0.7990 - val_loss: 0.4685 - val_accuracy: 0.8243\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8395 - val_loss: 0.4697 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4950 - accuracy: 0.8074 - val_loss: 0.4597 - val_accuracy: 0.8446\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5016 - accuracy: 0.8226 - val_loss: 0.4597 - val_accuracy: 0.8243\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4784 - accuracy: 0.8125 - val_loss: 0.4715 - val_accuracy: 0.8378\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4908 - accuracy: 0.7956 - val_loss: 0.4760 - val_accuracy: 0.8243\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.7939 - val_loss: 0.4750 - val_accuracy: 0.8378\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.8041 - val_loss: 0.4836 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5068 - accuracy: 0.8057 - val_loss: 0.4863 - val_accuracy: 0.8243\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5548 - accuracy: 0.7787 - val_loss: 0.4848 - val_accuracy: 0.8446\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5064 - accuracy: 0.7973 - val_loss: 0.4836 - val_accuracy: 0.8378\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4881 - accuracy: 0.8125 - val_loss: 0.4773 - val_accuracy: 0.8514\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5459 - accuracy: 0.8024 - val_loss: 0.4781 - val_accuracy: 0.8378\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5093 - accuracy: 0.8024 - val_loss: 0.4831 - val_accuracy: 0.8176\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4760 - accuracy: 0.8226 - val_loss: 0.4822 - val_accuracy: 0.8446\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5095 - accuracy: 0.8041 - val_loss: 0.4769 - val_accuracy: 0.8446\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4948 - accuracy: 0.8209 - val_loss: 0.4674 - val_accuracy: 0.8581\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4787 - accuracy: 0.8193 - val_loss: 0.4623 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.7990 - val_loss: 0.4751 - val_accuracy: 0.8446\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5735 - accuracy: 0.7939 - val_loss: 0.4799 - val_accuracy: 0.8311\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4890 - accuracy: 0.8209 - val_loss: 0.4859 - val_accuracy: 0.8108\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.8378 - val_loss: 0.4805 - val_accuracy: 0.8378\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5180 - accuracy: 0.8108 - val_loss: 0.4880 - val_accuracy: 0.8108\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5454 - accuracy: 0.7905 - val_loss: 0.4794 - val_accuracy: 0.8108\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4889 - accuracy: 0.8226 - val_loss: 0.4831 - val_accuracy: 0.8243\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7753 - val_loss: 0.4863 - val_accuracy: 0.8243\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5161 - accuracy: 0.8159 - val_loss: 0.4943 - val_accuracy: 0.8108\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4849 - accuracy: 0.8226 - val_loss: 0.4850 - val_accuracy: 0.8311\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5283 - accuracy: 0.7905 - val_loss: 0.4738 - val_accuracy: 0.8378\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5467 - accuracy: 0.7905 - val_loss: 0.4749 - val_accuracy: 0.8311\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4730 - accuracy: 0.8277 - val_loss: 0.4748 - val_accuracy: 0.8311\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5254 - accuracy: 0.8041 - val_loss: 0.4925 - val_accuracy: 0.8176\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4840 - accuracy: 0.8176 - val_loss: 0.4856 - val_accuracy: 0.8176\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.8193 - val_loss: 0.4814 - val_accuracy: 0.8311\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5011 - accuracy: 0.8209 - val_loss: 0.4872 - val_accuracy: 0.8108\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5334 - accuracy: 0.8074 - val_loss: 0.4869 - val_accuracy: 0.8243\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4679 - accuracy: 0.8243 - val_loss: 0.4723 - val_accuracy: 0.8378\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5058 - accuracy: 0.8024 - val_loss: 0.4741 - val_accuracy: 0.8378\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5132 - accuracy: 0.7990 - val_loss: 0.4702 - val_accuracy: 0.8378\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5319 - accuracy: 0.7939 - val_loss: 0.4687 - val_accuracy: 0.8311\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4887 - accuracy: 0.7990 - val_loss: 0.4765 - val_accuracy: 0.8514\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.7855 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5411 - accuracy: 0.7838 - val_loss: 0.4904 - val_accuracy: 0.8378\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.8057 - val_loss: 0.4799 - val_accuracy: 0.8176\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5136 - accuracy: 0.8243 - val_loss: 0.4722 - val_accuracy: 0.8311\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5052 - accuracy: 0.8074 - val_loss: 0.4813 - val_accuracy: 0.8311\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5433 - accuracy: 0.8193 - val_loss: 0.4762 - val_accuracy: 0.8311\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5096 - accuracy: 0.7889 - val_loss: 0.4772 - val_accuracy: 0.8378\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.8361 - val_loss: 0.4659 - val_accuracy: 0.8378\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5468 - accuracy: 0.7787 - val_loss: 0.4823 - val_accuracy: 0.8311\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4943 - accuracy: 0.8159 - val_loss: 0.4866 - val_accuracy: 0.8378\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5178 - accuracy: 0.8024 - val_loss: 0.4923 - val_accuracy: 0.8311\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5244 - accuracy: 0.7990 - val_loss: 0.4884 - val_accuracy: 0.8378\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5635 - accuracy: 0.7990 - val_loss: 0.4784 - val_accuracy: 0.8514\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5292 - accuracy: 0.8007 - val_loss: 0.4777 - val_accuracy: 0.8378\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4953 - accuracy: 0.8159 - val_loss: 0.4819 - val_accuracy: 0.8243\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5336 - accuracy: 0.7838 - val_loss: 0.4782 - val_accuracy: 0.8446\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5028 - accuracy: 0.7973 - val_loss: 0.4730 - val_accuracy: 0.8446\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4816 - accuracy: 0.8176 - val_loss: 0.4797 - val_accuracy: 0.8378\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5247 - accuracy: 0.8007 - val_loss: 0.4795 - val_accuracy: 0.8311\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5155 - accuracy: 0.7872 - val_loss: 0.4872 - val_accuracy: 0.8311\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4950 - accuracy: 0.8108 - val_loss: 0.4809 - val_accuracy: 0.8378\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5077 - accuracy: 0.7939 - val_loss: 0.4753 - val_accuracy: 0.8446\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5163 - accuracy: 0.8024 - val_loss: 0.4680 - val_accuracy: 0.8446\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4971 - accuracy: 0.8226 - val_loss: 0.4666 - val_accuracy: 0.8311\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4858 - accuracy: 0.8209 - val_loss: 0.4756 - val_accuracy: 0.8176\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5249 - accuracy: 0.8074 - val_loss: 0.4830 - val_accuracy: 0.8311\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4947 - accuracy: 0.8091 - val_loss: 0.4732 - val_accuracy: 0.8243\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4901 - accuracy: 0.8243 - val_loss: 0.4739 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.8125 - val_loss: 0.4682 - val_accuracy: 0.8176\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4798 - accuracy: 0.8277 - val_loss: 0.4666 - val_accuracy: 0.8311\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4935 - accuracy: 0.8159 - val_loss: 0.4651 - val_accuracy: 0.8446\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5091 - accuracy: 0.8057 - val_loss: 0.4602 - val_accuracy: 0.8446\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4648 - accuracy: 0.8378 - val_loss: 0.4565 - val_accuracy: 0.8446\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4522 - accuracy: 0.8378 - val_loss: 0.4628 - val_accuracy: 0.8378\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.8226 - val_loss: 0.4625 - val_accuracy: 0.8581\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5048 - accuracy: 0.8024 - val_loss: 0.4720 - val_accuracy: 0.8514\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4544 - accuracy: 0.8497 - val_loss: 0.4783 - val_accuracy: 0.8378\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4767 - accuracy: 0.8125 - val_loss: 0.4851 - val_accuracy: 0.8176\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5025 - accuracy: 0.8142 - val_loss: 0.4811 - val_accuracy: 0.8378\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4633 - accuracy: 0.8159 - val_loss: 0.4880 - val_accuracy: 0.8378\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5342 - accuracy: 0.8142 - val_loss: 0.4801 - val_accuracy: 0.8378\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5012 - accuracy: 0.8142 - val_loss: 0.4781 - val_accuracy: 0.8514\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5657 - accuracy: 0.7652 - val_loss: 0.4794 - val_accuracy: 0.8378\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5073 - accuracy: 0.8057 - val_loss: 0.4812 - val_accuracy: 0.8378\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.4613 - accuracy: 0.8564 - val_loss: 0.4860 - val_accuracy: 0.8311\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5161 - accuracy: 0.8024 - val_loss: 0.4770 - val_accuracy: 0.8514\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4978 - accuracy: 0.8142 - val_loss: 0.4827 - val_accuracy: 0.8446\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5090 - accuracy: 0.8041 - val_loss: 0.4901 - val_accuracy: 0.8446\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.8108 - val_loss: 0.4946 - val_accuracy: 0.8311\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4648 - accuracy: 0.8057 - val_loss: 0.4922 - val_accuracy: 0.8176\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4950 - accuracy: 0.8328 - val_loss: 0.4806 - val_accuracy: 0.8311\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5165 - accuracy: 0.7872 - val_loss: 0.4827 - val_accuracy: 0.8108\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5211 - accuracy: 0.8159 - val_loss: 0.4864 - val_accuracy: 0.8176\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.8057 - val_loss: 0.4817 - val_accuracy: 0.8311\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5064 - accuracy: 0.8091 - val_loss: 0.4876 - val_accuracy: 0.8176\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5396 - accuracy: 0.7855 - val_loss: 0.4864 - val_accuracy: 0.8311\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5673 - accuracy: 0.7838 - val_loss: 0.4974 - val_accuracy: 0.8108\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5414 - accuracy: 0.7838 - val_loss: 0.4924 - val_accuracy: 0.8311\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.8091 - val_loss: 0.4814 - val_accuracy: 0.8311\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5040 - accuracy: 0.8226 - val_loss: 0.4793 - val_accuracy: 0.8311\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4856 - accuracy: 0.8446 - val_loss: 0.4758 - val_accuracy: 0.8243\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4960 - accuracy: 0.8091 - val_loss: 0.4774 - val_accuracy: 0.8311\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5434 - accuracy: 0.7922 - val_loss: 0.4820 - val_accuracy: 0.8243\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5395 - accuracy: 0.8142 - val_loss: 0.4831 - val_accuracy: 0.8243\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5321 - accuracy: 0.7956 - val_loss: 0.4724 - val_accuracy: 0.8311\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5073 - accuracy: 0.7990 - val_loss: 0.4741 - val_accuracy: 0.8311\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5339 - accuracy: 0.8057 - val_loss: 0.4772 - val_accuracy: 0.8311\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5222 - accuracy: 0.8125 - val_loss: 0.4786 - val_accuracy: 0.8311\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5179 - accuracy: 0.7872 - val_loss: 0.4762 - val_accuracy: 0.8446\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8446\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bb6f49edcfc3>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 5s 12ms/step - loss: 2.1545 - accuracy: 0.5017 - val_loss: 1.3693 - val_accuracy: 0.5203\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.8317 - accuracy: 0.5287 - val_loss: 1.3739 - val_accuracy: 0.4932\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.7290 - accuracy: 0.5253 - val_loss: 1.3611 - val_accuracy: 0.4730\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.6387 - accuracy: 0.5068 - val_loss: 1.3469 - val_accuracy: 0.4797\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.6059 - accuracy: 0.5118 - val_loss: 1.3284 - val_accuracy: 0.5405\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.5014 - accuracy: 0.5422 - val_loss: 1.3160 - val_accuracy: 0.5270\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.4988 - accuracy: 0.5118 - val_loss: 1.3010 - val_accuracy: 0.5338\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.4247 - accuracy: 0.5389 - val_loss: 1.2875 - val_accuracy: 0.5338\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.3883 - accuracy: 0.5152 - val_loss: 1.2745 - val_accuracy: 0.5338\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.3681 - accuracy: 0.5118 - val_loss: 1.2629 - val_accuracy: 0.5405\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3407 - accuracy: 0.5220 - val_loss: 1.2479 - val_accuracy: 0.5473\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2767 - accuracy: 0.5422 - val_loss: 1.2360 - val_accuracy: 0.5135\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2404 - accuracy: 0.5760 - val_loss: 1.2219 - val_accuracy: 0.5203\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 1.2335 - accuracy: 0.5389 - val_loss: 1.2088 - val_accuracy: 0.5000\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2066 - accuracy: 0.5507 - val_loss: 1.1914 - val_accuracy: 0.5270\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2016 - accuracy: 0.5524 - val_loss: 1.1767 - val_accuracy: 0.5270\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1769 - accuracy: 0.5524 - val_loss: 1.1632 - val_accuracy: 0.5068\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1466 - accuracy: 0.5709 - val_loss: 1.1483 - val_accuracy: 0.5068\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1346 - accuracy: 0.5608 - val_loss: 1.1316 - val_accuracy: 0.5135\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1273 - accuracy: 0.5456 - val_loss: 1.1157 - val_accuracy: 0.5203\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1006 - accuracy: 0.5557 - val_loss: 1.1002 - val_accuracy: 0.5338\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0853 - accuracy: 0.5777 - val_loss: 1.0830 - val_accuracy: 0.5676\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0882 - accuracy: 0.5439 - val_loss: 1.0670 - val_accuracy: 0.5743\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0410 - accuracy: 0.6182 - val_loss: 1.0502 - val_accuracy: 0.5676\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0195 - accuracy: 0.5946 - val_loss: 1.0224 - val_accuracy: 0.5946\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.0238 - accuracy: 0.5828 - val_loss: 1.0140 - val_accuracy: 0.6014\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.0112 - accuracy: 0.5608 - val_loss: 0.9945 - val_accuracy: 0.6216\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9758 - accuracy: 0.6064 - val_loss: 0.9857 - val_accuracy: 0.5743\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9682 - accuracy: 0.5997 - val_loss: 0.9660 - val_accuracy: 0.6014\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9573 - accuracy: 0.6030 - val_loss: 0.9473 - val_accuracy: 0.6486\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9125 - accuracy: 0.6402 - val_loss: 0.9215 - val_accuracy: 0.6622\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.9234 - accuracy: 0.6233 - val_loss: 0.9105 - val_accuracy: 0.6554\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9318 - accuracy: 0.6030 - val_loss: 0.8871 - val_accuracy: 0.6824\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9048 - accuracy: 0.6216 - val_loss: 0.8634 - val_accuracy: 0.7297\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.8676 - accuracy: 0.6318 - val_loss: 0.8441 - val_accuracy: 0.7095\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8721 - accuracy: 0.6402 - val_loss: 0.8426 - val_accuracy: 0.7297\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8536 - accuracy: 0.6436 - val_loss: 0.8351 - val_accuracy: 0.7230\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8524 - accuracy: 0.6486 - val_loss: 0.8209 - val_accuracy: 0.7230\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8260 - accuracy: 0.6605 - val_loss: 0.8153 - val_accuracy: 0.7095\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8348 - accuracy: 0.6351 - val_loss: 0.8013 - val_accuracy: 0.7095\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7890 - accuracy: 0.6655 - val_loss: 0.7782 - val_accuracy: 0.7297\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8138 - accuracy: 0.6436 - val_loss: 0.7777 - val_accuracy: 0.7230\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8011 - accuracy: 0.6858 - val_loss: 0.7543 - val_accuracy: 0.7568\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7906 - accuracy: 0.6453 - val_loss: 0.7478 - val_accuracy: 0.7500\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7835 - accuracy: 0.6774 - val_loss: 0.7551 - val_accuracy: 0.7162\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7761 - accuracy: 0.6672 - val_loss: 0.7419 - val_accuracy: 0.7297\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7575 - accuracy: 0.6976 - val_loss: 0.7401 - val_accuracy: 0.7162\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7312 - accuracy: 0.7061 - val_loss: 0.6940 - val_accuracy: 0.7703\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7334 - accuracy: 0.6926 - val_loss: 0.6825 - val_accuracy: 0.7500\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7276 - accuracy: 0.6943 - val_loss: 0.6686 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7320 - accuracy: 0.7061 - val_loss: 0.6596 - val_accuracy: 0.7905\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7531 - accuracy: 0.6824 - val_loss: 0.6715 - val_accuracy: 0.7500\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7264 - accuracy: 0.6993 - val_loss: 0.6822 - val_accuracy: 0.7432\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7085 - accuracy: 0.7010 - val_loss: 0.6823 - val_accuracy: 0.7230\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7323 - accuracy: 0.6993 - val_loss: 0.6671 - val_accuracy: 0.7297\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7057 - accuracy: 0.7162 - val_loss: 0.6451 - val_accuracy: 0.7635\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7091 - accuracy: 0.6993 - val_loss: 0.6545 - val_accuracy: 0.7365\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6895 - accuracy: 0.7095 - val_loss: 0.6639 - val_accuracy: 0.7432\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6534 - accuracy: 0.7449 - val_loss: 0.6476 - val_accuracy: 0.7500\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6896 - accuracy: 0.7128 - val_loss: 0.6367 - val_accuracy: 0.7432\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.7247 - val_loss: 0.6341 - val_accuracy: 0.7568\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.7044 - val_loss: 0.6189 - val_accuracy: 0.7568\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6815 - accuracy: 0.7280 - val_loss: 0.6170 - val_accuracy: 0.7770\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.7382 - val_loss: 0.6318 - val_accuracy: 0.7297\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6680 - accuracy: 0.7162 - val_loss: 0.6347 - val_accuracy: 0.7230\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6567 - accuracy: 0.7416 - val_loss: 0.6236 - val_accuracy: 0.7365\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.7449 - val_loss: 0.6302 - val_accuracy: 0.7297\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6250 - accuracy: 0.7517 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6518 - accuracy: 0.7466 - val_loss: 0.6004 - val_accuracy: 0.7568\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.7213 - val_loss: 0.6079 - val_accuracy: 0.7635\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6317 - accuracy: 0.7382 - val_loss: 0.5851 - val_accuracy: 0.7770\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6356 - accuracy: 0.7568 - val_loss: 0.5825 - val_accuracy: 0.7703\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6432 - accuracy: 0.7230 - val_loss: 0.6172 - val_accuracy: 0.7500\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6470 - accuracy: 0.7348 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6039 - accuracy: 0.7635 - val_loss: 0.5762 - val_accuracy: 0.7838\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6362 - accuracy: 0.7382 - val_loss: 0.5659 - val_accuracy: 0.8041\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6281 - accuracy: 0.7601 - val_loss: 0.5712 - val_accuracy: 0.8041\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6322 - accuracy: 0.7517 - val_loss: 0.5855 - val_accuracy: 0.7838\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6153 - accuracy: 0.7551 - val_loss: 0.5844 - val_accuracy: 0.7838\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6291 - accuracy: 0.7551 - val_loss: 0.5736 - val_accuracy: 0.7635\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5939 - accuracy: 0.7804 - val_loss: 0.5544 - val_accuracy: 0.8041\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5971 - accuracy: 0.7500 - val_loss: 0.5491 - val_accuracy: 0.7770\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6426 - accuracy: 0.7348 - val_loss: 0.5458 - val_accuracy: 0.7838\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6112 - accuracy: 0.7466 - val_loss: 0.5463 - val_accuracy: 0.8108\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6258 - accuracy: 0.7432 - val_loss: 0.5800 - val_accuracy: 0.7635\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7635 - val_loss: 0.5454 - val_accuracy: 0.7973\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6012 - accuracy: 0.7449 - val_loss: 0.5460 - val_accuracy: 0.7905\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6392 - accuracy: 0.7584 - val_loss: 0.5526 - val_accuracy: 0.7770\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6097 - accuracy: 0.7787 - val_loss: 0.5612 - val_accuracy: 0.7635\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6524 - accuracy: 0.7314 - val_loss: 0.5639 - val_accuracy: 0.7568\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.7720 - val_loss: 0.5621 - val_accuracy: 0.7770\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5987 - accuracy: 0.7669 - val_loss: 0.5586 - val_accuracy: 0.7770\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.7905 - val_loss: 0.5526 - val_accuracy: 0.7838\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5994 - accuracy: 0.7466 - val_loss: 0.5461 - val_accuracy: 0.7905\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7568 - val_loss: 0.5523 - val_accuracy: 0.7838\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5948 - accuracy: 0.7584 - val_loss: 0.5399 - val_accuracy: 0.8041\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.7601 - val_loss: 0.5156 - val_accuracy: 0.8176\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.7635 - val_loss: 0.5125 - val_accuracy: 0.8108\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6061 - accuracy: 0.7517 - val_loss: 0.5227 - val_accuracy: 0.8108\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6254 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.8041\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5833 - accuracy: 0.7686 - val_loss: 0.5269 - val_accuracy: 0.7973\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.7821 - val_loss: 0.5365 - val_accuracy: 0.8176\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5852 - accuracy: 0.7720 - val_loss: 0.5488 - val_accuracy: 0.8041\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6088 - accuracy: 0.7753 - val_loss: 0.5334 - val_accuracy: 0.8378\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7551 - val_loss: 0.5460 - val_accuracy: 0.7973\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5766 - accuracy: 0.7838 - val_loss: 0.6114 - val_accuracy: 0.7365\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5693 - accuracy: 0.7905 - val_loss: 0.5399 - val_accuracy: 0.7905\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5940 - accuracy: 0.7618 - val_loss: 0.5181 - val_accuracy: 0.8243\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5857 - accuracy: 0.7652 - val_loss: 0.5022 - val_accuracy: 0.8243\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.6091 - accuracy: 0.7652 - val_loss: 0.5169 - val_accuracy: 0.8176\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5443 - accuracy: 0.7855 - val_loss: 0.5005 - val_accuracy: 0.8311\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7686 - val_loss: 0.5084 - val_accuracy: 0.8243\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7838 - val_loss: 0.5019 - val_accuracy: 0.8446\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.7568 - val_loss: 0.5184 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7635 - val_loss: 0.5239 - val_accuracy: 0.7973\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.7889 - val_loss: 0.5207 - val_accuracy: 0.8176\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6392 - accuracy: 0.7483 - val_loss: 0.5198 - val_accuracy: 0.8108\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5790 - accuracy: 0.7787 - val_loss: 0.5288 - val_accuracy: 0.7973\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5633 - accuracy: 0.7855 - val_loss: 0.5117 - val_accuracy: 0.8243\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5910 - accuracy: 0.7669 - val_loss: 0.5356 - val_accuracy: 0.8041\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.7466 - val_loss: 0.5455 - val_accuracy: 0.7973\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5997 - accuracy: 0.7855 - val_loss: 0.5399 - val_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5832 - accuracy: 0.7584 - val_loss: 0.5154 - val_accuracy: 0.8243\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5458 - accuracy: 0.8007 - val_loss: 0.5165 - val_accuracy: 0.8176\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5862 - accuracy: 0.7652 - val_loss: 0.5230 - val_accuracy: 0.8108\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5722 - accuracy: 0.7939 - val_loss: 0.5119 - val_accuracy: 0.8108\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5802 - accuracy: 0.7922 - val_loss: 0.5136 - val_accuracy: 0.8243\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5920 - accuracy: 0.7669 - val_loss: 0.5225 - val_accuracy: 0.8176\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5805 - accuracy: 0.7821 - val_loss: 0.5165 - val_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5834 - accuracy: 0.7618 - val_loss: 0.5273 - val_accuracy: 0.7905\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5784 - accuracy: 0.7838 - val_loss: 0.5189 - val_accuracy: 0.8041\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5902 - accuracy: 0.7804 - val_loss: 0.5097 - val_accuracy: 0.8041\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5719 - accuracy: 0.7905 - val_loss: 0.5036 - val_accuracy: 0.8176\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5831 - accuracy: 0.7821 - val_loss: 0.4948 - val_accuracy: 0.8378\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5451 - accuracy: 0.7973 - val_loss: 0.5098 - val_accuracy: 0.8176\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5846 - accuracy: 0.7720 - val_loss: 0.4944 - val_accuracy: 0.8311\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5803 - accuracy: 0.7686 - val_loss: 0.5066 - val_accuracy: 0.8041\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5943 - accuracy: 0.7416 - val_loss: 0.5183 - val_accuracy: 0.7973\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.7686 - val_loss: 0.5089 - val_accuracy: 0.8041\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5784 - accuracy: 0.7821 - val_loss: 0.5324 - val_accuracy: 0.8108\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5690 - accuracy: 0.7669 - val_loss: 0.5420 - val_accuracy: 0.8041\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.7770 - val_loss: 0.5618 - val_accuracy: 0.8041\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5581 - accuracy: 0.7872 - val_loss: 0.5280 - val_accuracy: 0.8108\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.7753 - val_loss: 0.5253 - val_accuracy: 0.8108\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7821 - val_loss: 0.5097 - val_accuracy: 0.8243\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.7939 - val_loss: 0.5113 - val_accuracy: 0.8243\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.7939 - val_loss: 0.5007 - val_accuracy: 0.8176\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5343 - accuracy: 0.7905 - val_loss: 0.5111 - val_accuracy: 0.8176\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5678 - accuracy: 0.7669 - val_loss: 0.4820 - val_accuracy: 0.8243\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7669 - val_loss: 0.5029 - val_accuracy: 0.8108\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.7855 - val_loss: 0.5082 - val_accuracy: 0.8041\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7889 - val_loss: 0.4933 - val_accuracy: 0.8176\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7990 - val_loss: 0.4986 - val_accuracy: 0.8243\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5736 - accuracy: 0.7753 - val_loss: 0.4980 - val_accuracy: 0.8243\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5537 - accuracy: 0.7787 - val_loss: 0.4855 - val_accuracy: 0.8378\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7787 - val_loss: 0.5015 - val_accuracy: 0.7973\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6027 - accuracy: 0.7669 - val_loss: 0.5010 - val_accuracy: 0.7973\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5725 - accuracy: 0.7889 - val_loss: 0.5075 - val_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5756 - accuracy: 0.7872 - val_loss: 0.5274 - val_accuracy: 0.8041\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5693 - accuracy: 0.7872 - val_loss: 0.5187 - val_accuracy: 0.8041\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5812 - accuracy: 0.7821 - val_loss: 0.4969 - val_accuracy: 0.8176\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5945 - accuracy: 0.7635 - val_loss: 0.5029 - val_accuracy: 0.8108\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5831 - accuracy: 0.7551 - val_loss: 0.5100 - val_accuracy: 0.8176\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7703 - val_loss: 0.5096 - val_accuracy: 0.8243\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5477 - accuracy: 0.7889 - val_loss: 0.5095 - val_accuracy: 0.8108\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5558 - accuracy: 0.7889 - val_loss: 0.5024 - val_accuracy: 0.8176\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7872 - val_loss: 0.5158 - val_accuracy: 0.7973\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5773 - accuracy: 0.7736 - val_loss: 0.4869 - val_accuracy: 0.8311\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7973 - val_loss: 0.4861 - val_accuracy: 0.8243\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5773 - accuracy: 0.7736 - val_loss: 0.4973 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5916 - accuracy: 0.7669 - val_loss: 0.5021 - val_accuracy: 0.8378\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.8024 - val_loss: 0.5111 - val_accuracy: 0.8041\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 0.7804 - val_loss: 0.4921 - val_accuracy: 0.8311\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7990 - val_loss: 0.4920 - val_accuracy: 0.8311\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5486 - accuracy: 0.7872 - val_loss: 0.4937 - val_accuracy: 0.8243\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5555 - accuracy: 0.7922 - val_loss: 0.4960 - val_accuracy: 0.8108\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5514 - accuracy: 0.7838 - val_loss: 0.5114 - val_accuracy: 0.8108\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7703 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5587 - accuracy: 0.7821 - val_loss: 0.4957 - val_accuracy: 0.8108\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5980 - accuracy: 0.7720 - val_loss: 0.4865 - val_accuracy: 0.8243\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5668 - accuracy: 0.7720 - val_loss: 0.5049 - val_accuracy: 0.8243\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5691 - accuracy: 0.7922 - val_loss: 0.4978 - val_accuracy: 0.8243\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5853 - accuracy: 0.7804 - val_loss: 0.4908 - val_accuracy: 0.8176\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5473 - accuracy: 0.8057 - val_loss: 0.5169 - val_accuracy: 0.8176\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5657 - accuracy: 0.7787 - val_loss: 0.5060 - val_accuracy: 0.8243\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5801 - accuracy: 0.7720 - val_loss: 0.5061 - val_accuracy: 0.8176\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5321 - accuracy: 0.7838 - val_loss: 0.4872 - val_accuracy: 0.8311\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7618 - val_loss: 0.5322 - val_accuracy: 0.7838\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5276 - accuracy: 0.7990 - val_loss: 0.5403 - val_accuracy: 0.7905\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7720 - val_loss: 0.5262 - val_accuracy: 0.8176\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5534 - accuracy: 0.7753 - val_loss: 0.5357 - val_accuracy: 0.8041\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7973 - val_loss: 0.5115 - val_accuracy: 0.8108\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7821 - val_loss: 0.5004 - val_accuracy: 0.8176\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8074 - val_loss: 0.4866 - val_accuracy: 0.8446\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.7889 - val_loss: 0.4941 - val_accuracy: 0.8378\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.8041 - val_loss: 0.4962 - val_accuracy: 0.8311\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7872 - val_loss: 0.4985 - val_accuracy: 0.8243\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6021 - accuracy: 0.7821 - val_loss: 0.5029 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5519 - accuracy: 0.7872 - val_loss: 0.5060 - val_accuracy: 0.8108\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.7855 - val_loss: 0.4986 - val_accuracy: 0.8108\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.7720 - val_loss: 0.5035 - val_accuracy: 0.8176\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.7736 - val_loss: 0.5123 - val_accuracy: 0.8041\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5369 - accuracy: 0.8074 - val_loss: 0.5153 - val_accuracy: 0.7973\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.7973 - val_loss: 0.5034 - val_accuracy: 0.8041\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5424 - accuracy: 0.7821 - val_loss: 0.5155 - val_accuracy: 0.7770\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7568 - val_loss: 0.4889 - val_accuracy: 0.7905\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5329 - accuracy: 0.7939 - val_loss: 0.5166 - val_accuracy: 0.8041\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5697 - accuracy: 0.7652 - val_loss: 0.4957 - val_accuracy: 0.8176\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5646 - accuracy: 0.7956 - val_loss: 0.4953 - val_accuracy: 0.8176\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5583 - accuracy: 0.7872 - val_loss: 0.4845 - val_accuracy: 0.8311\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5766 - accuracy: 0.7753 - val_loss: 0.4734 - val_accuracy: 0.8514\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5661 - accuracy: 0.7770 - val_loss: 0.4802 - val_accuracy: 0.8378\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.7787 - val_loss: 0.4842 - val_accuracy: 0.8243\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7956 - val_loss: 0.4833 - val_accuracy: 0.8311\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5843 - accuracy: 0.7517 - val_loss: 0.4810 - val_accuracy: 0.8176\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7872 - val_loss: 0.4766 - val_accuracy: 0.8041\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5692 - accuracy: 0.7990 - val_loss: 0.4822 - val_accuracy: 0.8108\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5382 - accuracy: 0.7872 - val_loss: 0.4981 - val_accuracy: 0.8041\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5444 - accuracy: 0.7922 - val_loss: 0.5023 - val_accuracy: 0.8176\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7956 - val_loss: 0.5050 - val_accuracy: 0.8108\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5539 - accuracy: 0.7838 - val_loss: 0.5148 - val_accuracy: 0.7973\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.8125 - val_loss: 0.4794 - val_accuracy: 0.7973\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5584 - accuracy: 0.8024 - val_loss: 0.4642 - val_accuracy: 0.8446\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5582 - accuracy: 0.7821 - val_loss: 0.4630 - val_accuracy: 0.8378\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5665 - accuracy: 0.7703 - val_loss: 0.4897 - val_accuracy: 0.8176\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5642 - accuracy: 0.7753 - val_loss: 0.4940 - val_accuracy: 0.8243\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7601 - val_loss: 0.4826 - val_accuracy: 0.8243\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.7889 - val_loss: 0.5348 - val_accuracy: 0.8041\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5357 - accuracy: 0.7922 - val_loss: 0.5244 - val_accuracy: 0.7973\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7635 - val_loss: 0.5110 - val_accuracy: 0.7973\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5591 - accuracy: 0.7905 - val_loss: 0.5179 - val_accuracy: 0.8041\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4987 - accuracy: 0.7905 - val_loss: 0.4996 - val_accuracy: 0.8041\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5542 - accuracy: 0.7922 - val_loss: 0.4969 - val_accuracy: 0.8108\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5372 - accuracy: 0.8074 - val_loss: 0.4971 - val_accuracy: 0.8176\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5188 - accuracy: 0.8007 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5264 - accuracy: 0.7889 - val_loss: 0.4997 - val_accuracy: 0.8041\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5594 - accuracy: 0.7821 - val_loss: 0.5131 - val_accuracy: 0.7973\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.7804 - val_loss: 0.4901 - val_accuracy: 0.8176\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7838 - val_loss: 0.4989 - val_accuracy: 0.7838\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5077 - accuracy: 0.8108 - val_loss: 0.5079 - val_accuracy: 0.7973\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5368 - accuracy: 0.8007 - val_loss: 0.4899 - val_accuracy: 0.8311\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.8159 - val_loss: 0.4999 - val_accuracy: 0.8176\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7990 - val_loss: 0.5060 - val_accuracy: 0.8108\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5696 - accuracy: 0.7872 - val_loss: 0.5061 - val_accuracy: 0.8041\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5650 - accuracy: 0.7770 - val_loss: 0.4995 - val_accuracy: 0.8041\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.8057 - val_loss: 0.4870 - val_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5275 - accuracy: 0.8074 - val_loss: 0.4866 - val_accuracy: 0.8041\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5676 - accuracy: 0.7838 - val_loss: 0.4862 - val_accuracy: 0.8176\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5189 - accuracy: 0.8193 - val_loss: 0.4855 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5076 - accuracy: 0.8193 - val_loss: 0.4778 - val_accuracy: 0.7973\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.8142 - val_loss: 0.4995 - val_accuracy: 0.7973\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.8226 - val_loss: 0.4739 - val_accuracy: 0.8311\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5351 - accuracy: 0.7855 - val_loss: 0.4696 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7956 - val_loss: 0.4767 - val_accuracy: 0.8378\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5224 - accuracy: 0.7973 - val_loss: 0.4697 - val_accuracy: 0.8311\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.8277 - val_loss: 0.4765 - val_accuracy: 0.8108\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5024 - accuracy: 0.8226 - val_loss: 0.4597 - val_accuracy: 0.8311\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5235 - accuracy: 0.8007 - val_loss: 0.4656 - val_accuracy: 0.8378\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5505 - accuracy: 0.7703 - val_loss: 0.4747 - val_accuracy: 0.8243\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5380 - accuracy: 0.8125 - val_loss: 0.4570 - val_accuracy: 0.8581\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5011 - accuracy: 0.8125 - val_loss: 0.4791 - val_accuracy: 0.8176\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5744 - accuracy: 0.7770 - val_loss: 0.4786 - val_accuracy: 0.8108\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5417 - accuracy: 0.7973 - val_loss: 0.4735 - val_accuracy: 0.8176\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.8159 - val_loss: 0.4697 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5549 - accuracy: 0.7939 - val_loss: 0.4781 - val_accuracy: 0.7973\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.7990 - val_loss: 0.4718 - val_accuracy: 0.8108\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5019 - accuracy: 0.7990 - val_loss: 0.4854 - val_accuracy: 0.8041\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7956 - val_loss: 0.4861 - val_accuracy: 0.8176\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5357 - accuracy: 0.7872 - val_loss: 0.4552 - val_accuracy: 0.8378\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5728 - accuracy: 0.7686 - val_loss: 0.4577 - val_accuracy: 0.8176\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8277 - val_loss: 0.4715 - val_accuracy: 0.8176\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.8057 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5671 - accuracy: 0.7838 - val_loss: 0.4775 - val_accuracy: 0.8243\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4948 - accuracy: 0.8159 - val_loss: 0.4745 - val_accuracy: 0.8311\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.7889 - val_loss: 0.4774 - val_accuracy: 0.8108\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.7855 - val_loss: 0.4772 - val_accuracy: 0.8108\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.8007 - val_loss: 0.4712 - val_accuracy: 0.8041\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5270 - accuracy: 0.8108 - val_loss: 0.4892 - val_accuracy: 0.8108\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7990 - val_loss: 0.4644 - val_accuracy: 0.8311\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.8176 - val_loss: 0.4791 - val_accuracy: 0.8041\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.7956 - val_loss: 0.4741 - val_accuracy: 0.7973\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4930 - accuracy: 0.7973 - val_loss: 0.4999 - val_accuracy: 0.7905\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5268 - accuracy: 0.7990 - val_loss: 0.5011 - val_accuracy: 0.8041\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4797 - accuracy: 0.8311 - val_loss: 0.4999 - val_accuracy: 0.7973\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5370 - accuracy: 0.8024 - val_loss: 0.4913 - val_accuracy: 0.7905\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5207 - accuracy: 0.8057 - val_loss: 0.4769 - val_accuracy: 0.8311\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4989 - accuracy: 0.8074 - val_loss: 0.4742 - val_accuracy: 0.8176\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5838 - accuracy: 0.7905 - val_loss: 0.4877 - val_accuracy: 0.8041\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.8074 - val_loss: 0.5011 - val_accuracy: 0.7973\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.7922 - val_loss: 0.5179 - val_accuracy: 0.8041\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.8074 - val_loss: 0.4945 - val_accuracy: 0.8176\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5113 - accuracy: 0.8345 - val_loss: 0.4766 - val_accuracy: 0.8176\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.8091 - val_loss: 0.4768 - val_accuracy: 0.8176\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5718 - accuracy: 0.7787 - val_loss: 0.4709 - val_accuracy: 0.8243\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5382 - accuracy: 0.8007 - val_loss: 0.4729 - val_accuracy: 0.8176\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4879 - accuracy: 0.8429 - val_loss: 0.4690 - val_accuracy: 0.8243\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5063 - accuracy: 0.8395 - val_loss: 0.4737 - val_accuracy: 0.8176\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5474 - accuracy: 0.7905 - val_loss: 0.4725 - val_accuracy: 0.8311\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.8074 - val_loss: 0.4737 - val_accuracy: 0.8243\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.7872 - val_loss: 0.4824 - val_accuracy: 0.8176\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5095 - accuracy: 0.8041 - val_loss: 0.4888 - val_accuracy: 0.8041\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5422 - accuracy: 0.7939 - val_loss: 0.5122 - val_accuracy: 0.8041\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5403 - accuracy: 0.8209 - val_loss: 0.5025 - val_accuracy: 0.8041\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5239 - accuracy: 0.8176 - val_loss: 0.4829 - val_accuracy: 0.8041\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5527 - accuracy: 0.7855 - val_loss: 0.4881 - val_accuracy: 0.8108\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.8209 - val_loss: 0.4806 - val_accuracy: 0.8108\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5395 - accuracy: 0.7838 - val_loss: 0.4937 - val_accuracy: 0.8041\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5370 - accuracy: 0.8007 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5279 - accuracy: 0.7939 - val_loss: 0.4894 - val_accuracy: 0.8108\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5125 - accuracy: 0.7956 - val_loss: 0.4804 - val_accuracy: 0.8378\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4872 - accuracy: 0.8209 - val_loss: 0.4667 - val_accuracy: 0.8243\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5143 - accuracy: 0.8041 - val_loss: 0.4595 - val_accuracy: 0.8311\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.7990 - val_loss: 0.4678 - val_accuracy: 0.8176\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.8209 - val_loss: 0.4921 - val_accuracy: 0.8108\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5280 - accuracy: 0.8057 - val_loss: 0.4748 - val_accuracy: 0.8108\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4683 - accuracy: 0.8463 - val_loss: 0.4781 - val_accuracy: 0.8176\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5365 - accuracy: 0.8142 - val_loss: 0.4848 - val_accuracy: 0.8108\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5233 - accuracy: 0.8142 - val_loss: 0.4561 - val_accuracy: 0.8108\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5158 - accuracy: 0.8209 - val_loss: 0.4634 - val_accuracy: 0.8243\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4913 - accuracy: 0.8108 - val_loss: 0.4761 - val_accuracy: 0.8176\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8176 - val_loss: 0.4626 - val_accuracy: 0.8311\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5444 - accuracy: 0.8108 - val_loss: 0.4744 - val_accuracy: 0.8311\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5263 - accuracy: 0.7990 - val_loss: 0.4640 - val_accuracy: 0.8108\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5539 - accuracy: 0.7753 - val_loss: 0.4597 - val_accuracy: 0.8108\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5567 - accuracy: 0.7956 - val_loss: 0.4708 - val_accuracy: 0.8176\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4647 - accuracy: 0.8581 - val_loss: 0.4691 - val_accuracy: 0.8176\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5210 - accuracy: 0.8057 - val_loss: 0.4711 - val_accuracy: 0.8108\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5150 - accuracy: 0.8193 - val_loss: 0.4641 - val_accuracy: 0.8176\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.8294 - val_loss: 0.4552 - val_accuracy: 0.8378\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5199 - accuracy: 0.7855 - val_loss: 0.4638 - val_accuracy: 0.8243\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5132 - accuracy: 0.7973 - val_loss: 0.4607 - val_accuracy: 0.8243\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4981 - accuracy: 0.8260 - val_loss: 0.4746 - val_accuracy: 0.8108\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5283 - accuracy: 0.7956 - val_loss: 0.4792 - val_accuracy: 0.8041\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5206 - accuracy: 0.8209 - val_loss: 0.4852 - val_accuracy: 0.8108\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5134 - accuracy: 0.8159 - val_loss: 0.4674 - val_accuracy: 0.8176\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4784 - accuracy: 0.8176 - val_loss: 0.4658 - val_accuracy: 0.8243\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.8057 - val_loss: 0.4522 - val_accuracy: 0.8446\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.8328 - val_loss: 0.4567 - val_accuracy: 0.8446\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5573 - accuracy: 0.8057 - val_loss: 0.4696 - val_accuracy: 0.8041\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.8142 - val_loss: 0.4710 - val_accuracy: 0.8041\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.8125 - val_loss: 0.4561 - val_accuracy: 0.8176\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5006 - accuracy: 0.8311 - val_loss: 0.4660 - val_accuracy: 0.8176\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5289 - accuracy: 0.7838 - val_loss: 0.4747 - val_accuracy: 0.8041\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5065 - accuracy: 0.8193 - val_loss: 0.4668 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.7990 - val_loss: 0.4640 - val_accuracy: 0.8041\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.8041 - val_loss: 0.4554 - val_accuracy: 0.8108\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.8007 - val_loss: 0.4588 - val_accuracy: 0.8176\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.8125 - val_loss: 0.4688 - val_accuracy: 0.8311\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7973 - val_loss: 0.4683 - val_accuracy: 0.8108\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.8378 - val_loss: 0.4775 - val_accuracy: 0.7905\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7922 - val_loss: 0.4759 - val_accuracy: 0.7838\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5278 - accuracy: 0.8209 - val_loss: 0.4530 - val_accuracy: 0.8041\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.8378 - val_loss: 0.4487 - val_accuracy: 0.8041\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5388 - accuracy: 0.8041 - val_loss: 0.4395 - val_accuracy: 0.8243\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5106 - accuracy: 0.8041 - val_loss: 0.4514 - val_accuracy: 0.8108\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5481 - accuracy: 0.7889 - val_loss: 0.4531 - val_accuracy: 0.8176\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5028 - accuracy: 0.8193 - val_loss: 0.4568 - val_accuracy: 0.8311\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5565 - accuracy: 0.7736 - val_loss: 0.4577 - val_accuracy: 0.8311\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5289 - accuracy: 0.8125 - val_loss: 0.4670 - val_accuracy: 0.8243\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5239 - accuracy: 0.8125 - val_loss: 0.4668 - val_accuracy: 0.8108\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5231 - accuracy: 0.7838 - val_loss: 0.4524 - val_accuracy: 0.8378\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5911 - accuracy: 0.7804 - val_loss: 0.4754 - val_accuracy: 0.8176\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5505 - accuracy: 0.8159 - val_loss: 0.4731 - val_accuracy: 0.8243\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.8041 - val_loss: 0.4634 - val_accuracy: 0.8108\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4686 - accuracy: 0.8514 - val_loss: 0.4440 - val_accuracy: 0.8243\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5021 - accuracy: 0.8193 - val_loss: 0.4602 - val_accuracy: 0.8243\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7956 - val_loss: 0.4446 - val_accuracy: 0.8378\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4917 - accuracy: 0.8091 - val_loss: 0.4581 - val_accuracy: 0.8243\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4818 - accuracy: 0.8429 - val_loss: 0.4436 - val_accuracy: 0.8243\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.8108 - val_loss: 0.4452 - val_accuracy: 0.8176\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.7922 - val_loss: 0.4602 - val_accuracy: 0.8243\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5005 - accuracy: 0.8176 - val_loss: 0.4532 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5131 - accuracy: 0.7973 - val_loss: 0.4558 - val_accuracy: 0.8108\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5393 - accuracy: 0.8260 - val_loss: 0.4668 - val_accuracy: 0.8108\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5207 - accuracy: 0.7990 - val_loss: 0.4777 - val_accuracy: 0.7973\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5057 - accuracy: 0.8243 - val_loss: 0.4714 - val_accuracy: 0.8108\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.8057 - val_loss: 0.4801 - val_accuracy: 0.8176\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4977 - accuracy: 0.8142 - val_loss: 0.4700 - val_accuracy: 0.8041\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5355 - accuracy: 0.8142 - val_loss: 0.4795 - val_accuracy: 0.8041\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.7973 - val_loss: 0.4641 - val_accuracy: 0.8243\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5264 - accuracy: 0.8007 - val_loss: 0.4604 - val_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5494 - accuracy: 0.8057 - val_loss: 0.4625 - val_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5027 - accuracy: 0.8057 - val_loss: 0.4504 - val_accuracy: 0.8378\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5525 - accuracy: 0.7838 - val_loss: 0.4766 - val_accuracy: 0.8108\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5292 - accuracy: 0.7990 - val_loss: 0.4535 - val_accuracy: 0.8311\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5171 - accuracy: 0.8311 - val_loss: 0.4663 - val_accuracy: 0.8311\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5280 - accuracy: 0.7939 - val_loss: 0.4737 - val_accuracy: 0.7973\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5280 - accuracy: 0.8125 - val_loss: 0.4663 - val_accuracy: 0.8311\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4969 - accuracy: 0.8395 - val_loss: 0.4604 - val_accuracy: 0.8108\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.8243 - val_loss: 0.4747 - val_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.8041 - val_loss: 0.4626 - val_accuracy: 0.8311\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.8057 - val_loss: 0.4571 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7736 - val_loss: 0.4563 - val_accuracy: 0.8446\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.8024 - val_loss: 0.4719 - val_accuracy: 0.8378\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5082 - accuracy: 0.8142 - val_loss: 0.4777 - val_accuracy: 0.8446\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5108 - accuracy: 0.7973 - val_loss: 0.4747 - val_accuracy: 0.8311\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4997 - accuracy: 0.8176 - val_loss: 0.4683 - val_accuracy: 0.8378\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.8209 - val_loss: 0.4685 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.8277 - val_loss: 0.4554 - val_accuracy: 0.8243\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5262 - accuracy: 0.8142 - val_loss: 0.4479 - val_accuracy: 0.8311\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5154 - accuracy: 0.8074 - val_loss: 0.4552 - val_accuracy: 0.8176\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.8226 - val_loss: 0.4651 - val_accuracy: 0.8176\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5446 - accuracy: 0.7939 - val_loss: 0.4617 - val_accuracy: 0.8243\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8226 - val_loss: 0.4633 - val_accuracy: 0.8243\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5543 - accuracy: 0.8091 - val_loss: 0.4572 - val_accuracy: 0.8311\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4830 - accuracy: 0.8176 - val_loss: 0.4619 - val_accuracy: 0.8378\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5105 - accuracy: 0.8041 - val_loss: 0.4656 - val_accuracy: 0.8243\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4947 - accuracy: 0.8142 - val_loss: 0.4672 - val_accuracy: 0.8041\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4384 - accuracy: 0.8277 - val_loss: 0.4656 - val_accuracy: 0.8176\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5109 - accuracy: 0.8159 - val_loss: 0.4615 - val_accuracy: 0.8176\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4975 - accuracy: 0.8328 - val_loss: 0.4532 - val_accuracy: 0.8311\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4940 - accuracy: 0.8125 - val_loss: 0.4650 - val_accuracy: 0.8243\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5250 - accuracy: 0.8057 - val_loss: 0.4606 - val_accuracy: 0.8581\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5057 - accuracy: 0.8193 - val_loss: 0.4666 - val_accuracy: 0.8378\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5246 - accuracy: 0.7889 - val_loss: 0.4706 - val_accuracy: 0.8243\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5144 - accuracy: 0.8108 - val_loss: 0.4755 - val_accuracy: 0.8108\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5119 - accuracy: 0.8125 - val_loss: 0.4746 - val_accuracy: 0.8176\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8260 - val_loss: 0.4691 - val_accuracy: 0.8108\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5140 - accuracy: 0.8074 - val_loss: 0.4493 - val_accuracy: 0.8243\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5071 - accuracy: 0.8294 - val_loss: 0.4513 - val_accuracy: 0.8311\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5141 - accuracy: 0.8057 - val_loss: 0.4583 - val_accuracy: 0.8243\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5174 - accuracy: 0.8193 - val_loss: 0.4705 - val_accuracy: 0.8311\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4886 - accuracy: 0.8243 - val_loss: 0.4694 - val_accuracy: 0.8176\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4944 - accuracy: 0.8142 - val_loss: 0.4738 - val_accuracy: 0.8041\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4868 - accuracy: 0.8378 - val_loss: 0.4769 - val_accuracy: 0.8108\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.8176 - val_loss: 0.4808 - val_accuracy: 0.8108\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4808 - accuracy: 0.8243 - val_loss: 0.4783 - val_accuracy: 0.8108\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4918 - accuracy: 0.8226 - val_loss: 0.4741 - val_accuracy: 0.8108\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5216 - accuracy: 0.8311 - val_loss: 0.4745 - val_accuracy: 0.8176\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.7990 - val_loss: 0.4665 - val_accuracy: 0.8176\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4818 - accuracy: 0.8243 - val_loss: 0.4665 - val_accuracy: 0.8311\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5239 - accuracy: 0.7973 - val_loss: 0.4813 - val_accuracy: 0.8108\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5384 - accuracy: 0.7736 - val_loss: 0.4641 - val_accuracy: 0.8243\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5156 - accuracy: 0.8041 - val_loss: 0.4757 - val_accuracy: 0.7973\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5239 - accuracy: 0.8209 - val_loss: 0.4859 - val_accuracy: 0.8041\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5175 - accuracy: 0.7939 - val_loss: 0.4695 - val_accuracy: 0.8176\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5456 - accuracy: 0.7787 - val_loss: 0.4786 - val_accuracy: 0.8041\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4861 - accuracy: 0.8176 - val_loss: 0.4543 - val_accuracy: 0.8311\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5218 - accuracy: 0.8074 - val_loss: 0.4604 - val_accuracy: 0.8176\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5818 - accuracy: 0.7703 - val_loss: 0.4542 - val_accuracy: 0.8378\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.7990 - val_loss: 0.4587 - val_accuracy: 0.8311\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7956 - val_loss: 0.4571 - val_accuracy: 0.8108\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8125 - val_loss: 0.4391 - val_accuracy: 0.8514\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5139 - accuracy: 0.8074 - val_loss: 0.4529 - val_accuracy: 0.8378\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4796 - accuracy: 0.8159 - val_loss: 0.4555 - val_accuracy: 0.8108\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5468 - accuracy: 0.7905 - val_loss: 0.4581 - val_accuracy: 0.8041\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5353 - accuracy: 0.8091 - val_loss: 0.4526 - val_accuracy: 0.8378\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.7821 - val_loss: 0.4530 - val_accuracy: 0.8176\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5594 - accuracy: 0.7821 - val_loss: 0.4669 - val_accuracy: 0.8108\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.8024 - val_loss: 0.4859 - val_accuracy: 0.7973\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.8091 - val_loss: 0.4736 - val_accuracy: 0.8041\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4989 - accuracy: 0.8041 - val_loss: 0.4614 - val_accuracy: 0.7838\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.7905 - val_loss: 0.4607 - val_accuracy: 0.8041\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.8091 - val_loss: 0.4542 - val_accuracy: 0.8311\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5515 - accuracy: 0.7905 - val_loss: 0.4575 - val_accuracy: 0.8108\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5199 - accuracy: 0.7922 - val_loss: 0.4679 - val_accuracy: 0.8243\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5037 - accuracy: 0.7956 - val_loss: 0.4616 - val_accuracy: 0.8243\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4793 - accuracy: 0.8142 - val_loss: 0.4497 - val_accuracy: 0.8311\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5408 - accuracy: 0.7973 - val_loss: 0.4564 - val_accuracy: 0.8243\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4917 - accuracy: 0.8311 - val_loss: 0.4581 - val_accuracy: 0.8176\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5191 - accuracy: 0.8159 - val_loss: 0.4600 - val_accuracy: 0.8041\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4783 - accuracy: 0.8209 - val_loss: 0.4544 - val_accuracy: 0.8041\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.7990 - val_loss: 0.4526 - val_accuracy: 0.8108\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4617 - accuracy: 0.8345 - val_loss: 0.4478 - val_accuracy: 0.8243\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.8412 - val_loss: 0.4502 - val_accuracy: 0.8446\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5283 - accuracy: 0.7753 - val_loss: 0.4701 - val_accuracy: 0.7973\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5156 - accuracy: 0.8091 - val_loss: 0.4627 - val_accuracy: 0.8176\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5478 - accuracy: 0.8007 - val_loss: 0.4615 - val_accuracy: 0.8176\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5237 - accuracy: 0.8024 - val_loss: 0.4606 - val_accuracy: 0.8108\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4750 - accuracy: 0.8361 - val_loss: 0.4536 - val_accuracy: 0.8176\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5100 - accuracy: 0.8125 - val_loss: 0.4556 - val_accuracy: 0.8108\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5303 - accuracy: 0.7956 - val_loss: 0.4546 - val_accuracy: 0.8446\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4661 - accuracy: 0.8294 - val_loss: 0.4496 - val_accuracy: 0.8446\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5017 - accuracy: 0.8142 - val_loss: 0.4495 - val_accuracy: 0.8446\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4956 - accuracy: 0.7973 - val_loss: 0.4426 - val_accuracy: 0.8378\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4848 - accuracy: 0.8074 - val_loss: 0.4660 - val_accuracy: 0.8176\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5183 - accuracy: 0.7990 - val_loss: 0.4702 - val_accuracy: 0.8108\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.7821 - val_loss: 0.4683 - val_accuracy: 0.8243\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5394 - accuracy: 0.7990 - val_loss: 0.4610 - val_accuracy: 0.8446\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4982 - accuracy: 0.8176 - val_loss: 0.4572 - val_accuracy: 0.8311\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5204 - accuracy: 0.8176 - val_loss: 0.4761 - val_accuracy: 0.8041\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4676 - accuracy: 0.8226 - val_loss: 0.4520 - val_accuracy: 0.8243\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4680 - accuracy: 0.8159 - val_loss: 0.4481 - val_accuracy: 0.8378\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5253 - accuracy: 0.8125 - val_loss: 0.4453 - val_accuracy: 0.8311\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5226 - accuracy: 0.7956 - val_loss: 0.4577 - val_accuracy: 0.8243\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4946 - accuracy: 0.8378 - val_loss: 0.4608 - val_accuracy: 0.8108\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5520 - accuracy: 0.8108 - val_loss: 0.4468 - val_accuracy: 0.8378\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4962 - accuracy: 0.7990 - val_loss: 0.4567 - val_accuracy: 0.8311\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5415 - accuracy: 0.7922 - val_loss: 0.4592 - val_accuracy: 0.8311\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4890 - accuracy: 0.8345 - val_loss: 0.4720 - val_accuracy: 0.7905\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4797 - accuracy: 0.8294 - val_loss: 0.4627 - val_accuracy: 0.8176\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5040 - accuracy: 0.8007 - val_loss: 0.4730 - val_accuracy: 0.7973\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5087 - accuracy: 0.7990 - val_loss: 0.4534 - val_accuracy: 0.8446\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5111 - accuracy: 0.8091 - val_loss: 0.4520 - val_accuracy: 0.8446\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5295 - accuracy: 0.7973 - val_loss: 0.4472 - val_accuracy: 0.8649\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4907 - accuracy: 0.8361 - val_loss: 0.4698 - val_accuracy: 0.8311\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5195 - accuracy: 0.7990 - val_loss: 0.4797 - val_accuracy: 0.8108\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5168 - accuracy: 0.7905 - val_loss: 0.4568 - val_accuracy: 0.8176\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5100 - accuracy: 0.8209 - val_loss: 0.4563 - val_accuracy: 0.8176\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4984 - accuracy: 0.8243 - val_loss: 0.4492 - val_accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bb6f49edcfc3>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 6s 13ms/step - loss: 1.9713 - accuracy: 0.4730 - val_loss: 1.4067 - val_accuracy: 0.5000\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.8765 - accuracy: 0.5068 - val_loss: 1.3841 - val_accuracy: 0.5135\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.7223 - accuracy: 0.4628 - val_loss: 1.3578 - val_accuracy: 0.5338\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.6191 - accuracy: 0.5135 - val_loss: 1.3465 - val_accuracy: 0.5135\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.4905 - accuracy: 0.5574 - val_loss: 1.3206 - val_accuracy: 0.5270\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.4868 - accuracy: 0.4983 - val_loss: 1.3037 - val_accuracy: 0.5203\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3993 - accuracy: 0.5439 - val_loss: 1.2862 - val_accuracy: 0.5270\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3588 - accuracy: 0.5169 - val_loss: 1.2730 - val_accuracy: 0.5405\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3061 - accuracy: 0.5659 - val_loss: 1.2517 - val_accuracy: 0.5405\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3232 - accuracy: 0.5118 - val_loss: 1.2364 - val_accuracy: 0.5270\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2823 - accuracy: 0.5355 - val_loss: 1.2195 - val_accuracy: 0.5608\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2306 - accuracy: 0.5405 - val_loss: 1.2024 - val_accuracy: 0.5743\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.5541 - val_loss: 1.1871 - val_accuracy: 0.5608\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1980 - accuracy: 0.5253 - val_loss: 1.1709 - val_accuracy: 0.5743\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1784 - accuracy: 0.5355 - val_loss: 1.1531 - val_accuracy: 0.5743\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1522 - accuracy: 0.5760 - val_loss: 1.1387 - val_accuracy: 0.5541\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1354 - accuracy: 0.5490 - val_loss: 1.1225 - val_accuracy: 0.5541\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1175 - accuracy: 0.5541 - val_loss: 1.1054 - val_accuracy: 0.5473\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.1003 - accuracy: 0.5709 - val_loss: 1.0887 - val_accuracy: 0.5405\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0693 - accuracy: 0.6047 - val_loss: 1.0645 - val_accuracy: 0.5811\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0682 - accuracy: 0.5557 - val_loss: 1.0462 - val_accuracy: 0.6081\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0477 - accuracy: 0.5760 - val_loss: 1.0296 - val_accuracy: 0.5946\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0354 - accuracy: 0.5676 - val_loss: 1.0128 - val_accuracy: 0.6419\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.5946 - val_loss: 0.9942 - val_accuracy: 0.7027\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9990 - accuracy: 0.6014 - val_loss: 0.9809 - val_accuracy: 0.6757\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9893 - accuracy: 0.5929 - val_loss: 0.9670 - val_accuracy: 0.6622\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9775 - accuracy: 0.6166 - val_loss: 0.9502 - val_accuracy: 0.6757\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9556 - accuracy: 0.6301 - val_loss: 0.9306 - val_accuracy: 0.6824\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9607 - accuracy: 0.5895 - val_loss: 0.9182 - val_accuracy: 0.6622\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.9096 - accuracy: 0.6486 - val_loss: 0.8910 - val_accuracy: 0.6824\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9174 - accuracy: 0.6334 - val_loss: 0.8802 - val_accuracy: 0.6824\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8998 - accuracy: 0.6199 - val_loss: 0.8683 - val_accuracy: 0.6689\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8744 - accuracy: 0.6318 - val_loss: 0.8509 - val_accuracy: 0.6757\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8884 - accuracy: 0.6233 - val_loss: 0.8388 - val_accuracy: 0.6959\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8658 - accuracy: 0.6486 - val_loss: 0.8236 - val_accuracy: 0.6892\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8501 - accuracy: 0.6402 - val_loss: 0.8137 - val_accuracy: 0.7162\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8244 - accuracy: 0.6554 - val_loss: 0.7926 - val_accuracy: 0.7162\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7952 - accuracy: 0.6740 - val_loss: 0.7599 - val_accuracy: 0.7297\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8184 - accuracy: 0.6622 - val_loss: 0.7569 - val_accuracy: 0.7230\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8033 - accuracy: 0.6689 - val_loss: 0.7491 - val_accuracy: 0.7297\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7813 - accuracy: 0.6757 - val_loss: 0.7297 - val_accuracy: 0.7297\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7923 - accuracy: 0.6740 - val_loss: 0.7311 - val_accuracy: 0.7500\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7894 - accuracy: 0.6588 - val_loss: 0.7347 - val_accuracy: 0.7365\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7589 - accuracy: 0.6791 - val_loss: 0.7250 - val_accuracy: 0.7432\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7370 - accuracy: 0.6943 - val_loss: 0.7021 - val_accuracy: 0.7365\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7385 - accuracy: 0.7027 - val_loss: 0.6893 - val_accuracy: 0.7432\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7333 - accuracy: 0.6976 - val_loss: 0.6827 - val_accuracy: 0.7365\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7230 - accuracy: 0.7095 - val_loss: 0.6758 - val_accuracy: 0.7703\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6757 - accuracy: 0.7331 - val_loss: 0.6577 - val_accuracy: 0.7500\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7062 - accuracy: 0.7128 - val_loss: 0.6554 - val_accuracy: 0.7635\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.7010 - val_loss: 0.6615 - val_accuracy: 0.7635\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.6976 - val_loss: 0.6441 - val_accuracy: 0.7568\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7063 - accuracy: 0.7179 - val_loss: 0.6485 - val_accuracy: 0.7500\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6753 - accuracy: 0.7382 - val_loss: 0.6480 - val_accuracy: 0.7365\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.6807 - val_loss: 0.6330 - val_accuracy: 0.7635\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6829 - accuracy: 0.7247 - val_loss: 0.6244 - val_accuracy: 0.7703\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6859 - accuracy: 0.7264 - val_loss: 0.6279 - val_accuracy: 0.7635\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6606 - accuracy: 0.7230 - val_loss: 0.6058 - val_accuracy: 0.7838\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6764 - accuracy: 0.7247 - val_loss: 0.6041 - val_accuracy: 0.7838\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6552 - accuracy: 0.7432 - val_loss: 0.6003 - val_accuracy: 0.7973\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6145 - accuracy: 0.7483 - val_loss: 0.5956 - val_accuracy: 0.7703\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6328 - accuracy: 0.7449 - val_loss: 0.5888 - val_accuracy: 0.7838\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6519 - accuracy: 0.7382 - val_loss: 0.5802 - val_accuracy: 0.7973\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.7196 - val_loss: 0.5766 - val_accuracy: 0.8041\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6551 - accuracy: 0.7264 - val_loss: 0.5679 - val_accuracy: 0.8041\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6242 - accuracy: 0.7584 - val_loss: 0.5602 - val_accuracy: 0.8243\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6443 - accuracy: 0.7264 - val_loss: 0.5613 - val_accuracy: 0.8108\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5900 - accuracy: 0.7905 - val_loss: 0.5574 - val_accuracy: 0.8108\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6501 - accuracy: 0.7534 - val_loss: 0.5565 - val_accuracy: 0.8108\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6421 - accuracy: 0.7331 - val_loss: 0.5466 - val_accuracy: 0.8176\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6190 - accuracy: 0.7584 - val_loss: 0.5476 - val_accuracy: 0.8041\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6500 - accuracy: 0.7331 - val_loss: 0.5396 - val_accuracy: 0.8041\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6537 - accuracy: 0.7314 - val_loss: 0.5566 - val_accuracy: 0.8041\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6176 - accuracy: 0.7517 - val_loss: 0.5517 - val_accuracy: 0.7973\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6161 - accuracy: 0.7534 - val_loss: 0.5552 - val_accuracy: 0.7973\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.7500 - val_loss: 0.5465 - val_accuracy: 0.8108\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7601 - val_loss: 0.5340 - val_accuracy: 0.8311\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.7770 - val_loss: 0.5369 - val_accuracy: 0.8108\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5789 - accuracy: 0.7804 - val_loss: 0.5168 - val_accuracy: 0.8176\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.7264 - val_loss: 0.5085 - val_accuracy: 0.8176\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5916 - accuracy: 0.7669 - val_loss: 0.5262 - val_accuracy: 0.8108\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7922 - val_loss: 0.5056 - val_accuracy: 0.8311\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.7821 - val_loss: 0.4969 - val_accuracy: 0.8446\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6572 - accuracy: 0.7382 - val_loss: 0.5240 - val_accuracy: 0.8041\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6190 - accuracy: 0.7568 - val_loss: 0.5121 - val_accuracy: 0.8378\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5906 - accuracy: 0.7686 - val_loss: 0.5016 - val_accuracy: 0.8243\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.7872 - val_loss: 0.5068 - val_accuracy: 0.8311\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.7517 - val_loss: 0.5165 - val_accuracy: 0.8311\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5793 - accuracy: 0.7703 - val_loss: 0.5194 - val_accuracy: 0.8243\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5713 - accuracy: 0.7753 - val_loss: 0.5142 - val_accuracy: 0.8176\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5630 - accuracy: 0.7939 - val_loss: 0.5143 - val_accuracy: 0.8041\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5614 - accuracy: 0.7804 - val_loss: 0.5141 - val_accuracy: 0.8041\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.7821 - val_loss: 0.5355 - val_accuracy: 0.8041\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5742 - accuracy: 0.7939 - val_loss: 0.5060 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6064 - accuracy: 0.7601 - val_loss: 0.5146 - val_accuracy: 0.8176\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5481 - accuracy: 0.7905 - val_loss: 0.5218 - val_accuracy: 0.8108\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6165 - accuracy: 0.7686 - val_loss: 0.5030 - val_accuracy: 0.8311\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6294 - accuracy: 0.7399 - val_loss: 0.5294 - val_accuracy: 0.8108\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5931 - accuracy: 0.7584 - val_loss: 0.5328 - val_accuracy: 0.7973\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5544 - accuracy: 0.7956 - val_loss: 0.5196 - val_accuracy: 0.8176\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5873 - accuracy: 0.7635 - val_loss: 0.5235 - val_accuracy: 0.8108\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5664 - accuracy: 0.7669 - val_loss: 0.5180 - val_accuracy: 0.8311\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.7551 - val_loss: 0.5212 - val_accuracy: 0.8176\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7905 - val_loss: 0.5150 - val_accuracy: 0.7905\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5702 - accuracy: 0.7855 - val_loss: 0.5116 - val_accuracy: 0.8243\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.7669 - val_loss: 0.5114 - val_accuracy: 0.8176\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.8007 - val_loss: 0.5092 - val_accuracy: 0.8041\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5507 - accuracy: 0.7821 - val_loss: 0.5086 - val_accuracy: 0.8108\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.8142 - val_loss: 0.5063 - val_accuracy: 0.8243\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.7618 - val_loss: 0.5067 - val_accuracy: 0.8108\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7669 - val_loss: 0.5054 - val_accuracy: 0.8243\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7889 - val_loss: 0.5228 - val_accuracy: 0.8311\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5634 - accuracy: 0.7922 - val_loss: 0.5287 - val_accuracy: 0.8041\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.7517 - val_loss: 0.5224 - val_accuracy: 0.7973\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.7804 - val_loss: 0.5265 - val_accuracy: 0.8041\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.8091 - val_loss: 0.5223 - val_accuracy: 0.7905\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5957 - accuracy: 0.7973 - val_loss: 0.5164 - val_accuracy: 0.7973\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5852 - accuracy: 0.7905 - val_loss: 0.5145 - val_accuracy: 0.8176\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5778 - accuracy: 0.7669 - val_loss: 0.5206 - val_accuracy: 0.8176\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.7990 - val_loss: 0.5114 - val_accuracy: 0.8243\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.7872 - val_loss: 0.5101 - val_accuracy: 0.7973\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5484 - accuracy: 0.7990 - val_loss: 0.5054 - val_accuracy: 0.8176\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5615 - accuracy: 0.7855 - val_loss: 0.4886 - val_accuracy: 0.8378\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5787 - accuracy: 0.7973 - val_loss: 0.4876 - val_accuracy: 0.8311\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5741 - accuracy: 0.7753 - val_loss: 0.4945 - val_accuracy: 0.8243\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5229 - accuracy: 0.8277 - val_loss: 0.4864 - val_accuracy: 0.8243\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5458 - accuracy: 0.7872 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5716 - accuracy: 0.7720 - val_loss: 0.4859 - val_accuracy: 0.8311\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5711 - accuracy: 0.7922 - val_loss: 0.4952 - val_accuracy: 0.8041\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7956 - val_loss: 0.4885 - val_accuracy: 0.8243\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5853 - accuracy: 0.7889 - val_loss: 0.4816 - val_accuracy: 0.8446\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.7534 - val_loss: 0.4974 - val_accuracy: 0.8378\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.7770 - val_loss: 0.4970 - val_accuracy: 0.8243\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5908 - accuracy: 0.7787 - val_loss: 0.4894 - val_accuracy: 0.8311\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.7922 - val_loss: 0.4966 - val_accuracy: 0.8378\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5335 - accuracy: 0.7973 - val_loss: 0.4844 - val_accuracy: 0.8108\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.8108 - val_loss: 0.4870 - val_accuracy: 0.8176\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7855 - val_loss: 0.4951 - val_accuracy: 0.8176\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5499 - accuracy: 0.7905 - val_loss: 0.4827 - val_accuracy: 0.7973\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7686 - val_loss: 0.4886 - val_accuracy: 0.8041\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5600 - accuracy: 0.7990 - val_loss: 0.4912 - val_accuracy: 0.8176\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.8108 - val_loss: 0.5017 - val_accuracy: 0.8108\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7652 - val_loss: 0.4880 - val_accuracy: 0.8243\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.7939 - val_loss: 0.4793 - val_accuracy: 0.8176\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.8041 - val_loss: 0.4720 - val_accuracy: 0.8311\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.8024 - val_loss: 0.4715 - val_accuracy: 0.8446\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5512 - accuracy: 0.7889 - val_loss: 0.4776 - val_accuracy: 0.8311\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5603 - accuracy: 0.7973 - val_loss: 0.4898 - val_accuracy: 0.8243\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5402 - accuracy: 0.8108 - val_loss: 0.4714 - val_accuracy: 0.8378\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5448 - accuracy: 0.8108 - val_loss: 0.4801 - val_accuracy: 0.8243\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5715 - accuracy: 0.8108 - val_loss: 0.4965 - val_accuracy: 0.8108\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6036 - accuracy: 0.7787 - val_loss: 0.4863 - val_accuracy: 0.8446\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5576 - accuracy: 0.7804 - val_loss: 0.4813 - val_accuracy: 0.8378\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.8074 - val_loss: 0.4756 - val_accuracy: 0.8581\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7889 - val_loss: 0.4811 - val_accuracy: 0.8378\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5600 - accuracy: 0.7973 - val_loss: 0.4780 - val_accuracy: 0.8243\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5338 - accuracy: 0.7956 - val_loss: 0.4979 - val_accuracy: 0.8176\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5393 - accuracy: 0.7872 - val_loss: 0.4779 - val_accuracy: 0.8378\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.8159 - val_loss: 0.4801 - val_accuracy: 0.8378\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5734 - accuracy: 0.7922 - val_loss: 0.4906 - val_accuracy: 0.8243\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7804 - val_loss: 0.4812 - val_accuracy: 0.8446\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5466 - accuracy: 0.7922 - val_loss: 0.4880 - val_accuracy: 0.8446\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5542 - accuracy: 0.8007 - val_loss: 0.4835 - val_accuracy: 0.8514\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5143 - accuracy: 0.8041 - val_loss: 0.4765 - val_accuracy: 0.8446\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5719 - accuracy: 0.7753 - val_loss: 0.4725 - val_accuracy: 0.8514\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5313 - accuracy: 0.8007 - val_loss: 0.4710 - val_accuracy: 0.8446\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5250 - accuracy: 0.7973 - val_loss: 0.4630 - val_accuracy: 0.8581\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.7804 - val_loss: 0.4774 - val_accuracy: 0.8378\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7990 - val_loss: 0.4855 - val_accuracy: 0.8311\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5329 - accuracy: 0.7922 - val_loss: 0.4974 - val_accuracy: 0.8243\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.7855 - val_loss: 0.4874 - val_accuracy: 0.8311\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.7804 - val_loss: 0.4882 - val_accuracy: 0.8176\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.8074 - val_loss: 0.4968 - val_accuracy: 0.8176\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6024 - accuracy: 0.7889 - val_loss: 0.4924 - val_accuracy: 0.8176\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5853 - accuracy: 0.7821 - val_loss: 0.5001 - val_accuracy: 0.8311\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5506 - accuracy: 0.8159 - val_loss: 0.4982 - val_accuracy: 0.8378\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5575 - accuracy: 0.7872 - val_loss: 0.4971 - val_accuracy: 0.8446\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5294 - accuracy: 0.7905 - val_loss: 0.4802 - val_accuracy: 0.8581\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5072 - accuracy: 0.8159 - val_loss: 0.4707 - val_accuracy: 0.8446\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5270 - accuracy: 0.8311 - val_loss: 0.4702 - val_accuracy: 0.8446\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5514 - accuracy: 0.7922 - val_loss: 0.4797 - val_accuracy: 0.8378\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8260 - val_loss: 0.4817 - val_accuracy: 0.8243\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.8057 - val_loss: 0.4654 - val_accuracy: 0.8514\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.8074 - val_loss: 0.4637 - val_accuracy: 0.8311\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7973 - val_loss: 0.4895 - val_accuracy: 0.8108\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5032 - accuracy: 0.8277 - val_loss: 0.4772 - val_accuracy: 0.8243\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.7787 - val_loss: 0.4829 - val_accuracy: 0.8243\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5176 - accuracy: 0.7973 - val_loss: 0.4888 - val_accuracy: 0.8176\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5240 - accuracy: 0.8108 - val_loss: 0.4868 - val_accuracy: 0.8311\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4872 - accuracy: 0.8328 - val_loss: 0.4781 - val_accuracy: 0.8243\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7990 - val_loss: 0.4810 - val_accuracy: 0.8446\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5113 - accuracy: 0.8091 - val_loss: 0.4738 - val_accuracy: 0.8378\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5220 - accuracy: 0.8176 - val_loss: 0.4880 - val_accuracy: 0.8311\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.8091 - val_loss: 0.4820 - val_accuracy: 0.8311\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.8091 - val_loss: 0.4720 - val_accuracy: 0.8243\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.8108 - val_loss: 0.4902 - val_accuracy: 0.8243\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.8142 - val_loss: 0.4873 - val_accuracy: 0.8378\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.8345 - val_loss: 0.4794 - val_accuracy: 0.8243\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.8108 - val_loss: 0.4900 - val_accuracy: 0.8243\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5728 - accuracy: 0.7990 - val_loss: 0.4984 - val_accuracy: 0.8176\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5615 - accuracy: 0.8091 - val_loss: 0.5016 - val_accuracy: 0.8041\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5306 - accuracy: 0.8024 - val_loss: 0.4921 - val_accuracy: 0.8176\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5536 - accuracy: 0.7905 - val_loss: 0.4857 - val_accuracy: 0.8176\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5347 - accuracy: 0.7922 - val_loss: 0.4943 - val_accuracy: 0.8311\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5328 - accuracy: 0.7889 - val_loss: 0.4919 - val_accuracy: 0.8243\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5194 - accuracy: 0.8041 - val_loss: 0.5048 - val_accuracy: 0.8243\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.8074 - val_loss: 0.4871 - val_accuracy: 0.8243\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5068 - accuracy: 0.8226 - val_loss: 0.4809 - val_accuracy: 0.8311\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5603 - accuracy: 0.7838 - val_loss: 0.4707 - val_accuracy: 0.8311\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5495 - accuracy: 0.7939 - val_loss: 0.4697 - val_accuracy: 0.8378\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5583 - accuracy: 0.7787 - val_loss: 0.4833 - val_accuracy: 0.8311\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5219 - accuracy: 0.8057 - val_loss: 0.4664 - val_accuracy: 0.8243\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4844 - accuracy: 0.8277 - val_loss: 0.4689 - val_accuracy: 0.8176\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5200 - accuracy: 0.8108 - val_loss: 0.4618 - val_accuracy: 0.8108\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7973 - val_loss: 0.4777 - val_accuracy: 0.8176\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5542 - accuracy: 0.8243 - val_loss: 0.4805 - val_accuracy: 0.8243\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5296 - accuracy: 0.7905 - val_loss: 0.4702 - val_accuracy: 0.8311\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7973 - val_loss: 0.4659 - val_accuracy: 0.8311\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.8209 - val_loss: 0.5031 - val_accuracy: 0.8243\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5272 - accuracy: 0.8041 - val_loss: 0.5029 - val_accuracy: 0.8243\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5597 - accuracy: 0.7753 - val_loss: 0.4945 - val_accuracy: 0.8108\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.8142 - val_loss: 0.4855 - val_accuracy: 0.8176\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4942 - accuracy: 0.8226 - val_loss: 0.4903 - val_accuracy: 0.8108\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5204 - accuracy: 0.8091 - val_loss: 0.4842 - val_accuracy: 0.8108\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4977 - accuracy: 0.8345 - val_loss: 0.4947 - val_accuracy: 0.8108\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5213 - accuracy: 0.8091 - val_loss: 0.5030 - val_accuracy: 0.8041\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5086 - accuracy: 0.8024 - val_loss: 0.4977 - val_accuracy: 0.8108\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4990 - accuracy: 0.8176 - val_loss: 0.4870 - val_accuracy: 0.8176\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5050 - accuracy: 0.8277 - val_loss: 0.5170 - val_accuracy: 0.8176\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5399 - accuracy: 0.7889 - val_loss: 0.4957 - val_accuracy: 0.8311\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5079 - accuracy: 0.8209 - val_loss: 0.4828 - val_accuracy: 0.8311\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.8378 - val_loss: 0.4679 - val_accuracy: 0.8378\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.8142 - val_loss: 0.4692 - val_accuracy: 0.8176\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.8091 - val_loss: 0.4660 - val_accuracy: 0.8378\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4788 - accuracy: 0.8311 - val_loss: 0.4781 - val_accuracy: 0.8243\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5051 - accuracy: 0.8125 - val_loss: 0.4933 - val_accuracy: 0.8243\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.8176 - val_loss: 0.4924 - val_accuracy: 0.8041\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.8024 - val_loss: 0.4814 - val_accuracy: 0.8108\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.8260 - val_loss: 0.4793 - val_accuracy: 0.8041\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7922 - val_loss: 0.4891 - val_accuracy: 0.7973\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5394 - accuracy: 0.7956 - val_loss: 0.5025 - val_accuracy: 0.8108\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4908 - accuracy: 0.8209 - val_loss: 0.5093 - val_accuracy: 0.8108\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5322 - accuracy: 0.8041 - val_loss: 0.5056 - val_accuracy: 0.8108\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.7652 - val_loss: 0.4894 - val_accuracy: 0.8176\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.8041 - val_loss: 0.4819 - val_accuracy: 0.8243\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4977 - accuracy: 0.8311 - val_loss: 0.4889 - val_accuracy: 0.8176\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5329 - accuracy: 0.7956 - val_loss: 0.4916 - val_accuracy: 0.7973\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5273 - accuracy: 0.8024 - val_loss: 0.4788 - val_accuracy: 0.8176\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4789 - accuracy: 0.8108 - val_loss: 0.4826 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5121 - accuracy: 0.8209 - val_loss: 0.4755 - val_accuracy: 0.8311\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4926 - accuracy: 0.8108 - val_loss: 0.4839 - val_accuracy: 0.8108\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5490 - accuracy: 0.7855 - val_loss: 0.4824 - val_accuracy: 0.8176\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4902 - accuracy: 0.8108 - val_loss: 0.4791 - val_accuracy: 0.8176\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4893 - accuracy: 0.8091 - val_loss: 0.5087 - val_accuracy: 0.8108\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5576 - accuracy: 0.8074 - val_loss: 0.4988 - val_accuracy: 0.8108\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5456 - accuracy: 0.7889 - val_loss: 0.5180 - val_accuracy: 0.8041\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5391 - accuracy: 0.8243 - val_loss: 0.4979 - val_accuracy: 0.8243\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.8159 - val_loss: 0.4969 - val_accuracy: 0.8041\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5443 - accuracy: 0.7939 - val_loss: 0.4973 - val_accuracy: 0.7973\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5167 - accuracy: 0.8108 - val_loss: 0.5058 - val_accuracy: 0.7838\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.8142 - val_loss: 0.4953 - val_accuracy: 0.7838\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5092 - accuracy: 0.8108 - val_loss: 0.5066 - val_accuracy: 0.7905\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.8041 - val_loss: 0.4909 - val_accuracy: 0.8041\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5357 - accuracy: 0.8007 - val_loss: 0.4973 - val_accuracy: 0.7905\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5367 - accuracy: 0.7973 - val_loss: 0.4939 - val_accuracy: 0.7905\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5056 - accuracy: 0.8074 - val_loss: 0.4974 - val_accuracy: 0.8108\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5123 - accuracy: 0.8074 - val_loss: 0.4863 - val_accuracy: 0.8108\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4752 - accuracy: 0.8057 - val_loss: 0.4947 - val_accuracy: 0.7973\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.8057 - val_loss: 0.4735 - val_accuracy: 0.8378\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5138 - accuracy: 0.8074 - val_loss: 0.4822 - val_accuracy: 0.8108\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5253 - accuracy: 0.7956 - val_loss: 0.4888 - val_accuracy: 0.8108\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5410 - accuracy: 0.7770 - val_loss: 0.4862 - val_accuracy: 0.8176\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.8108 - val_loss: 0.4898 - val_accuracy: 0.8041\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4845 - accuracy: 0.8260 - val_loss: 0.4930 - val_accuracy: 0.7973\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.8057 - val_loss: 0.4879 - val_accuracy: 0.8176\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5007 - accuracy: 0.8361 - val_loss: 0.4962 - val_accuracy: 0.8041\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5054 - accuracy: 0.8007 - val_loss: 0.5180 - val_accuracy: 0.7770\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5259 - accuracy: 0.8142 - val_loss: 0.5060 - val_accuracy: 0.7973\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4902 - accuracy: 0.8041 - val_loss: 0.4982 - val_accuracy: 0.7905\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4823 - accuracy: 0.8378 - val_loss: 0.4809 - val_accuracy: 0.8041\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.8243 - val_loss: 0.4779 - val_accuracy: 0.8176\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.7905 - val_loss: 0.4818 - val_accuracy: 0.8041\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5347 - accuracy: 0.7973 - val_loss: 0.4958 - val_accuracy: 0.8041\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7889 - val_loss: 0.4883 - val_accuracy: 0.7973\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5037 - accuracy: 0.8125 - val_loss: 0.4851 - val_accuracy: 0.8041\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4622 - accuracy: 0.8328 - val_loss: 0.4708 - val_accuracy: 0.8243\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.8446 - val_loss: 0.4778 - val_accuracy: 0.8176\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.8176 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4935 - accuracy: 0.8074 - val_loss: 0.4674 - val_accuracy: 0.8243\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5214 - accuracy: 0.8108 - val_loss: 0.4579 - val_accuracy: 0.8176\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5361 - accuracy: 0.8041 - val_loss: 0.4679 - val_accuracy: 0.8311\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4650 - accuracy: 0.8108 - val_loss: 0.4988 - val_accuracy: 0.8108\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.8024 - val_loss: 0.4785 - val_accuracy: 0.8176\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5105 - accuracy: 0.8041 - val_loss: 0.4893 - val_accuracy: 0.8041\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.7956 - val_loss: 0.4779 - val_accuracy: 0.8378\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4864 - accuracy: 0.8311 - val_loss: 0.4774 - val_accuracy: 0.8311\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8294 - val_loss: 0.4925 - val_accuracy: 0.8108\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5239 - accuracy: 0.8091 - val_loss: 0.5122 - val_accuracy: 0.8041\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5011 - accuracy: 0.8057 - val_loss: 0.5123 - val_accuracy: 0.8041\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5461 - accuracy: 0.7922 - val_loss: 0.5215 - val_accuracy: 0.8041\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5234 - accuracy: 0.8024 - val_loss: 0.5002 - val_accuracy: 0.8176\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5278 - accuracy: 0.8074 - val_loss: 0.5052 - val_accuracy: 0.8041\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5097 - accuracy: 0.8193 - val_loss: 0.4971 - val_accuracy: 0.7905\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5212 - accuracy: 0.7990 - val_loss: 0.4961 - val_accuracy: 0.8108\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4976 - accuracy: 0.7939 - val_loss: 0.4810 - val_accuracy: 0.8311\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.8243 - val_loss: 0.5041 - val_accuracy: 0.8108\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5087 - accuracy: 0.8125 - val_loss: 0.4963 - val_accuracy: 0.8176\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4978 - accuracy: 0.7990 - val_loss: 0.4988 - val_accuracy: 0.7973\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.8125 - val_loss: 0.4892 - val_accuracy: 0.8108\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5475 - accuracy: 0.8176 - val_loss: 0.4855 - val_accuracy: 0.8176\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5225 - accuracy: 0.7990 - val_loss: 0.4949 - val_accuracy: 0.7973\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4937 - accuracy: 0.8226 - val_loss: 0.4895 - val_accuracy: 0.8041\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5293 - accuracy: 0.8041 - val_loss: 0.4686 - val_accuracy: 0.8176\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.8260 - val_loss: 0.4714 - val_accuracy: 0.8176\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.8108 - val_loss: 0.4738 - val_accuracy: 0.8108\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5110 - accuracy: 0.8142 - val_loss: 0.4865 - val_accuracy: 0.8108\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4627 - accuracy: 0.8378 - val_loss: 0.4783 - val_accuracy: 0.8176\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5452 - accuracy: 0.7973 - val_loss: 0.4966 - val_accuracy: 0.8176\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5451 - accuracy: 0.8024 - val_loss: 0.5032 - val_accuracy: 0.8108\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4994 - accuracy: 0.8277 - val_loss: 0.4980 - val_accuracy: 0.8041\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.7990 - val_loss: 0.4856 - val_accuracy: 0.7973\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5201 - accuracy: 0.8057 - val_loss: 0.4840 - val_accuracy: 0.8041\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8176 - val_loss: 0.4816 - val_accuracy: 0.8041\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5325 - accuracy: 0.7804 - val_loss: 0.4902 - val_accuracy: 0.7973\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5211 - accuracy: 0.8142 - val_loss: 0.5001 - val_accuracy: 0.7905\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5043 - accuracy: 0.8159 - val_loss: 0.4899 - val_accuracy: 0.7905\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5238 - accuracy: 0.7905 - val_loss: 0.4901 - val_accuracy: 0.8041\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5003 - accuracy: 0.8041 - val_loss: 0.4812 - val_accuracy: 0.8041\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4868 - accuracy: 0.8193 - val_loss: 0.4953 - val_accuracy: 0.8176\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5305 - accuracy: 0.8041 - val_loss: 0.4970 - val_accuracy: 0.8041\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4686 - accuracy: 0.8024 - val_loss: 0.4844 - val_accuracy: 0.8108\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4526 - accuracy: 0.8429 - val_loss: 0.5023 - val_accuracy: 0.8041\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8024 - val_loss: 0.5069 - val_accuracy: 0.8041\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4812 - accuracy: 0.8328 - val_loss: 0.4869 - val_accuracy: 0.8176\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4694 - accuracy: 0.8176 - val_loss: 0.4953 - val_accuracy: 0.8108\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.8226 - val_loss: 0.5076 - val_accuracy: 0.8041\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5306 - accuracy: 0.7990 - val_loss: 0.5150 - val_accuracy: 0.7973\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7990 - val_loss: 0.5040 - val_accuracy: 0.8041\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.8159 - val_loss: 0.5068 - val_accuracy: 0.8108\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.8125 - val_loss: 0.5161 - val_accuracy: 0.8041\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5170 - accuracy: 0.8041 - val_loss: 0.5226 - val_accuracy: 0.7973\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5032 - accuracy: 0.8041 - val_loss: 0.5177 - val_accuracy: 0.7973\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5142 - accuracy: 0.8041 - val_loss: 0.5120 - val_accuracy: 0.7905\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4861 - accuracy: 0.8193 - val_loss: 0.5069 - val_accuracy: 0.8041\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.8142 - val_loss: 0.5105 - val_accuracy: 0.7905\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4928 - accuracy: 0.8328 - val_loss: 0.4970 - val_accuracy: 0.7838\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4778 - accuracy: 0.8226 - val_loss: 0.4952 - val_accuracy: 0.8041\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5362 - accuracy: 0.8209 - val_loss: 0.4973 - val_accuracy: 0.7905\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5119 - accuracy: 0.8057 - val_loss: 0.4887 - val_accuracy: 0.8108\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5294 - accuracy: 0.7922 - val_loss: 0.4876 - val_accuracy: 0.8041\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5174 - accuracy: 0.8007 - val_loss: 0.4931 - val_accuracy: 0.7838\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5232 - accuracy: 0.7889 - val_loss: 0.4919 - val_accuracy: 0.8041\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5010 - accuracy: 0.8057 - val_loss: 0.4955 - val_accuracy: 0.8176\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5032 - accuracy: 0.8294 - val_loss: 0.4959 - val_accuracy: 0.7905\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5324 - accuracy: 0.8277 - val_loss: 0.4933 - val_accuracy: 0.7973\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4723 - accuracy: 0.8514 - val_loss: 0.4945 - val_accuracy: 0.7905\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4672 - accuracy: 0.8328 - val_loss: 0.4908 - val_accuracy: 0.7838\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4906 - accuracy: 0.8091 - val_loss: 0.5026 - val_accuracy: 0.7770\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4901 - accuracy: 0.8176 - val_loss: 0.4998 - val_accuracy: 0.7770\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5138 - accuracy: 0.7855 - val_loss: 0.4849 - val_accuracy: 0.7973\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5447 - accuracy: 0.7939 - val_loss: 0.5005 - val_accuracy: 0.7838\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5244 - accuracy: 0.8125 - val_loss: 0.4995 - val_accuracy: 0.7973\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5122 - accuracy: 0.8108 - val_loss: 0.5190 - val_accuracy: 0.7770\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4901 - accuracy: 0.8243 - val_loss: 0.5118 - val_accuracy: 0.7838\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5113 - accuracy: 0.8074 - val_loss: 0.5041 - val_accuracy: 0.7973\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5109 - accuracy: 0.8209 - val_loss: 0.4997 - val_accuracy: 0.8041\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.8125 - val_loss: 0.5016 - val_accuracy: 0.8108\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4899 - accuracy: 0.8142 - val_loss: 0.4925 - val_accuracy: 0.8041\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.8328 - val_loss: 0.4906 - val_accuracy: 0.8243\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5444 - accuracy: 0.8041 - val_loss: 0.4801 - val_accuracy: 0.8243\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.8412 - val_loss: 0.4848 - val_accuracy: 0.8311\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4480 - accuracy: 0.8412 - val_loss: 0.4689 - val_accuracy: 0.8378\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5421 - accuracy: 0.7872 - val_loss: 0.4918 - val_accuracy: 0.8176\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5250 - accuracy: 0.8108 - val_loss: 0.4970 - val_accuracy: 0.8108\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5014 - accuracy: 0.8226 - val_loss: 0.4914 - val_accuracy: 0.8108\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5356 - accuracy: 0.8193 - val_loss: 0.4873 - val_accuracy: 0.8108\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5070 - accuracy: 0.8209 - val_loss: 0.5082 - val_accuracy: 0.8311\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5309 - accuracy: 0.8057 - val_loss: 0.4873 - val_accuracy: 0.8243\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4895 - accuracy: 0.8294 - val_loss: 0.4943 - val_accuracy: 0.8041\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4711 - accuracy: 0.8091 - val_loss: 0.4814 - val_accuracy: 0.8378\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.8108 - val_loss: 0.4780 - val_accuracy: 0.8311\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.8142 - val_loss: 0.4831 - val_accuracy: 0.8311\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5088 - accuracy: 0.8277 - val_loss: 0.4951 - val_accuracy: 0.8041\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5365 - accuracy: 0.8074 - val_loss: 0.4843 - val_accuracy: 0.8176\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4997 - accuracy: 0.8091 - val_loss: 0.5065 - val_accuracy: 0.7905\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4556 - accuracy: 0.8311 - val_loss: 0.4878 - val_accuracy: 0.8311\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.8243 - val_loss: 0.4921 - val_accuracy: 0.8243\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5156 - accuracy: 0.8007 - val_loss: 0.5023 - val_accuracy: 0.8041\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5065 - accuracy: 0.8260 - val_loss: 0.4977 - val_accuracy: 0.8243\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5052 - accuracy: 0.7990 - val_loss: 0.4880 - val_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.7855 - val_loss: 0.4829 - val_accuracy: 0.8311\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5003 - accuracy: 0.8074 - val_loss: 0.5003 - val_accuracy: 0.8108\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.8142 - val_loss: 0.5022 - val_accuracy: 0.8176\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5037 - accuracy: 0.7956 - val_loss: 0.5001 - val_accuracy: 0.8041\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8209 - val_loss: 0.4828 - val_accuracy: 0.7973\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.8395 - val_loss: 0.4888 - val_accuracy: 0.8108\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4753 - accuracy: 0.8277 - val_loss: 0.5190 - val_accuracy: 0.7973\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5680 - accuracy: 0.7703 - val_loss: 0.5316 - val_accuracy: 0.7838\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4975 - accuracy: 0.7905 - val_loss: 0.5144 - val_accuracy: 0.7703\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4883 - accuracy: 0.8057 - val_loss: 0.5068 - val_accuracy: 0.7838\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5054 - accuracy: 0.8007 - val_loss: 0.4997 - val_accuracy: 0.7838\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5220 - accuracy: 0.8243 - val_loss: 0.4882 - val_accuracy: 0.7770\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4871 - accuracy: 0.8277 - val_loss: 0.4893 - val_accuracy: 0.7973\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4803 - accuracy: 0.8260 - val_loss: 0.4780 - val_accuracy: 0.8041\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4806 - accuracy: 0.8074 - val_loss: 0.4672 - val_accuracy: 0.8108\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4831 - accuracy: 0.8125 - val_loss: 0.4676 - val_accuracy: 0.8041\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4703 - accuracy: 0.8243 - val_loss: 0.4590 - val_accuracy: 0.8311\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.8176 - val_loss: 0.4493 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4817 - accuracy: 0.8209 - val_loss: 0.4439 - val_accuracy: 0.8311\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.7956 - val_loss: 0.4614 - val_accuracy: 0.8176\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.8193 - val_loss: 0.4776 - val_accuracy: 0.8176\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4473 - accuracy: 0.8429 - val_loss: 0.4692 - val_accuracy: 0.8108\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.8142 - val_loss: 0.4769 - val_accuracy: 0.8108\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5066 - accuracy: 0.7990 - val_loss: 0.4709 - val_accuracy: 0.8311\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5230 - accuracy: 0.7956 - val_loss: 0.4529 - val_accuracy: 0.8311\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4903 - accuracy: 0.8361 - val_loss: 0.4666 - val_accuracy: 0.8108\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.7939 - val_loss: 0.4533 - val_accuracy: 0.8243\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4954 - accuracy: 0.7939 - val_loss: 0.4899 - val_accuracy: 0.8108\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.8395 - val_loss: 0.4947 - val_accuracy: 0.7838\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4443 - accuracy: 0.8429 - val_loss: 0.4951 - val_accuracy: 0.7770\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.8108 - val_loss: 0.4732 - val_accuracy: 0.7905\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4698 - accuracy: 0.8209 - val_loss: 0.4760 - val_accuracy: 0.7973\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4568 - accuracy: 0.8311 - val_loss: 0.4730 - val_accuracy: 0.7973\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5282 - accuracy: 0.8108 - val_loss: 0.4766 - val_accuracy: 0.7905\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5152 - accuracy: 0.8193 - val_loss: 0.4804 - val_accuracy: 0.8041\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5282 - accuracy: 0.8176 - val_loss: 0.4722 - val_accuracy: 0.8243\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4850 - accuracy: 0.8193 - val_loss: 0.4652 - val_accuracy: 0.8243\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4782 - accuracy: 0.8345 - val_loss: 0.4774 - val_accuracy: 0.8041\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5159 - accuracy: 0.8108 - val_loss: 0.4506 - val_accuracy: 0.8243\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4800 - accuracy: 0.8260 - val_loss: 0.4413 - val_accuracy: 0.8378\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4741 - accuracy: 0.8193 - val_loss: 0.4526 - val_accuracy: 0.8378\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.8091 - val_loss: 0.4484 - val_accuracy: 0.8378\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4633 - accuracy: 0.8159 - val_loss: 0.4646 - val_accuracy: 0.8311\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.7905 - val_loss: 0.4726 - val_accuracy: 0.8176\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.8125 - val_loss: 0.4736 - val_accuracy: 0.8108\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4852 - accuracy: 0.8193 - val_loss: 0.4730 - val_accuracy: 0.8176\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4391 - accuracy: 0.8395 - val_loss: 0.4805 - val_accuracy: 0.8243\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4918 - accuracy: 0.8260 - val_loss: 0.4544 - val_accuracy: 0.8378\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5151 - accuracy: 0.7973 - val_loss: 0.4376 - val_accuracy: 0.8514\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4588 - accuracy: 0.8361 - val_loss: 0.4509 - val_accuracy: 0.8378\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4738 - accuracy: 0.8378 - val_loss: 0.4573 - val_accuracy: 0.8108\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.8057 - val_loss: 0.4483 - val_accuracy: 0.8311\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.7855 - val_loss: 0.4555 - val_accuracy: 0.8378\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5059 - accuracy: 0.8091 - val_loss: 0.4687 - val_accuracy: 0.8176\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4783 - accuracy: 0.8243 - val_loss: 0.4544 - val_accuracy: 0.8311\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4908 - accuracy: 0.8345 - val_loss: 0.4618 - val_accuracy: 0.8108\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4729 - accuracy: 0.8260 - val_loss: 0.4564 - val_accuracy: 0.8446\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.8176 - val_loss: 0.4549 - val_accuracy: 0.8378\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5051 - accuracy: 0.8125 - val_loss: 0.4645 - val_accuracy: 0.8311\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4999 - accuracy: 0.8226 - val_loss: 0.4598 - val_accuracy: 0.8243\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4678 - accuracy: 0.8243 - val_loss: 0.4725 - val_accuracy: 0.8311\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.8243 - val_loss: 0.4660 - val_accuracy: 0.8311\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4598 - accuracy: 0.8159 - val_loss: 0.5050 - val_accuracy: 0.8108\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4550 - accuracy: 0.8209 - val_loss: 0.4738 - val_accuracy: 0.8243\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4810 - accuracy: 0.8176 - val_loss: 0.4944 - val_accuracy: 0.8108\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4971 - accuracy: 0.8193 - val_loss: 0.4874 - val_accuracy: 0.8108\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4755 - accuracy: 0.8260 - val_loss: 0.4903 - val_accuracy: 0.8108\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4786 - accuracy: 0.8226 - val_loss: 0.4812 - val_accuracy: 0.8108\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4908 - accuracy: 0.8311 - val_loss: 0.4741 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5036 - accuracy: 0.8328 - val_loss: 0.4859 - val_accuracy: 0.8176\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.8277 - val_loss: 0.4841 - val_accuracy: 0.8108\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4289 - accuracy: 0.8328 - val_loss: 0.4778 - val_accuracy: 0.8311\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.8243 - val_loss: 0.4848 - val_accuracy: 0.8176\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8176 - val_loss: 0.4830 - val_accuracy: 0.8243\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4496 - accuracy: 0.8243 - val_loss: 0.4838 - val_accuracy: 0.7973\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5325 - accuracy: 0.7922 - val_loss: 0.4947 - val_accuracy: 0.8176\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.8497 - val_loss: 0.4824 - val_accuracy: 0.8378\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5251 - accuracy: 0.8176 - val_loss: 0.4734 - val_accuracy: 0.8243\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4856 - accuracy: 0.8395 - val_loss: 0.4703 - val_accuracy: 0.8176\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5057 - accuracy: 0.8108 - val_loss: 0.4969 - val_accuracy: 0.8108\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4683 - accuracy: 0.8108 - val_loss: 0.5041 - val_accuracy: 0.8041\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4639 - accuracy: 0.8243 - val_loss: 0.5065 - val_accuracy: 0.8041\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4837 - accuracy: 0.8176 - val_loss: 0.4810 - val_accuracy: 0.8243\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4963 - accuracy: 0.8209 - val_loss: 0.4975 - val_accuracy: 0.7973\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4500 - accuracy: 0.8311 - val_loss: 0.4952 - val_accuracy: 0.7838\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4930 - accuracy: 0.8057 - val_loss: 0.5330 - val_accuracy: 0.8041\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5015 - accuracy: 0.7939 - val_loss: 0.5137 - val_accuracy: 0.8108\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4540 - accuracy: 0.8682 - val_loss: 0.5012 - val_accuracy: 0.7905\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5435 - accuracy: 0.8142 - val_loss: 0.5052 - val_accuracy: 0.8041\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5044 - accuracy: 0.8125 - val_loss: 0.4983 - val_accuracy: 0.8041\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4661 - accuracy: 0.8243 - val_loss: 0.4885 - val_accuracy: 0.8041\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4985 - accuracy: 0.8159 - val_loss: 0.4924 - val_accuracy: 0.8108\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4667 - accuracy: 0.8209 - val_loss: 0.4754 - val_accuracy: 0.8311\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.8024 - val_loss: 0.4822 - val_accuracy: 0.8108\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5025 - accuracy: 0.8074 - val_loss: 0.4969 - val_accuracy: 0.8041\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.8294 - val_loss: 0.4905 - val_accuracy: 0.7973\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5387 - accuracy: 0.7889 - val_loss: 0.4760 - val_accuracy: 0.8041\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4550 - accuracy: 0.8429 - val_loss: 0.4948 - val_accuracy: 0.7973\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5076 - accuracy: 0.8294 - val_loss: 0.5022 - val_accuracy: 0.8108\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4960 - accuracy: 0.8057 - val_loss: 0.4771 - val_accuracy: 0.8041\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5398 - accuracy: 0.7855 - val_loss: 0.4854 - val_accuracy: 0.7973\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5126 - accuracy: 0.8260 - val_loss: 0.4985 - val_accuracy: 0.8041\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5227 - accuracy: 0.8209 - val_loss: 0.4890 - val_accuracy: 0.8041\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4681 - accuracy: 0.8193 - val_loss: 0.5014 - val_accuracy: 0.8041\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4322 - accuracy: 0.8378 - val_loss: 0.5107 - val_accuracy: 0.8041\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.8193 - val_loss: 0.5064 - val_accuracy: 0.8108\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4776 - accuracy: 0.8057 - val_loss: 0.5099 - val_accuracy: 0.7973\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4571 - accuracy: 0.8361 - val_loss: 0.5015 - val_accuracy: 0.7973\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4930 - accuracy: 0.8294 - val_loss: 0.5092 - val_accuracy: 0.8041\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.8446 - val_loss: 0.4975 - val_accuracy: 0.7973\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.7973\n",
            "5/5 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bb6f49edcfc3>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 6s 13ms/step - loss: 1.8526 - accuracy: 0.4780 - val_loss: 1.4253 - val_accuracy: 0.5338\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6161 - accuracy: 0.5439 - val_loss: 1.4285 - val_accuracy: 0.5473\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.6363 - accuracy: 0.4780 - val_loss: 1.4014 - val_accuracy: 0.5473\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.5069 - accuracy: 0.5000 - val_loss: 1.3680 - val_accuracy: 0.5473\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.4907 - accuracy: 0.4966 - val_loss: 1.3309 - val_accuracy: 0.5473\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.4195 - accuracy: 0.4983 - val_loss: 1.3029 - val_accuracy: 0.5473\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3561 - accuracy: 0.5220 - val_loss: 1.2789 - val_accuracy: 0.5473\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3161 - accuracy: 0.5456 - val_loss: 1.2567 - val_accuracy: 0.5473\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2772 - accuracy: 0.5456 - val_loss: 1.2362 - val_accuracy: 0.5473\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2540 - accuracy: 0.5118 - val_loss: 1.2154 - val_accuracy: 0.5541\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2197 - accuracy: 0.5338 - val_loss: 1.1950 - val_accuracy: 0.5541\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2186 - accuracy: 0.5118 - val_loss: 1.1758 - val_accuracy: 0.5541\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1802 - accuracy: 0.5253 - val_loss: 1.1561 - val_accuracy: 0.6014\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.1448 - accuracy: 0.5709 - val_loss: 1.1355 - val_accuracy: 0.6351\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1273 - accuracy: 0.5591 - val_loss: 1.1137 - val_accuracy: 0.6486\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1172 - accuracy: 0.5101 - val_loss: 1.0963 - val_accuracy: 0.6284\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0927 - accuracy: 0.5304 - val_loss: 1.0784 - val_accuracy: 0.6351\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.0716 - accuracy: 0.5524 - val_loss: 1.0600 - val_accuracy: 0.6149\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.0519 - accuracy: 0.5372 - val_loss: 1.0379 - val_accuracy: 0.6622\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.0320 - accuracy: 0.5591 - val_loss: 1.0168 - val_accuracy: 0.6689\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0133 - accuracy: 0.5541 - val_loss: 0.9986 - val_accuracy: 0.6622\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9957 - accuracy: 0.5372 - val_loss: 0.9794 - val_accuracy: 0.6689\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9743 - accuracy: 0.5726 - val_loss: 0.9611 - val_accuracy: 0.6622\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.9524 - accuracy: 0.5794 - val_loss: 0.9389 - val_accuracy: 0.6689\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.9461 - accuracy: 0.5709 - val_loss: 0.9183 - val_accuracy: 0.6689\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.9283 - accuracy: 0.5845 - val_loss: 0.9047 - val_accuracy: 0.7027\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9024 - accuracy: 0.5946 - val_loss: 0.8862 - val_accuracy: 0.6757\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9101 - accuracy: 0.5760 - val_loss: 0.8734 - val_accuracy: 0.6892\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8875 - accuracy: 0.5878 - val_loss: 0.8613 - val_accuracy: 0.7162\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8806 - accuracy: 0.5693 - val_loss: 0.8451 - val_accuracy: 0.7095\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8871 - accuracy: 0.5405 - val_loss: 0.8378 - val_accuracy: 0.7027\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8585 - accuracy: 0.5895 - val_loss: 0.8095 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8427 - accuracy: 0.6098 - val_loss: 0.7903 - val_accuracy: 0.7432\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8302 - accuracy: 0.6030 - val_loss: 0.7754 - val_accuracy: 0.7432\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8048 - accuracy: 0.6182 - val_loss: 0.7468 - val_accuracy: 0.7635\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8033 - accuracy: 0.6385 - val_loss: 0.7280 - val_accuracy: 0.7838\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7850 - accuracy: 0.6622 - val_loss: 0.7121 - val_accuracy: 0.7838\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8154 - accuracy: 0.5878 - val_loss: 0.7113 - val_accuracy: 0.7568\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7902 - accuracy: 0.6149 - val_loss: 0.7004 - val_accuracy: 0.7568\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7492 - accuracy: 0.6655 - val_loss: 0.6759 - val_accuracy: 0.7568\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7694 - accuracy: 0.6419 - val_loss: 0.6658 - val_accuracy: 0.7635\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7564 - accuracy: 0.6622 - val_loss: 0.6552 - val_accuracy: 0.7635\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7576 - accuracy: 0.6571 - val_loss: 0.6443 - val_accuracy: 0.7635\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7358 - accuracy: 0.7044 - val_loss: 0.6445 - val_accuracy: 0.7770\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7403 - accuracy: 0.6824 - val_loss: 0.6510 - val_accuracy: 0.7838\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.7239 - accuracy: 0.6976 - val_loss: 0.6434 - val_accuracy: 0.7973\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6961 - accuracy: 0.7044 - val_loss: 0.6226 - val_accuracy: 0.7905\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7047 - accuracy: 0.6723 - val_loss: 0.6005 - val_accuracy: 0.7770\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6953 - accuracy: 0.7128 - val_loss: 0.5954 - val_accuracy: 0.7973\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6909 - accuracy: 0.7111 - val_loss: 0.5888 - val_accuracy: 0.7838\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.6875 - accuracy: 0.6909 - val_loss: 0.5872 - val_accuracy: 0.7770\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6942 - accuracy: 0.7027 - val_loss: 0.5685 - val_accuracy: 0.7905\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.6959 - val_loss: 0.5699 - val_accuracy: 0.7973\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.6959 - val_loss: 0.5684 - val_accuracy: 0.8041\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.6959 - val_loss: 0.5683 - val_accuracy: 0.7838\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6623 - accuracy: 0.7179 - val_loss: 0.5567 - val_accuracy: 0.8108\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6988 - accuracy: 0.6926 - val_loss: 0.5630 - val_accuracy: 0.8108\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.7213 - val_loss: 0.5639 - val_accuracy: 0.8041\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.7145 - val_loss: 0.5455 - val_accuracy: 0.8041\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.7196 - val_loss: 0.5449 - val_accuracy: 0.8041\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.7145 - val_loss: 0.5442 - val_accuracy: 0.8176\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6641 - accuracy: 0.7213 - val_loss: 0.5460 - val_accuracy: 0.8108\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.7466 - val_loss: 0.5421 - val_accuracy: 0.8041\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6679 - accuracy: 0.7128 - val_loss: 0.5414 - val_accuracy: 0.7905\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.7264 - val_loss: 0.5396 - val_accuracy: 0.8108\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6578 - accuracy: 0.7331 - val_loss: 0.5323 - val_accuracy: 0.8108\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.7213 - val_loss: 0.5236 - val_accuracy: 0.8108\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6360 - accuracy: 0.7517 - val_loss: 0.5181 - val_accuracy: 0.8176\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6317 - accuracy: 0.7686 - val_loss: 0.5200 - val_accuracy: 0.8176\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6661 - accuracy: 0.6943 - val_loss: 0.5250 - val_accuracy: 0.8311\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6488 - accuracy: 0.7432 - val_loss: 0.5279 - val_accuracy: 0.8176\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6372 - accuracy: 0.7416 - val_loss: 0.5379 - val_accuracy: 0.8108\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6468 - accuracy: 0.7348 - val_loss: 0.5331 - val_accuracy: 0.8041\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6434 - accuracy: 0.7551 - val_loss: 0.5330 - val_accuracy: 0.8041\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6349 - accuracy: 0.7382 - val_loss: 0.5372 - val_accuracy: 0.8108\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6677 - accuracy: 0.7128 - val_loss: 0.5301 - val_accuracy: 0.8176\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6446 - accuracy: 0.7145 - val_loss: 0.5267 - val_accuracy: 0.7973\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6331 - accuracy: 0.7365 - val_loss: 0.5226 - val_accuracy: 0.7905\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7703 - val_loss: 0.5105 - val_accuracy: 0.7838\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6444 - accuracy: 0.7314 - val_loss: 0.5075 - val_accuracy: 0.7973\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6436 - accuracy: 0.7331 - val_loss: 0.5094 - val_accuracy: 0.8108\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6426 - accuracy: 0.7534 - val_loss: 0.5147 - val_accuracy: 0.8311\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.7247 - val_loss: 0.5220 - val_accuracy: 0.8041\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5995 - accuracy: 0.7889 - val_loss: 0.5068 - val_accuracy: 0.8311\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6311 - accuracy: 0.7432 - val_loss: 0.5060 - val_accuracy: 0.8243\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6094 - accuracy: 0.7720 - val_loss: 0.5064 - val_accuracy: 0.8041\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.7416 - val_loss: 0.4991 - val_accuracy: 0.8311\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.7618 - val_loss: 0.4790 - val_accuracy: 0.8446\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6004 - accuracy: 0.7601 - val_loss: 0.4806 - val_accuracy: 0.8243\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6185 - accuracy: 0.7551 - val_loss: 0.4850 - val_accuracy: 0.8378\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6435 - accuracy: 0.7196 - val_loss: 0.4866 - val_accuracy: 0.8243\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6313 - accuracy: 0.7601 - val_loss: 0.4820 - val_accuracy: 0.8514\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.7382 - val_loss: 0.4942 - val_accuracy: 0.8446\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6199 - accuracy: 0.7466 - val_loss: 0.4977 - val_accuracy: 0.8311\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7483 - val_loss: 0.4943 - val_accuracy: 0.8176\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6424 - accuracy: 0.7416 - val_loss: 0.5019 - val_accuracy: 0.8243\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5979 - accuracy: 0.7770 - val_loss: 0.5010 - val_accuracy: 0.8311\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6106 - accuracy: 0.7821 - val_loss: 0.4910 - val_accuracy: 0.8108\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5445 - accuracy: 0.7838 - val_loss: 0.4794 - val_accuracy: 0.8176\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6407 - accuracy: 0.7382 - val_loss: 0.4839 - val_accuracy: 0.8581\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6087 - accuracy: 0.7618 - val_loss: 0.4915 - val_accuracy: 0.8243\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6212 - accuracy: 0.7382 - val_loss: 0.4993 - val_accuracy: 0.8311\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6051 - accuracy: 0.7618 - val_loss: 0.4945 - val_accuracy: 0.8041\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5963 - accuracy: 0.7720 - val_loss: 0.4917 - val_accuracy: 0.8243\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5726 - accuracy: 0.7686 - val_loss: 0.4757 - val_accuracy: 0.8108\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7534 - val_loss: 0.4788 - val_accuracy: 0.8446\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6031 - accuracy: 0.7382 - val_loss: 0.4813 - val_accuracy: 0.8446\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6234 - accuracy: 0.7382 - val_loss: 0.4768 - val_accuracy: 0.8311\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5844 - accuracy: 0.7601 - val_loss: 0.4778 - val_accuracy: 0.8108\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7889 - val_loss: 0.4658 - val_accuracy: 0.8378\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5943 - accuracy: 0.7584 - val_loss: 0.4678 - val_accuracy: 0.8514\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6243 - accuracy: 0.7736 - val_loss: 0.4748 - val_accuracy: 0.8446\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6143 - accuracy: 0.7568 - val_loss: 0.4722 - val_accuracy: 0.8378\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5846 - accuracy: 0.7838 - val_loss: 0.4694 - val_accuracy: 0.8108\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7905 - val_loss: 0.4576 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6022 - accuracy: 0.7466 - val_loss: 0.4621 - val_accuracy: 0.8311\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.7618 - val_loss: 0.4597 - val_accuracy: 0.8378\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6420 - accuracy: 0.7517 - val_loss: 0.4671 - val_accuracy: 0.8446\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5857 - accuracy: 0.7652 - val_loss: 0.4627 - val_accuracy: 0.8311\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.8041 - val_loss: 0.4555 - val_accuracy: 0.8514\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5980 - accuracy: 0.7889 - val_loss: 0.4656 - val_accuracy: 0.8311\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.7517 - val_loss: 0.4668 - val_accuracy: 0.8243\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5752 - accuracy: 0.7753 - val_loss: 0.4591 - val_accuracy: 0.8514\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6201 - accuracy: 0.7703 - val_loss: 0.4622 - val_accuracy: 0.8649\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5953 - accuracy: 0.7618 - val_loss: 0.4644 - val_accuracy: 0.8446\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5949 - accuracy: 0.7534 - val_loss: 0.4701 - val_accuracy: 0.8514\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5920 - accuracy: 0.7838 - val_loss: 0.4646 - val_accuracy: 0.8378\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5950 - accuracy: 0.7568 - val_loss: 0.4625 - val_accuracy: 0.8446\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5589 - accuracy: 0.7905 - val_loss: 0.4516 - val_accuracy: 0.8716\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7821 - val_loss: 0.4419 - val_accuracy: 0.8581\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.7483 - val_loss: 0.4397 - val_accuracy: 0.8581\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5888 - accuracy: 0.7584 - val_loss: 0.4443 - val_accuracy: 0.8446\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5740 - accuracy: 0.7889 - val_loss: 0.4334 - val_accuracy: 0.8716\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6084 - accuracy: 0.7703 - val_loss: 0.4494 - val_accuracy: 0.8514\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5864 - accuracy: 0.7855 - val_loss: 0.4435 - val_accuracy: 0.8716\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5856 - accuracy: 0.7449 - val_loss: 0.4414 - val_accuracy: 0.8581\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7838 - val_loss: 0.4419 - val_accuracy: 0.8446\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5846 - accuracy: 0.7720 - val_loss: 0.4425 - val_accuracy: 0.8581\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6234 - accuracy: 0.7500 - val_loss: 0.4486 - val_accuracy: 0.8514\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7855 - val_loss: 0.4434 - val_accuracy: 0.8446\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5875 - accuracy: 0.7804 - val_loss: 0.4403 - val_accuracy: 0.8378\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6051 - accuracy: 0.7652 - val_loss: 0.4554 - val_accuracy: 0.8581\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5891 - accuracy: 0.7568 - val_loss: 0.4560 - val_accuracy: 0.8446\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5738 - accuracy: 0.7821 - val_loss: 0.4497 - val_accuracy: 0.8311\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.8057 - val_loss: 0.4385 - val_accuracy: 0.8649\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5285 - accuracy: 0.7956 - val_loss: 0.4305 - val_accuracy: 0.8784\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5657 - accuracy: 0.7584 - val_loss: 0.4258 - val_accuracy: 0.8716\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5602 - accuracy: 0.7720 - val_loss: 0.4383 - val_accuracy: 0.8514\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5813 - accuracy: 0.7990 - val_loss: 0.4428 - val_accuracy: 0.8311\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5890 - accuracy: 0.7838 - val_loss: 0.4391 - val_accuracy: 0.8514\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5773 - accuracy: 0.7618 - val_loss: 0.4353 - val_accuracy: 0.8716\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5434 - accuracy: 0.7889 - val_loss: 0.4314 - val_accuracy: 0.8581\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5786 - accuracy: 0.7770 - val_loss: 0.4401 - val_accuracy: 0.8581\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7753 - val_loss: 0.4413 - val_accuracy: 0.8581\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.8091 - val_loss: 0.4383 - val_accuracy: 0.8514\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5602 - accuracy: 0.8193 - val_loss: 0.4406 - val_accuracy: 0.8514\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6094 - accuracy: 0.7601 - val_loss: 0.4365 - val_accuracy: 0.8446\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5804 - accuracy: 0.7686 - val_loss: 0.4455 - val_accuracy: 0.8446\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6036 - accuracy: 0.7618 - val_loss: 0.4526 - val_accuracy: 0.8378\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5750 - accuracy: 0.7618 - val_loss: 0.4427 - val_accuracy: 0.8581\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7905 - val_loss: 0.4455 - val_accuracy: 0.8581\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5421 - accuracy: 0.7956 - val_loss: 0.4292 - val_accuracy: 0.8649\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.8159 - val_loss: 0.4407 - val_accuracy: 0.8514\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6212 - accuracy: 0.7432 - val_loss: 0.4238 - val_accuracy: 0.8581\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5929 - accuracy: 0.7770 - val_loss: 0.4274 - val_accuracy: 0.8581\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5792 - accuracy: 0.7652 - val_loss: 0.4218 - val_accuracy: 0.8784\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5667 - accuracy: 0.7720 - val_loss: 0.4190 - val_accuracy: 0.8784\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5667 - accuracy: 0.7703 - val_loss: 0.4245 - val_accuracy: 0.8649\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5720 - accuracy: 0.7821 - val_loss: 0.4226 - val_accuracy: 0.8784\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5742 - accuracy: 0.7770 - val_loss: 0.4359 - val_accuracy: 0.8581\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.7821 - val_loss: 0.4347 - val_accuracy: 0.8716\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5291 - accuracy: 0.8108 - val_loss: 0.4237 - val_accuracy: 0.8649\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.7922 - val_loss: 0.4302 - val_accuracy: 0.8581\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5668 - accuracy: 0.7855 - val_loss: 0.4339 - val_accuracy: 0.8649\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5497 - accuracy: 0.7905 - val_loss: 0.4303 - val_accuracy: 0.8581\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5669 - accuracy: 0.7939 - val_loss: 0.4353 - val_accuracy: 0.8446\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5521 - accuracy: 0.7973 - val_loss: 0.4380 - val_accuracy: 0.8446\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5755 - accuracy: 0.7872 - val_loss: 0.4257 - val_accuracy: 0.8716\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5643 - accuracy: 0.8007 - val_loss: 0.4519 - val_accuracy: 0.8311\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5810 - accuracy: 0.7635 - val_loss: 0.4416 - val_accuracy: 0.8446\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5829 - accuracy: 0.7635 - val_loss: 0.4355 - val_accuracy: 0.8581\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5608 - accuracy: 0.7770 - val_loss: 0.4230 - val_accuracy: 0.8784\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6103 - accuracy: 0.7686 - val_loss: 0.4242 - val_accuracy: 0.8716\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5974 - accuracy: 0.7905 - val_loss: 0.4361 - val_accuracy: 0.8716\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5972 - accuracy: 0.7584 - val_loss: 0.4311 - val_accuracy: 0.8716\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.7956 - val_loss: 0.4139 - val_accuracy: 0.8919\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5393 - accuracy: 0.8091 - val_loss: 0.4015 - val_accuracy: 0.8986\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5699 - accuracy: 0.7770 - val_loss: 0.4089 - val_accuracy: 0.8784\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5591 - accuracy: 0.7990 - val_loss: 0.4086 - val_accuracy: 0.8581\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.7703 - val_loss: 0.4136 - val_accuracy: 0.8649\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6014 - accuracy: 0.7483 - val_loss: 0.4119 - val_accuracy: 0.8649\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.8024 - val_loss: 0.4046 - val_accuracy: 0.8514\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5762 - accuracy: 0.7922 - val_loss: 0.4149 - val_accuracy: 0.8514\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5528 - accuracy: 0.8024 - val_loss: 0.4172 - val_accuracy: 0.8851\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5488 - accuracy: 0.7804 - val_loss: 0.4063 - val_accuracy: 0.8649\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5453 - accuracy: 0.7838 - val_loss: 0.3983 - val_accuracy: 0.8784\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5437 - accuracy: 0.7990 - val_loss: 0.4009 - val_accuracy: 0.8716\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5532 - accuracy: 0.8074 - val_loss: 0.4113 - val_accuracy: 0.8581\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.6035 - accuracy: 0.7449 - val_loss: 0.4114 - val_accuracy: 0.8851\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5514 - accuracy: 0.7855 - val_loss: 0.4100 - val_accuracy: 0.8784\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5482 - accuracy: 0.7872 - val_loss: 0.4102 - val_accuracy: 0.8986\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5606 - accuracy: 0.7838 - val_loss: 0.4100 - val_accuracy: 0.8784\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5437 - accuracy: 0.8041 - val_loss: 0.4046 - val_accuracy: 0.8649\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5765 - accuracy: 0.7905 - val_loss: 0.4082 - val_accuracy: 0.8851\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5454 - accuracy: 0.8108 - val_loss: 0.4158 - val_accuracy: 0.8851\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.8007 - val_loss: 0.4077 - val_accuracy: 0.8784\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5598 - accuracy: 0.7838 - val_loss: 0.4102 - val_accuracy: 0.8851\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5629 - accuracy: 0.7787 - val_loss: 0.4119 - val_accuracy: 0.8649\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.8007 - val_loss: 0.4081 - val_accuracy: 0.8784\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5544 - accuracy: 0.7990 - val_loss: 0.4109 - val_accuracy: 0.8716\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.8193 - val_loss: 0.4085 - val_accuracy: 0.8851\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5383 - accuracy: 0.8041 - val_loss: 0.3996 - val_accuracy: 0.8784\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5656 - accuracy: 0.7889 - val_loss: 0.4009 - val_accuracy: 0.8784\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5554 - accuracy: 0.7889 - val_loss: 0.4015 - val_accuracy: 0.8851\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.7956 - val_loss: 0.4034 - val_accuracy: 0.8919\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5238 - accuracy: 0.8041 - val_loss: 0.4015 - val_accuracy: 0.8784\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5575 - accuracy: 0.7922 - val_loss: 0.4150 - val_accuracy: 0.8446\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5722 - accuracy: 0.7821 - val_loss: 0.4229 - val_accuracy: 0.8514\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5223 - accuracy: 0.8091 - val_loss: 0.4078 - val_accuracy: 0.8649\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5138 - accuracy: 0.8091 - val_loss: 0.4076 - val_accuracy: 0.8581\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5484 - accuracy: 0.8041 - val_loss: 0.4126 - val_accuracy: 0.8649\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5393 - accuracy: 0.7855 - val_loss: 0.4188 - val_accuracy: 0.8446\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5233 - accuracy: 0.7939 - val_loss: 0.4192 - val_accuracy: 0.8446\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5297 - accuracy: 0.7956 - val_loss: 0.4183 - val_accuracy: 0.8581\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5473 - accuracy: 0.7939 - val_loss: 0.4206 - val_accuracy: 0.8716\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5748 - accuracy: 0.7669 - val_loss: 0.4190 - val_accuracy: 0.8851\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5727 - accuracy: 0.7804 - val_loss: 0.4095 - val_accuracy: 0.8716\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5574 - accuracy: 0.7669 - val_loss: 0.4130 - val_accuracy: 0.8716\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5234 - accuracy: 0.7973 - val_loss: 0.4068 - val_accuracy: 0.8784\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5607 - accuracy: 0.7821 - val_loss: 0.4026 - val_accuracy: 0.8716\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6005 - accuracy: 0.7736 - val_loss: 0.4072 - val_accuracy: 0.8784\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5685 - accuracy: 0.7736 - val_loss: 0.4069 - val_accuracy: 0.8784\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5624 - accuracy: 0.7838 - val_loss: 0.4053 - val_accuracy: 0.8649\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5382 - accuracy: 0.8074 - val_loss: 0.4026 - val_accuracy: 0.8716\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7939 - val_loss: 0.3993 - val_accuracy: 0.8784\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5562 - accuracy: 0.8091 - val_loss: 0.3995 - val_accuracy: 0.8649\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5733 - accuracy: 0.7821 - val_loss: 0.3998 - val_accuracy: 0.8851\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.7973 - val_loss: 0.4060 - val_accuracy: 0.8649\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.8007 - val_loss: 0.3915 - val_accuracy: 0.8784\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5444 - accuracy: 0.7973 - val_loss: 0.3958 - val_accuracy: 0.8716\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.8024 - val_loss: 0.4023 - val_accuracy: 0.8649\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5133 - accuracy: 0.7990 - val_loss: 0.4026 - val_accuracy: 0.8514\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5321 - accuracy: 0.8057 - val_loss: 0.3978 - val_accuracy: 0.8514\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5521 - accuracy: 0.7872 - val_loss: 0.3932 - val_accuracy: 0.8716\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7973 - val_loss: 0.3990 - val_accuracy: 0.8716\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7922 - val_loss: 0.4028 - val_accuracy: 0.8784\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5433 - accuracy: 0.8108 - val_loss: 0.4037 - val_accuracy: 0.8716\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5570 - accuracy: 0.7990 - val_loss: 0.4035 - val_accuracy: 0.8581\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5203 - accuracy: 0.8176 - val_loss: 0.4067 - val_accuracy: 0.8649\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5197 - accuracy: 0.8024 - val_loss: 0.4063 - val_accuracy: 0.8378\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5550 - accuracy: 0.8007 - val_loss: 0.4063 - val_accuracy: 0.8446\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5458 - accuracy: 0.7703 - val_loss: 0.4135 - val_accuracy: 0.8649\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5552 - accuracy: 0.8142 - val_loss: 0.4152 - val_accuracy: 0.8716\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.8311 - val_loss: 0.4184 - val_accuracy: 0.8581\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.7990 - val_loss: 0.4081 - val_accuracy: 0.8716\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5557 - accuracy: 0.8007 - val_loss: 0.4194 - val_accuracy: 0.8581\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5175 - accuracy: 0.8108 - val_loss: 0.4133 - val_accuracy: 0.8514\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5663 - accuracy: 0.7889 - val_loss: 0.4117 - val_accuracy: 0.8649\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5342 - accuracy: 0.8125 - val_loss: 0.4044 - val_accuracy: 0.8581\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5590 - accuracy: 0.7905 - val_loss: 0.4005 - val_accuracy: 0.8716\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7990 - val_loss: 0.4027 - val_accuracy: 0.8784\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5419 - accuracy: 0.7905 - val_loss: 0.4039 - val_accuracy: 0.8716\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5496 - accuracy: 0.8041 - val_loss: 0.4167 - val_accuracy: 0.8378\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5158 - accuracy: 0.8311 - val_loss: 0.4074 - val_accuracy: 0.8514\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5625 - accuracy: 0.7905 - val_loss: 0.4040 - val_accuracy: 0.8716\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.8041 - val_loss: 0.3941 - val_accuracy: 0.8784\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5125 - accuracy: 0.7939 - val_loss: 0.3879 - val_accuracy: 0.8649\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.8108 - val_loss: 0.3890 - val_accuracy: 0.8649\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.8007 - val_loss: 0.4034 - val_accuracy: 0.8581\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5458 - accuracy: 0.7855 - val_loss: 0.3960 - val_accuracy: 0.8581\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5740 - accuracy: 0.7956 - val_loss: 0.3995 - val_accuracy: 0.8784\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5430 - accuracy: 0.8041 - val_loss: 0.4028 - val_accuracy: 0.8649\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5287 - accuracy: 0.8125 - val_loss: 0.4089 - val_accuracy: 0.8581\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5533 - accuracy: 0.7770 - val_loss: 0.4143 - val_accuracy: 0.8581\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5304 - accuracy: 0.7939 - val_loss: 0.4171 - val_accuracy: 0.8649\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5241 - accuracy: 0.8007 - val_loss: 0.4087 - val_accuracy: 0.8649\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5491 - accuracy: 0.7770 - val_loss: 0.4033 - val_accuracy: 0.8581\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5686 - accuracy: 0.7720 - val_loss: 0.4071 - val_accuracy: 0.8716\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5332 - accuracy: 0.8125 - val_loss: 0.4011 - val_accuracy: 0.8581\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5637 - accuracy: 0.7905 - val_loss: 0.4064 - val_accuracy: 0.8649\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5324 - accuracy: 0.8277 - val_loss: 0.4045 - val_accuracy: 0.8581\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5145 - accuracy: 0.8176 - val_loss: 0.3929 - val_accuracy: 0.8514\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5192 - accuracy: 0.8209 - val_loss: 0.4018 - val_accuracy: 0.8581\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5414 - accuracy: 0.8159 - val_loss: 0.4067 - val_accuracy: 0.8581\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.8108 - val_loss: 0.3924 - val_accuracy: 0.8514\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5603 - accuracy: 0.7973 - val_loss: 0.4058 - val_accuracy: 0.8716\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5463 - accuracy: 0.7855 - val_loss: 0.3964 - val_accuracy: 0.8581\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.7905 - val_loss: 0.3893 - val_accuracy: 0.8649\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.7872 - val_loss: 0.3925 - val_accuracy: 0.8784\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.8108 - val_loss: 0.3909 - val_accuracy: 0.8784\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5657 - accuracy: 0.7905 - val_loss: 0.4018 - val_accuracy: 0.8514\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5599 - accuracy: 0.7838 - val_loss: 0.4052 - val_accuracy: 0.8649\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5408 - accuracy: 0.8007 - val_loss: 0.4004 - val_accuracy: 0.8716\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5262 - accuracy: 0.8057 - val_loss: 0.4058 - val_accuracy: 0.8378\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5897 - accuracy: 0.7804 - val_loss: 0.4032 - val_accuracy: 0.8649\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5845 - accuracy: 0.7720 - val_loss: 0.4067 - val_accuracy: 0.8581\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5460 - accuracy: 0.7956 - val_loss: 0.4054 - val_accuracy: 0.8716\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5201 - accuracy: 0.8176 - val_loss: 0.3927 - val_accuracy: 0.8919\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4980 - accuracy: 0.8176 - val_loss: 0.3980 - val_accuracy: 0.8784\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4992 - accuracy: 0.7990 - val_loss: 0.3906 - val_accuracy: 0.8581\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5326 - accuracy: 0.7990 - val_loss: 0.3974 - val_accuracy: 0.8514\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5376 - accuracy: 0.7939 - val_loss: 0.3948 - val_accuracy: 0.8716\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5606 - accuracy: 0.7905 - val_loss: 0.4034 - val_accuracy: 0.8446\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5570 - accuracy: 0.7804 - val_loss: 0.4218 - val_accuracy: 0.8446\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5444 - accuracy: 0.7905 - val_loss: 0.4263 - val_accuracy: 0.8649\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5380 - accuracy: 0.7905 - val_loss: 0.4167 - val_accuracy: 0.8649\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5437 - accuracy: 0.7821 - val_loss: 0.4222 - val_accuracy: 0.8446\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5618 - accuracy: 0.7939 - val_loss: 0.4099 - val_accuracy: 0.8649\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.7956 - val_loss: 0.4093 - val_accuracy: 0.8581\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5347 - accuracy: 0.8057 - val_loss: 0.4111 - val_accuracy: 0.8581\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.7889 - val_loss: 0.4055 - val_accuracy: 0.8581\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8226 - val_loss: 0.4003 - val_accuracy: 0.8649\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5349 - accuracy: 0.7939 - val_loss: 0.4077 - val_accuracy: 0.8581\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.8007 - val_loss: 0.4056 - val_accuracy: 0.8784\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5226 - accuracy: 0.8193 - val_loss: 0.4140 - val_accuracy: 0.8446\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.7821 - val_loss: 0.4046 - val_accuracy: 0.8716\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5251 - accuracy: 0.7973 - val_loss: 0.4045 - val_accuracy: 0.8649\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5206 - accuracy: 0.8243 - val_loss: 0.4010 - val_accuracy: 0.8716\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.8345 - val_loss: 0.4070 - val_accuracy: 0.8446\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5527 - accuracy: 0.7703 - val_loss: 0.4070 - val_accuracy: 0.8649\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5339 - accuracy: 0.7855 - val_loss: 0.4049 - val_accuracy: 0.8649\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5389 - accuracy: 0.8057 - val_loss: 0.4021 - val_accuracy: 0.8649\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5134 - accuracy: 0.7973 - val_loss: 0.3891 - val_accuracy: 0.8784\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5418 - accuracy: 0.8108 - val_loss: 0.3835 - val_accuracy: 0.8649\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4963 - accuracy: 0.8226 - val_loss: 0.3873 - val_accuracy: 0.8716\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5294 - accuracy: 0.7973 - val_loss: 0.3956 - val_accuracy: 0.8514\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5437 - accuracy: 0.7905 - val_loss: 0.3826 - val_accuracy: 0.8851\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5288 - accuracy: 0.7956 - val_loss: 0.3799 - val_accuracy: 0.8649\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.8294 - val_loss: 0.3833 - val_accuracy: 0.8649\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5718 - accuracy: 0.7753 - val_loss: 0.3944 - val_accuracy: 0.8581\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5490 - accuracy: 0.7922 - val_loss: 0.3955 - val_accuracy: 0.8919\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.8193 - val_loss: 0.4025 - val_accuracy: 0.8851\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5254 - accuracy: 0.8074 - val_loss: 0.3932 - val_accuracy: 0.8784\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5666 - accuracy: 0.7770 - val_loss: 0.3909 - val_accuracy: 0.8514\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.8176 - val_loss: 0.3979 - val_accuracy: 0.8649\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5131 - accuracy: 0.8142 - val_loss: 0.3980 - val_accuracy: 0.8649\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.8057 - val_loss: 0.3904 - val_accuracy: 0.8649\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5343 - accuracy: 0.7922 - val_loss: 0.4002 - val_accuracy: 0.8514\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7990 - val_loss: 0.3998 - val_accuracy: 0.8716\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5372 - accuracy: 0.7838 - val_loss: 0.4254 - val_accuracy: 0.8378\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5055 - accuracy: 0.8260 - val_loss: 0.4176 - val_accuracy: 0.8446\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5612 - accuracy: 0.7973 - val_loss: 0.4191 - val_accuracy: 0.8446\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.8243 - val_loss: 0.4084 - val_accuracy: 0.8514\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5474 - accuracy: 0.7922 - val_loss: 0.4149 - val_accuracy: 0.8649\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.8277 - val_loss: 0.4105 - val_accuracy: 0.8716\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5572 - accuracy: 0.7821 - val_loss: 0.3977 - val_accuracy: 0.8784\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5427 - accuracy: 0.8024 - val_loss: 0.4209 - val_accuracy: 0.8649\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5330 - accuracy: 0.8007 - val_loss: 0.4010 - val_accuracy: 0.8784\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5344 - accuracy: 0.7922 - val_loss: 0.4036 - val_accuracy: 0.8784\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4932 - accuracy: 0.8361 - val_loss: 0.4087 - val_accuracy: 0.8581\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5296 - accuracy: 0.7973 - val_loss: 0.4095 - val_accuracy: 0.8581\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5166 - accuracy: 0.7872 - val_loss: 0.4067 - val_accuracy: 0.8716\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5478 - accuracy: 0.7922 - val_loss: 0.4132 - val_accuracy: 0.8581\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5329 - accuracy: 0.8007 - val_loss: 0.4314 - val_accuracy: 0.8514\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5188 - accuracy: 0.8024 - val_loss: 0.4179 - val_accuracy: 0.8514\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5620 - accuracy: 0.7939 - val_loss: 0.4097 - val_accuracy: 0.8581\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5101 - accuracy: 0.8226 - val_loss: 0.4143 - val_accuracy: 0.8649\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5165 - accuracy: 0.8007 - val_loss: 0.4137 - val_accuracy: 0.8581\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5544 - accuracy: 0.7804 - val_loss: 0.4178 - val_accuracy: 0.8514\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.7990 - val_loss: 0.3976 - val_accuracy: 0.8649\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.8159 - val_loss: 0.3980 - val_accuracy: 0.8514\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.7939 - val_loss: 0.3902 - val_accuracy: 0.8581\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4881 - accuracy: 0.8345 - val_loss: 0.3950 - val_accuracy: 0.8716\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8226 - val_loss: 0.3930 - val_accuracy: 0.8716\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5695 - accuracy: 0.7635 - val_loss: 0.4080 - val_accuracy: 0.8716\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.7922 - val_loss: 0.3975 - val_accuracy: 0.8716\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5416 - accuracy: 0.8024 - val_loss: 0.3895 - val_accuracy: 0.8649\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5768 - accuracy: 0.7720 - val_loss: 0.3999 - val_accuracy: 0.8649\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.8041 - val_loss: 0.4051 - val_accuracy: 0.8581\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5329 - accuracy: 0.8176 - val_loss: 0.4016 - val_accuracy: 0.8784\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5325 - accuracy: 0.8091 - val_loss: 0.4038 - val_accuracy: 0.8514\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5390 - accuracy: 0.8007 - val_loss: 0.4070 - val_accuracy: 0.8581\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5237 - accuracy: 0.8007 - val_loss: 0.4028 - val_accuracy: 0.8581\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5601 - accuracy: 0.8074 - val_loss: 0.4038 - val_accuracy: 0.8514\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5360 - accuracy: 0.8024 - val_loss: 0.4119 - val_accuracy: 0.8649\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4841 - accuracy: 0.8260 - val_loss: 0.4051 - val_accuracy: 0.8581\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5563 - accuracy: 0.7990 - val_loss: 0.4126 - val_accuracy: 0.8581\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5259 - accuracy: 0.8176 - val_loss: 0.4093 - val_accuracy: 0.8581\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5634 - accuracy: 0.7889 - val_loss: 0.4009 - val_accuracy: 0.8581\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5253 - accuracy: 0.8142 - val_loss: 0.4002 - val_accuracy: 0.8514\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7838 - val_loss: 0.4105 - val_accuracy: 0.8649\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.8007 - val_loss: 0.4138 - val_accuracy: 0.8649\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5691 - accuracy: 0.7686 - val_loss: 0.3967 - val_accuracy: 0.8784\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5455 - accuracy: 0.7905 - val_loss: 0.3967 - val_accuracy: 0.8784\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5145 - accuracy: 0.8209 - val_loss: 0.4039 - val_accuracy: 0.8581\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5130 - accuracy: 0.8193 - val_loss: 0.3940 - val_accuracy: 0.8716\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5164 - accuracy: 0.8193 - val_loss: 0.3884 - val_accuracy: 0.8514\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.7939 - val_loss: 0.3931 - val_accuracy: 0.8514\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4968 - accuracy: 0.8142 - val_loss: 0.3982 - val_accuracy: 0.8514\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5141 - accuracy: 0.8041 - val_loss: 0.3946 - val_accuracy: 0.8446\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5581 - accuracy: 0.7956 - val_loss: 0.4042 - val_accuracy: 0.8446\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.8041 - val_loss: 0.4000 - val_accuracy: 0.8378\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.8277 - val_loss: 0.3945 - val_accuracy: 0.8446\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5493 - accuracy: 0.8074 - val_loss: 0.3939 - val_accuracy: 0.8378\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.8041 - val_loss: 0.3912 - val_accuracy: 0.8446\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.8294 - val_loss: 0.3870 - val_accuracy: 0.8446\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5452 - accuracy: 0.7939 - val_loss: 0.3933 - val_accuracy: 0.8446\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.8125 - val_loss: 0.4027 - val_accuracy: 0.8446\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5232 - accuracy: 0.8125 - val_loss: 0.4051 - val_accuracy: 0.8378\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5304 - accuracy: 0.8142 - val_loss: 0.4213 - val_accuracy: 0.8446\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5584 - accuracy: 0.7804 - val_loss: 0.4027 - val_accuracy: 0.8514\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5118 - accuracy: 0.8074 - val_loss: 0.4037 - val_accuracy: 0.8514\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5138 - accuracy: 0.8159 - val_loss: 0.4064 - val_accuracy: 0.8378\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5154 - accuracy: 0.7973 - val_loss: 0.4060 - val_accuracy: 0.8581\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4931 - accuracy: 0.8159 - val_loss: 0.3981 - val_accuracy: 0.8446\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5129 - accuracy: 0.8108 - val_loss: 0.3983 - val_accuracy: 0.8581\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5217 - accuracy: 0.7973 - val_loss: 0.4066 - val_accuracy: 0.8446\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.7889 - val_loss: 0.4047 - val_accuracy: 0.8446\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5101 - accuracy: 0.7973 - val_loss: 0.4152 - val_accuracy: 0.8581\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5342 - accuracy: 0.7872 - val_loss: 0.4022 - val_accuracy: 0.8649\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5259 - accuracy: 0.7922 - val_loss: 0.4109 - val_accuracy: 0.8514\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5074 - accuracy: 0.8142 - val_loss: 0.4081 - val_accuracy: 0.8243\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5396 - accuracy: 0.7922 - val_loss: 0.4030 - val_accuracy: 0.8243\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5190 - accuracy: 0.7956 - val_loss: 0.4163 - val_accuracy: 0.8311\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5469 - accuracy: 0.7872 - val_loss: 0.4217 - val_accuracy: 0.8378\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 19ms/step - loss: 0.5039 - accuracy: 0.8125 - val_loss: 0.4212 - val_accuracy: 0.8243\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 19ms/step - loss: 0.5137 - accuracy: 0.8142 - val_loss: 0.4102 - val_accuracy: 0.8446\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 19ms/step - loss: 0.5035 - accuracy: 0.8142 - val_loss: 0.4037 - val_accuracy: 0.8378\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 2s 23ms/step - loss: 0.5088 - accuracy: 0.8260 - val_loss: 0.4129 - val_accuracy: 0.8446\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 2s 23ms/step - loss: 0.5269 - accuracy: 0.8057 - val_loss: 0.3976 - val_accuracy: 0.8514\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.5099 - accuracy: 0.8209 - val_loss: 0.3993 - val_accuracy: 0.8581\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.4713 - accuracy: 0.8294 - val_loss: 0.3932 - val_accuracy: 0.8581\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5103 - accuracy: 0.7956 - val_loss: 0.3899 - val_accuracy: 0.8716\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5204 - accuracy: 0.7905 - val_loss: 0.4000 - val_accuracy: 0.8649\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5347 - accuracy: 0.7990 - val_loss: 0.4014 - val_accuracy: 0.8649\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8209 - val_loss: 0.3994 - val_accuracy: 0.8784\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5291 - accuracy: 0.7973 - val_loss: 0.3983 - val_accuracy: 0.8851\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5018 - accuracy: 0.8209 - val_loss: 0.4020 - val_accuracy: 0.8716\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5228 - accuracy: 0.8159 - val_loss: 0.4146 - val_accuracy: 0.8581\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5210 - accuracy: 0.8057 - val_loss: 0.4271 - val_accuracy: 0.8446\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5619 - accuracy: 0.7855 - val_loss: 0.4123 - val_accuracy: 0.8581\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.4889 - accuracy: 0.8226 - val_loss: 0.4004 - val_accuracy: 0.8514\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.4748 - accuracy: 0.8159 - val_loss: 0.3909 - val_accuracy: 0.8716\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 2s 20ms/step - loss: 0.5378 - accuracy: 0.8041 - val_loss: 0.3918 - val_accuracy: 0.8649\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 2s 24ms/step - loss: 0.5487 - accuracy: 0.7753 - val_loss: 0.3970 - val_accuracy: 0.8649\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 20ms/step - loss: 0.5189 - accuracy: 0.8007 - val_loss: 0.3942 - val_accuracy: 0.8649\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5135 - accuracy: 0.8074 - val_loss: 0.3978 - val_accuracy: 0.8649\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5577 - accuracy: 0.7973 - val_loss: 0.4045 - val_accuracy: 0.8649\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5297 - accuracy: 0.8041 - val_loss: 0.4081 - val_accuracy: 0.8581\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5173 - accuracy: 0.8260 - val_loss: 0.4097 - val_accuracy: 0.8649\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.4759 - accuracy: 0.8311 - val_loss: 0.4021 - val_accuracy: 0.8581\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5275 - accuracy: 0.8007 - val_loss: 0.4109 - val_accuracy: 0.8446\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.5693 - accuracy: 0.7838 - val_loss: 0.4029 - val_accuracy: 0.8514\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 19ms/step - loss: 0.5522 - accuracy: 0.7787 - val_loss: 0.3990 - val_accuracy: 0.8716\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5129 - accuracy: 0.8277 - val_loss: 0.4089 - val_accuracy: 0.8716\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 19ms/step - loss: 0.5155 - accuracy: 0.8057 - val_loss: 0.4132 - val_accuracy: 0.8581\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.4979 - accuracy: 0.8328 - val_loss: 0.4013 - val_accuracy: 0.8784\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5088 - accuracy: 0.8209 - val_loss: 0.4040 - val_accuracy: 0.8649\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5322 - accuracy: 0.8159 - val_loss: 0.4122 - val_accuracy: 0.8919\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5143 - accuracy: 0.7956 - val_loss: 0.4069 - val_accuracy: 0.8649\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5474 - accuracy: 0.8125 - val_loss: 0.4070 - val_accuracy: 0.8649\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5029 - accuracy: 0.8226 - val_loss: 0.4005 - val_accuracy: 0.8919\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5165 - accuracy: 0.7973 - val_loss: 0.3898 - val_accuracy: 0.8986\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5489 - accuracy: 0.7770 - val_loss: 0.3954 - val_accuracy: 0.8919\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5172 - accuracy: 0.7838 - val_loss: 0.3925 - val_accuracy: 0.8919\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5671 - accuracy: 0.7720 - val_loss: 0.3994 - val_accuracy: 0.8986\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.4693 - accuracy: 0.8395 - val_loss: 0.3855 - val_accuracy: 0.8784\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5203 - accuracy: 0.7855 - val_loss: 0.3847 - val_accuracy: 0.8986\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.4892 - accuracy: 0.8243 - val_loss: 0.3801 - val_accuracy: 0.8919\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5299 - accuracy: 0.7821 - val_loss: 0.3913 - val_accuracy: 0.8716\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.4624 - accuracy: 0.8294 - val_loss: 0.3964 - val_accuracy: 0.8514\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5083 - accuracy: 0.8024 - val_loss: 0.3889 - val_accuracy: 0.8649\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.5184 - accuracy: 0.7973 - val_loss: 0.3796 - val_accuracy: 0.8919\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.4856 - accuracy: 0.8311 - val_loss: 0.3945 - val_accuracy: 0.8919\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5137 - accuracy: 0.7922 - val_loss: 0.3793 - val_accuracy: 0.8919\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.4897 - accuracy: 0.8074 - val_loss: 0.3803 - val_accuracy: 0.8784\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5187 - accuracy: 0.7990 - val_loss: 0.3836 - val_accuracy: 0.8851\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4993 - accuracy: 0.8091 - val_loss: 0.3844 - val_accuracy: 0.8919\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5027 - accuracy: 0.7973 - val_loss: 0.3832 - val_accuracy: 0.8851\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5078 - accuracy: 0.8260 - val_loss: 0.3917 - val_accuracy: 0.8784\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5162 - accuracy: 0.8108 - val_loss: 0.3936 - val_accuracy: 0.8716\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5126 - accuracy: 0.8091 - val_loss: 0.3876 - val_accuracy: 0.8784\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4586 - accuracy: 0.8378 - val_loss: 0.3816 - val_accuracy: 0.8851\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5431 - accuracy: 0.7703 - val_loss: 0.3899 - val_accuracy: 0.8649\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5231 - accuracy: 0.8125 - val_loss: 0.3763 - val_accuracy: 0.8851\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 20ms/step - loss: 0.5174 - accuracy: 0.8193 - val_loss: 0.3755 - val_accuracy: 0.8919\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.4735 - accuracy: 0.8243 - val_loss: 0.3785 - val_accuracy: 0.8716\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5263 - accuracy: 0.8057 - val_loss: 0.3752 - val_accuracy: 0.8851\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5326 - accuracy: 0.7939 - val_loss: 0.3761 - val_accuracy: 0.8919\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.4949 - accuracy: 0.8193 - val_loss: 0.3739 - val_accuracy: 0.8986\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.4945 - accuracy: 0.8209 - val_loss: 0.3941 - val_accuracy: 0.8581\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5072 - accuracy: 0.8057 - val_loss: 0.3781 - val_accuracy: 0.9054\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5432 - accuracy: 0.7939 - val_loss: 0.3871 - val_accuracy: 0.8919\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5485 - accuracy: 0.7905 - val_loss: 0.3769 - val_accuracy: 0.8919\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5384 - accuracy: 0.8108 - val_loss: 0.3757 - val_accuracy: 0.8919\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5089 - accuracy: 0.8142 - val_loss: 0.3732 - val_accuracy: 0.8919\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5236 - accuracy: 0.8007 - val_loss: 0.3841 - val_accuracy: 0.8851\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5329 - accuracy: 0.8057 - val_loss: 0.3870 - val_accuracy: 0.8784\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4943 - accuracy: 0.8311 - val_loss: 0.3843 - val_accuracy: 0.8716\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5344 - accuracy: 0.7956 - val_loss: 0.3849 - val_accuracy: 0.8784\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5373 - accuracy: 0.7872 - val_loss: 0.3835 - val_accuracy: 0.8649\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5202 - accuracy: 0.7889 - val_loss: 0.3881 - val_accuracy: 0.8649\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.4806 - accuracy: 0.8108 - val_loss: 0.3876 - val_accuracy: 0.8581\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.5393 - accuracy: 0.8074 - val_loss: 0.3901 - val_accuracy: 0.8514\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.5244 - accuracy: 0.8125 - val_loss: 0.3856 - val_accuracy: 0.8716\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5238 - accuracy: 0.8108 - val_loss: 0.3786 - val_accuracy: 0.8919\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.4702 - accuracy: 0.8226 - val_loss: 0.3751 - val_accuracy: 0.8851\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5413 - accuracy: 0.7990 - val_loss: 0.3926 - val_accuracy: 0.8581\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.5602 - accuracy: 0.7939 - val_loss: 0.4025 - val_accuracy: 0.8446\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.5074 - accuracy: 0.8007 - val_loss: 0.3996 - val_accuracy: 0.8514\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3996 - accuracy: 0.8514\n",
            "5/5 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bb6f49edcfc3>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 8s 18ms/step - loss: 2.0345 - accuracy: 0.4916 - val_loss: 1.3936 - val_accuracy: 0.5608\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.8389 - accuracy: 0.4645 - val_loss: 1.3706 - val_accuracy: 0.6014\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.7507 - accuracy: 0.5287 - val_loss: 1.3467 - val_accuracy: 0.5878\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.6578 - accuracy: 0.4865 - val_loss: 1.3234 - val_accuracy: 0.6284\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.6059 - accuracy: 0.4916 - val_loss: 1.3074 - val_accuracy: 0.6622\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.4672 - accuracy: 0.5372 - val_loss: 1.2934 - val_accuracy: 0.6351\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.4372 - accuracy: 0.5084 - val_loss: 1.2789 - val_accuracy: 0.6824\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.3691 - accuracy: 0.5355 - val_loss: 1.2660 - val_accuracy: 0.6622\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.3170 - accuracy: 0.5304 - val_loss: 1.2534 - val_accuracy: 0.6554\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2809 - accuracy: 0.5456 - val_loss: 1.2399 - val_accuracy: 0.6959\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.2988 - accuracy: 0.5135 - val_loss: 1.2245 - val_accuracy: 0.6689\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2733 - accuracy: 0.5084 - val_loss: 1.2131 - val_accuracy: 0.6419\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 1.2370 - accuracy: 0.5507 - val_loss: 1.2000 - val_accuracy: 0.6284\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.2092 - accuracy: 0.5608 - val_loss: 1.1837 - val_accuracy: 0.6486\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1881 - accuracy: 0.5743 - val_loss: 1.1673 - val_accuracy: 0.6351\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1658 - accuracy: 0.5541 - val_loss: 1.1510 - val_accuracy: 0.6284\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1548 - accuracy: 0.5405 - val_loss: 1.1339 - val_accuracy: 0.6284\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 1.1353 - accuracy: 0.5541 - val_loss: 1.1176 - val_accuracy: 0.6622\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1228 - accuracy: 0.5287 - val_loss: 1.1012 - val_accuracy: 0.6554\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 1.1010 - accuracy: 0.5253 - val_loss: 1.0843 - val_accuracy: 0.6486\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 1.0816 - accuracy: 0.5760 - val_loss: 1.0653 - val_accuracy: 0.6419\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0607 - accuracy: 0.5625 - val_loss: 1.0487 - val_accuracy: 0.6351\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0411 - accuracy: 0.5861 - val_loss: 1.0272 - val_accuracy: 0.6554\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 1.0451 - accuracy: 0.5304 - val_loss: 1.0131 - val_accuracy: 0.6554\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 1.0185 - accuracy: 0.5355 - val_loss: 0.9977 - val_accuracy: 0.6554\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.9954 - accuracy: 0.5828 - val_loss: 0.9808 - val_accuracy: 0.6419\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9753 - accuracy: 0.5980 - val_loss: 0.9613 - val_accuracy: 0.6757\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9692 - accuracy: 0.5490 - val_loss: 0.9435 - val_accuracy: 0.7027\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.9438 - accuracy: 0.5541 - val_loss: 0.9278 - val_accuracy: 0.7230\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.9233 - accuracy: 0.5878 - val_loss: 0.9099 - val_accuracy: 0.6824\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.9116 - accuracy: 0.6199 - val_loss: 0.8870 - val_accuracy: 0.7297\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8923 - accuracy: 0.6115 - val_loss: 0.8711 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8838 - accuracy: 0.6182 - val_loss: 0.8506 - val_accuracy: 0.7568\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8806 - accuracy: 0.5963 - val_loss: 0.8394 - val_accuracy: 0.7770\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8539 - accuracy: 0.6301 - val_loss: 0.8221 - val_accuracy: 0.7432\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8629 - accuracy: 0.5963 - val_loss: 0.8078 - val_accuracy: 0.7568\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8490 - accuracy: 0.6014 - val_loss: 0.7953 - val_accuracy: 0.7770\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8300 - accuracy: 0.6267 - val_loss: 0.7745 - val_accuracy: 0.7838\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8102 - accuracy: 0.6757 - val_loss: 0.7589 - val_accuracy: 0.7973\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.7918 - accuracy: 0.6639 - val_loss: 0.7421 - val_accuracy: 0.8041\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7994 - accuracy: 0.6098 - val_loss: 0.7367 - val_accuracy: 0.7973\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.8107 - accuracy: 0.6453 - val_loss: 0.7277 - val_accuracy: 0.7973\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7628 - accuracy: 0.6588 - val_loss: 0.7034 - val_accuracy: 0.7905\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.7413 - accuracy: 0.6858 - val_loss: 0.6872 - val_accuracy: 0.8108\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7384 - accuracy: 0.6706 - val_loss: 0.6786 - val_accuracy: 0.7973\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.6909 - val_loss: 0.6622 - val_accuracy: 0.8176\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.7208 - accuracy: 0.6892 - val_loss: 0.6496 - val_accuracy: 0.8108\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7448 - accuracy: 0.6689 - val_loss: 0.6457 - val_accuracy: 0.7973\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.7157 - accuracy: 0.6858 - val_loss: 0.6325 - val_accuracy: 0.7973\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.7191 - accuracy: 0.6976 - val_loss: 0.6325 - val_accuracy: 0.7838\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.7074 - accuracy: 0.7044 - val_loss: 0.6266 - val_accuracy: 0.7770\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6784 - accuracy: 0.7128 - val_loss: 0.6087 - val_accuracy: 0.7905\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.7024 - accuracy: 0.6959 - val_loss: 0.6094 - val_accuracy: 0.7973\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6789 - accuracy: 0.7111 - val_loss: 0.6030 - val_accuracy: 0.8041\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6718 - accuracy: 0.6892 - val_loss: 0.5879 - val_accuracy: 0.8041\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6542 - accuracy: 0.7331 - val_loss: 0.5831 - val_accuracy: 0.8108\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6835 - accuracy: 0.7230 - val_loss: 0.5823 - val_accuracy: 0.8108\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6584 - accuracy: 0.7280 - val_loss: 0.5924 - val_accuracy: 0.8041\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6877 - accuracy: 0.7314 - val_loss: 0.5789 - val_accuracy: 0.8176\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6802 - accuracy: 0.7196 - val_loss: 0.5793 - val_accuracy: 0.8176\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6788 - accuracy: 0.7264 - val_loss: 0.5787 - val_accuracy: 0.8108\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6606 - accuracy: 0.7365 - val_loss: 0.5696 - val_accuracy: 0.8108\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6672 - accuracy: 0.7297 - val_loss: 0.5685 - val_accuracy: 0.8108\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6540 - accuracy: 0.7399 - val_loss: 0.5564 - val_accuracy: 0.8243\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6245 - accuracy: 0.7534 - val_loss: 0.5425 - val_accuracy: 0.8176\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6307 - accuracy: 0.7399 - val_loss: 0.5383 - val_accuracy: 0.8311\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6351 - accuracy: 0.7399 - val_loss: 0.5320 - val_accuracy: 0.8378\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6538 - accuracy: 0.7095 - val_loss: 0.5376 - val_accuracy: 0.8243\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6352 - accuracy: 0.7196 - val_loss: 0.5235 - val_accuracy: 0.8176\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6409 - accuracy: 0.7483 - val_loss: 0.5205 - val_accuracy: 0.8176\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6326 - accuracy: 0.7432 - val_loss: 0.5288 - val_accuracy: 0.8108\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6453 - accuracy: 0.7399 - val_loss: 0.5287 - val_accuracy: 0.8243\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6267 - accuracy: 0.7466 - val_loss: 0.5125 - val_accuracy: 0.8446\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6440 - accuracy: 0.7517 - val_loss: 0.5218 - val_accuracy: 0.8446\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6333 - accuracy: 0.7483 - val_loss: 0.5142 - val_accuracy: 0.8446\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6183 - accuracy: 0.7331 - val_loss: 0.5075 - val_accuracy: 0.8446\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5983 - accuracy: 0.7669 - val_loss: 0.4988 - val_accuracy: 0.8378\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6162 - accuracy: 0.7365 - val_loss: 0.4942 - val_accuracy: 0.8378\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6008 - accuracy: 0.7432 - val_loss: 0.4975 - val_accuracy: 0.8581\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6703 - accuracy: 0.7365 - val_loss: 0.5066 - val_accuracy: 0.8514\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6063 - accuracy: 0.7736 - val_loss: 0.5014 - val_accuracy: 0.8716\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5688 - accuracy: 0.7551 - val_loss: 0.4931 - val_accuracy: 0.8514\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6293 - accuracy: 0.7297 - val_loss: 0.5118 - val_accuracy: 0.8514\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6300 - accuracy: 0.7382 - val_loss: 0.5134 - val_accuracy: 0.8311\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6226 - accuracy: 0.7466 - val_loss: 0.5149 - val_accuracy: 0.8446\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6101 - accuracy: 0.7551 - val_loss: 0.5173 - val_accuracy: 0.8378\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7720 - val_loss: 0.5139 - val_accuracy: 0.8378\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6372 - accuracy: 0.7399 - val_loss: 0.5017 - val_accuracy: 0.8514\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6048 - accuracy: 0.7466 - val_loss: 0.5031 - val_accuracy: 0.8446\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6234 - accuracy: 0.7618 - val_loss: 0.5074 - val_accuracy: 0.8514\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6116 - accuracy: 0.7584 - val_loss: 0.5092 - val_accuracy: 0.8446\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5829 - accuracy: 0.7720 - val_loss: 0.5072 - val_accuracy: 0.8446\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6182 - accuracy: 0.7551 - val_loss: 0.4960 - val_accuracy: 0.8378\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.6143 - accuracy: 0.7584 - val_loss: 0.4994 - val_accuracy: 0.8243\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6263 - accuracy: 0.7432 - val_loss: 0.5057 - val_accuracy: 0.8378\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5809 - accuracy: 0.7568 - val_loss: 0.4928 - val_accuracy: 0.8446\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5806 - accuracy: 0.7635 - val_loss: 0.4847 - val_accuracy: 0.8514\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5961 - accuracy: 0.7720 - val_loss: 0.4885 - val_accuracy: 0.8514\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.6046 - accuracy: 0.7280 - val_loss: 0.4880 - val_accuracy: 0.8311\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5924 - accuracy: 0.7652 - val_loss: 0.4808 - val_accuracy: 0.8581\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6142 - accuracy: 0.7618 - val_loss: 0.4804 - val_accuracy: 0.8581\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6074 - accuracy: 0.7618 - val_loss: 0.4839 - val_accuracy: 0.8649\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6273 - accuracy: 0.7331 - val_loss: 0.4854 - val_accuracy: 0.8649\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5962 - accuracy: 0.7720 - val_loss: 0.4866 - val_accuracy: 0.8649\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6262 - accuracy: 0.7618 - val_loss: 0.4827 - val_accuracy: 0.8514\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5998 - accuracy: 0.7720 - val_loss: 0.4845 - val_accuracy: 0.8378\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5789 - accuracy: 0.7838 - val_loss: 0.4819 - val_accuracy: 0.8311\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6121 - accuracy: 0.7720 - val_loss: 0.4884 - val_accuracy: 0.8311\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5863 - accuracy: 0.7601 - val_loss: 0.4822 - val_accuracy: 0.8446\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6172 - accuracy: 0.7449 - val_loss: 0.4777 - val_accuracy: 0.8378\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5854 - accuracy: 0.7584 - val_loss: 0.4628 - val_accuracy: 0.8581\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5758 - accuracy: 0.7686 - val_loss: 0.4578 - val_accuracy: 0.8514\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.6031 - accuracy: 0.7618 - val_loss: 0.4565 - val_accuracy: 0.8514\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.7736 - val_loss: 0.4596 - val_accuracy: 0.8581\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5953 - accuracy: 0.7686 - val_loss: 0.4661 - val_accuracy: 0.8581\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5664 - accuracy: 0.7939 - val_loss: 0.4632 - val_accuracy: 0.8649\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5934 - accuracy: 0.7584 - val_loss: 0.4596 - val_accuracy: 0.8514\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5935 - accuracy: 0.7753 - val_loss: 0.4646 - val_accuracy: 0.8446\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6171 - accuracy: 0.7601 - val_loss: 0.4733 - val_accuracy: 0.8581\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6205 - accuracy: 0.7652 - val_loss: 0.4796 - val_accuracy: 0.8311\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5528 - accuracy: 0.7838 - val_loss: 0.4635 - val_accuracy: 0.8311\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.6182 - accuracy: 0.7584 - val_loss: 0.4784 - val_accuracy: 0.8514\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5504 - accuracy: 0.7939 - val_loss: 0.4682 - val_accuracy: 0.8446\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5492 - accuracy: 0.7889 - val_loss: 0.4623 - val_accuracy: 0.8514\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.7905 - val_loss: 0.4480 - val_accuracy: 0.8581\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6028 - accuracy: 0.7500 - val_loss: 0.4495 - val_accuracy: 0.8581\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.7601 - val_loss: 0.4490 - val_accuracy: 0.8649\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5708 - accuracy: 0.7855 - val_loss: 0.4602 - val_accuracy: 0.8716\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5796 - accuracy: 0.7720 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6040 - accuracy: 0.7517 - val_loss: 0.4613 - val_accuracy: 0.8311\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6224 - accuracy: 0.7382 - val_loss: 0.4588 - val_accuracy: 0.8514\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5921 - accuracy: 0.7720 - val_loss: 0.4612 - val_accuracy: 0.8311\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6071 - accuracy: 0.7618 - val_loss: 0.4607 - val_accuracy: 0.8514\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5907 - accuracy: 0.7618 - val_loss: 0.4579 - val_accuracy: 0.8716\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5824 - accuracy: 0.7787 - val_loss: 0.4571 - val_accuracy: 0.8446\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5607 - accuracy: 0.7821 - val_loss: 0.4575 - val_accuracy: 0.8446\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5464 - accuracy: 0.7855 - val_loss: 0.4463 - val_accuracy: 0.8446\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.7787 - val_loss: 0.4462 - val_accuracy: 0.8649\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5737 - accuracy: 0.7534 - val_loss: 0.4412 - val_accuracy: 0.8581\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5747 - accuracy: 0.7635 - val_loss: 0.4434 - val_accuracy: 0.8378\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5848 - accuracy: 0.7635 - val_loss: 0.4473 - val_accuracy: 0.8514\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5552 - accuracy: 0.7736 - val_loss: 0.4493 - val_accuracy: 0.8514\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5941 - accuracy: 0.7939 - val_loss: 0.4516 - val_accuracy: 0.8514\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5941 - accuracy: 0.7584 - val_loss: 0.4417 - val_accuracy: 0.8581\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5404 - accuracy: 0.7905 - val_loss: 0.4372 - val_accuracy: 0.8716\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5755 - accuracy: 0.7770 - val_loss: 0.4345 - val_accuracy: 0.8784\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5823 - accuracy: 0.7703 - val_loss: 0.4351 - val_accuracy: 0.8581\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5663 - accuracy: 0.7804 - val_loss: 0.4414 - val_accuracy: 0.8581\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5800 - accuracy: 0.7821 - val_loss: 0.4394 - val_accuracy: 0.8581\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5967 - accuracy: 0.7652 - val_loss: 0.4342 - val_accuracy: 0.8649\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.7838 - val_loss: 0.4329 - val_accuracy: 0.8649\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5804 - accuracy: 0.7669 - val_loss: 0.4295 - val_accuracy: 0.8716\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5725 - accuracy: 0.7787 - val_loss: 0.4451 - val_accuracy: 0.8514\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5643 - accuracy: 0.7753 - val_loss: 0.4393 - val_accuracy: 0.8514\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.8125 - val_loss: 0.4412 - val_accuracy: 0.8514\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5665 - accuracy: 0.7922 - val_loss: 0.4327 - val_accuracy: 0.8649\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5511 - accuracy: 0.7804 - val_loss: 0.4331 - val_accuracy: 0.8581\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5344 - accuracy: 0.7804 - val_loss: 0.4255 - val_accuracy: 0.8446\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5852 - accuracy: 0.7669 - val_loss: 0.4295 - val_accuracy: 0.8446\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5614 - accuracy: 0.7905 - val_loss: 0.4175 - val_accuracy: 0.8919\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5619 - accuracy: 0.7838 - val_loss: 0.4198 - val_accuracy: 0.8514\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5895 - accuracy: 0.7872 - val_loss: 0.4151 - val_accuracy: 0.8716\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5428 - accuracy: 0.7922 - val_loss: 0.4208 - val_accuracy: 0.8716\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.7753 - val_loss: 0.4231 - val_accuracy: 0.8649\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5621 - accuracy: 0.7821 - val_loss: 0.4275 - val_accuracy: 0.8716\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5905 - accuracy: 0.7753 - val_loss: 0.4242 - val_accuracy: 0.8514\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5431 - accuracy: 0.7855 - val_loss: 0.4258 - val_accuracy: 0.8581\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5560 - accuracy: 0.7922 - val_loss: 0.4320 - val_accuracy: 0.8514\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5666 - accuracy: 0.7720 - val_loss: 0.4326 - val_accuracy: 0.8514\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5720 - accuracy: 0.7889 - val_loss: 0.4259 - val_accuracy: 0.8514\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5845 - accuracy: 0.7584 - val_loss: 0.4342 - val_accuracy: 0.8649\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5870 - accuracy: 0.7720 - val_loss: 0.4346 - val_accuracy: 0.8649\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5534 - accuracy: 0.7956 - val_loss: 0.4346 - val_accuracy: 0.8649\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.6099 - accuracy: 0.7466 - val_loss: 0.4294 - val_accuracy: 0.8649\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5617 - accuracy: 0.7905 - val_loss: 0.4197 - val_accuracy: 0.8851\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5382 - accuracy: 0.7939 - val_loss: 0.4159 - val_accuracy: 0.8716\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5630 - accuracy: 0.7922 - val_loss: 0.4173 - val_accuracy: 0.8784\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5588 - accuracy: 0.7770 - val_loss: 0.4162 - val_accuracy: 0.8986\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.7939 - val_loss: 0.4227 - val_accuracy: 0.8986\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5621 - accuracy: 0.7720 - val_loss: 0.4282 - val_accuracy: 0.8581\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.7534 - val_loss: 0.4303 - val_accuracy: 0.8784\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.7584 - val_loss: 0.4377 - val_accuracy: 0.8581\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5733 - accuracy: 0.7720 - val_loss: 0.4241 - val_accuracy: 0.8784\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5368 - accuracy: 0.7652 - val_loss: 0.4256 - val_accuracy: 0.8784\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5558 - accuracy: 0.7990 - val_loss: 0.4232 - val_accuracy: 0.8649\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.7855 - val_loss: 0.4246 - val_accuracy: 0.8986\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7720 - val_loss: 0.4150 - val_accuracy: 0.8784\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5434 - accuracy: 0.8024 - val_loss: 0.4111 - val_accuracy: 0.8716\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5852 - accuracy: 0.7736 - val_loss: 0.4198 - val_accuracy: 0.8581\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7872 - val_loss: 0.4186 - val_accuracy: 0.8851\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5524 - accuracy: 0.7889 - val_loss: 0.4102 - val_accuracy: 0.8581\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5584 - accuracy: 0.7821 - val_loss: 0.4079 - val_accuracy: 0.8649\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.7889 - val_loss: 0.4117 - val_accuracy: 0.8716\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.8108 - val_loss: 0.4189 - val_accuracy: 0.8581\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5309 - accuracy: 0.8108 - val_loss: 0.4183 - val_accuracy: 0.8716\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5459 - accuracy: 0.7922 - val_loss: 0.4090 - val_accuracy: 0.8784\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5759 - accuracy: 0.7872 - val_loss: 0.4154 - val_accuracy: 0.8649\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5609 - accuracy: 0.7889 - val_loss: 0.4190 - val_accuracy: 0.8716\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5643 - accuracy: 0.7838 - val_loss: 0.4117 - val_accuracy: 0.8851\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5576 - accuracy: 0.7770 - val_loss: 0.4071 - val_accuracy: 0.8919\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5476 - accuracy: 0.8007 - val_loss: 0.4084 - val_accuracy: 0.8986\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.8007 - val_loss: 0.4042 - val_accuracy: 0.8851\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5593 - accuracy: 0.7939 - val_loss: 0.4063 - val_accuracy: 0.8919\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5631 - accuracy: 0.7872 - val_loss: 0.4075 - val_accuracy: 0.8581\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5782 - accuracy: 0.7787 - val_loss: 0.4087 - val_accuracy: 0.8784\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5207 - accuracy: 0.8142 - val_loss: 0.3913 - val_accuracy: 0.8851\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.8041 - val_loss: 0.3984 - val_accuracy: 0.8716\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.5458 - accuracy: 0.8057 - val_loss: 0.4147 - val_accuracy: 0.8581\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6029 - accuracy: 0.7703 - val_loss: 0.4099 - val_accuracy: 0.8784\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5326 - accuracy: 0.7889 - val_loss: 0.4140 - val_accuracy: 0.8919\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.8041 - val_loss: 0.4048 - val_accuracy: 0.8919\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7787 - val_loss: 0.4019 - val_accuracy: 0.8784\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.8108 - val_loss: 0.4029 - val_accuracy: 0.8649\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.7652 - val_loss: 0.3997 - val_accuracy: 0.8784\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5578 - accuracy: 0.8041 - val_loss: 0.4032 - val_accuracy: 0.8784\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5840 - accuracy: 0.7720 - val_loss: 0.4060 - val_accuracy: 0.8919\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5967 - accuracy: 0.7753 - val_loss: 0.4129 - val_accuracy: 0.8851\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5722 - accuracy: 0.7872 - val_loss: 0.4170 - val_accuracy: 0.8649\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5569 - accuracy: 0.7905 - val_loss: 0.4095 - val_accuracy: 0.8851\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5230 - accuracy: 0.8057 - val_loss: 0.4025 - val_accuracy: 0.8851\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5229 - accuracy: 0.8041 - val_loss: 0.3976 - val_accuracy: 0.8986\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5424 - accuracy: 0.7652 - val_loss: 0.4115 - val_accuracy: 0.8716\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5705 - accuracy: 0.7905 - val_loss: 0.4209 - val_accuracy: 0.8514\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5826 - accuracy: 0.7669 - val_loss: 0.4206 - val_accuracy: 0.8649\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5595 - accuracy: 0.7855 - val_loss: 0.4176 - val_accuracy: 0.8784\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5424 - accuracy: 0.8108 - val_loss: 0.4134 - val_accuracy: 0.8716\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7990 - val_loss: 0.4146 - val_accuracy: 0.8716\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7889 - val_loss: 0.4105 - val_accuracy: 0.8919\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5327 - accuracy: 0.8091 - val_loss: 0.4069 - val_accuracy: 0.8919\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5355 - accuracy: 0.7855 - val_loss: 0.4035 - val_accuracy: 0.8919\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5824 - accuracy: 0.7720 - val_loss: 0.4051 - val_accuracy: 0.8851\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5423 - accuracy: 0.8125 - val_loss: 0.4119 - val_accuracy: 0.8851\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5412 - accuracy: 0.7736 - val_loss: 0.4179 - val_accuracy: 0.8784\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5539 - accuracy: 0.7922 - val_loss: 0.4135 - val_accuracy: 0.8851\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5849 - accuracy: 0.7804 - val_loss: 0.4199 - val_accuracy: 0.8784\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.8142 - val_loss: 0.4115 - val_accuracy: 0.8851\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5420 - accuracy: 0.7855 - val_loss: 0.4002 - val_accuracy: 0.8919\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5583 - accuracy: 0.7838 - val_loss: 0.4131 - val_accuracy: 0.8716\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5255 - accuracy: 0.8176 - val_loss: 0.4120 - val_accuracy: 0.8851\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5512 - accuracy: 0.7838 - val_loss: 0.4122 - val_accuracy: 0.8649\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5561 - accuracy: 0.7905 - val_loss: 0.4182 - val_accuracy: 0.8581\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.7753 - val_loss: 0.4236 - val_accuracy: 0.8716\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5655 - accuracy: 0.7905 - val_loss: 0.4316 - val_accuracy: 0.8581\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7736 - val_loss: 0.4153 - val_accuracy: 0.8716\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5095 - accuracy: 0.8074 - val_loss: 0.4133 - val_accuracy: 0.8851\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5656 - accuracy: 0.7855 - val_loss: 0.4059 - val_accuracy: 0.8649\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5335 - accuracy: 0.7872 - val_loss: 0.3990 - val_accuracy: 0.8716\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5401 - accuracy: 0.7821 - val_loss: 0.3979 - val_accuracy: 0.8716\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5056 - accuracy: 0.8057 - val_loss: 0.4030 - val_accuracy: 0.8851\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5643 - accuracy: 0.7804 - val_loss: 0.4136 - val_accuracy: 0.8649\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5870 - accuracy: 0.7652 - val_loss: 0.4137 - val_accuracy: 0.8784\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5630 - accuracy: 0.7821 - val_loss: 0.4189 - val_accuracy: 0.8784\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5556 - accuracy: 0.7973 - val_loss: 0.4189 - val_accuracy: 0.8784\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5359 - accuracy: 0.7956 - val_loss: 0.4223 - val_accuracy: 0.8514\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7922 - val_loss: 0.4185 - val_accuracy: 0.8649\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5126 - accuracy: 0.8108 - val_loss: 0.4105 - val_accuracy: 0.8851\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5492 - accuracy: 0.7720 - val_loss: 0.4089 - val_accuracy: 0.8716\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7652 - val_loss: 0.4227 - val_accuracy: 0.8919\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7618 - val_loss: 0.4295 - val_accuracy: 0.8649\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7872 - val_loss: 0.4304 - val_accuracy: 0.8514\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5260 - accuracy: 0.8209 - val_loss: 0.4318 - val_accuracy: 0.8378\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.8041 - val_loss: 0.4315 - val_accuracy: 0.8446\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.8057 - val_loss: 0.4258 - val_accuracy: 0.8919\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5592 - accuracy: 0.7669 - val_loss: 0.4239 - val_accuracy: 0.8716\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5138 - accuracy: 0.7838 - val_loss: 0.4159 - val_accuracy: 0.8784\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5416 - accuracy: 0.7855 - val_loss: 0.4167 - val_accuracy: 0.8581\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5202 - accuracy: 0.7736 - val_loss: 0.4108 - val_accuracy: 0.8851\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.8125 - val_loss: 0.4096 - val_accuracy: 0.8784\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5329 - accuracy: 0.7855 - val_loss: 0.4111 - val_accuracy: 0.8784\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5350 - accuracy: 0.7956 - val_loss: 0.4187 - val_accuracy: 0.8649\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5253 - accuracy: 0.8057 - val_loss: 0.4082 - val_accuracy: 0.8851\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5474 - accuracy: 0.7905 - val_loss: 0.4235 - val_accuracy: 0.8649\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5543 - accuracy: 0.8074 - val_loss: 0.4161 - val_accuracy: 0.8716\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5178 - accuracy: 0.8226 - val_loss: 0.4024 - val_accuracy: 0.8784\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5398 - accuracy: 0.8074 - val_loss: 0.4151 - val_accuracy: 0.8784\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5428 - accuracy: 0.7855 - val_loss: 0.4067 - val_accuracy: 0.8851\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5345 - accuracy: 0.8091 - val_loss: 0.4005 - val_accuracy: 0.8919\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.7838 - val_loss: 0.4001 - val_accuracy: 0.8919\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5567 - accuracy: 0.8041 - val_loss: 0.3954 - val_accuracy: 0.9054\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5286 - accuracy: 0.7956 - val_loss: 0.3963 - val_accuracy: 0.9054\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.7922 - val_loss: 0.3895 - val_accuracy: 0.8919\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.8159 - val_loss: 0.3938 - val_accuracy: 0.8919\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.8159 - val_loss: 0.3842 - val_accuracy: 0.8851\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5667 - accuracy: 0.7787 - val_loss: 0.3984 - val_accuracy: 0.8919\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7922 - val_loss: 0.4049 - val_accuracy: 0.8716\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5211 - accuracy: 0.8243 - val_loss: 0.3994 - val_accuracy: 0.8986\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.8024 - val_loss: 0.4044 - val_accuracy: 0.8784\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.8193 - val_loss: 0.4050 - val_accuracy: 0.8851\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5614 - accuracy: 0.7973 - val_loss: 0.4088 - val_accuracy: 0.8716\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5858 - accuracy: 0.7720 - val_loss: 0.4055 - val_accuracy: 0.8649\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4963 - accuracy: 0.8108 - val_loss: 0.3975 - val_accuracy: 0.8851\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.8091 - val_loss: 0.3973 - val_accuracy: 0.8716\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5530 - accuracy: 0.7905 - val_loss: 0.3959 - val_accuracy: 0.8851\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5549 - accuracy: 0.7889 - val_loss: 0.3938 - val_accuracy: 0.8851\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5728 - accuracy: 0.7720 - val_loss: 0.4084 - val_accuracy: 0.8784\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5477 - accuracy: 0.7872 - val_loss: 0.4035 - val_accuracy: 0.8851\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5526 - accuracy: 0.7736 - val_loss: 0.3972 - val_accuracy: 0.8784\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5284 - accuracy: 0.8091 - val_loss: 0.3999 - val_accuracy: 0.8784\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4883 - accuracy: 0.8277 - val_loss: 0.3926 - val_accuracy: 0.8851\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5234 - accuracy: 0.7855 - val_loss: 0.3794 - val_accuracy: 0.8986\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5123 - accuracy: 0.8007 - val_loss: 0.3839 - val_accuracy: 0.8919\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4849 - accuracy: 0.8226 - val_loss: 0.3932 - val_accuracy: 0.8716\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5628 - accuracy: 0.7669 - val_loss: 0.3849 - val_accuracy: 0.8784\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5193 - accuracy: 0.8041 - val_loss: 0.3851 - val_accuracy: 0.8919\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4963 - accuracy: 0.8091 - val_loss: 0.3802 - val_accuracy: 0.8851\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5536 - accuracy: 0.7855 - val_loss: 0.3806 - val_accuracy: 0.8784\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5229 - accuracy: 0.7956 - val_loss: 0.3996 - val_accuracy: 0.8851\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5294 - accuracy: 0.7922 - val_loss: 0.3912 - val_accuracy: 0.8784\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5227 - accuracy: 0.8159 - val_loss: 0.3974 - val_accuracy: 0.8851\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7905 - val_loss: 0.4012 - val_accuracy: 0.8919\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5456 - accuracy: 0.7821 - val_loss: 0.4005 - val_accuracy: 0.8919\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.8193 - val_loss: 0.3905 - val_accuracy: 0.8784\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5770 - accuracy: 0.7804 - val_loss: 0.3952 - val_accuracy: 0.8851\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5330 - accuracy: 0.8193 - val_loss: 0.4035 - val_accuracy: 0.8784\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5198 - accuracy: 0.8007 - val_loss: 0.4075 - val_accuracy: 0.8851\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5455 - accuracy: 0.7990 - val_loss: 0.4038 - val_accuracy: 0.8784\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5085 - accuracy: 0.7956 - val_loss: 0.3967 - val_accuracy: 0.8919\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5269 - accuracy: 0.7922 - val_loss: 0.3897 - val_accuracy: 0.8986\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5121 - accuracy: 0.8209 - val_loss: 0.3810 - val_accuracy: 0.8919\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5492 - accuracy: 0.7787 - val_loss: 0.3786 - val_accuracy: 0.8851\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5714 - accuracy: 0.7956 - val_loss: 0.3856 - val_accuracy: 0.9054\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5262 - accuracy: 0.8125 - val_loss: 0.3899 - val_accuracy: 0.8784\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5390 - accuracy: 0.8108 - val_loss: 0.3827 - val_accuracy: 0.8986\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5791 - accuracy: 0.7669 - val_loss: 0.3924 - val_accuracy: 0.9054\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5376 - accuracy: 0.7990 - val_loss: 0.3919 - val_accuracy: 0.8851\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5031 - accuracy: 0.8108 - val_loss: 0.3956 - val_accuracy: 0.8919\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5153 - accuracy: 0.8074 - val_loss: 0.3955 - val_accuracy: 0.8784\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5308 - accuracy: 0.8091 - val_loss: 0.3881 - val_accuracy: 0.8851\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5213 - accuracy: 0.8091 - val_loss: 0.3938 - val_accuracy: 0.8784\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5293 - accuracy: 0.7804 - val_loss: 0.3825 - val_accuracy: 0.8919\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5490 - accuracy: 0.8024 - val_loss: 0.3935 - val_accuracy: 0.8851\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5357 - accuracy: 0.7804 - val_loss: 0.3936 - val_accuracy: 0.8851\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5347 - accuracy: 0.8007 - val_loss: 0.4027 - val_accuracy: 0.8716\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5063 - accuracy: 0.8074 - val_loss: 0.4041 - val_accuracy: 0.8851\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5400 - accuracy: 0.8057 - val_loss: 0.3911 - val_accuracy: 0.9054\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5520 - accuracy: 0.7939 - val_loss: 0.3962 - val_accuracy: 0.9122\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5575 - accuracy: 0.7635 - val_loss: 0.3997 - val_accuracy: 0.8919\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5099 - accuracy: 0.8108 - val_loss: 0.4016 - val_accuracy: 0.8919\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5184 - accuracy: 0.8209 - val_loss: 0.3965 - val_accuracy: 0.8851\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5429 - accuracy: 0.8057 - val_loss: 0.3847 - val_accuracy: 0.8986\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5422 - accuracy: 0.7889 - val_loss: 0.3922 - val_accuracy: 0.8919\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5017 - accuracy: 0.8091 - val_loss: 0.3900 - val_accuracy: 0.8851\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4974 - accuracy: 0.8142 - val_loss: 0.3889 - val_accuracy: 0.8851\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5002 - accuracy: 0.8041 - val_loss: 0.3882 - val_accuracy: 0.8851\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5203 - accuracy: 0.7889 - val_loss: 0.3940 - val_accuracy: 0.8851\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5282 - accuracy: 0.8142 - val_loss: 0.3941 - val_accuracy: 0.8851\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5680 - accuracy: 0.7787 - val_loss: 0.3861 - val_accuracy: 0.9122\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4850 - accuracy: 0.8226 - val_loss: 0.3856 - val_accuracy: 0.8986\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5364 - accuracy: 0.8294 - val_loss: 0.3930 - val_accuracy: 0.8784\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4717 - accuracy: 0.8328 - val_loss: 0.3780 - val_accuracy: 0.8919\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5259 - accuracy: 0.7956 - val_loss: 0.3893 - val_accuracy: 0.8851\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5475 - accuracy: 0.7939 - val_loss: 0.3912 - val_accuracy: 0.8649\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7804 - val_loss: 0.3928 - val_accuracy: 0.8514\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5476 - accuracy: 0.7838 - val_loss: 0.3886 - val_accuracy: 0.8514\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5191 - accuracy: 0.8176 - val_loss: 0.3940 - val_accuracy: 0.8716\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5504 - accuracy: 0.7889 - val_loss: 0.3877 - val_accuracy: 0.8784\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5468 - accuracy: 0.7973 - val_loss: 0.3844 - val_accuracy: 0.8919\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5352 - accuracy: 0.7872 - val_loss: 0.3846 - val_accuracy: 0.8851\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5497 - accuracy: 0.7787 - val_loss: 0.3841 - val_accuracy: 0.9054\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5312 - accuracy: 0.8108 - val_loss: 0.3897 - val_accuracy: 0.9054\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7939 - val_loss: 0.3839 - val_accuracy: 0.9054\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5664 - accuracy: 0.7922 - val_loss: 0.3779 - val_accuracy: 0.9189\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5439 - accuracy: 0.7905 - val_loss: 0.3851 - val_accuracy: 0.8716\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4964 - accuracy: 0.7905 - val_loss: 0.3814 - val_accuracy: 0.8581\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5563 - accuracy: 0.7889 - val_loss: 0.3914 - val_accuracy: 0.8851\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4918 - accuracy: 0.8209 - val_loss: 0.3727 - val_accuracy: 0.8919\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5536 - accuracy: 0.7889 - val_loss: 0.3801 - val_accuracy: 0.8649\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5287 - accuracy: 0.8277 - val_loss: 0.3868 - val_accuracy: 0.8784\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5476 - accuracy: 0.7905 - val_loss: 0.3817 - val_accuracy: 0.8716\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7855 - val_loss: 0.3774 - val_accuracy: 0.8784\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5025 - accuracy: 0.8277 - val_loss: 0.3785 - val_accuracy: 0.8851\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5538 - accuracy: 0.7821 - val_loss: 0.3904 - val_accuracy: 0.8514\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5034 - accuracy: 0.7956 - val_loss: 0.3815 - val_accuracy: 0.8649\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5352 - accuracy: 0.7838 - val_loss: 0.3789 - val_accuracy: 0.8919\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4910 - accuracy: 0.8159 - val_loss: 0.3806 - val_accuracy: 0.8784\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5248 - accuracy: 0.8074 - val_loss: 0.3770 - val_accuracy: 0.8716\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5610 - accuracy: 0.8024 - val_loss: 0.3793 - val_accuracy: 0.8919\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5291 - accuracy: 0.7922 - val_loss: 0.3807 - val_accuracy: 0.8919\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4722 - accuracy: 0.8311 - val_loss: 0.3778 - val_accuracy: 0.9054\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5354 - accuracy: 0.8125 - val_loss: 0.3752 - val_accuracy: 0.8919\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.8007 - val_loss: 0.3907 - val_accuracy: 0.8649\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5719 - accuracy: 0.7736 - val_loss: 0.3920 - val_accuracy: 0.8716\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5211 - accuracy: 0.8007 - val_loss: 0.3831 - val_accuracy: 0.8919\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5530 - accuracy: 0.7889 - val_loss: 0.3803 - val_accuracy: 0.8919\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4976 - accuracy: 0.8226 - val_loss: 0.3672 - val_accuracy: 0.8986\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5339 - accuracy: 0.8024 - val_loss: 0.3641 - val_accuracy: 0.8986\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.7770 - val_loss: 0.3809 - val_accuracy: 0.8784\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.4745 - accuracy: 0.8226 - val_loss: 0.3718 - val_accuracy: 0.8919\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.8159 - val_loss: 0.3754 - val_accuracy: 0.8986\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4671 - accuracy: 0.8328 - val_loss: 0.3704 - val_accuracy: 0.9122\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5475 - accuracy: 0.7922 - val_loss: 0.3793 - val_accuracy: 0.9189\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5235 - accuracy: 0.7990 - val_loss: 0.3825 - val_accuracy: 0.9122\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.8209 - val_loss: 0.3776 - val_accuracy: 0.8986\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4947 - accuracy: 0.8091 - val_loss: 0.3901 - val_accuracy: 0.8784\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.8091 - val_loss: 0.3909 - val_accuracy: 0.8716\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5638 - accuracy: 0.7973 - val_loss: 0.3848 - val_accuracy: 0.8649\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5486 - accuracy: 0.7973 - val_loss: 0.3913 - val_accuracy: 0.8919\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4709 - accuracy: 0.8260 - val_loss: 0.3877 - val_accuracy: 0.8851\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5170 - accuracy: 0.8176 - val_loss: 0.3818 - val_accuracy: 0.8716\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5024 - accuracy: 0.8125 - val_loss: 0.3743 - val_accuracy: 0.8649\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5238 - accuracy: 0.8057 - val_loss: 0.3720 - val_accuracy: 0.8581\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5497 - accuracy: 0.7922 - val_loss: 0.3776 - val_accuracy: 0.8716\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5371 - accuracy: 0.8091 - val_loss: 0.3837 - val_accuracy: 0.8716\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5076 - accuracy: 0.7990 - val_loss: 0.3878 - val_accuracy: 0.8716\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5723 - accuracy: 0.7973 - val_loss: 0.3926 - val_accuracy: 0.8784\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4980 - accuracy: 0.8125 - val_loss: 0.3892 - val_accuracy: 0.8649\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.5507 - accuracy: 0.7753 - val_loss: 0.3951 - val_accuracy: 0.8716\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4967 - accuracy: 0.8294 - val_loss: 0.3824 - val_accuracy: 0.8716\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5381 - accuracy: 0.7973 - val_loss: 0.3867 - val_accuracy: 0.8649\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5268 - accuracy: 0.8024 - val_loss: 0.3844 - val_accuracy: 0.8784\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5369 - accuracy: 0.7922 - val_loss: 0.3950 - val_accuracy: 0.8581\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5446 - accuracy: 0.7787 - val_loss: 0.3992 - val_accuracy: 0.8581\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7889 - val_loss: 0.3963 - val_accuracy: 0.8716\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5300 - accuracy: 0.8108 - val_loss: 0.3960 - val_accuracy: 0.8649\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5386 - accuracy: 0.8057 - val_loss: 0.4033 - val_accuracy: 0.8514\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.8159 - val_loss: 0.3814 - val_accuracy: 0.8649\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4798 - accuracy: 0.8193 - val_loss: 0.3810 - val_accuracy: 0.8716\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.8294 - val_loss: 0.3885 - val_accuracy: 0.8851\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5132 - accuracy: 0.8074 - val_loss: 0.3783 - val_accuracy: 0.8716\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5508 - accuracy: 0.7872 - val_loss: 0.4001 - val_accuracy: 0.8649\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.5360 - accuracy: 0.7838 - val_loss: 0.3981 - val_accuracy: 0.8784\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5372 - accuracy: 0.7922 - val_loss: 0.3973 - val_accuracy: 0.8851\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5077 - accuracy: 0.7990 - val_loss: 0.3924 - val_accuracy: 0.8716\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4949 - accuracy: 0.8007 - val_loss: 0.3903 - val_accuracy: 0.8919\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5256 - accuracy: 0.8226 - val_loss: 0.3821 - val_accuracy: 0.8986\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5243 - accuracy: 0.7973 - val_loss: 0.3812 - val_accuracy: 0.8784\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5080 - accuracy: 0.8007 - val_loss: 0.3864 - val_accuracy: 0.8784\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5506 - accuracy: 0.7652 - val_loss: 0.3800 - val_accuracy: 0.8851\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5264 - accuracy: 0.8057 - val_loss: 0.3713 - val_accuracy: 0.8784\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4696 - accuracy: 0.8480 - val_loss: 0.3754 - val_accuracy: 0.8851\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5089 - accuracy: 0.7973 - val_loss: 0.3749 - val_accuracy: 0.8919\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5450 - accuracy: 0.7889 - val_loss: 0.3877 - val_accuracy: 0.8784\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.8345 - val_loss: 0.3813 - val_accuracy: 0.8784\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5372 - accuracy: 0.7990 - val_loss: 0.3846 - val_accuracy: 0.8851\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4896 - accuracy: 0.8091 - val_loss: 0.3784 - val_accuracy: 0.8716\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5399 - accuracy: 0.7753 - val_loss: 0.3813 - val_accuracy: 0.8919\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5158 - accuracy: 0.8193 - val_loss: 0.3851 - val_accuracy: 0.8716\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5235 - accuracy: 0.8024 - val_loss: 0.3936 - val_accuracy: 0.8851\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5040 - accuracy: 0.8176 - val_loss: 0.3825 - val_accuracy: 0.8851\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5131 - accuracy: 0.7939 - val_loss: 0.3761 - val_accuracy: 0.8784\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5017 - accuracy: 0.8108 - val_loss: 0.3684 - val_accuracy: 0.8784\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5257 - accuracy: 0.8277 - val_loss: 0.3665 - val_accuracy: 0.8784\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5137 - accuracy: 0.7990 - val_loss: 0.3707 - val_accuracy: 0.8784\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.8412 - val_loss: 0.3705 - val_accuracy: 0.8986\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.8125 - val_loss: 0.3816 - val_accuracy: 0.8919\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5222 - accuracy: 0.8007 - val_loss: 0.3752 - val_accuracy: 0.8986\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5125 - accuracy: 0.8142 - val_loss: 0.3767 - val_accuracy: 0.8986\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5298 - accuracy: 0.8024 - val_loss: 0.3698 - val_accuracy: 0.8919\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4781 - accuracy: 0.8361 - val_loss: 0.3707 - val_accuracy: 0.8851\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5036 - accuracy: 0.8193 - val_loss: 0.3754 - val_accuracy: 0.8649\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5012 - accuracy: 0.8142 - val_loss: 0.3729 - val_accuracy: 0.8986\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4917 - accuracy: 0.8294 - val_loss: 0.3747 - val_accuracy: 0.8851\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5087 - accuracy: 0.8091 - val_loss: 0.3764 - val_accuracy: 0.9122\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5004 - accuracy: 0.8074 - val_loss: 0.3789 - val_accuracy: 0.8986\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4997 - accuracy: 0.8277 - val_loss: 0.3714 - val_accuracy: 0.8851\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5681 - accuracy: 0.7787 - val_loss: 0.3852 - val_accuracy: 0.8784\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5700 - accuracy: 0.7753 - val_loss: 0.4013 - val_accuracy: 0.8784\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4769 - accuracy: 0.8243 - val_loss: 0.3923 - val_accuracy: 0.8649\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.8429 - val_loss: 0.3856 - val_accuracy: 0.8581\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5170 - accuracy: 0.8176 - val_loss: 0.3897 - val_accuracy: 0.8716\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5114 - accuracy: 0.8159 - val_loss: 0.3834 - val_accuracy: 0.8784\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5236 - accuracy: 0.8243 - val_loss: 0.3886 - val_accuracy: 0.9122\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5319 - accuracy: 0.8176 - val_loss: 0.3898 - val_accuracy: 0.8919\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.8007 - val_loss: 0.3906 - val_accuracy: 0.8851\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4665 - accuracy: 0.8142 - val_loss: 0.3941 - val_accuracy: 0.8649\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5354 - accuracy: 0.8176 - val_loss: 0.4002 - val_accuracy: 0.8581\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5072 - accuracy: 0.8176 - val_loss: 0.3840 - val_accuracy: 0.8716\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4937 - accuracy: 0.8395 - val_loss: 0.3810 - val_accuracy: 0.8716\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4948 - accuracy: 0.8057 - val_loss: 0.3762 - val_accuracy: 0.8851\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.8108 - val_loss: 0.3815 - val_accuracy: 0.8851\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5116 - accuracy: 0.8125 - val_loss: 0.3652 - val_accuracy: 0.8919\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5219 - accuracy: 0.8057 - val_loss: 0.3640 - val_accuracy: 0.9054\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.4909 - accuracy: 0.8057 - val_loss: 0.3613 - val_accuracy: 0.8851\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.5275 - accuracy: 0.7922 - val_loss: 0.3717 - val_accuracy: 0.8851\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5548 - accuracy: 0.7956 - val_loss: 0.3872 - val_accuracy: 0.8851\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5286 - accuracy: 0.7973 - val_loss: 0.3909 - val_accuracy: 0.8784\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.4941 - accuracy: 0.8125 - val_loss: 0.3891 - val_accuracy: 0.8851\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5766 - accuracy: 0.7703 - val_loss: 0.3991 - val_accuracy: 0.8716\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4874 - accuracy: 0.8176 - val_loss: 0.3919 - val_accuracy: 0.8649\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4955 - accuracy: 0.8074 - val_loss: 0.3810 - val_accuracy: 0.8649\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4764 - accuracy: 0.8193 - val_loss: 0.3816 - val_accuracy: 0.8649\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4757 - accuracy: 0.8345 - val_loss: 0.3779 - val_accuracy: 0.8851\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.8007 - val_loss: 0.3821 - val_accuracy: 0.8784\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5351 - accuracy: 0.7956 - val_loss: 0.3935 - val_accuracy: 0.8649\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.8007 - val_loss: 0.3800 - val_accuracy: 0.8784\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5256 - accuracy: 0.8007 - val_loss: 0.3755 - val_accuracy: 0.8919\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5082 - accuracy: 0.8074 - val_loss: 0.3849 - val_accuracy: 0.8784\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5075 - accuracy: 0.8159 - val_loss: 0.3837 - val_accuracy: 0.8649\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.7787 - val_loss: 0.3886 - val_accuracy: 0.8716\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.5258 - accuracy: 0.8159 - val_loss: 0.4033 - val_accuracy: 0.8716\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.7956 - val_loss: 0.3934 - val_accuracy: 0.8919\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4913 - accuracy: 0.8159 - val_loss: 0.3887 - val_accuracy: 0.8784\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5003 - accuracy: 0.8057 - val_loss: 0.3847 - val_accuracy: 0.8851\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4769 - accuracy: 0.8345 - val_loss: 0.3810 - val_accuracy: 0.8784\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.5226 - accuracy: 0.7905 - val_loss: 0.3787 - val_accuracy: 0.8919\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.8294 - val_loss: 0.3834 - val_accuracy: 0.8784\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.4897 - accuracy: 0.8328 - val_loss: 0.3886 - val_accuracy: 0.8919\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.5484 - accuracy: 0.8007 - val_loss: 0.3838 - val_accuracy: 0.8784\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.5158 - accuracy: 0.8176 - val_loss: 0.3879 - val_accuracy: 0.8919\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.4886 - accuracy: 0.8345 - val_loss: 0.3827 - val_accuracy: 0.8919\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3827 - accuracy: 0.8919\n",
            "5/5 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-bb6f49edcfc3>:209: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8445945978164673, 0.8310810923576355, 0.7972972989082336, 0.8513513803482056, 0.8918918967247009]\n",
            "Accuracy: 0.84\n",
            "Sensitivity: 0.8570\n",
            "Specificity: 0.8275\n",
            "MCC: 0.6843\n",
            "Precision: 0.8391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn')\n",
        "model.save_weights('acp_mhcnn_weights')"
      ],
      "metadata": {
        "id": "i-ySuIJePlfJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn.keras')"
      ],
      "metadata": {
        "id": "sUnKQ39Oql-p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/acp_mhcnn.zip /content/acp_mhcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCPrPTFlq03j",
        "outputId": "dde7e92c-ccb0-41cd-ba5c-cd18defe97f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/acp_mhcnn/ (stored 0%)\n",
            "updating: content/acp_mhcnn/keras_metadata.pb (deflated 94%)\n",
            "updating: content/acp_mhcnn/saved_model.pb (deflated 90%)\n",
            "updating: content/acp_mhcnn/variables/ (stored 0%)\n",
            "updating: content/acp_mhcnn/variables/variables.data-00000-of-00001 (deflated 28%)\n",
            "updating: content/acp_mhcnn/variables/variables.index (deflated 73%)\n",
            "updating: content/acp_mhcnn/fingerprint.pb (stored 0%)\n",
            "updating: content/acp_mhcnn/assets/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1YZag2MrItN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}