{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-NCx8Mc7DwG",
        "outputId": "eaad27e9-1ca7-4ee2-96a3-c04ecce3f8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "4Ievu6ie7KcN",
        "outputId": "1c8d614b-1644-41bf-9df1-ba3f0b6bd1dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03e26343-0190-41a1-92d9-23e9d0098b0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03e26343-0190-41a1-92d9-23e9d0098b0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bits-740.npy to bits-740 (1).npy\n",
            "Saving blosum-740.npy to blosum-740 (1).npy\n",
            "Saving bpf-740.npy to bpf-740 (1).npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('kir')"
      ],
      "metadata": {
        "id": "c0_ZLCx7ntwx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Neural Networks:\n",
        "import tensorflow as tf; print('We\\'re using TF-{}.'.format(tf.__version__))\n",
        "# import keras; print('We\\'re using Keras-{}.'.format(keras.__version__))\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Flatten, BatchNormalization,\n",
        "                                     Conv1D, Conv2D, MaxPooling1D, MaxPooling2D,\n",
        "                                     LSTM, GRU, Embedding, Bidirectional, Concatenate)\n",
        "from tensorflow.keras.regularizers import (l1, l2, l1_l2)\n",
        "from tensorflow.keras.optimizers import (RMSprop, Adam, SGD)\n",
        "from tensorflow.keras.models import (Sequential, Model)\n",
        "\n",
        "# Core:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import interp\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Performance:\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, matthews_corrcoef, precision_score, roc_curve, auc)\n",
        "from sklearn.model_selection import (StratifiedKFold, KFold, train_test_split)\n",
        "\n",
        "#Utilities:\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical as labelEncoding   # Usages: Y = labelEncoding(Y, dtype=int)\n",
        "from tensorflow.keras.utils import plot_model                        # Usages: plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "#end-import\n",
        "\n",
        "def lossPlot(results):\n",
        "    plt.title(label='Loss: Training and Validation')\n",
        "    plt.plot(results.history['loss'], label='Training Loss')\n",
        "    plt.plot(results.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def accuracyPlot(results):\n",
        "    plt.title(label='Accuracy: Training and Validation')\n",
        "    plt.plot(results.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(results.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "def rocPlot(TPR, meanFPR):\n",
        "    plt.plot([0,1], [0,1],linestyle = '--',lw = 2,color = 'black')\n",
        "    meanTPR = np.mean(TPR, axis=0)\n",
        "    meanAUC = auc(meanFPR, meanTPR)\n",
        "    plt.plot(meanFPR, meanTPR, color='blue',\n",
        "            label=r'Mean ROC (AUC = %0.2f )' % (meanAUC),lw=2, alpha=1)\n",
        "\n",
        "    plt.xlabel('False Positive Rate (FPR)')\n",
        "    plt.ylabel('True Positive Rate (TPR)')\n",
        "    plt.title('Receiver Operating Characteristic Curve (ROC Curve)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.savefig('ROC-740.png')\n",
        "    plt.show()\n",
        "#end-def\n",
        "\n",
        "T = 15 # terminus_length\n",
        "\n",
        "X1 = np.load('bpf-740.npy')\n",
        "X2 = np.load('bits-740.npy')\n",
        "X3 = np.load('blosum-740.npy')\n",
        "\n",
        "\n",
        "X1 = X1[:,0:T,:]\n",
        "X2 = X2[:,0:T,:]\n",
        "X3 = X3[:,0:T,:]\n",
        "\n",
        "\n",
        "Y  = [1 for _ in range(376)]\n",
        "Y += [0 for _ in range(364)]\n",
        "\n",
        "Y = labelEncoding(Y, dtype=int)\n",
        "\n",
        "\n",
        "print(X1.shape)\n",
        "print(X2.shape)\n",
        "print(X3.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "### Model-740\n",
        "\n",
        "def Network():\n",
        "    ### Head-1:\n",
        "    input1 = Input(shape=X1[0].shape)\n",
        "\n",
        "    x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input1)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.80)(x)\n",
        "\n",
        "    x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    head1 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-2:\n",
        "    # input2 = Input(shape=X2[0].shape)\n",
        "\n",
        "    # x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(input2)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # head2 = Flatten()(x)\n",
        "\n",
        "\n",
        "    ### Head-3:\n",
        "    # input3 = Input(shape=X3[0].shape)\n",
        "\n",
        "    # x = Conv1D(filters=10, kernel_size=4, padding='same', activation='relu',)(input3)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # x = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu', kernel_regularizer=l2(l=0.01))(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Dropout(rate=0.70)(x)\n",
        "\n",
        "    # head3 = Flatten()(x)\n",
        "\n",
        "\n",
        "    # merge\n",
        "    # merge = Concatenate()([head1, head3])\n",
        "    merge = Concatenate()([head1])\n",
        "\n",
        "    output = Dense(units=8, activation='relu', kernel_regularizer=l2(l=0.01))(merge)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Dropout(rate=0.70)(output)\n",
        "\n",
        "    output = Dense(units=2, activation='softmax')(output)\n",
        "\n",
        "    # return Model(inputs=[input1, input3], outputs=[output])\n",
        "    return Model(inputs=[input1], outputs=[output])\n",
        "#end-def\n",
        "\n",
        "model = Network()\n",
        "model.summary()\n",
        "plot_model(model, to_file='model-740.png', show_shapes=True, show_layer_names=False, expand_nested=True)\n",
        "\n",
        "setEpochNumber     = 500     # Performed-welled in epoch 600.\n",
        "setBatchSizeNumber = 8\n",
        "####################################################\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=101)\n",
        "\n",
        "Accuracy = []\n",
        "Sensitivity = []\n",
        "Specificity = []\n",
        "Precision = []\n",
        "MCC = []\n",
        "\n",
        "# ROC Curve:\n",
        "fig1 = plt.figure(figsize=[12,12])\n",
        "\n",
        "TPR = []\n",
        "meanFPR = np.linspace(0, 1, 100)\n",
        "\n",
        "i = 1\n",
        "\n",
        "# CM = np.array([\n",
        "#      [0, 0],\n",
        "#      [0, 0],\n",
        "# ], dtype=int)\n",
        "\n",
        "for train, test in cv.split(Y):\n",
        "\n",
        "    # Compile Model:\n",
        "    model = Network()\n",
        "    model.compile(optimizer=Adam(lr=0.005),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Run Model:\n",
        "    results = model.fit(x=[X1[train,:,:]],\n",
        "                        y=Y[train,:],\n",
        "                        validation_data=([X1[test,:,:]], Y[test,:]),\n",
        "                        batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "                        verbose=1,\n",
        "                        callbacks=[])\n",
        "        # results = model.fit(x=[X1[train,:,:], X3[train,:,:]],\n",
        "        #                 y=Y[train,:],\n",
        "        #                 validation_data=([X1[test,:,:], X3[test,:,:],], Y[test,:]),\n",
        "        #                 batch_size=setBatchSizeNumber, epochs=setEpochNumber,\n",
        "        #                 verbose=1,\n",
        "        #                 callbacks=[])\n",
        "\n",
        "    # Evaluate the Model:\n",
        "    # accuracy = model.evaluate(x=[X1[test,:,:], X3[test,:,:]], y=Y[test,:])\n",
        "    accuracy = model.evaluate(x=[X1[test,:,:]], y=Y[test,:])\n",
        "    Accuracy.append(accuracy[1])\n",
        "\n",
        "    # Performance Metices:\n",
        "    Yactual = Y[test,:].argmax(axis=1)\n",
        "    # Yp = model.predict([X1[test,:,:], X3[test,:,:]])\n",
        "    Yp = model.predict([X1[test,:,:]])\n",
        "    v = Yp\n",
        "    Yp = Yp.argmax(axis=1)\n",
        "\n",
        "    CM = confusion_matrix(y_pred=Yp, y_true=Yactual)\n",
        "    TN, FP, FN, TP = CM.ravel()\n",
        "\n",
        "    MCC.append(matthews_corrcoef(y_true=Yactual, y_pred=Yp))\n",
        "    Sensitivity.append( TP / (TP + FN) )\n",
        "    Specificity.append( TN / (TN + FP) )\n",
        "    Precision.append(precision_score(y_true=Yactual, y_pred=Yp))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(Yactual, v[:,1])\n",
        "    TPR.append(interp(meanFPR, fpr, tpr))\n",
        "    rocauc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, rocauc))\n",
        "    i= i+1\n",
        "\n",
        "    # # Performance Plot\n",
        "    # print('#################################################')\n",
        "    # print('Fold\\'s Accuracy: {:.2f}'.format(accuracy[1]*100.0))\n",
        "    # lossPlot(results)\n",
        "    # accuracyPlot(results)\n",
        "    # print('#################################################')\n",
        "\n",
        "#end-for\n",
        "\n",
        "rocPlot(TPR, meanFPR)\n",
        "\n",
        "print(Accuracy)\n",
        "print('Accuracy: {:.2f}'.format(np.sum(Accuracy)/5.0))\n",
        "print('Sensitivity: {0:.4f}'.format(np.sum(Sensitivity)/5.00))\n",
        "print('Specificity: {0:.4f}'.format(np.sum(Specificity)/5.00))\n",
        "print('MCC: {0:.4f}'.format(np.sum(MCC)/5.00))\n",
        "print('Precision: {0:.4f}'.format(np.sum(Precision)/5.00))"
      ],
      "metadata": {
        "id": "_o28L8jW7KnB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e85e261d-fc98-44d9-d41e-3df966073478"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're using TF-2.15.0.\n",
            "(740, 15, 20)\n",
            "(740, 15, 31)\n",
            "(740, 15, 20)\n",
            "(740, 2)\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 15, 20)]          0         \n",
            "                                                                 \n",
            " conv1d_26 (Conv1D)          (None, 15, 10)            810       \n",
            "                                                                 \n",
            " batch_normalization_39 (Ba  (None, 15, 10)            40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 15, 10)            0         \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 15, 8)             248       \n",
            "                                                                 \n",
            " batch_normalization_40 (Ba  (None, 15, 8)             32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 15, 8)             0         \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 120)               0         \n",
            "                                                                 \n",
            " concatenate_13 (Concatenat  (None, 120)               0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 8)                 968       \n",
            "                                                                 \n",
            " batch_normalization_41 (Ba  (None, 8)                 32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2148 (8.39 KB)\n",
            "Trainable params: 2096 (8.19 KB)\n",
            "Non-trainable params: 52 (208.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 2s 5ms/step - loss: 1.5048 - accuracy: 0.4831 - val_loss: 1.0600 - val_accuracy: 0.5203\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.3845 - accuracy: 0.5034 - val_loss: 1.0525 - val_accuracy: 0.5135\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.3334 - accuracy: 0.5203 - val_loss: 1.0423 - val_accuracy: 0.5203\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2068 - accuracy: 0.5034 - val_loss: 1.0336 - val_accuracy: 0.5135\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1404 - accuracy: 0.5591 - val_loss: 1.0264 - val_accuracy: 0.5068\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1600 - accuracy: 0.4949 - val_loss: 1.0174 - val_accuracy: 0.5068\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0968 - accuracy: 0.4865 - val_loss: 1.0089 - val_accuracy: 0.5203\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.5220 - val_loss: 1.0000 - val_accuracy: 0.5068\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.5000 - val_loss: 0.9910 - val_accuracy: 0.5203\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0080 - accuracy: 0.5186 - val_loss: 0.9809 - val_accuracy: 0.5541\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9964 - accuracy: 0.5304 - val_loss: 0.9716 - val_accuracy: 0.5405\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9953 - accuracy: 0.5135 - val_loss: 0.9641 - val_accuracy: 0.5000\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.4831 - val_loss: 0.9555 - val_accuracy: 0.5405\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9602 - accuracy: 0.5321 - val_loss: 0.9478 - val_accuracy: 0.5338\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9448 - accuracy: 0.5236 - val_loss: 0.9383 - val_accuracy: 0.5338\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9329 - accuracy: 0.5456 - val_loss: 0.9294 - val_accuracy: 0.5270\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.9379 - accuracy: 0.5456 - val_loss: 0.9213 - val_accuracy: 0.5338\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9203 - accuracy: 0.5152 - val_loss: 0.9129 - val_accuracy: 0.5203\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9113 - accuracy: 0.5270 - val_loss: 0.9045 - val_accuracy: 0.5338\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9086 - accuracy: 0.5068 - val_loss: 0.8965 - val_accuracy: 0.5405\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8976 - accuracy: 0.5084 - val_loss: 0.8885 - val_accuracy: 0.5135\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 7ms/step - loss: 0.8847 - accuracy: 0.5574 - val_loss: 0.8805 - val_accuracy: 0.4730\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8773 - accuracy: 0.5118 - val_loss: 0.8726 - val_accuracy: 0.4730\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8713 - accuracy: 0.5118 - val_loss: 0.8638 - val_accuracy: 0.4730\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8585 - accuracy: 0.5304 - val_loss: 0.8552 - val_accuracy: 0.4730\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.8557 - accuracy: 0.5135 - val_loss: 0.8476 - val_accuracy: 0.4730\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8473 - accuracy: 0.5186 - val_loss: 0.8403 - val_accuracy: 0.4797\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.5608 - val_loss: 0.8329 - val_accuracy: 0.4797\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.8367 - accuracy: 0.4848 - val_loss: 0.8274 - val_accuracy: 0.4797\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8226 - accuracy: 0.5236 - val_loss: 0.8185 - val_accuracy: 0.5068\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8162 - accuracy: 0.5490 - val_loss: 0.8088 - val_accuracy: 0.6216\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8094 - accuracy: 0.5270 - val_loss: 0.8002 - val_accuracy: 0.6757\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7954 - accuracy: 0.5676 - val_loss: 0.7912 - val_accuracy: 0.6757\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8010 - accuracy: 0.5372 - val_loss: 0.7872 - val_accuracy: 0.6351\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7934 - accuracy: 0.5169 - val_loss: 0.7798 - val_accuracy: 0.6216\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7887 - accuracy: 0.5152 - val_loss: 0.7735 - val_accuracy: 0.6216\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7828 - accuracy: 0.5507 - val_loss: 0.7689 - val_accuracy: 0.6216\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7716 - accuracy: 0.5625 - val_loss: 0.7596 - val_accuracy: 0.6284\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.5439 - val_loss: 0.7481 - val_accuracy: 0.6689\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7674 - accuracy: 0.5490 - val_loss: 0.7391 - val_accuracy: 0.7027\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.6047 - val_loss: 0.7242 - val_accuracy: 0.7162\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7505 - accuracy: 0.5625 - val_loss: 0.7046 - val_accuracy: 0.7568\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7268 - accuracy: 0.6081 - val_loss: 0.6935 - val_accuracy: 0.7568\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.6233 - val_loss: 0.6748 - val_accuracy: 0.7432\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.7156 - accuracy: 0.6301 - val_loss: 0.6642 - val_accuracy: 0.7568\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.6486 - val_loss: 0.6572 - val_accuracy: 0.7838\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.6672 - val_loss: 0.6421 - val_accuracy: 0.7432\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.6182 - val_loss: 0.6481 - val_accuracy: 0.7230\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.6554 - val_loss: 0.6429 - val_accuracy: 0.7432\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6943 - val_loss: 0.6310 - val_accuracy: 0.7432\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.6301 - val_loss: 0.6315 - val_accuracy: 0.7635\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.6250 - val_loss: 0.6346 - val_accuracy: 0.7432\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7111 - val_loss: 0.6183 - val_accuracy: 0.7500\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.6993 - val_loss: 0.6180 - val_accuracy: 0.7635\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.6706 - val_loss: 0.6149 - val_accuracy: 0.7905\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6791 - val_loss: 0.6133 - val_accuracy: 0.7770\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6493 - accuracy: 0.6723 - val_loss: 0.5959 - val_accuracy: 0.7905\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6588 - accuracy: 0.6807 - val_loss: 0.5855 - val_accuracy: 0.7838\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 1s 7ms/step - loss: 0.6458 - accuracy: 0.6672 - val_loss: 0.5796 - val_accuracy: 0.7905\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.7044 - val_loss: 0.5721 - val_accuracy: 0.7973\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.7297 - val_loss: 0.5676 - val_accuracy: 0.7973\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.7078 - val_loss: 0.5751 - val_accuracy: 0.7973\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6440 - accuracy: 0.6926 - val_loss: 0.5687 - val_accuracy: 0.8041\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6959 - val_loss: 0.5593 - val_accuracy: 0.8108\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.7061 - val_loss: 0.5590 - val_accuracy: 0.7905\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.7010 - val_loss: 0.5427 - val_accuracy: 0.8108\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.7128 - val_loss: 0.5481 - val_accuracy: 0.8108\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.6959 - val_loss: 0.5484 - val_accuracy: 0.8108\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.7128 - val_loss: 0.5548 - val_accuracy: 0.8041\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.7297 - val_loss: 0.5406 - val_accuracy: 0.8108\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7399 - val_loss: 0.5296 - val_accuracy: 0.8243\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.7382 - val_loss: 0.5229 - val_accuracy: 0.8041\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7179 - val_loss: 0.5275 - val_accuracy: 0.7905\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7280 - val_loss: 0.5264 - val_accuracy: 0.7973\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7331 - val_loss: 0.5226 - val_accuracy: 0.8041\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.7280 - val_loss: 0.5303 - val_accuracy: 0.7905\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7449 - val_loss: 0.5363 - val_accuracy: 0.7973\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7162 - val_loss: 0.5354 - val_accuracy: 0.7973\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7365 - val_loss: 0.5296 - val_accuracy: 0.8041\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7432 - val_loss: 0.5271 - val_accuracy: 0.7973\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6993 - val_loss: 0.5310 - val_accuracy: 0.7973\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7382 - val_loss: 0.5360 - val_accuracy: 0.7905\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7416 - val_loss: 0.5297 - val_accuracy: 0.8041\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7348 - val_loss: 0.5282 - val_accuracy: 0.8108\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7230 - val_loss: 0.5237 - val_accuracy: 0.8108\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.7230 - val_loss: 0.5353 - val_accuracy: 0.8176\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7297 - val_loss: 0.5446 - val_accuracy: 0.7770\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7111 - val_loss: 0.5339 - val_accuracy: 0.7838\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7416 - val_loss: 0.5295 - val_accuracy: 0.7703\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7551 - val_loss: 0.5216 - val_accuracy: 0.8041\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7314 - val_loss: 0.5156 - val_accuracy: 0.8041\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.7095 - val_loss: 0.5296 - val_accuracy: 0.8041\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7162 - val_loss: 0.5228 - val_accuracy: 0.8041\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7432 - val_loss: 0.5193 - val_accuracy: 0.7905\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7534 - val_loss: 0.5216 - val_accuracy: 0.7905\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7466 - val_loss: 0.5162 - val_accuracy: 0.7905\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7483 - val_loss: 0.5146 - val_accuracy: 0.7905\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7247 - val_loss: 0.5224 - val_accuracy: 0.7838\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7416 - val_loss: 0.5183 - val_accuracy: 0.7905\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7179 - val_loss: 0.5223 - val_accuracy: 0.7905\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7382 - val_loss: 0.5132 - val_accuracy: 0.7838\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7483 - val_loss: 0.5115 - val_accuracy: 0.8108\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7517 - val_loss: 0.5148 - val_accuracy: 0.7973\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7551 - val_loss: 0.5131 - val_accuracy: 0.8041\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7416 - val_loss: 0.5099 - val_accuracy: 0.7973\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7736 - val_loss: 0.5082 - val_accuracy: 0.7905\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7736 - val_loss: 0.5082 - val_accuracy: 0.7973\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7568 - val_loss: 0.5056 - val_accuracy: 0.7973\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7551 - val_loss: 0.5112 - val_accuracy: 0.7838\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7466 - val_loss: 0.5161 - val_accuracy: 0.7905\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7483 - val_loss: 0.5161 - val_accuracy: 0.7905\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7128 - val_loss: 0.5140 - val_accuracy: 0.8041\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7551 - val_loss: 0.5064 - val_accuracy: 0.8041\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7534 - val_loss: 0.5015 - val_accuracy: 0.8108\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7297 - val_loss: 0.4963 - val_accuracy: 0.7973\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.7399 - val_loss: 0.5043 - val_accuracy: 0.8108\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7736 - val_loss: 0.4972 - val_accuracy: 0.8108\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.5047 - val_accuracy: 0.8041\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7449 - val_loss: 0.5068 - val_accuracy: 0.7973\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7584 - val_loss: 0.4998 - val_accuracy: 0.7973\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5929 - accuracy: 0.7551 - val_loss: 0.5015 - val_accuracy: 0.7973\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7500 - val_loss: 0.5085 - val_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7568 - val_loss: 0.5064 - val_accuracy: 0.7973\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7618 - val_loss: 0.5107 - val_accuracy: 0.7905\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7449 - val_loss: 0.5137 - val_accuracy: 0.7703\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7618 - val_loss: 0.5192 - val_accuracy: 0.7703\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7652 - val_loss: 0.5045 - val_accuracy: 0.7838\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.7517 - val_loss: 0.5077 - val_accuracy: 0.7905\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7483 - val_loss: 0.5018 - val_accuracy: 0.7838\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7432 - val_loss: 0.5064 - val_accuracy: 0.7770\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7584 - val_loss: 0.4989 - val_accuracy: 0.7973\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7821 - val_loss: 0.4893 - val_accuracy: 0.8176\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7601 - val_loss: 0.4875 - val_accuracy: 0.8108\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7196 - val_loss: 0.4905 - val_accuracy: 0.8041\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7432 - val_loss: 0.4851 - val_accuracy: 0.8041\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7568 - val_loss: 0.4787 - val_accuracy: 0.8311\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7753 - val_loss: 0.4811 - val_accuracy: 0.8176\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7196 - val_loss: 0.4833 - val_accuracy: 0.8041\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7534 - val_loss: 0.4927 - val_accuracy: 0.8108\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7483 - val_loss: 0.4946 - val_accuracy: 0.8311\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7601 - val_loss: 0.4989 - val_accuracy: 0.8311\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7618 - val_loss: 0.4973 - val_accuracy: 0.8176\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7618 - val_loss: 0.5026 - val_accuracy: 0.7905\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7517 - val_loss: 0.4982 - val_accuracy: 0.8041\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7652 - val_loss: 0.4921 - val_accuracy: 0.8311\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7720 - val_loss: 0.4926 - val_accuracy: 0.8108\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7517 - val_loss: 0.5058 - val_accuracy: 0.7838\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7838 - val_loss: 0.4889 - val_accuracy: 0.8311\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7483 - val_loss: 0.4913 - val_accuracy: 0.8243\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7213 - val_loss: 0.5025 - val_accuracy: 0.8176\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7551 - val_loss: 0.5034 - val_accuracy: 0.8176\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7568 - val_loss: 0.4906 - val_accuracy: 0.8176\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7669 - val_loss: 0.5049 - val_accuracy: 0.7973\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7584 - val_loss: 0.5054 - val_accuracy: 0.7973\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7348 - val_loss: 0.4928 - val_accuracy: 0.8176\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7635 - val_loss: 0.4856 - val_accuracy: 0.8176\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7652 - val_loss: 0.4890 - val_accuracy: 0.8176\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7551 - val_loss: 0.4938 - val_accuracy: 0.8176\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7720 - val_loss: 0.4927 - val_accuracy: 0.8311\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7770 - val_loss: 0.4865 - val_accuracy: 0.8243\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7770 - val_loss: 0.4872 - val_accuracy: 0.8311\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7551 - val_loss: 0.4974 - val_accuracy: 0.8176\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7652 - val_loss: 0.5005 - val_accuracy: 0.8176\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7753 - val_loss: 0.4892 - val_accuracy: 0.8108\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7686 - val_loss: 0.4923 - val_accuracy: 0.8176\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7517 - val_loss: 0.4884 - val_accuracy: 0.8108\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7973 - val_loss: 0.4813 - val_accuracy: 0.8243\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7314 - val_loss: 0.4902 - val_accuracy: 0.8108\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7804 - val_loss: 0.4879 - val_accuracy: 0.8176\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7601 - val_loss: 0.4884 - val_accuracy: 0.8243\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7703 - val_loss: 0.4839 - val_accuracy: 0.8243\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7855 - val_loss: 0.4749 - val_accuracy: 0.8176\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7618 - val_loss: 0.4823 - val_accuracy: 0.8108\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7517 - val_loss: 0.4759 - val_accuracy: 0.8041\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7551 - val_loss: 0.4864 - val_accuracy: 0.8108\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7331 - val_loss: 0.4835 - val_accuracy: 0.7973\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7466 - val_loss: 0.4863 - val_accuracy: 0.7973\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7618 - val_loss: 0.4872 - val_accuracy: 0.7973\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7652 - val_loss: 0.4909 - val_accuracy: 0.8108\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7922 - val_loss: 0.4847 - val_accuracy: 0.8108\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7466 - val_loss: 0.4834 - val_accuracy: 0.7973\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7804 - val_loss: 0.4830 - val_accuracy: 0.8108\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7753 - val_loss: 0.4814 - val_accuracy: 0.8108\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7973 - val_loss: 0.4810 - val_accuracy: 0.8108\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7534 - val_loss: 0.4886 - val_accuracy: 0.8041\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7500 - val_loss: 0.4807 - val_accuracy: 0.8041\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7551 - val_loss: 0.4736 - val_accuracy: 0.7973\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7889 - val_loss: 0.4878 - val_accuracy: 0.7973\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7686 - val_loss: 0.4797 - val_accuracy: 0.8041\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7466 - val_loss: 0.4914 - val_accuracy: 0.8108\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7314 - val_loss: 0.4837 - val_accuracy: 0.8041\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7855 - val_loss: 0.4826 - val_accuracy: 0.8176\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7365 - val_loss: 0.4879 - val_accuracy: 0.8176\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7399 - val_loss: 0.4788 - val_accuracy: 0.8176\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7500 - val_loss: 0.4932 - val_accuracy: 0.8108\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7635 - val_loss: 0.4809 - val_accuracy: 0.8176\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7720 - val_loss: 0.4777 - val_accuracy: 0.8108\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7652 - val_loss: 0.4885 - val_accuracy: 0.8176\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7753 - val_loss: 0.4936 - val_accuracy: 0.8108\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7618 - val_loss: 0.4977 - val_accuracy: 0.8041\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7399 - val_loss: 0.4958 - val_accuracy: 0.8041\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7770 - val_loss: 0.4893 - val_accuracy: 0.8176\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7736 - val_loss: 0.4912 - val_accuracy: 0.8243\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7804 - val_loss: 0.4831 - val_accuracy: 0.8176\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7601 - val_loss: 0.4806 - val_accuracy: 0.8311\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7601 - val_loss: 0.4884 - val_accuracy: 0.8108\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7770 - val_loss: 0.4783 - val_accuracy: 0.8243\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7247 - val_loss: 0.4826 - val_accuracy: 0.8378\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7652 - val_loss: 0.4861 - val_accuracy: 0.8243\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7804 - val_loss: 0.4894 - val_accuracy: 0.8243\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7686 - val_loss: 0.4942 - val_accuracy: 0.8176\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7770 - val_loss: 0.4888 - val_accuracy: 0.8041\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7584 - val_loss: 0.4847 - val_accuracy: 0.8041\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7922 - val_loss: 0.4917 - val_accuracy: 0.8176\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7584 - val_loss: 0.4962 - val_accuracy: 0.8108\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7720 - val_loss: 0.4872 - val_accuracy: 0.8311\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7652 - val_loss: 0.4904 - val_accuracy: 0.8378\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7568 - val_loss: 0.4776 - val_accuracy: 0.8243\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7838 - val_loss: 0.4715 - val_accuracy: 0.8514\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7804 - val_loss: 0.4747 - val_accuracy: 0.8311\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7736 - val_loss: 0.4722 - val_accuracy: 0.8446\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7534 - val_loss: 0.4723 - val_accuracy: 0.8378\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7855 - val_loss: 0.4764 - val_accuracy: 0.8446\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7584 - val_loss: 0.4858 - val_accuracy: 0.8243\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7635 - val_loss: 0.4792 - val_accuracy: 0.8378\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7483 - val_loss: 0.4870 - val_accuracy: 0.8378\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7720 - val_loss: 0.4844 - val_accuracy: 0.8311\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7686 - val_loss: 0.4752 - val_accuracy: 0.8446\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7652 - val_loss: 0.4775 - val_accuracy: 0.8243\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7720 - val_loss: 0.4845 - val_accuracy: 0.8311\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7618 - val_loss: 0.4790 - val_accuracy: 0.8243\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7584 - val_loss: 0.4745 - val_accuracy: 0.8108\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7787 - val_loss: 0.4707 - val_accuracy: 0.8446\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7703 - val_loss: 0.4741 - val_accuracy: 0.8378\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7720 - val_loss: 0.4783 - val_accuracy: 0.8514\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7736 - val_loss: 0.4759 - val_accuracy: 0.8378\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7399 - val_loss: 0.4824 - val_accuracy: 0.8446\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7618 - val_loss: 0.4821 - val_accuracy: 0.8176\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7568 - val_loss: 0.4791 - val_accuracy: 0.8378\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7838 - val_loss: 0.4847 - val_accuracy: 0.8378\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7652 - val_loss: 0.4770 - val_accuracy: 0.8311\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7517 - val_loss: 0.4861 - val_accuracy: 0.8176\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7939 - val_loss: 0.4799 - val_accuracy: 0.8311\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7736 - val_loss: 0.4950 - val_accuracy: 0.8176\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7669 - val_loss: 0.4983 - val_accuracy: 0.7973\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7449 - val_loss: 0.5045 - val_accuracy: 0.8041\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7601 - val_loss: 0.4972 - val_accuracy: 0.8108\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7669 - val_loss: 0.4984 - val_accuracy: 0.7973\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7770 - val_loss: 0.4945 - val_accuracy: 0.7905\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.8007 - val_loss: 0.4996 - val_accuracy: 0.7973\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7770 - val_loss: 0.4999 - val_accuracy: 0.8108\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7686 - val_loss: 0.5006 - val_accuracy: 0.8108\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5388 - accuracy: 0.7517 - val_loss: 0.4980 - val_accuracy: 0.8108\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7635 - val_loss: 0.4938 - val_accuracy: 0.8108\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7703 - val_loss: 0.4908 - val_accuracy: 0.8176\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7584 - val_loss: 0.4923 - val_accuracy: 0.8176\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7534 - val_loss: 0.4910 - val_accuracy: 0.8041\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7297 - val_loss: 0.4804 - val_accuracy: 0.8311\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7736 - val_loss: 0.4725 - val_accuracy: 0.8176\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.7838 - val_loss: 0.4694 - val_accuracy: 0.8378\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7753 - val_loss: 0.4700 - val_accuracy: 0.8243\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7872 - val_loss: 0.4727 - val_accuracy: 0.8311\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7618 - val_loss: 0.4767 - val_accuracy: 0.8176\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7889 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7618 - val_loss: 0.4730 - val_accuracy: 0.8378\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7872 - val_loss: 0.4692 - val_accuracy: 0.8243\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7517 - val_loss: 0.4784 - val_accuracy: 0.8243\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7618 - val_loss: 0.4848 - val_accuracy: 0.7973\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7821 - val_loss: 0.4791 - val_accuracy: 0.8108\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7736 - val_loss: 0.4787 - val_accuracy: 0.8176\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7652 - val_loss: 0.4864 - val_accuracy: 0.8176\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7601 - val_loss: 0.4894 - val_accuracy: 0.8108\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7736 - val_loss: 0.4818 - val_accuracy: 0.8108\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7584 - val_loss: 0.4836 - val_accuracy: 0.8176\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7753 - val_loss: 0.4759 - val_accuracy: 0.8243\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7669 - val_loss: 0.4789 - val_accuracy: 0.8176\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7686 - val_loss: 0.4804 - val_accuracy: 0.8108\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7821 - val_loss: 0.4814 - val_accuracy: 0.8108\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7821 - val_loss: 0.4837 - val_accuracy: 0.8311\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7449 - val_loss: 0.4905 - val_accuracy: 0.8041\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7720 - val_loss: 0.4876 - val_accuracy: 0.8176\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7568 - val_loss: 0.4867 - val_accuracy: 0.8378\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7821 - val_loss: 0.4882 - val_accuracy: 0.8311\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7432 - val_loss: 0.4782 - val_accuracy: 0.8243\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7517 - val_loss: 0.4742 - val_accuracy: 0.8446\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7821 - val_loss: 0.4824 - val_accuracy: 0.8378\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7770 - val_loss: 0.4684 - val_accuracy: 0.8311\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7922 - val_loss: 0.4699 - val_accuracy: 0.8176\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7720 - val_loss: 0.4727 - val_accuracy: 0.8176\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7703 - val_loss: 0.4801 - val_accuracy: 0.8311\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7314 - val_loss: 0.4927 - val_accuracy: 0.8243\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7669 - val_loss: 0.4860 - val_accuracy: 0.8243\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7753 - val_loss: 0.4835 - val_accuracy: 0.8311\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7449 - val_loss: 0.4822 - val_accuracy: 0.8243\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7686 - val_loss: 0.4887 - val_accuracy: 0.8176\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7720 - val_loss: 0.4771 - val_accuracy: 0.8378\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7855 - val_loss: 0.4746 - val_accuracy: 0.8446\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7787 - val_loss: 0.4744 - val_accuracy: 0.8243\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7483 - val_loss: 0.4817 - val_accuracy: 0.8378\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7551 - val_loss: 0.4768 - val_accuracy: 0.8311\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7838 - val_loss: 0.4746 - val_accuracy: 0.8378\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7686 - val_loss: 0.4735 - val_accuracy: 0.8243\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7787 - val_loss: 0.4790 - val_accuracy: 0.8243\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7686 - val_loss: 0.4797 - val_accuracy: 0.8243\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7703 - val_loss: 0.4774 - val_accuracy: 0.8311\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8243 - val_loss: 0.4687 - val_accuracy: 0.8243\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7669 - val_loss: 0.4703 - val_accuracy: 0.8243\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7922 - val_loss: 0.4732 - val_accuracy: 0.8108\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7720 - val_loss: 0.4675 - val_accuracy: 0.8311\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7584 - val_loss: 0.4714 - val_accuracy: 0.8446\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7348 - val_loss: 0.4731 - val_accuracy: 0.8108\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7720 - val_loss: 0.4739 - val_accuracy: 0.8378\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7770 - val_loss: 0.4756 - val_accuracy: 0.8311\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7483 - val_loss: 0.4741 - val_accuracy: 0.8311\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7601 - val_loss: 0.4661 - val_accuracy: 0.8311\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.8041 - val_loss: 0.4627 - val_accuracy: 0.8446\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7804 - val_loss: 0.4667 - val_accuracy: 0.8581\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7686 - val_loss: 0.4680 - val_accuracy: 0.8378\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7956 - val_loss: 0.4695 - val_accuracy: 0.8514\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7584 - val_loss: 0.4792 - val_accuracy: 0.8446\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7872 - val_loss: 0.4704 - val_accuracy: 0.8514\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7905 - val_loss: 0.4700 - val_accuracy: 0.8378\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7720 - val_loss: 0.4677 - val_accuracy: 0.8378\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7483 - val_loss: 0.4733 - val_accuracy: 0.8311\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7466 - val_loss: 0.4895 - val_accuracy: 0.8243\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7601 - val_loss: 0.4834 - val_accuracy: 0.8311\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7703 - val_loss: 0.4875 - val_accuracy: 0.8311\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7534 - val_loss: 0.4910 - val_accuracy: 0.8243\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7804 - val_loss: 0.4839 - val_accuracy: 0.8243\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8007 - val_loss: 0.4821 - val_accuracy: 0.8311\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7703 - val_loss: 0.4805 - val_accuracy: 0.8176\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7770 - val_loss: 0.4747 - val_accuracy: 0.8176\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7483 - val_loss: 0.4754 - val_accuracy: 0.8176\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7416 - val_loss: 0.4791 - val_accuracy: 0.8041\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7889 - val_loss: 0.4738 - val_accuracy: 0.8243\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7736 - val_loss: 0.4789 - val_accuracy: 0.8243\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7601 - val_loss: 0.4720 - val_accuracy: 0.8243\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7905 - val_loss: 0.4728 - val_accuracy: 0.8311\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7889 - val_loss: 0.4687 - val_accuracy: 0.8311\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7382 - val_loss: 0.4844 - val_accuracy: 0.8243\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7753 - val_loss: 0.4811 - val_accuracy: 0.8176\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7736 - val_loss: 0.4756 - val_accuracy: 0.8243\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7348 - val_loss: 0.4771 - val_accuracy: 0.8108\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7770 - val_loss: 0.4806 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7432 - val_loss: 0.4939 - val_accuracy: 0.8041\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7787 - val_loss: 0.4869 - val_accuracy: 0.8176\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7736 - val_loss: 0.4760 - val_accuracy: 0.8108\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7787 - val_loss: 0.4701 - val_accuracy: 0.8378\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7956 - val_loss: 0.4671 - val_accuracy: 0.8378\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7584 - val_loss: 0.4686 - val_accuracy: 0.8176\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7736 - val_loss: 0.4663 - val_accuracy: 0.8176\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7736 - val_loss: 0.4702 - val_accuracy: 0.8243\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7787 - val_loss: 0.4611 - val_accuracy: 0.8176\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7365 - val_loss: 0.4626 - val_accuracy: 0.8446\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7905 - val_loss: 0.4732 - val_accuracy: 0.8311\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7534 - val_loss: 0.4868 - val_accuracy: 0.8176\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7990 - val_loss: 0.4854 - val_accuracy: 0.8108\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7618 - val_loss: 0.4799 - val_accuracy: 0.8243\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7618 - val_loss: 0.4847 - val_accuracy: 0.8176\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7855 - val_loss: 0.4730 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7720 - val_loss: 0.4655 - val_accuracy: 0.8176\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7399 - val_loss: 0.4655 - val_accuracy: 0.8243\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.7483 - val_loss: 0.4794 - val_accuracy: 0.8176\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7787 - val_loss: 0.4712 - val_accuracy: 0.8311\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7905 - val_loss: 0.4751 - val_accuracy: 0.8176\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7517 - val_loss: 0.4688 - val_accuracy: 0.8311\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7534 - val_loss: 0.4730 - val_accuracy: 0.8446\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7466 - val_loss: 0.4812 - val_accuracy: 0.8311\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7787 - val_loss: 0.4822 - val_accuracy: 0.8378\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7652 - val_loss: 0.4774 - val_accuracy: 0.8378\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7652 - val_loss: 0.4849 - val_accuracy: 0.8446\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7449 - val_loss: 0.4813 - val_accuracy: 0.8514\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7669 - val_loss: 0.4832 - val_accuracy: 0.8514\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7889 - val_loss: 0.4788 - val_accuracy: 0.8446\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7449 - val_loss: 0.4831 - val_accuracy: 0.8311\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7517 - val_loss: 0.4801 - val_accuracy: 0.8311\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7517 - val_loss: 0.4840 - val_accuracy: 0.8446\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7703 - val_loss: 0.4935 - val_accuracy: 0.8176\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7753 - val_loss: 0.4875 - val_accuracy: 0.8311\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7669 - val_loss: 0.4787 - val_accuracy: 0.8514\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7534 - val_loss: 0.4897 - val_accuracy: 0.8176\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7753 - val_loss: 0.4766 - val_accuracy: 0.8446\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7635 - val_loss: 0.4700 - val_accuracy: 0.8446\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7635 - val_loss: 0.4682 - val_accuracy: 0.8514\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7804 - val_loss: 0.4704 - val_accuracy: 0.8446\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.8007 - val_loss: 0.4836 - val_accuracy: 0.8243\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7551 - val_loss: 0.4721 - val_accuracy: 0.8243\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7753 - val_loss: 0.4897 - val_accuracy: 0.7973\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7331 - val_loss: 0.4933 - val_accuracy: 0.8041\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7635 - val_loss: 0.4957 - val_accuracy: 0.8243\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7483 - val_loss: 0.4840 - val_accuracy: 0.7905\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7686 - val_loss: 0.4788 - val_accuracy: 0.8108\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7314 - val_loss: 0.4855 - val_accuracy: 0.8176\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7483 - val_loss: 0.4855 - val_accuracy: 0.8041\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7686 - val_loss: 0.4889 - val_accuracy: 0.8243\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7534 - val_loss: 0.4809 - val_accuracy: 0.8514\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7804 - val_loss: 0.4906 - val_accuracy: 0.8311\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7601 - val_loss: 0.4848 - val_accuracy: 0.8243\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7635 - val_loss: 0.4802 - val_accuracy: 0.8108\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7669 - val_loss: 0.4833 - val_accuracy: 0.8311\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7568 - val_loss: 0.4839 - val_accuracy: 0.8176\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7686 - val_loss: 0.4841 - val_accuracy: 0.8311\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7905 - val_loss: 0.4926 - val_accuracy: 0.8311\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7314 - val_loss: 0.4870 - val_accuracy: 0.8243\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7770 - val_loss: 0.4910 - val_accuracy: 0.8243\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7652 - val_loss: 0.4842 - val_accuracy: 0.8243\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7483 - val_loss: 0.4853 - val_accuracy: 0.8108\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7736 - val_loss: 0.4798 - val_accuracy: 0.8311\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7601 - val_loss: 0.4779 - val_accuracy: 0.8311\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7703 - val_loss: 0.4829 - val_accuracy: 0.8446\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7855 - val_loss: 0.4873 - val_accuracy: 0.8514\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7551 - val_loss: 0.4846 - val_accuracy: 0.8378\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7703 - val_loss: 0.4812 - val_accuracy: 0.8311\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7601 - val_loss: 0.4842 - val_accuracy: 0.8378\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7838 - val_loss: 0.4744 - val_accuracy: 0.8311\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7432 - val_loss: 0.4846 - val_accuracy: 0.8243\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7669 - val_loss: 0.4971 - val_accuracy: 0.8378\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7770 - val_loss: 0.5006 - val_accuracy: 0.8311\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7584 - val_loss: 0.4917 - val_accuracy: 0.8243\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7669 - val_loss: 0.4893 - val_accuracy: 0.8243\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7601 - val_loss: 0.4852 - val_accuracy: 0.8378\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7652 - val_loss: 0.4866 - val_accuracy: 0.8311\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7889 - val_loss: 0.4916 - val_accuracy: 0.8311\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7804 - val_loss: 0.4977 - val_accuracy: 0.8311\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7787 - val_loss: 0.4854 - val_accuracy: 0.8243\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7534 - val_loss: 0.4864 - val_accuracy: 0.8243\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7584 - val_loss: 0.4777 - val_accuracy: 0.8378\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7838 - val_loss: 0.4722 - val_accuracy: 0.8446\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7601 - val_loss: 0.4729 - val_accuracy: 0.8176\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7939 - val_loss: 0.4742 - val_accuracy: 0.8311\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7686 - val_loss: 0.4922 - val_accuracy: 0.8311\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7551 - val_loss: 0.4911 - val_accuracy: 0.7973\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7855 - val_loss: 0.4946 - val_accuracy: 0.8311\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7720 - val_loss: 0.4891 - val_accuracy: 0.8243\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7736 - val_loss: 0.4864 - val_accuracy: 0.8108\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7449 - val_loss: 0.4846 - val_accuracy: 0.8243\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7720 - val_loss: 0.4799 - val_accuracy: 0.8176\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7770 - val_loss: 0.4741 - val_accuracy: 0.8243\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7720 - val_loss: 0.4842 - val_accuracy: 0.8243\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7889 - val_loss: 0.4806 - val_accuracy: 0.8243\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7753 - val_loss: 0.4884 - val_accuracy: 0.8311\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7669 - val_loss: 0.4826 - val_accuracy: 0.8378\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7855 - val_loss: 0.4768 - val_accuracy: 0.8378\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7618 - val_loss: 0.4834 - val_accuracy: 0.8311\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7736 - val_loss: 0.4870 - val_accuracy: 0.8243\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7736 - val_loss: 0.4854 - val_accuracy: 0.8243\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7635 - val_loss: 0.4804 - val_accuracy: 0.8243\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7635 - val_loss: 0.4813 - val_accuracy: 0.8176\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7720 - val_loss: 0.4867 - val_accuracy: 0.8108\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7669 - val_loss: 0.4872 - val_accuracy: 0.8041\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7753 - val_loss: 0.4820 - val_accuracy: 0.8108\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7905 - val_loss: 0.4863 - val_accuracy: 0.8176\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7568 - val_loss: 0.4879 - val_accuracy: 0.8108\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7736 - val_loss: 0.4842 - val_accuracy: 0.8378\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7686 - val_loss: 0.4891 - val_accuracy: 0.8176\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7551 - val_loss: 0.4846 - val_accuracy: 0.8311\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7432 - val_loss: 0.4955 - val_accuracy: 0.8243\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7568 - val_loss: 0.4901 - val_accuracy: 0.8176\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7770 - val_loss: 0.4951 - val_accuracy: 0.8108\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7601 - val_loss: 0.5038 - val_accuracy: 0.8176\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7601 - val_loss: 0.4921 - val_accuracy: 0.8108\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7669 - val_loss: 0.4955 - val_accuracy: 0.8176\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7922 - val_loss: 0.4931 - val_accuracy: 0.8176\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7551 - val_loss: 0.4862 - val_accuracy: 0.8108\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7399 - val_loss: 0.4968 - val_accuracy: 0.8176\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7889 - val_loss: 0.5001 - val_accuracy: 0.8108\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7635 - val_loss: 0.4949 - val_accuracy: 0.8176\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7534 - val_loss: 0.4868 - val_accuracy: 0.8176\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7601 - val_loss: 0.4937 - val_accuracy: 0.8108\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7517 - val_loss: 0.4878 - val_accuracy: 0.8243\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7618 - val_loss: 0.4892 - val_accuracy: 0.8243\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7855 - val_loss: 0.4812 - val_accuracy: 0.8243\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7703 - val_loss: 0.4787 - val_accuracy: 0.8176\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7686 - val_loss: 0.4833 - val_accuracy: 0.8108\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7601 - val_loss: 0.4910 - val_accuracy: 0.8176\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7568 - val_loss: 0.4951 - val_accuracy: 0.8108\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7804 - val_loss: 0.4899 - val_accuracy: 0.8176\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7483 - val_loss: 0.5067 - val_accuracy: 0.8243\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7652 - val_loss: 0.4908 - val_accuracy: 0.8243\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7720 - val_loss: 0.4920 - val_accuracy: 0.8378\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7568 - val_loss: 0.4901 - val_accuracy: 0.8243\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7889 - val_loss: 0.4965 - val_accuracy: 0.8378\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7618 - val_loss: 0.4953 - val_accuracy: 0.8243\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7838 - val_loss: 0.4891 - val_accuracy: 0.8176\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7922 - val_loss: 0.5035 - val_accuracy: 0.8176\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7855 - val_loss: 0.5118 - val_accuracy: 0.8176\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7686 - val_loss: 0.5134 - val_accuracy: 0.8108\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7483 - val_loss: 0.5104 - val_accuracy: 0.8108\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7568 - val_loss: 0.5043 - val_accuracy: 0.7905\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7855 - val_loss: 0.4954 - val_accuracy: 0.8108\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7855 - val_loss: 0.4929 - val_accuracy: 0.8243\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7736 - val_loss: 0.4950 - val_accuracy: 0.8108\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7686 - val_loss: 0.4961 - val_accuracy: 0.7838\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7703 - val_loss: 0.4843 - val_accuracy: 0.8108\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7601 - val_loss: 0.4872 - val_accuracy: 0.8311\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7652 - val_loss: 0.4906 - val_accuracy: 0.8311\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7652 - val_loss: 0.4916 - val_accuracy: 0.8378\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7432 - val_loss: 0.4889 - val_accuracy: 0.7973\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7770 - val_loss: 0.4886 - val_accuracy: 0.8108\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7584 - val_loss: 0.4885 - val_accuracy: 0.8176\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8176\n",
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2b9853e732c7>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 2s 5ms/step - loss: 1.5444 - accuracy: 0.4848 - val_loss: 1.1141 - val_accuracy: 0.3919\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.4008 - accuracy: 0.5203 - val_loss: 1.1188 - val_accuracy: 0.3919\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2665 - accuracy: 0.5118 - val_loss: 1.1175 - val_accuracy: 0.3919\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2049 - accuracy: 0.5338 - val_loss: 1.1040 - val_accuracy: 0.3919\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1758 - accuracy: 0.4696 - val_loss: 1.0755 - val_accuracy: 0.3851\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1605 - accuracy: 0.4916 - val_loss: 1.0573 - val_accuracy: 0.3851\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0923 - accuracy: 0.4780 - val_loss: 1.0395 - val_accuracy: 0.3919\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0654 - accuracy: 0.5203 - val_loss: 1.0278 - val_accuracy: 0.3919\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.4831 - val_loss: 1.0146 - val_accuracy: 0.3919\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5338 - val_loss: 1.0112 - val_accuracy: 0.3919\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0073 - accuracy: 0.4932 - val_loss: 1.0015 - val_accuracy: 0.3919\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.5051 - val_loss: 0.9895 - val_accuracy: 0.3919\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9829 - accuracy: 0.5017 - val_loss: 0.9789 - val_accuracy: 0.3919\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.5253 - val_loss: 0.9744 - val_accuracy: 0.3919\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9621 - accuracy: 0.5051 - val_loss: 0.9673 - val_accuracy: 0.3919\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.5321 - val_loss: 0.9585 - val_accuracy: 0.3919\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.5068 - val_loss: 0.9495 - val_accuracy: 0.3919\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9351 - accuracy: 0.5017 - val_loss: 0.9371 - val_accuracy: 0.3919\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.9258 - accuracy: 0.5068 - val_loss: 0.9273 - val_accuracy: 0.3919\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9180 - accuracy: 0.5203 - val_loss: 0.9196 - val_accuracy: 0.3919\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.9027 - accuracy: 0.5456 - val_loss: 0.9093 - val_accuracy: 0.3851\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.9029 - accuracy: 0.5372 - val_loss: 0.9075 - val_accuracy: 0.3919\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8974 - accuracy: 0.5287 - val_loss: 0.9006 - val_accuracy: 0.3919\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8891 - accuracy: 0.5051 - val_loss: 0.8905 - val_accuracy: 0.3919\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8814 - accuracy: 0.4865 - val_loss: 0.8815 - val_accuracy: 0.3919\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.5355 - val_loss: 0.8734 - val_accuracy: 0.3919\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8655 - accuracy: 0.4983 - val_loss: 0.8674 - val_accuracy: 0.3919\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8576 - accuracy: 0.5084 - val_loss: 0.8639 - val_accuracy: 0.3919\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8495 - accuracy: 0.5118 - val_loss: 0.8568 - val_accuracy: 0.3919\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8422 - accuracy: 0.5135 - val_loss: 0.8469 - val_accuracy: 0.3919\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8338 - accuracy: 0.5169 - val_loss: 0.8394 - val_accuracy: 0.3919\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8293 - accuracy: 0.5034 - val_loss: 0.8362 - val_accuracy: 0.3919\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8211 - accuracy: 0.5405 - val_loss: 0.8276 - val_accuracy: 0.3919\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.5068 - val_loss: 0.8218 - val_accuracy: 0.3919\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.5236 - val_loss: 0.8177 - val_accuracy: 0.3919\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8036 - accuracy: 0.5203 - val_loss: 0.8129 - val_accuracy: 0.3919\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7992 - accuracy: 0.5186 - val_loss: 0.8027 - val_accuracy: 0.3919\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7906 - accuracy: 0.5372 - val_loss: 0.7920 - val_accuracy: 0.3919\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7876 - accuracy: 0.5051 - val_loss: 0.7904 - val_accuracy: 0.3919\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7795 - accuracy: 0.5321 - val_loss: 0.7893 - val_accuracy: 0.3919\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.5203 - val_loss: 0.7841 - val_accuracy: 0.3919\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7708 - accuracy: 0.5152 - val_loss: 0.7786 - val_accuracy: 0.3919\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7676 - accuracy: 0.5017 - val_loss: 0.7699 - val_accuracy: 0.3919\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.5220 - val_loss: 0.7649 - val_accuracy: 0.3919\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7543 - accuracy: 0.5422 - val_loss: 0.7595 - val_accuracy: 0.4122\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7545 - accuracy: 0.5372 - val_loss: 0.7577 - val_accuracy: 0.3919\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.5287 - val_loss: 0.7563 - val_accuracy: 0.3986\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.5389 - val_loss: 0.7491 - val_accuracy: 0.4459\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7420 - accuracy: 0.5574 - val_loss: 0.7482 - val_accuracy: 0.4257\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7456 - accuracy: 0.5253 - val_loss: 0.7435 - val_accuracy: 0.4730\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7354 - accuracy: 0.5473 - val_loss: 0.7380 - val_accuracy: 0.5338\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.5625 - val_loss: 0.7353 - val_accuracy: 0.5473\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7230 - accuracy: 0.5811 - val_loss: 0.7240 - val_accuracy: 0.6554\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7351 - accuracy: 0.5456 - val_loss: 0.7222 - val_accuracy: 0.6959\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7231 - accuracy: 0.5726 - val_loss: 0.7150 - val_accuracy: 0.7095\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.5794 - val_loss: 0.7059 - val_accuracy: 0.7027\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.5980 - val_loss: 0.6913 - val_accuracy: 0.7230\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.6233 - val_loss: 0.6799 - val_accuracy: 0.7432\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7004 - accuracy: 0.6132 - val_loss: 0.6686 - val_accuracy: 0.7297\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6284 - val_loss: 0.6536 - val_accuracy: 0.7703\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.6233 - val_loss: 0.6372 - val_accuracy: 0.7838\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.6436 - val_loss: 0.6379 - val_accuracy: 0.7703\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6892 - val_loss: 0.6201 - val_accuracy: 0.7905\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6739 - accuracy: 0.6470 - val_loss: 0.6113 - val_accuracy: 0.7838\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6846 - accuracy: 0.6554 - val_loss: 0.6188 - val_accuracy: 0.7770\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.7230 - val_loss: 0.6051 - val_accuracy: 0.7973\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6791 - val_loss: 0.6044 - val_accuracy: 0.7703\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.6520 - val_loss: 0.6038 - val_accuracy: 0.7703\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6774 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6807 - val_loss: 0.6057 - val_accuracy: 0.7703\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6875 - val_loss: 0.5995 - val_accuracy: 0.7838\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7162 - val_loss: 0.5914 - val_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.7348 - val_loss: 0.5876 - val_accuracy: 0.7905\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.7111 - val_loss: 0.5862 - val_accuracy: 0.7905\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.7213 - val_loss: 0.5812 - val_accuracy: 0.7703\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.7128 - val_loss: 0.5797 - val_accuracy: 0.7703\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.7027 - val_loss: 0.5741 - val_accuracy: 0.7838\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.7196 - val_loss: 0.5664 - val_accuracy: 0.7838\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6332 - accuracy: 0.7027 - val_loss: 0.5662 - val_accuracy: 0.7703\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.7162 - val_loss: 0.5669 - val_accuracy: 0.7905\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7027 - val_loss: 0.5628 - val_accuracy: 0.7770\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6858 - val_loss: 0.5615 - val_accuracy: 0.7905\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7111 - val_loss: 0.5652 - val_accuracy: 0.7770\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6043 - accuracy: 0.7264 - val_loss: 0.5688 - val_accuracy: 0.7770\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7399 - val_loss: 0.5628 - val_accuracy: 0.7703\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7483 - val_loss: 0.5572 - val_accuracy: 0.7770\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7568 - val_loss: 0.5483 - val_accuracy: 0.7838\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7483 - val_loss: 0.5475 - val_accuracy: 0.7635\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7145 - val_loss: 0.5411 - val_accuracy: 0.7770\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7483 - val_loss: 0.5450 - val_accuracy: 0.7770\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7466 - val_loss: 0.5519 - val_accuracy: 0.7905\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7314 - val_loss: 0.5621 - val_accuracy: 0.7770\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6240 - accuracy: 0.7145 - val_loss: 0.5555 - val_accuracy: 0.7905\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7399 - val_loss: 0.5581 - val_accuracy: 0.7703\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7162 - val_loss: 0.5542 - val_accuracy: 0.7635\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7416 - val_loss: 0.5469 - val_accuracy: 0.7905\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7551 - val_loss: 0.5500 - val_accuracy: 0.7770\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.7500 - val_loss: 0.5409 - val_accuracy: 0.7703\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5850 - accuracy: 0.7551 - val_loss: 0.5424 - val_accuracy: 0.7703\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.7247 - val_loss: 0.5421 - val_accuracy: 0.7703\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7635 - val_loss: 0.5362 - val_accuracy: 0.7635\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7449 - val_loss: 0.5374 - val_accuracy: 0.7770\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7297 - val_loss: 0.5425 - val_accuracy: 0.7905\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7568 - val_loss: 0.5402 - val_accuracy: 0.7770\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7736 - val_loss: 0.5369 - val_accuracy: 0.7838\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7551 - val_loss: 0.5488 - val_accuracy: 0.7838\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7449 - val_loss: 0.5435 - val_accuracy: 0.7703\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7449 - val_loss: 0.5392 - val_accuracy: 0.7838\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7736 - val_loss: 0.5380 - val_accuracy: 0.7905\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7770 - val_loss: 0.5307 - val_accuracy: 0.7838\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7618 - val_loss: 0.5289 - val_accuracy: 0.7838\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7584 - val_loss: 0.5261 - val_accuracy: 0.7838\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.7348 - val_loss: 0.5304 - val_accuracy: 0.7703\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.7399 - val_loss: 0.5321 - val_accuracy: 0.8041\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7601 - val_loss: 0.5254 - val_accuracy: 0.7973\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.7179 - val_loss: 0.5283 - val_accuracy: 0.7973\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.7601 - val_loss: 0.5227 - val_accuracy: 0.7838\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7838 - val_loss: 0.5239 - val_accuracy: 0.7703\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7230 - val_loss: 0.5321 - val_accuracy: 0.7838\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7500 - val_loss: 0.5278 - val_accuracy: 0.7838\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7703 - val_loss: 0.5342 - val_accuracy: 0.7635\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7720 - val_loss: 0.5223 - val_accuracy: 0.7973\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7804 - val_loss: 0.5185 - val_accuracy: 0.8041\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7162 - val_loss: 0.5093 - val_accuracy: 0.8378\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7753 - val_loss: 0.5173 - val_accuracy: 0.7973\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7432 - val_loss: 0.5261 - val_accuracy: 0.7905\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7584 - val_loss: 0.5285 - val_accuracy: 0.7770\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7804 - val_loss: 0.5159 - val_accuracy: 0.7905\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7568 - val_loss: 0.5173 - val_accuracy: 0.7703\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7686 - val_loss: 0.5139 - val_accuracy: 0.7973\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7331 - val_loss: 0.5124 - val_accuracy: 0.8041\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 0.5215 - val_accuracy: 0.7905\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7720 - val_loss: 0.5260 - val_accuracy: 0.7703\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7483 - val_loss: 0.5309 - val_accuracy: 0.7568\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7601 - val_loss: 0.5137 - val_accuracy: 0.8041\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7365 - val_loss: 0.5154 - val_accuracy: 0.7905\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7770 - val_loss: 0.5023 - val_accuracy: 0.8041\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7770 - val_loss: 0.5081 - val_accuracy: 0.7905\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7635 - val_loss: 0.5034 - val_accuracy: 0.8108\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7753 - val_loss: 0.5109 - val_accuracy: 0.7973\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7635 - val_loss: 0.5280 - val_accuracy: 0.7568\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7601 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7534 - val_loss: 0.5242 - val_accuracy: 0.7635\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7669 - val_loss: 0.5142 - val_accuracy: 0.7770\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7720 - val_loss: 0.5171 - val_accuracy: 0.7770\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7517 - val_loss: 0.5177 - val_accuracy: 0.7905\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7787 - val_loss: 0.5168 - val_accuracy: 0.7838\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7584 - val_loss: 0.5197 - val_accuracy: 0.7905\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7770\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7449 - val_loss: 0.5208 - val_accuracy: 0.7838\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7568 - val_loss: 0.5207 - val_accuracy: 0.7703\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7872 - val_loss: 0.5152 - val_accuracy: 0.7770\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7956 - val_loss: 0.5079 - val_accuracy: 0.7973\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7753 - val_loss: 0.5085 - val_accuracy: 0.7973\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7821 - val_loss: 0.5125 - val_accuracy: 0.7905\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7804 - val_loss: 0.5133 - val_accuracy: 0.7770\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.7449 - val_loss: 0.5225 - val_accuracy: 0.7703\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7601 - val_loss: 0.5121 - val_accuracy: 0.7905\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7652 - val_loss: 0.5198 - val_accuracy: 0.7703\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.7652 - val_loss: 0.5115 - val_accuracy: 0.7838\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7635 - val_loss: 0.5070 - val_accuracy: 0.7838\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7534 - val_loss: 0.5002 - val_accuracy: 0.8041\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7652 - val_loss: 0.5084 - val_accuracy: 0.7770\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7601 - val_loss: 0.4989 - val_accuracy: 0.8243\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7551 - val_loss: 0.4927 - val_accuracy: 0.8243\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7568 - val_loss: 0.5019 - val_accuracy: 0.7973\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7652 - val_loss: 0.4943 - val_accuracy: 0.8041\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7618 - val_loss: 0.4964 - val_accuracy: 0.7973\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7652 - val_loss: 0.5030 - val_accuracy: 0.7635\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7855 - val_loss: 0.5007 - val_accuracy: 0.7838\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7703 - val_loss: 0.4919 - val_accuracy: 0.8108\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7584 - val_loss: 0.4967 - val_accuracy: 0.8243\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7753 - val_loss: 0.4997 - val_accuracy: 0.7973\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7551 - val_loss: 0.5002 - val_accuracy: 0.8041\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.8108 - val_loss: 0.5014 - val_accuracy: 0.8041\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7635 - val_loss: 0.4984 - val_accuracy: 0.8176\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7618 - val_loss: 0.5001 - val_accuracy: 0.8108\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7736 - val_loss: 0.5069 - val_accuracy: 0.7973\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7753 - val_loss: 0.5073 - val_accuracy: 0.7973\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7584 - val_loss: 0.5102 - val_accuracy: 0.7905\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7652 - val_loss: 0.5088 - val_accuracy: 0.7838\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7686 - val_loss: 0.5015 - val_accuracy: 0.8041\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7652 - val_loss: 0.5071 - val_accuracy: 0.7770\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7686 - val_loss: 0.4994 - val_accuracy: 0.8108\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7804 - val_loss: 0.5032 - val_accuracy: 0.8243\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7432 - val_loss: 0.5037 - val_accuracy: 0.8041\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7618 - val_loss: 0.5006 - val_accuracy: 0.8243\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7804 - val_loss: 0.5071 - val_accuracy: 0.8041\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7618 - val_loss: 0.5018 - val_accuracy: 0.8041\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7500 - val_loss: 0.5065 - val_accuracy: 0.7973\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7365 - val_loss: 0.4998 - val_accuracy: 0.8176\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7753 - val_loss: 0.4977 - val_accuracy: 0.8041\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7365 - val_loss: 0.4970 - val_accuracy: 0.8243\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7703 - val_loss: 0.5046 - val_accuracy: 0.8041\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7804 - val_loss: 0.4878 - val_accuracy: 0.8311\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7703 - val_loss: 0.4875 - val_accuracy: 0.8176\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7720 - val_loss: 0.4862 - val_accuracy: 0.8176\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7517 - val_loss: 0.4814 - val_accuracy: 0.8311\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7905 - val_loss: 0.4775 - val_accuracy: 0.8378\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7720 - val_loss: 0.4952 - val_accuracy: 0.7905\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7736 - val_loss: 0.5065 - val_accuracy: 0.7905\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7686 - val_loss: 0.4916 - val_accuracy: 0.7905\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7821 - val_loss: 0.4828 - val_accuracy: 0.8041\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7872 - val_loss: 0.4851 - val_accuracy: 0.7973\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7720 - val_loss: 0.4868 - val_accuracy: 0.8041\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7686 - val_loss: 0.4866 - val_accuracy: 0.8041\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7416 - val_loss: 0.4888 - val_accuracy: 0.8176\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7736 - val_loss: 0.5065 - val_accuracy: 0.7838\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7669 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7804 - val_loss: 0.4999 - val_accuracy: 0.7905\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7686 - val_loss: 0.4988 - val_accuracy: 0.7905\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7416 - val_loss: 0.4955 - val_accuracy: 0.7905\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7517 - val_loss: 0.4884 - val_accuracy: 0.7770\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7703 - val_loss: 0.5022 - val_accuracy: 0.7635\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7652 - val_loss: 0.4902 - val_accuracy: 0.7973\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7821 - val_loss: 0.4854 - val_accuracy: 0.7905\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7956 - val_loss: 0.4903 - val_accuracy: 0.7905\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7669 - val_loss: 0.4899 - val_accuracy: 0.8176\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7686 - val_loss: 0.4904 - val_accuracy: 0.8176\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7601 - val_loss: 0.4939 - val_accuracy: 0.8108\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7669 - val_loss: 0.4790 - val_accuracy: 0.8378\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7855 - val_loss: 0.4884 - val_accuracy: 0.8041\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7618 - val_loss: 0.4943 - val_accuracy: 0.7770\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8041 - val_loss: 0.4858 - val_accuracy: 0.8108\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7872 - val_loss: 0.4736 - val_accuracy: 0.8311\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7416 - val_loss: 0.4734 - val_accuracy: 0.8446\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7990 - val_loss: 0.4819 - val_accuracy: 0.8176\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7635 - val_loss: 0.4789 - val_accuracy: 0.8108\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7601 - val_loss: 0.4802 - val_accuracy: 0.8311\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7669 - val_loss: 0.4831 - val_accuracy: 0.8243\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7517 - val_loss: 0.4786 - val_accuracy: 0.8378\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7399 - val_loss: 0.4865 - val_accuracy: 0.8311\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7584 - val_loss: 0.4957 - val_accuracy: 0.7905\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7686 - val_loss: 0.4841 - val_accuracy: 0.8176\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7686 - val_loss: 0.4788 - val_accuracy: 0.8243\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7838 - val_loss: 0.4842 - val_accuracy: 0.8378\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7584 - val_loss: 0.4855 - val_accuracy: 0.8311\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7568 - val_loss: 0.4954 - val_accuracy: 0.8176\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7416 - val_loss: 0.4950 - val_accuracy: 0.8176\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7736 - val_loss: 0.4908 - val_accuracy: 0.8311\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7551 - val_loss: 0.4969 - val_accuracy: 0.8176\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7365 - val_loss: 0.4974 - val_accuracy: 0.8378\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7568 - val_loss: 0.4958 - val_accuracy: 0.8378\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.8041 - val_loss: 0.4898 - val_accuracy: 0.8446\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7466 - val_loss: 0.4936 - val_accuracy: 0.8108\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7618 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7618 - val_loss: 0.4938 - val_accuracy: 0.8176\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8007 - val_loss: 0.4942 - val_accuracy: 0.8108\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7855 - val_loss: 0.4866 - val_accuracy: 0.8176\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7517 - val_loss: 0.4852 - val_accuracy: 0.8176\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7601 - val_loss: 0.4842 - val_accuracy: 0.8311\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7399 - val_loss: 0.4851 - val_accuracy: 0.8378\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7652 - val_loss: 0.4885 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7804 - val_loss: 0.4866 - val_accuracy: 0.8243\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7669 - val_loss: 0.4832 - val_accuracy: 0.8311\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7635 - val_loss: 0.4992 - val_accuracy: 0.8108\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7551 - val_loss: 0.4893 - val_accuracy: 0.8108\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7635 - val_loss: 0.4916 - val_accuracy: 0.8176\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7905 - val_loss: 0.5111 - val_accuracy: 0.8041\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7703 - val_loss: 0.4890 - val_accuracy: 0.8243\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7568 - val_loss: 0.4883 - val_accuracy: 0.8176\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7736 - val_loss: 0.4868 - val_accuracy: 0.8243\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7905 - val_loss: 0.4919 - val_accuracy: 0.8311\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7534 - val_loss: 0.4911 - val_accuracy: 0.8311\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7669 - val_loss: 0.5036 - val_accuracy: 0.8243\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7601 - val_loss: 0.5050 - val_accuracy: 0.8311\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7652 - val_loss: 0.4951 - val_accuracy: 0.8311\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7584 - val_loss: 0.4959 - val_accuracy: 0.8176\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7821 - val_loss: 0.5010 - val_accuracy: 0.8041\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7703 - val_loss: 0.5076 - val_accuracy: 0.7905\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7534 - val_loss: 0.5046 - val_accuracy: 0.7838\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7922 - val_loss: 0.5056 - val_accuracy: 0.7838\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7889 - val_loss: 0.4943 - val_accuracy: 0.7973\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7432 - val_loss: 0.4968 - val_accuracy: 0.8108\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7466 - val_loss: 0.4920 - val_accuracy: 0.8446\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7838 - val_loss: 0.4969 - val_accuracy: 0.8311\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7635 - val_loss: 0.4923 - val_accuracy: 0.8311\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7517 - val_loss: 0.4888 - val_accuracy: 0.8243\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7568 - val_loss: 0.4898 - val_accuracy: 0.8108\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7686 - val_loss: 0.4901 - val_accuracy: 0.8176\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7821 - val_loss: 0.4969 - val_accuracy: 0.8041\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7652 - val_loss: 0.4869 - val_accuracy: 0.8041\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7838 - val_loss: 0.4824 - val_accuracy: 0.8176\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7601 - val_loss: 0.4847 - val_accuracy: 0.8108\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7686 - val_loss: 0.4857 - val_accuracy: 0.8108\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7686 - val_loss: 0.4911 - val_accuracy: 0.8041\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7804 - val_loss: 0.4864 - val_accuracy: 0.7905\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7787 - val_loss: 0.4959 - val_accuracy: 0.7838\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7432 - val_loss: 0.4997 - val_accuracy: 0.7905\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7669 - val_loss: 0.4931 - val_accuracy: 0.8176\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7703 - val_loss: 0.4852 - val_accuracy: 0.8514\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7551 - val_loss: 0.5008 - val_accuracy: 0.8108\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.8007 - val_loss: 0.5011 - val_accuracy: 0.8108\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7686 - val_loss: 0.4978 - val_accuracy: 0.8108\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7855 - val_loss: 0.4901 - val_accuracy: 0.8041\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7483 - val_loss: 0.4979 - val_accuracy: 0.8041\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7584 - val_loss: 0.4935 - val_accuracy: 0.8108\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7889 - val_loss: 0.4924 - val_accuracy: 0.8108\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8159 - val_loss: 0.4914 - val_accuracy: 0.8108\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7432 - val_loss: 0.4863 - val_accuracy: 0.8041\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7770 - val_loss: 0.4949 - val_accuracy: 0.7905\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7720 - val_loss: 0.4912 - val_accuracy: 0.8311\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7956 - val_loss: 0.4927 - val_accuracy: 0.8108\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7703 - val_loss: 0.4906 - val_accuracy: 0.8243\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7838 - val_loss: 0.4881 - val_accuracy: 0.8311\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7770 - val_loss: 0.4766 - val_accuracy: 0.8243\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7855 - val_loss: 0.4783 - val_accuracy: 0.8311\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7416 - val_loss: 0.4802 - val_accuracy: 0.8243\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7720 - val_loss: 0.4913 - val_accuracy: 0.8446\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7838 - val_loss: 0.4814 - val_accuracy: 0.8378\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8024 - val_loss: 0.4887 - val_accuracy: 0.8378\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7669 - val_loss: 0.4853 - val_accuracy: 0.8243\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7432 - val_loss: 0.4973 - val_accuracy: 0.8108\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7618 - val_loss: 0.4978 - val_accuracy: 0.8176\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7770 - val_loss: 0.4922 - val_accuracy: 0.8108\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7703 - val_loss: 0.4910 - val_accuracy: 0.8108\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7686 - val_loss: 0.4894 - val_accuracy: 0.8108\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7635 - val_loss: 0.5060 - val_accuracy: 0.7838\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7432 - val_loss: 0.4942 - val_accuracy: 0.7905\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7534 - val_loss: 0.4837 - val_accuracy: 0.8243\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7753 - val_loss: 0.4843 - val_accuracy: 0.8108\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8159 - val_loss: 0.4837 - val_accuracy: 0.8041\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7821 - val_loss: 0.4802 - val_accuracy: 0.8311\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7736 - val_loss: 0.4739 - val_accuracy: 0.8446\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7720 - val_loss: 0.4933 - val_accuracy: 0.8041\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7753 - val_loss: 0.4783 - val_accuracy: 0.8446\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7720 - val_loss: 0.4791 - val_accuracy: 0.8378\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7939 - val_loss: 0.4850 - val_accuracy: 0.8108\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7534 - val_loss: 0.4852 - val_accuracy: 0.8108\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7922 - val_loss: 0.4899 - val_accuracy: 0.8243\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7821 - val_loss: 0.4830 - val_accuracy: 0.8176\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7804 - val_loss: 0.4882 - val_accuracy: 0.7973\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7483 - val_loss: 0.4844 - val_accuracy: 0.7905\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7551 - val_loss: 0.4845 - val_accuracy: 0.8108\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7635 - val_loss: 0.4865 - val_accuracy: 0.8176\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7770 - val_loss: 0.5006 - val_accuracy: 0.8041\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7568 - val_loss: 0.4963 - val_accuracy: 0.8041\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7804 - val_loss: 0.5040 - val_accuracy: 0.8041\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8024 - val_loss: 0.4822 - val_accuracy: 0.8041\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7889 - val_loss: 0.4890 - val_accuracy: 0.8041\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7551 - val_loss: 0.4850 - val_accuracy: 0.8041\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7990 - val_loss: 0.4725 - val_accuracy: 0.8041\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7855 - val_loss: 0.4802 - val_accuracy: 0.8041\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7551 - val_loss: 0.4812 - val_accuracy: 0.7838\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8057 - val_loss: 0.4776 - val_accuracy: 0.7973\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8074 - val_loss: 0.5014 - val_accuracy: 0.7703\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7449 - val_loss: 0.4885 - val_accuracy: 0.8176\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7399 - val_loss: 0.4852 - val_accuracy: 0.8041\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7686 - val_loss: 0.4838 - val_accuracy: 0.8176\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7517 - val_loss: 0.4914 - val_accuracy: 0.8108\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7584 - val_loss: 0.4976 - val_accuracy: 0.7905\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7922 - val_loss: 0.4995 - val_accuracy: 0.7905\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7736 - val_loss: 0.4886 - val_accuracy: 0.7905\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7787 - val_loss: 0.4944 - val_accuracy: 0.7838\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7703 - val_loss: 0.4925 - val_accuracy: 0.8108\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.7652 - val_loss: 0.4908 - val_accuracy: 0.7973\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7770 - val_loss: 0.4819 - val_accuracy: 0.8311\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7787 - val_loss: 0.4837 - val_accuracy: 0.8243\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7736 - val_loss: 0.4832 - val_accuracy: 0.8243\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5577 - accuracy: 0.7534 - val_loss: 0.4878 - val_accuracy: 0.8176\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7517 - val_loss: 0.4801 - val_accuracy: 0.8176\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7753 - val_loss: 0.4826 - val_accuracy: 0.8176\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7990 - val_loss: 0.4873 - val_accuracy: 0.8108\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7872 - val_loss: 0.4950 - val_accuracy: 0.8108\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7770 - val_loss: 0.4886 - val_accuracy: 0.8176\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7517 - val_loss: 0.4940 - val_accuracy: 0.8176\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7821 - val_loss: 0.4932 - val_accuracy: 0.8041\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7551 - val_loss: 0.4916 - val_accuracy: 0.8108\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7466 - val_loss: 0.4976 - val_accuracy: 0.8108\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7939 - val_loss: 0.4934 - val_accuracy: 0.7905\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7669 - val_loss: 0.4911 - val_accuracy: 0.8176\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7618 - val_loss: 0.4873 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7314 - val_loss: 0.4952 - val_accuracy: 0.8108\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7804 - val_loss: 0.4985 - val_accuracy: 0.8041\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7635 - val_loss: 0.4976 - val_accuracy: 0.7973\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7669 - val_loss: 0.4865 - val_accuracy: 0.8176\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7889 - val_loss: 0.4818 - val_accuracy: 0.8311\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7922 - val_loss: 0.4879 - val_accuracy: 0.7973\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7720 - val_loss: 0.4895 - val_accuracy: 0.8108\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7517 - val_loss: 0.4962 - val_accuracy: 0.8311\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7770 - val_loss: 0.4916 - val_accuracy: 0.8176\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7804 - val_loss: 0.4902 - val_accuracy: 0.8176\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7686 - val_loss: 0.4967 - val_accuracy: 0.8176\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7517 - val_loss: 0.4976 - val_accuracy: 0.8243\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7466 - val_loss: 0.4992 - val_accuracy: 0.8108\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7939 - val_loss: 0.4919 - val_accuracy: 0.8108\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7956 - val_loss: 0.4850 - val_accuracy: 0.8176\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7770 - val_loss: 0.4960 - val_accuracy: 0.7838\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7652 - val_loss: 0.4928 - val_accuracy: 0.8108\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7872 - val_loss: 0.5040 - val_accuracy: 0.7905\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8007 - val_loss: 0.5031 - val_accuracy: 0.7905\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7905 - val_loss: 0.4944 - val_accuracy: 0.7973\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7432 - val_loss: 0.5046 - val_accuracy: 0.7770\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7703 - val_loss: 0.5124 - val_accuracy: 0.7770\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7736 - val_loss: 0.5024 - val_accuracy: 0.8041\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7669 - val_loss: 0.4970 - val_accuracy: 0.8108\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7787 - val_loss: 0.5025 - val_accuracy: 0.7973\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7889 - val_loss: 0.4921 - val_accuracy: 0.8514\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8041 - val_loss: 0.4919 - val_accuracy: 0.8378\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7483 - val_loss: 0.4859 - val_accuracy: 0.8581\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8024 - val_loss: 0.4884 - val_accuracy: 0.8041\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7753 - val_loss: 0.4923 - val_accuracy: 0.8108\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7618 - val_loss: 0.4903 - val_accuracy: 0.8108\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7787 - val_loss: 0.4886 - val_accuracy: 0.8243\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7855 - val_loss: 0.4945 - val_accuracy: 0.8041\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7821 - val_loss: 0.4856 - val_accuracy: 0.8176\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7568 - val_loss: 0.4905 - val_accuracy: 0.8243\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7753 - val_loss: 0.4909 - val_accuracy: 0.8108\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7635 - val_loss: 0.5002 - val_accuracy: 0.8108\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7652 - val_loss: 0.4934 - val_accuracy: 0.7905\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7736 - val_loss: 0.4905 - val_accuracy: 0.7905\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7534 - val_loss: 0.4938 - val_accuracy: 0.8041\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7652 - val_loss: 0.4862 - val_accuracy: 0.8176\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7720 - val_loss: 0.4931 - val_accuracy: 0.8243\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7686 - val_loss: 0.4936 - val_accuracy: 0.7905\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7770 - val_loss: 0.4891 - val_accuracy: 0.7905\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7584 - val_loss: 0.4936 - val_accuracy: 0.7905\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7652 - val_loss: 0.4922 - val_accuracy: 0.7973\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7635 - val_loss: 0.4858 - val_accuracy: 0.7973\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7753 - val_loss: 0.4908 - val_accuracy: 0.8041\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7686 - val_loss: 0.4918 - val_accuracy: 0.7905\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7652 - val_loss: 0.5004 - val_accuracy: 0.7838\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.7821 - val_loss: 0.5028 - val_accuracy: 0.7905\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7720 - val_loss: 0.5182 - val_accuracy: 0.7432\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7736 - val_loss: 0.4953 - val_accuracy: 0.8041\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7483 - val_loss: 0.5061 - val_accuracy: 0.8108\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7821 - val_loss: 0.4964 - val_accuracy: 0.8243\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7922 - val_loss: 0.4954 - val_accuracy: 0.8176\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7939 - val_loss: 0.4957 - val_accuracy: 0.7905\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7703 - val_loss: 0.4916 - val_accuracy: 0.7973\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7500 - val_loss: 0.4884 - val_accuracy: 0.8108\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7804 - val_loss: 0.4867 - val_accuracy: 0.8041\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7753 - val_loss: 0.4894 - val_accuracy: 0.7838\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7382 - val_loss: 0.4970 - val_accuracy: 0.7905\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7804 - val_loss: 0.4853 - val_accuracy: 0.8108\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7635 - val_loss: 0.4932 - val_accuracy: 0.8108\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7855 - val_loss: 0.4923 - val_accuracy: 0.8041\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7601 - val_loss: 0.4949 - val_accuracy: 0.8108\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7568 - val_loss: 0.4972 - val_accuracy: 0.7973\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7753 - val_loss: 0.4938 - val_accuracy: 0.7973\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7703 - val_loss: 0.4988 - val_accuracy: 0.8041\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7787 - val_loss: 0.4882 - val_accuracy: 0.7973\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7872 - val_loss: 0.4839 - val_accuracy: 0.8176\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7449 - val_loss: 0.4907 - val_accuracy: 0.8108\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7703 - val_loss: 0.4881 - val_accuracy: 0.8108\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7635 - val_loss: 0.4872 - val_accuracy: 0.8243\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7956 - val_loss: 0.4780 - val_accuracy: 0.8176\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7568 - val_loss: 0.4811 - val_accuracy: 0.8311\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7703 - val_loss: 0.4861 - val_accuracy: 0.8176\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7669 - val_loss: 0.4876 - val_accuracy: 0.8378\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7889 - val_loss: 0.4932 - val_accuracy: 0.7973\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7635 - val_loss: 0.4989 - val_accuracy: 0.7905\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7736 - val_loss: 0.4891 - val_accuracy: 0.8041\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7973 - val_loss: 0.4883 - val_accuracy: 0.8041\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7956 - val_loss: 0.4888 - val_accuracy: 0.8108\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7753 - val_loss: 0.4897 - val_accuracy: 0.8041\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7787 - val_loss: 0.4840 - val_accuracy: 0.8041\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7703 - val_loss: 0.4965 - val_accuracy: 0.7973\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7449 - val_loss: 0.4974 - val_accuracy: 0.8041\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7753 - val_loss: 0.4878 - val_accuracy: 0.7973\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7787 - val_loss: 0.4895 - val_accuracy: 0.8176\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7652 - val_loss: 0.4946 - val_accuracy: 0.8108\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7939 - val_loss: 0.4987 - val_accuracy: 0.7973\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7534 - val_loss: 0.4905 - val_accuracy: 0.7973\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7669 - val_loss: 0.4874 - val_accuracy: 0.8041\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7804 - val_loss: 0.4943 - val_accuracy: 0.7905\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7703 - val_loss: 0.4962 - val_accuracy: 0.8176\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7703 - val_loss: 0.4895 - val_accuracy: 0.7973\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7703 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7703 - val_loss: 0.4971 - val_accuracy: 0.8108\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8176 - val_loss: 0.5086 - val_accuracy: 0.7905\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7753 - val_loss: 0.4955 - val_accuracy: 0.7973\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7973 - val_loss: 0.4911 - val_accuracy: 0.7973\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7821 - val_loss: 0.4861 - val_accuracy: 0.8108\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7584 - val_loss: 0.5008 - val_accuracy: 0.8041\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7584 - val_loss: 0.4946 - val_accuracy: 0.8176\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7551 - val_loss: 0.4892 - val_accuracy: 0.8176\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7787 - val_loss: 0.4921 - val_accuracy: 0.7973\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.8125 - val_loss: 0.4849 - val_accuracy: 0.8041\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7855 - val_loss: 0.4913 - val_accuracy: 0.8041\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7855 - val_loss: 0.4912 - val_accuracy: 0.8108\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.7534 - val_loss: 0.4906 - val_accuracy: 0.7973\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7770 - val_loss: 0.4962 - val_accuracy: 0.7973\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7669 - val_loss: 0.5005 - val_accuracy: 0.8176\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7872 - val_loss: 0.4995 - val_accuracy: 0.8243\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7889 - val_loss: 0.4939 - val_accuracy: 0.8041\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7736 - val_loss: 0.4904 - val_accuracy: 0.7973\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7669 - val_loss: 0.4935 - val_accuracy: 0.7905\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7872 - val_loss: 0.4922 - val_accuracy: 0.8041\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7686 - val_loss: 0.4887 - val_accuracy: 0.7973\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7584 - val_loss: 0.4896 - val_accuracy: 0.8041\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7787 - val_loss: 0.4912 - val_accuracy: 0.8176\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8024 - val_loss: 0.4914 - val_accuracy: 0.8243\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7601 - val_loss: 0.4928 - val_accuracy: 0.8041\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.7551 - val_loss: 0.4905 - val_accuracy: 0.8041\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7618 - val_loss: 0.4940 - val_accuracy: 0.7973\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7753 - val_loss: 0.4919 - val_accuracy: 0.8041\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7635 - val_loss: 0.4916 - val_accuracy: 0.8108\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7466 - val_loss: 0.4951 - val_accuracy: 0.8176\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7669 - val_loss: 0.4924 - val_accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2b9853e732c7>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 1s 4ms/step - loss: 1.5851 - accuracy: 0.5287 - val_loss: 1.1403 - val_accuracy: 0.5135\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.4315 - accuracy: 0.5135 - val_loss: 1.1668 - val_accuracy: 0.5135\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.3535 - accuracy: 0.5051 - val_loss: 1.1446 - val_accuracy: 0.5135\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2629 - accuracy: 0.5084 - val_loss: 1.1037 - val_accuracy: 0.5135\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2018 - accuracy: 0.4882 - val_loss: 1.0725 - val_accuracy: 0.5135\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0980 - accuracy: 0.5236 - val_loss: 1.0529 - val_accuracy: 0.5135\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1190 - accuracy: 0.5068 - val_loss: 1.0348 - val_accuracy: 0.5135\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1111 - accuracy: 0.4713 - val_loss: 1.0183 - val_accuracy: 0.5135\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.4814 - val_loss: 1.0055 - val_accuracy: 0.5135\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0127 - accuracy: 0.5203 - val_loss: 0.9952 - val_accuracy: 0.5135\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0176 - accuracy: 0.4848 - val_loss: 0.9837 - val_accuracy: 0.5135\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9914 - accuracy: 0.4696 - val_loss: 0.9736 - val_accuracy: 0.5135\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9817 - accuracy: 0.4696 - val_loss: 0.9643 - val_accuracy: 0.5135\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.5169 - val_loss: 0.9557 - val_accuracy: 0.5135\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.4899 - val_loss: 0.9469 - val_accuracy: 0.5135\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.5051 - val_loss: 0.9385 - val_accuracy: 0.5135\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.4983 - val_loss: 0.9309 - val_accuracy: 0.5135\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.5473 - val_loss: 0.9233 - val_accuracy: 0.5135\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.5169 - val_loss: 0.9148 - val_accuracy: 0.5135\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.5236 - val_loss: 0.9070 - val_accuracy: 0.5135\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9036 - accuracy: 0.5068 - val_loss: 0.8991 - val_accuracy: 0.5135\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.5186 - val_loss: 0.8916 - val_accuracy: 0.5135\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8864 - accuracy: 0.5304 - val_loss: 0.8837 - val_accuracy: 0.5135\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.5220 - val_loss: 0.8765 - val_accuracy: 0.5135\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.5321 - val_loss: 0.8699 - val_accuracy: 0.5135\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8696 - accuracy: 0.4966 - val_loss: 0.8613 - val_accuracy: 0.5135\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8562 - accuracy: 0.5304 - val_loss: 0.8538 - val_accuracy: 0.5135\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8508 - accuracy: 0.5000 - val_loss: 0.8472 - val_accuracy: 0.5135\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8456 - accuracy: 0.5101 - val_loss: 0.8405 - val_accuracy: 0.5135\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8348 - accuracy: 0.5270 - val_loss: 0.8340 - val_accuracy: 0.5135\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8342 - accuracy: 0.5270 - val_loss: 0.8277 - val_accuracy: 0.5135\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8267 - accuracy: 0.5118 - val_loss: 0.8206 - val_accuracy: 0.5270\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8252 - accuracy: 0.4595 - val_loss: 0.8147 - val_accuracy: 0.5203\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8140 - accuracy: 0.5169 - val_loss: 0.8083 - val_accuracy: 0.5203\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8056 - accuracy: 0.5000 - val_loss: 0.8022 - val_accuracy: 0.5203\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7986 - accuracy: 0.5051 - val_loss: 0.7959 - val_accuracy: 0.5946\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.5304 - val_loss: 0.7894 - val_accuracy: 0.5878\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7880 - accuracy: 0.5203 - val_loss: 0.7839 - val_accuracy: 0.5878\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.5000 - val_loss: 0.7793 - val_accuracy: 0.5270\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7797 - accuracy: 0.5068 - val_loss: 0.7744 - val_accuracy: 0.5135\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7694 - accuracy: 0.5507 - val_loss: 0.7690 - val_accuracy: 0.5135\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7656 - accuracy: 0.5338 - val_loss: 0.7633 - val_accuracy: 0.5270\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.5101 - val_loss: 0.7594 - val_accuracy: 0.5203\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.5524 - val_loss: 0.7554 - val_accuracy: 0.5135\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7544 - accuracy: 0.5355 - val_loss: 0.7449 - val_accuracy: 0.5473\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.5642 - val_loss: 0.7435 - val_accuracy: 0.5338\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.7410 - accuracy: 0.5507 - val_loss: 0.7358 - val_accuracy: 0.5676\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.5693 - val_loss: 0.7281 - val_accuracy: 0.5811\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7279 - accuracy: 0.5777 - val_loss: 0.7207 - val_accuracy: 0.6081\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7322 - accuracy: 0.5861 - val_loss: 0.7046 - val_accuracy: 0.6351\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7143 - accuracy: 0.6115 - val_loss: 0.6829 - val_accuracy: 0.6959\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.5929 - val_loss: 0.6735 - val_accuracy: 0.7095\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.6402 - val_loss: 0.6655 - val_accuracy: 0.6892\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6969 - accuracy: 0.6318 - val_loss: 0.6507 - val_accuracy: 0.7095\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.6605 - val_loss: 0.6560 - val_accuracy: 0.7095\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.6267 - val_loss: 0.6513 - val_accuracy: 0.7027\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.6554 - val_loss: 0.6454 - val_accuracy: 0.7162\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6916 - accuracy: 0.6453 - val_loss: 0.6287 - val_accuracy: 0.7365\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.6520 - val_loss: 0.6237 - val_accuracy: 0.7432\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.6672 - val_loss: 0.6258 - val_accuracy: 0.7432\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6976 - val_loss: 0.6099 - val_accuracy: 0.7432\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6858 - val_loss: 0.6083 - val_accuracy: 0.7500\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6892 - val_loss: 0.5978 - val_accuracy: 0.7770\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6824 - val_loss: 0.5949 - val_accuracy: 0.7703\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6959 - val_loss: 0.5935 - val_accuracy: 0.7500\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6740 - val_loss: 0.5863 - val_accuracy: 0.7703\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.6892 - val_loss: 0.5900 - val_accuracy: 0.7635\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6740 - val_loss: 0.5977 - val_accuracy: 0.7500\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7044 - val_loss: 0.5992 - val_accuracy: 0.7432\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6824 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7061 - val_loss: 0.5916 - val_accuracy: 0.7568\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.6588 - val_loss: 0.5811 - val_accuracy: 0.8041\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6689 - val_loss: 0.5785 - val_accuracy: 0.7770\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7128 - val_loss: 0.5792 - val_accuracy: 0.7770\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.7128 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6740 - val_loss: 0.5925 - val_accuracy: 0.7432\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.7061 - val_loss: 0.5665 - val_accuracy: 0.7703\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6976 - val_loss: 0.5596 - val_accuracy: 0.7770\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.7095 - val_loss: 0.5700 - val_accuracy: 0.7635\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7111 - val_loss: 0.5607 - val_accuracy: 0.7432\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6959 - val_loss: 0.5663 - val_accuracy: 0.7568\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.7095 - val_loss: 0.5586 - val_accuracy: 0.7703\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6875 - val_loss: 0.5497 - val_accuracy: 0.7838\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7466 - val_loss: 0.5490 - val_accuracy: 0.7635\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6959 - val_loss: 0.5562 - val_accuracy: 0.7770\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.7044 - val_loss: 0.5468 - val_accuracy: 0.7838\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6993 - val_loss: 0.5439 - val_accuracy: 0.7703\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.6976 - val_loss: 0.5426 - val_accuracy: 0.8176\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.7314 - val_loss: 0.5415 - val_accuracy: 0.8041\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7061 - val_loss: 0.5397 - val_accuracy: 0.7905\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.7331 - val_loss: 0.5349 - val_accuracy: 0.7973\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7432 - val_loss: 0.5272 - val_accuracy: 0.7770\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7517 - val_loss: 0.5211 - val_accuracy: 0.7973\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7348 - val_loss: 0.5222 - val_accuracy: 0.7905\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5984 - accuracy: 0.7230 - val_loss: 0.5102 - val_accuracy: 0.8378\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7213 - val_loss: 0.5094 - val_accuracy: 0.8243\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.7348 - val_loss: 0.5135 - val_accuracy: 0.8243\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7365 - val_loss: 0.5213 - val_accuracy: 0.8108\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.7044 - val_loss: 0.5270 - val_accuracy: 0.7973\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.7162 - val_loss: 0.5253 - val_accuracy: 0.7973\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7348 - val_loss: 0.5135 - val_accuracy: 0.8041\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7365 - val_loss: 0.5169 - val_accuracy: 0.7770\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7432 - val_loss: 0.5265 - val_accuracy: 0.7703\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.7128 - val_loss: 0.5066 - val_accuracy: 0.8176\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7230 - val_loss: 0.5104 - val_accuracy: 0.8108\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7432 - val_loss: 0.5072 - val_accuracy: 0.8243\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7061 - val_loss: 0.5013 - val_accuracy: 0.8311\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.7179 - val_loss: 0.5022 - val_accuracy: 0.8311\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.7297 - val_loss: 0.5047 - val_accuracy: 0.8311\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7280 - val_loss: 0.5072 - val_accuracy: 0.8378\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.7179 - val_loss: 0.5094 - val_accuracy: 0.8108\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7196 - val_loss: 0.5084 - val_accuracy: 0.8514\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7703 - val_loss: 0.5042 - val_accuracy: 0.8378\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.7280 - val_loss: 0.5030 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7432 - val_loss: 0.5048 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7584 - val_loss: 0.4954 - val_accuracy: 0.8514\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7247 - val_loss: 0.5062 - val_accuracy: 0.8108\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 0.4964 - val_accuracy: 0.8176\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6299 - accuracy: 0.7128 - val_loss: 0.4967 - val_accuracy: 0.8176\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.7348 - val_loss: 0.4984 - val_accuracy: 0.8446\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7297 - val_loss: 0.4970 - val_accuracy: 0.8378\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.7297 - val_loss: 0.4992 - val_accuracy: 0.8378\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7584 - val_loss: 0.4928 - val_accuracy: 0.8311\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.7432 - val_loss: 0.5063 - val_accuracy: 0.7905\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7466 - val_loss: 0.5020 - val_accuracy: 0.8041\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7534 - val_loss: 0.4947 - val_accuracy: 0.8041\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7365 - val_loss: 0.4964 - val_accuracy: 0.7905\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.7264 - val_loss: 0.4949 - val_accuracy: 0.8041\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.7416 - val_loss: 0.4883 - val_accuracy: 0.8243\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7078 - val_loss: 0.4933 - val_accuracy: 0.8243\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.7111 - val_loss: 0.5029 - val_accuracy: 0.7973\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7365 - val_loss: 0.5141 - val_accuracy: 0.7703\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.7095 - val_loss: 0.4983 - val_accuracy: 0.8243\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7703 - val_loss: 0.4845 - val_accuracy: 0.8243\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7416 - val_loss: 0.4912 - val_accuracy: 0.8176\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7416 - val_loss: 0.4869 - val_accuracy: 0.8108\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7534 - val_loss: 0.4954 - val_accuracy: 0.8108\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7449 - val_loss: 0.5035 - val_accuracy: 0.7973\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7416 - val_loss: 0.4885 - val_accuracy: 0.8108\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7584 - val_loss: 0.4976 - val_accuracy: 0.7973\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7568 - val_loss: 0.4766 - val_accuracy: 0.8311\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7432 - val_loss: 0.4867 - val_accuracy: 0.8514\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.7399 - val_loss: 0.4883 - val_accuracy: 0.8514\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7652 - val_loss: 0.4851 - val_accuracy: 0.8446\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7297 - val_loss: 0.4826 - val_accuracy: 0.8446\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7466 - val_loss: 0.4893 - val_accuracy: 0.8311\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.7230 - val_loss: 0.4881 - val_accuracy: 0.8176\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7652 - val_loss: 0.4796 - val_accuracy: 0.8311\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7382 - val_loss: 0.4754 - val_accuracy: 0.8446\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7432 - val_loss: 0.4758 - val_accuracy: 0.8378\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7432 - val_loss: 0.4766 - val_accuracy: 0.8311\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7483 - val_loss: 0.4713 - val_accuracy: 0.8311\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7770 - val_loss: 0.4713 - val_accuracy: 0.8378\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7534 - val_loss: 0.4781 - val_accuracy: 0.8311\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7534 - val_loss: 0.4836 - val_accuracy: 0.8176\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.7601 - val_loss: 0.4657 - val_accuracy: 0.8581\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.4755 - val_accuracy: 0.8514\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7568 - val_loss: 0.4820 - val_accuracy: 0.8446\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7432 - val_loss: 0.4775 - val_accuracy: 0.8514\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7179 - val_loss: 0.4814 - val_accuracy: 0.8446\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7365 - val_loss: 0.4820 - val_accuracy: 0.8378\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7770 - val_loss: 0.4683 - val_accuracy: 0.8378\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7703 - val_loss: 0.4618 - val_accuracy: 0.8243\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7399 - val_loss: 0.4809 - val_accuracy: 0.8446\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.7280 - val_loss: 0.4717 - val_accuracy: 0.8581\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7416 - val_loss: 0.4733 - val_accuracy: 0.8446\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7669 - val_loss: 0.4662 - val_accuracy: 0.8514\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7483 - val_loss: 0.4670 - val_accuracy: 0.8514\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7517 - val_loss: 0.4668 - val_accuracy: 0.8514\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7500 - val_loss: 0.4722 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7483 - val_loss: 0.4602 - val_accuracy: 0.8378\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.7331 - val_loss: 0.4723 - val_accuracy: 0.8311\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7635 - val_loss: 0.4638 - val_accuracy: 0.8378\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7483 - val_loss: 0.4675 - val_accuracy: 0.8311\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7720 - val_loss: 0.4683 - val_accuracy: 0.8243\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7770 - val_loss: 0.4668 - val_accuracy: 0.8514\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7314 - val_loss: 0.4654 - val_accuracy: 0.8378\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7652 - val_loss: 0.4555 - val_accuracy: 0.8378\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7466 - val_loss: 0.4517 - val_accuracy: 0.8446\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7517 - val_loss: 0.4514 - val_accuracy: 0.8514\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7500 - val_loss: 0.4554 - val_accuracy: 0.8514\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.7770 - val_loss: 0.4600 - val_accuracy: 0.8514\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7534 - val_loss: 0.4593 - val_accuracy: 0.8378\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7652 - val_loss: 0.4612 - val_accuracy: 0.8311\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7483 - val_loss: 0.4595 - val_accuracy: 0.8311\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7652 - val_loss: 0.4538 - val_accuracy: 0.8514\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7804 - val_loss: 0.4609 - val_accuracy: 0.8446\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7787 - val_loss: 0.4505 - val_accuracy: 0.8378\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7652 - val_loss: 0.4762 - val_accuracy: 0.8243\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7314 - val_loss: 0.4803 - val_accuracy: 0.8176\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7416 - val_loss: 0.4936 - val_accuracy: 0.8108\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7804 - val_loss: 0.4742 - val_accuracy: 0.8176\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7466 - val_loss: 0.4797 - val_accuracy: 0.8041\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7669 - val_loss: 0.4767 - val_accuracy: 0.8108\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7669 - val_loss: 0.4801 - val_accuracy: 0.8041\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7601 - val_loss: 0.4850 - val_accuracy: 0.8108\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7601 - val_loss: 0.4822 - val_accuracy: 0.8243\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7618 - val_loss: 0.4842 - val_accuracy: 0.8176\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7652 - val_loss: 0.4793 - val_accuracy: 0.8243\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7551 - val_loss: 0.4850 - val_accuracy: 0.8176\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7500 - val_loss: 0.4812 - val_accuracy: 0.8243\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7399 - val_loss: 0.4775 - val_accuracy: 0.8243\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7770 - val_loss: 0.4703 - val_accuracy: 0.8243\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7601 - val_loss: 0.4817 - val_accuracy: 0.8041\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7466 - val_loss: 0.4859 - val_accuracy: 0.8041\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7770 - val_loss: 0.4710 - val_accuracy: 0.8108\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7686 - val_loss: 0.4743 - val_accuracy: 0.8041\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7804 - val_loss: 0.4788 - val_accuracy: 0.7905\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7568 - val_loss: 0.4741 - val_accuracy: 0.8041\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7551 - val_loss: 0.4740 - val_accuracy: 0.8108\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7534 - val_loss: 0.4693 - val_accuracy: 0.7973\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7703 - val_loss: 0.4785 - val_accuracy: 0.8176\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7652 - val_loss: 0.4673 - val_accuracy: 0.8108\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7534 - val_loss: 0.4764 - val_accuracy: 0.8108\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7753 - val_loss: 0.4676 - val_accuracy: 0.8243\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.7264 - val_loss: 0.4804 - val_accuracy: 0.8311\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7838 - val_loss: 0.4721 - val_accuracy: 0.8176\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7466 - val_loss: 0.4744 - val_accuracy: 0.8243\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7669 - val_loss: 0.4721 - val_accuracy: 0.8311\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7601 - val_loss: 0.4656 - val_accuracy: 0.8243\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7753 - val_loss: 0.4658 - val_accuracy: 0.8176\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7466 - val_loss: 0.4679 - val_accuracy: 0.8108\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7399 - val_loss: 0.4695 - val_accuracy: 0.8243\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7669 - val_loss: 0.4767 - val_accuracy: 0.8108\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7770 - val_loss: 0.4679 - val_accuracy: 0.8176\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7922 - val_loss: 0.4654 - val_accuracy: 0.8176\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7449 - val_loss: 0.4560 - val_accuracy: 0.8311\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7601 - val_loss: 0.4570 - val_accuracy: 0.8378\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7416 - val_loss: 0.4605 - val_accuracy: 0.8446\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7703 - val_loss: 0.4652 - val_accuracy: 0.8378\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7500 - val_loss: 0.4733 - val_accuracy: 0.8176\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7247 - val_loss: 0.4770 - val_accuracy: 0.8243\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.7584 - val_loss: 0.4787 - val_accuracy: 0.8311\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7449 - val_loss: 0.4680 - val_accuracy: 0.8041\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7635 - val_loss: 0.4593 - val_accuracy: 0.8243\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7686 - val_loss: 0.4610 - val_accuracy: 0.8446\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7584 - val_loss: 0.4771 - val_accuracy: 0.8378\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7483 - val_loss: 0.4767 - val_accuracy: 0.8108\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7382 - val_loss: 0.4688 - val_accuracy: 0.8108\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7584 - val_loss: 0.4692 - val_accuracy: 0.8243\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7483 - val_loss: 0.4612 - val_accuracy: 0.7973\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7821 - val_loss: 0.4467 - val_accuracy: 0.8311\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7534 - val_loss: 0.4539 - val_accuracy: 0.8378\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7449 - val_loss: 0.4660 - val_accuracy: 0.8041\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7804 - val_loss: 0.4591 - val_accuracy: 0.8243\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7635 - val_loss: 0.4644 - val_accuracy: 0.8176\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7551 - val_loss: 0.4614 - val_accuracy: 0.8108\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7753 - val_loss: 0.4603 - val_accuracy: 0.8176\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.7517 - val_loss: 0.4566 - val_accuracy: 0.8108\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.7432 - val_loss: 0.4562 - val_accuracy: 0.8108\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.7686 - val_loss: 0.4505 - val_accuracy: 0.8311\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7770 - val_loss: 0.4512 - val_accuracy: 0.8176\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7280 - val_loss: 0.4521 - val_accuracy: 0.8243\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7551 - val_loss: 0.4518 - val_accuracy: 0.8311\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7551 - val_loss: 0.4470 - val_accuracy: 0.8378\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7584 - val_loss: 0.4541 - val_accuracy: 0.8446\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7466 - val_loss: 0.4539 - val_accuracy: 0.8446\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7770 - val_loss: 0.4514 - val_accuracy: 0.8446\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7500 - val_loss: 0.4513 - val_accuracy: 0.8311\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7466 - val_loss: 0.4451 - val_accuracy: 0.8311\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7601 - val_loss: 0.4496 - val_accuracy: 0.8378\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7483 - val_loss: 0.4588 - val_accuracy: 0.8378\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7551 - val_loss: 0.4595 - val_accuracy: 0.8311\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7787 - val_loss: 0.4499 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7736 - val_loss: 0.4510 - val_accuracy: 0.8514\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7618 - val_loss: 0.4631 - val_accuracy: 0.8311\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7736 - val_loss: 0.4635 - val_accuracy: 0.8311\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7855 - val_loss: 0.4490 - val_accuracy: 0.8514\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7568 - val_loss: 0.4532 - val_accuracy: 0.8446\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7770 - val_loss: 0.4566 - val_accuracy: 0.8581\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7432 - val_loss: 0.4559 - val_accuracy: 0.8514\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7753 - val_loss: 0.4688 - val_accuracy: 0.8446\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7483 - val_loss: 0.4717 - val_accuracy: 0.8378\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7264 - val_loss: 0.4760 - val_accuracy: 0.8581\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7753 - val_loss: 0.4691 - val_accuracy: 0.8446\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7618 - val_loss: 0.4771 - val_accuracy: 0.8514\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7720 - val_loss: 0.4689 - val_accuracy: 0.8378\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7432 - val_loss: 0.4657 - val_accuracy: 0.8514\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7517 - val_loss: 0.4643 - val_accuracy: 0.8176\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7568 - val_loss: 0.4599 - val_accuracy: 0.8041\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7939 - val_loss: 0.4589 - val_accuracy: 0.8378\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7838 - val_loss: 0.4583 - val_accuracy: 0.8446\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7584 - val_loss: 0.4642 - val_accuracy: 0.8311\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7720 - val_loss: 0.4611 - val_accuracy: 0.8446\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7652 - val_loss: 0.4580 - val_accuracy: 0.8446\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7416 - val_loss: 0.4652 - val_accuracy: 0.8243\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.8074 - val_loss: 0.4625 - val_accuracy: 0.8108\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7635 - val_loss: 0.4526 - val_accuracy: 0.8446\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7247 - val_loss: 0.4562 - val_accuracy: 0.8446\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7618 - val_loss: 0.4567 - val_accuracy: 0.8243\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7804 - val_loss: 0.4568 - val_accuracy: 0.8311\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7534 - val_loss: 0.4700 - val_accuracy: 0.8176\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7568 - val_loss: 0.4655 - val_accuracy: 0.8176\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7804 - val_loss: 0.4646 - val_accuracy: 0.8176\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7247 - val_loss: 0.4600 - val_accuracy: 0.8176\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7720 - val_loss: 0.4564 - val_accuracy: 0.8243\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7652 - val_loss: 0.4578 - val_accuracy: 0.8243\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7686 - val_loss: 0.4683 - val_accuracy: 0.8378\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7703 - val_loss: 0.4659 - val_accuracy: 0.8108\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7770 - val_loss: 0.4680 - val_accuracy: 0.8108\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7449 - val_loss: 0.4655 - val_accuracy: 0.8041\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5849 - accuracy: 0.7601 - val_loss: 0.4691 - val_accuracy: 0.8243\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7787 - val_loss: 0.4601 - val_accuracy: 0.8176\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7821 - val_loss: 0.4579 - val_accuracy: 0.8108\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7872 - val_loss: 0.4626 - val_accuracy: 0.7973\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7618 - val_loss: 0.4602 - val_accuracy: 0.8176\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7720 - val_loss: 0.4613 - val_accuracy: 0.8176\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7449 - val_loss: 0.4620 - val_accuracy: 0.8108\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7770 - val_loss: 0.4599 - val_accuracy: 0.8108\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7551 - val_loss: 0.4675 - val_accuracy: 0.8108\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5486 - accuracy: 0.7652 - val_loss: 0.4623 - val_accuracy: 0.8041\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7618 - val_loss: 0.4673 - val_accuracy: 0.8108\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7618 - val_loss: 0.4748 - val_accuracy: 0.8041\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7466 - val_loss: 0.4626 - val_accuracy: 0.8311\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.7787 - val_loss: 0.4663 - val_accuracy: 0.8176\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.7652 - val_loss: 0.4638 - val_accuracy: 0.8176\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7753 - val_loss: 0.4675 - val_accuracy: 0.8176\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7720 - val_loss: 0.4677 - val_accuracy: 0.8243\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8041 - val_loss: 0.4614 - val_accuracy: 0.8378\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7720 - val_loss: 0.4627 - val_accuracy: 0.8311\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7449 - val_loss: 0.4736 - val_accuracy: 0.8176\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7517 - val_loss: 0.4630 - val_accuracy: 0.8176\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7821 - val_loss: 0.4659 - val_accuracy: 0.8041\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7449 - val_loss: 0.4751 - val_accuracy: 0.8176\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7449 - val_loss: 0.4748 - val_accuracy: 0.8041\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7686 - val_loss: 0.4781 - val_accuracy: 0.8108\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7483 - val_loss: 0.4615 - val_accuracy: 0.8176\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5737 - accuracy: 0.7365 - val_loss: 0.4663 - val_accuracy: 0.8243\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7432 - val_loss: 0.4681 - val_accuracy: 0.8176\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7500 - val_loss: 0.4730 - val_accuracy: 0.8243\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7483 - val_loss: 0.4631 - val_accuracy: 0.8176\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7584 - val_loss: 0.4603 - val_accuracy: 0.8311\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8041 - val_loss: 0.4531 - val_accuracy: 0.8041\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7669 - val_loss: 0.4585 - val_accuracy: 0.8176\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7787 - val_loss: 0.4712 - val_accuracy: 0.8108\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7551 - val_loss: 0.4742 - val_accuracy: 0.8311\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7500 - val_loss: 0.4633 - val_accuracy: 0.8243\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7517 - val_loss: 0.4538 - val_accuracy: 0.8446\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7551 - val_loss: 0.4472 - val_accuracy: 0.8378\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7584 - val_loss: 0.4539 - val_accuracy: 0.8378\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7601 - val_loss: 0.4611 - val_accuracy: 0.8176\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7635 - val_loss: 0.4601 - val_accuracy: 0.8311\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7584 - val_loss: 0.4713 - val_accuracy: 0.8311\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7635 - val_loss: 0.4734 - val_accuracy: 0.8243\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7483 - val_loss: 0.4606 - val_accuracy: 0.8108\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7500 - val_loss: 0.4653 - val_accuracy: 0.8176\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7500 - val_loss: 0.4646 - val_accuracy: 0.8243\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7652 - val_loss: 0.4625 - val_accuracy: 0.8176\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7821 - val_loss: 0.4669 - val_accuracy: 0.8311\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.7635 - val_loss: 0.4737 - val_accuracy: 0.8311\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7568 - val_loss: 0.4668 - val_accuracy: 0.8311\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7821 - val_loss: 0.4684 - val_accuracy: 0.8311\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7601 - val_loss: 0.4554 - val_accuracy: 0.8378\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7568 - val_loss: 0.4590 - val_accuracy: 0.8243\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7686 - val_loss: 0.4787 - val_accuracy: 0.8041\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7432 - val_loss: 0.4743 - val_accuracy: 0.8243\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7449 - val_loss: 0.4697 - val_accuracy: 0.8311\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7872 - val_loss: 0.4780 - val_accuracy: 0.8378\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7669 - val_loss: 0.4677 - val_accuracy: 0.8108\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7500 - val_loss: 0.4632 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7720 - val_loss: 0.4525 - val_accuracy: 0.8243\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7534 - val_loss: 0.4612 - val_accuracy: 0.8108\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7922 - val_loss: 0.4631 - val_accuracy: 0.7973\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7331 - val_loss: 0.4680 - val_accuracy: 0.8108\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7584 - val_loss: 0.4690 - val_accuracy: 0.8108\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7500 - val_loss: 0.4681 - val_accuracy: 0.8108\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7348 - val_loss: 0.4644 - val_accuracy: 0.8041\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7720 - val_loss: 0.4691 - val_accuracy: 0.8176\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7466 - val_loss: 0.4651 - val_accuracy: 0.8243\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7669 - val_loss: 0.4664 - val_accuracy: 0.8378\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7416 - val_loss: 0.4695 - val_accuracy: 0.8108\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7483 - val_loss: 0.4719 - val_accuracy: 0.8176\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7551 - val_loss: 0.4667 - val_accuracy: 0.8041\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7838 - val_loss: 0.4681 - val_accuracy: 0.7973\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7821 - val_loss: 0.4595 - val_accuracy: 0.8108\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7669 - val_loss: 0.4519 - val_accuracy: 0.8108\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7804 - val_loss: 0.4557 - val_accuracy: 0.8108\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.7382 - val_loss: 0.4698 - val_accuracy: 0.7905\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7652 - val_loss: 0.4850 - val_accuracy: 0.7838\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7584 - val_loss: 0.4742 - val_accuracy: 0.8176\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7500 - val_loss: 0.4651 - val_accuracy: 0.8176\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7601 - val_loss: 0.4718 - val_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7601 - val_loss: 0.4703 - val_accuracy: 0.7973\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7652 - val_loss: 0.4635 - val_accuracy: 0.8176\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7584 - val_loss: 0.4681 - val_accuracy: 0.8108\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7889 - val_loss: 0.4666 - val_accuracy: 0.8108\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7720 - val_loss: 0.4621 - val_accuracy: 0.8243\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7770 - val_loss: 0.4662 - val_accuracy: 0.8176\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7753 - val_loss: 0.4755 - val_accuracy: 0.8041\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7804 - val_loss: 0.4528 - val_accuracy: 0.8176\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7432 - val_loss: 0.4652 - val_accuracy: 0.8176\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7821 - val_loss: 0.4564 - val_accuracy: 0.8378\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7753 - val_loss: 0.4643 - val_accuracy: 0.7973\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7517 - val_loss: 0.4598 - val_accuracy: 0.8243\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7804 - val_loss: 0.4606 - val_accuracy: 0.8108\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7720 - val_loss: 0.4498 - val_accuracy: 0.8041\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7534 - val_loss: 0.4550 - val_accuracy: 0.8041\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7889 - val_loss: 0.4642 - val_accuracy: 0.7973\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7331 - val_loss: 0.4796 - val_accuracy: 0.8041\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7601 - val_loss: 0.4590 - val_accuracy: 0.8243\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7601 - val_loss: 0.4538 - val_accuracy: 0.8243\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7399 - val_loss: 0.4685 - val_accuracy: 0.8243\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7551 - val_loss: 0.4563 - val_accuracy: 0.8446\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7449 - val_loss: 0.4524 - val_accuracy: 0.8311\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7720 - val_loss: 0.4647 - val_accuracy: 0.8378\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7365 - val_loss: 0.4715 - val_accuracy: 0.8311\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7669 - val_loss: 0.4638 - val_accuracy: 0.8243\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8041 - val_loss: 0.4584 - val_accuracy: 0.8243\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7939 - val_loss: 0.4598 - val_accuracy: 0.8176\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7568 - val_loss: 0.4570 - val_accuracy: 0.7973\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7838 - val_loss: 0.4638 - val_accuracy: 0.7973\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7973 - val_loss: 0.4600 - val_accuracy: 0.8176\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7568 - val_loss: 0.4622 - val_accuracy: 0.8041\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7601 - val_loss: 0.4556 - val_accuracy: 0.8311\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7804 - val_loss: 0.4549 - val_accuracy: 0.8649\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7517 - val_loss: 0.4441 - val_accuracy: 0.8649\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7787 - val_loss: 0.4467 - val_accuracy: 0.8378\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7770 - val_loss: 0.4468 - val_accuracy: 0.8243\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7703 - val_loss: 0.4408 - val_accuracy: 0.8514\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.7736 - val_loss: 0.4485 - val_accuracy: 0.8378\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7652 - val_loss: 0.4529 - val_accuracy: 0.8243\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7466 - val_loss: 0.4639 - val_accuracy: 0.8311\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7348 - val_loss: 0.4635 - val_accuracy: 0.8243\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7686 - val_loss: 0.4599 - val_accuracy: 0.8243\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7635 - val_loss: 0.4525 - val_accuracy: 0.8108\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7534 - val_loss: 0.4588 - val_accuracy: 0.8176\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7770 - val_loss: 0.4580 - val_accuracy: 0.8108\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7635 - val_loss: 0.4544 - val_accuracy: 0.8176\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7736 - val_loss: 0.4513 - val_accuracy: 0.8243\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7551 - val_loss: 0.4552 - val_accuracy: 0.8176\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7855 - val_loss: 0.4481 - val_accuracy: 0.8108\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7770 - val_loss: 0.4504 - val_accuracy: 0.8378\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.8041 - val_loss: 0.4576 - val_accuracy: 0.8176\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7534 - val_loss: 0.4527 - val_accuracy: 0.8243\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7872 - val_loss: 0.4559 - val_accuracy: 0.8378\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7821 - val_loss: 0.4540 - val_accuracy: 0.8378\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7568 - val_loss: 0.4611 - val_accuracy: 0.8176\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7720 - val_loss: 0.4591 - val_accuracy: 0.8243\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7601 - val_loss: 0.4663 - val_accuracy: 0.8378\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7922 - val_loss: 0.4670 - val_accuracy: 0.8446\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7838 - val_loss: 0.4662 - val_accuracy: 0.8243\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7584 - val_loss: 0.4659 - val_accuracy: 0.8108\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7449 - val_loss: 0.4647 - val_accuracy: 0.8108\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7635 - val_loss: 0.4570 - val_accuracy: 0.8041\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7416 - val_loss: 0.4592 - val_accuracy: 0.8108\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.7753 - val_loss: 0.4525 - val_accuracy: 0.8176\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.7618 - val_loss: 0.4578 - val_accuracy: 0.8176\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7517 - val_loss: 0.4553 - val_accuracy: 0.8311\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7264 - val_loss: 0.4541 - val_accuracy: 0.8311\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7669 - val_loss: 0.4646 - val_accuracy: 0.8243\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7618 - val_loss: 0.4578 - val_accuracy: 0.8311\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7584 - val_loss: 0.4521 - val_accuracy: 0.8378\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7652 - val_loss: 0.4617 - val_accuracy: 0.8243\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7669 - val_loss: 0.4621 - val_accuracy: 0.8108\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7787 - val_loss: 0.4665 - val_accuracy: 0.8176\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7483 - val_loss: 0.4533 - val_accuracy: 0.8108\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.7855 - val_loss: 0.4527 - val_accuracy: 0.8041\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.7618 - val_loss: 0.4737 - val_accuracy: 0.8041\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7669 - val_loss: 0.4696 - val_accuracy: 0.8041\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7889 - val_loss: 0.4607 - val_accuracy: 0.8041\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7382 - val_loss: 0.4684 - val_accuracy: 0.8108\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7872 - val_loss: 0.4654 - val_accuracy: 0.8176\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7787 - val_loss: 0.4872 - val_accuracy: 0.8041\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7855 - val_loss: 0.4826 - val_accuracy: 0.8108\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7382 - val_loss: 0.4658 - val_accuracy: 0.8108\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.8057 - val_loss: 0.4580 - val_accuracy: 0.8108\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7939 - val_loss: 0.4504 - val_accuracy: 0.8108\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7635 - val_loss: 0.4490 - val_accuracy: 0.8311\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7686 - val_loss: 0.4574 - val_accuracy: 0.8176\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7652 - val_loss: 0.4538 - val_accuracy: 0.8041\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7821 - val_loss: 0.4444 - val_accuracy: 0.8108\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7703 - val_loss: 0.4453 - val_accuracy: 0.8446\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7889 - val_loss: 0.4568 - val_accuracy: 0.8311\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7905 - val_loss: 0.4658 - val_accuracy: 0.8176\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7517 - val_loss: 0.4540 - val_accuracy: 0.8311\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7855 - val_loss: 0.4608 - val_accuracy: 0.8108\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7855 - val_loss: 0.4556 - val_accuracy: 0.8243\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7770 - val_loss: 0.4602 - val_accuracy: 0.8176\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7449 - val_loss: 0.4648 - val_accuracy: 0.8176\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7449 - val_loss: 0.4696 - val_accuracy: 0.8243\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7753 - val_loss: 0.4653 - val_accuracy: 0.8176\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7652 - val_loss: 0.4682 - val_accuracy: 0.8108\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7534 - val_loss: 0.4687 - val_accuracy: 0.8176\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7736 - val_loss: 0.4673 - val_accuracy: 0.8041\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.7517 - val_loss: 0.4563 - val_accuracy: 0.8243\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7939 - val_loss: 0.4528 - val_accuracy: 0.8176\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7669 - val_loss: 0.4674 - val_accuracy: 0.8108\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7213 - val_loss: 0.4580 - val_accuracy: 0.8108\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7990 - val_loss: 0.4561 - val_accuracy: 0.8243\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7517 - val_loss: 0.4567 - val_accuracy: 0.8243\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.7382 - val_loss: 0.4683 - val_accuracy: 0.8176\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7601 - val_loss: 0.4564 - val_accuracy: 0.8176\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7686 - val_loss: 0.4602 - val_accuracy: 0.8176\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7534 - val_loss: 0.4667 - val_accuracy: 0.8108\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7686 - val_loss: 0.4645 - val_accuracy: 0.8176\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7551 - val_loss: 0.4748 - val_accuracy: 0.8176\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7618 - val_loss: 0.4642 - val_accuracy: 0.8243\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7601 - val_loss: 0.4572 - val_accuracy: 0.8446\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7855 - val_loss: 0.4552 - val_accuracy: 0.8446\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7669 - val_loss: 0.4595 - val_accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.8311\n",
            "5/5 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2b9853e732c7>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 2s 4ms/step - loss: 1.7789 - accuracy: 0.4966 - val_loss: 1.0811 - val_accuracy: 0.5473\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.7291 - accuracy: 0.5000 - val_loss: 1.0930 - val_accuracy: 0.5473\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.5427 - accuracy: 0.5169 - val_loss: 1.0755 - val_accuracy: 0.5473\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.5194 - accuracy: 0.4848 - val_loss: 1.0594 - val_accuracy: 0.5405\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.4454 - accuracy: 0.4780 - val_loss: 1.0446 - val_accuracy: 0.5405\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.3497 - accuracy: 0.4797 - val_loss: 1.0330 - val_accuracy: 0.5270\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2682 - accuracy: 0.5068 - val_loss: 1.0216 - val_accuracy: 0.5338\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2076 - accuracy: 0.4882 - val_loss: 1.0154 - val_accuracy: 0.5338\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1641 - accuracy: 0.4696 - val_loss: 1.0110 - val_accuracy: 0.5203\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0948 - accuracy: 0.5101 - val_loss: 1.0043 - val_accuracy: 0.5203\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.4628 - val_loss: 0.9990 - val_accuracy: 0.5203\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0536 - accuracy: 0.5236 - val_loss: 0.9930 - val_accuracy: 0.5270\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.5152 - val_loss: 0.9878 - val_accuracy: 0.5270\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.5068 - val_loss: 0.9808 - val_accuracy: 0.5203\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9935 - accuracy: 0.5135 - val_loss: 0.9763 - val_accuracy: 0.5338\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.5118 - val_loss: 0.9709 - val_accuracy: 0.5608\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9820 - accuracy: 0.5236 - val_loss: 0.9636 - val_accuracy: 0.5878\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9697 - accuracy: 0.5068 - val_loss: 0.9580 - val_accuracy: 0.5000\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9540 - accuracy: 0.5253 - val_loss: 0.9507 - val_accuracy: 0.6081\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.5000 - val_loss: 0.9426 - val_accuracy: 0.6081\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.9422 - accuracy: 0.5355 - val_loss: 0.9373 - val_accuracy: 0.5135\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.5068 - val_loss: 0.9313 - val_accuracy: 0.5203\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9299 - accuracy: 0.5304 - val_loss: 0.9259 - val_accuracy: 0.4595\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9270 - accuracy: 0.5304 - val_loss: 0.9207 - val_accuracy: 0.4595\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.4949 - val_loss: 0.9134 - val_accuracy: 0.4527\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.9070 - accuracy: 0.5186 - val_loss: 0.9076 - val_accuracy: 0.4527\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.5186 - val_loss: 0.9010 - val_accuracy: 0.4527\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8946 - accuracy: 0.5338 - val_loss: 0.8956 - val_accuracy: 0.4527\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8874 - accuracy: 0.5236 - val_loss: 0.8891 - val_accuracy: 0.4527\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.5169 - val_loss: 0.8813 - val_accuracy: 0.4527\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.8764 - accuracy: 0.5270 - val_loss: 0.8771 - val_accuracy: 0.4527\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8678 - accuracy: 0.5152 - val_loss: 0.8691 - val_accuracy: 0.4527\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.8561 - accuracy: 0.5541 - val_loss: 0.8614 - val_accuracy: 0.4527\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.5321 - val_loss: 0.8535 - val_accuracy: 0.4527\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.5169 - val_loss: 0.8475 - val_accuracy: 0.4527\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8467 - accuracy: 0.5135 - val_loss: 0.8431 - val_accuracy: 0.4527\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8325 - accuracy: 0.5321 - val_loss: 0.8363 - val_accuracy: 0.4527\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8271 - accuracy: 0.5321 - val_loss: 0.8312 - val_accuracy: 0.4527\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8267 - accuracy: 0.5017 - val_loss: 0.8274 - val_accuracy: 0.4527\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8222 - accuracy: 0.5068 - val_loss: 0.8192 - val_accuracy: 0.4527\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.5608 - val_loss: 0.8139 - val_accuracy: 0.4527\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8118 - accuracy: 0.5051 - val_loss: 0.8081 - val_accuracy: 0.4527\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8012 - accuracy: 0.5152 - val_loss: 0.7995 - val_accuracy: 0.4595\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.5169 - val_loss: 0.7955 - val_accuracy: 0.4527\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.5135 - val_loss: 0.7899 - val_accuracy: 0.4527\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7831 - accuracy: 0.5473 - val_loss: 0.7834 - val_accuracy: 0.4595\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.5287 - val_loss: 0.7784 - val_accuracy: 0.4662\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7758 - accuracy: 0.5220 - val_loss: 0.7749 - val_accuracy: 0.4595\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.5389 - val_loss: 0.7710 - val_accuracy: 0.4595\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.5507 - val_loss: 0.7682 - val_accuracy: 0.4595\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.5186 - val_loss: 0.7628 - val_accuracy: 0.4595\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7548 - accuracy: 0.5490 - val_loss: 0.7590 - val_accuracy: 0.4595\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7572 - accuracy: 0.5135 - val_loss: 0.7559 - val_accuracy: 0.4595\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7465 - accuracy: 0.5574 - val_loss: 0.7494 - val_accuracy: 0.4865\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.5220 - val_loss: 0.7488 - val_accuracy: 0.4662\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7443 - accuracy: 0.5473 - val_loss: 0.7438 - val_accuracy: 0.4730\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7443 - accuracy: 0.5321 - val_loss: 0.7373 - val_accuracy: 0.4865\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7351 - accuracy: 0.5557 - val_loss: 0.7340 - val_accuracy: 0.4865\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7314 - accuracy: 0.5574 - val_loss: 0.7272 - val_accuracy: 0.5338\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7339 - accuracy: 0.5389 - val_loss: 0.7215 - val_accuracy: 0.5811\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7284 - accuracy: 0.5439 - val_loss: 0.7141 - val_accuracy: 0.6419\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.5574 - val_loss: 0.7102 - val_accuracy: 0.6622\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7224 - accuracy: 0.5642 - val_loss: 0.7036 - val_accuracy: 0.6757\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7301 - accuracy: 0.5676 - val_loss: 0.7004 - val_accuracy: 0.6892\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.6064 - val_loss: 0.6849 - val_accuracy: 0.7095\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.5912 - val_loss: 0.6750 - val_accuracy: 0.7500\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.6301 - val_loss: 0.6502 - val_accuracy: 0.7770\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6806 - accuracy: 0.6436 - val_loss: 0.6249 - val_accuracy: 0.7703\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6267 - val_loss: 0.6107 - val_accuracy: 0.7703\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6588 - val_loss: 0.5934 - val_accuracy: 0.7838\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.6301 - val_loss: 0.6058 - val_accuracy: 0.7770\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6605 - val_loss: 0.5933 - val_accuracy: 0.7838\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6622 - val_loss: 0.5811 - val_accuracy: 0.7635\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6351 - val_loss: 0.5810 - val_accuracy: 0.7838\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.6672 - val_loss: 0.5639 - val_accuracy: 0.8041\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6791 - val_loss: 0.5730 - val_accuracy: 0.8041\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.7078 - val_loss: 0.5610 - val_accuracy: 0.8041\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6858 - val_loss: 0.5531 - val_accuracy: 0.8176\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6824 - val_loss: 0.5459 - val_accuracy: 0.8243\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.7010 - val_loss: 0.5508 - val_accuracy: 0.7973\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.6993 - val_loss: 0.5399 - val_accuracy: 0.7973\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6824 - val_loss: 0.5439 - val_accuracy: 0.8041\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6824 - val_loss: 0.5405 - val_accuracy: 0.7905\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7111 - val_loss: 0.5320 - val_accuracy: 0.8176\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6976 - val_loss: 0.5291 - val_accuracy: 0.8041\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6892 - val_loss: 0.5347 - val_accuracy: 0.8176\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6993 - val_loss: 0.5365 - val_accuracy: 0.8176\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.7010 - val_loss: 0.5317 - val_accuracy: 0.8243\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6774 - val_loss: 0.5352 - val_accuracy: 0.8311\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.6976 - val_loss: 0.5272 - val_accuracy: 0.8243\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7145 - val_loss: 0.5222 - val_accuracy: 0.8311\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7483 - val_loss: 0.5111 - val_accuracy: 0.8041\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6602 - accuracy: 0.7010 - val_loss: 0.5188 - val_accuracy: 0.8311\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7297 - val_loss: 0.5033 - val_accuracy: 0.8446\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.6892 - val_loss: 0.5000 - val_accuracy: 0.8446\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7027 - val_loss: 0.5037 - val_accuracy: 0.8514\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7247 - val_loss: 0.5060 - val_accuracy: 0.8446\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7061 - val_loss: 0.5130 - val_accuracy: 0.8378\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.6943 - val_loss: 0.5013 - val_accuracy: 0.8378\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.7179 - val_loss: 0.4929 - val_accuracy: 0.8514\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6723 - val_loss: 0.4893 - val_accuracy: 0.8378\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7280 - val_loss: 0.4933 - val_accuracy: 0.8446\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.7179 - val_loss: 0.4915 - val_accuracy: 0.8378\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7280 - val_loss: 0.4852 - val_accuracy: 0.8446\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7078 - val_loss: 0.4827 - val_accuracy: 0.8446\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7416 - val_loss: 0.4851 - val_accuracy: 0.8446\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7247 - val_loss: 0.4751 - val_accuracy: 0.8378\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7179 - val_loss: 0.4729 - val_accuracy: 0.8514\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.7365 - val_loss: 0.4710 - val_accuracy: 0.8446\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.7264 - val_loss: 0.4883 - val_accuracy: 0.8514\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6926 - val_loss: 0.4889 - val_accuracy: 0.8581\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6909 - val_loss: 0.4921 - val_accuracy: 0.8514\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.7331 - val_loss: 0.4817 - val_accuracy: 0.8581\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.7264 - val_loss: 0.4890 - val_accuracy: 0.8581\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.7230 - val_loss: 0.4903 - val_accuracy: 0.8311\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.7348 - val_loss: 0.4937 - val_accuracy: 0.8446\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.7280 - val_loss: 0.4829 - val_accuracy: 0.8243\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.7483 - val_loss: 0.4830 - val_accuracy: 0.8446\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7230 - val_loss: 0.4666 - val_accuracy: 0.8311\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.7213 - val_loss: 0.4674 - val_accuracy: 0.8243\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.7162 - val_loss: 0.4682 - val_accuracy: 0.8446\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7432 - val_loss: 0.4690 - val_accuracy: 0.8311\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.7196 - val_loss: 0.4681 - val_accuracy: 0.8378\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7331 - val_loss: 0.4616 - val_accuracy: 0.8514\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7399 - val_loss: 0.4637 - val_accuracy: 0.8581\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.7551 - val_loss: 0.4496 - val_accuracy: 0.8649\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7382 - val_loss: 0.4486 - val_accuracy: 0.8649\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7314 - val_loss: 0.4539 - val_accuracy: 0.8581\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.7534 - val_loss: 0.4561 - val_accuracy: 0.8581\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7399 - val_loss: 0.4599 - val_accuracy: 0.8514\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.7466 - val_loss: 0.4608 - val_accuracy: 0.8581\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7449 - val_loss: 0.4560 - val_accuracy: 0.8514\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.7264 - val_loss: 0.4612 - val_accuracy: 0.8716\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7483 - val_loss: 0.4643 - val_accuracy: 0.8581\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7010 - val_loss: 0.4668 - val_accuracy: 0.8514\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.7280 - val_loss: 0.4620 - val_accuracy: 0.8649\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.7213 - val_loss: 0.4645 - val_accuracy: 0.8716\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7230 - val_loss: 0.4536 - val_accuracy: 0.8851\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7145 - val_loss: 0.4712 - val_accuracy: 0.8851\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7686 - val_loss: 0.4643 - val_accuracy: 0.8784\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7551 - val_loss: 0.4619 - val_accuracy: 0.8649\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.7230 - val_loss: 0.4609 - val_accuracy: 0.8716\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7399 - val_loss: 0.4576 - val_accuracy: 0.8784\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7230 - val_loss: 0.4469 - val_accuracy: 0.8581\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7331 - val_loss: 0.4514 - val_accuracy: 0.8514\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7399 - val_loss: 0.4473 - val_accuracy: 0.8649\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.7314 - val_loss: 0.4541 - val_accuracy: 0.8784\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7703 - val_loss: 0.4582 - val_accuracy: 0.8716\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7247 - val_loss: 0.4573 - val_accuracy: 0.8649\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7534 - val_loss: 0.4396 - val_accuracy: 0.8581\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.7247 - val_loss: 0.4457 - val_accuracy: 0.8716\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7382 - val_loss: 0.4419 - val_accuracy: 0.8784\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7534 - val_loss: 0.4385 - val_accuracy: 0.8784\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7331 - val_loss: 0.4453 - val_accuracy: 0.8581\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.7416 - val_loss: 0.4531 - val_accuracy: 0.8649\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7618 - val_loss: 0.4382 - val_accuracy: 0.8581\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7365 - val_loss: 0.4406 - val_accuracy: 0.8581\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7449 - val_loss: 0.4386 - val_accuracy: 0.8581\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.7399 - val_loss: 0.4483 - val_accuracy: 0.8649\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.7027 - val_loss: 0.4553 - val_accuracy: 0.8378\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6019 - accuracy: 0.7399 - val_loss: 0.4554 - val_accuracy: 0.8581\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7669 - val_loss: 0.4471 - val_accuracy: 0.8446\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.7314 - val_loss: 0.4404 - val_accuracy: 0.8446\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7280 - val_loss: 0.4405 - val_accuracy: 0.8446\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.7399 - val_loss: 0.4608 - val_accuracy: 0.8243\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6218 - accuracy: 0.7280 - val_loss: 0.4579 - val_accuracy: 0.8514\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7348 - val_loss: 0.4676 - val_accuracy: 0.8378\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7669 - val_loss: 0.4487 - val_accuracy: 0.8514\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7551 - val_loss: 0.4332 - val_accuracy: 0.8378\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.7111 - val_loss: 0.4523 - val_accuracy: 0.8649\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.7399 - val_loss: 0.4432 - val_accuracy: 0.8446\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7331 - val_loss: 0.4500 - val_accuracy: 0.8514\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7601 - val_loss: 0.4469 - val_accuracy: 0.8378\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7551 - val_loss: 0.4406 - val_accuracy: 0.8378\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.7331 - val_loss: 0.4590 - val_accuracy: 0.8041\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7382 - val_loss: 0.4639 - val_accuracy: 0.8041\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7449 - val_loss: 0.4596 - val_accuracy: 0.8176\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7247 - val_loss: 0.4469 - val_accuracy: 0.8446\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7314 - val_loss: 0.4610 - val_accuracy: 0.8446\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7297 - val_loss: 0.4565 - val_accuracy: 0.8311\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7635 - val_loss: 0.4418 - val_accuracy: 0.8649\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7449 - val_loss: 0.4341 - val_accuracy: 0.8446\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7213 - val_loss: 0.4429 - val_accuracy: 0.8784\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5963 - accuracy: 0.7213 - val_loss: 0.4531 - val_accuracy: 0.8514\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7652 - val_loss: 0.4430 - val_accuracy: 0.8446\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7736 - val_loss: 0.4542 - val_accuracy: 0.8514\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.7297 - val_loss: 0.4543 - val_accuracy: 0.8581\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.7280 - val_loss: 0.4577 - val_accuracy: 0.8514\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7382 - val_loss: 0.4494 - val_accuracy: 0.8514\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7551 - val_loss: 0.4455 - val_accuracy: 0.8581\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7466 - val_loss: 0.4468 - val_accuracy: 0.8649\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7365 - val_loss: 0.4364 - val_accuracy: 0.8581\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7044 - val_loss: 0.4526 - val_accuracy: 0.8514\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7703 - val_loss: 0.4461 - val_accuracy: 0.8716\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7466 - val_loss: 0.4549 - val_accuracy: 0.8581\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7297 - val_loss: 0.4471 - val_accuracy: 0.8716\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7331 - val_loss: 0.4424 - val_accuracy: 0.8514\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7686 - val_loss: 0.4347 - val_accuracy: 0.8514\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7145 - val_loss: 0.4474 - val_accuracy: 0.8446\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7551 - val_loss: 0.4382 - val_accuracy: 0.8649\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.7432 - val_loss: 0.4617 - val_accuracy: 0.8581\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7399 - val_loss: 0.4612 - val_accuracy: 0.8514\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.7382 - val_loss: 0.4524 - val_accuracy: 0.8514\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7416 - val_loss: 0.4485 - val_accuracy: 0.8446\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7314 - val_loss: 0.4539 - val_accuracy: 0.8514\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7382 - val_loss: 0.4551 - val_accuracy: 0.8581\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5993 - accuracy: 0.7280 - val_loss: 0.4434 - val_accuracy: 0.8514\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7601 - val_loss: 0.4408 - val_accuracy: 0.8581\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7466 - val_loss: 0.4284 - val_accuracy: 0.8514\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.7399 - val_loss: 0.4426 - val_accuracy: 0.8446\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.7247 - val_loss: 0.4443 - val_accuracy: 0.8378\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7331 - val_loss: 0.4476 - val_accuracy: 0.8514\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.7196 - val_loss: 0.4539 - val_accuracy: 0.8581\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7517 - val_loss: 0.4461 - val_accuracy: 0.8649\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7618 - val_loss: 0.4335 - val_accuracy: 0.8581\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7517 - val_loss: 0.4293 - val_accuracy: 0.8716\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7230 - val_loss: 0.4368 - val_accuracy: 0.8581\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7264 - val_loss: 0.4508 - val_accuracy: 0.8581\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.7635 - val_loss: 0.4457 - val_accuracy: 0.8446\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7568 - val_loss: 0.4402 - val_accuracy: 0.8581\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7686 - val_loss: 0.4365 - val_accuracy: 0.8446\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7584 - val_loss: 0.4349 - val_accuracy: 0.8446\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7517 - val_loss: 0.4438 - val_accuracy: 0.8446\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7264 - val_loss: 0.4378 - val_accuracy: 0.8446\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7534 - val_loss: 0.4438 - val_accuracy: 0.8311\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7297 - val_loss: 0.4544 - val_accuracy: 0.8311\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7956 - val_loss: 0.4389 - val_accuracy: 0.8176\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.7432 - val_loss: 0.4266 - val_accuracy: 0.8378\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6064 - accuracy: 0.7179 - val_loss: 0.4301 - val_accuracy: 0.8243\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7534 - val_loss: 0.4331 - val_accuracy: 0.8446\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7804 - val_loss: 0.4364 - val_accuracy: 0.8176\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7196 - val_loss: 0.4525 - val_accuracy: 0.8378\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7618 - val_loss: 0.4572 - val_accuracy: 0.8108\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.7297 - val_loss: 0.4468 - val_accuracy: 0.8446\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7669 - val_loss: 0.4358 - val_accuracy: 0.8446\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7331 - val_loss: 0.4471 - val_accuracy: 0.8108\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7297 - val_loss: 0.4422 - val_accuracy: 0.8378\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7399 - val_loss: 0.4411 - val_accuracy: 0.8243\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7770 - val_loss: 0.4248 - val_accuracy: 0.8311\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7821 - val_loss: 0.4247 - val_accuracy: 0.8378\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7399 - val_loss: 0.4239 - val_accuracy: 0.8446\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7500 - val_loss: 0.4206 - val_accuracy: 0.8311\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7145 - val_loss: 0.4268 - val_accuracy: 0.8311\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7551 - val_loss: 0.4248 - val_accuracy: 0.8311\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7348 - val_loss: 0.4315 - val_accuracy: 0.8311\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7399 - val_loss: 0.4290 - val_accuracy: 0.8243\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5607 - accuracy: 0.7500 - val_loss: 0.4230 - val_accuracy: 0.8514\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7601 - val_loss: 0.4179 - val_accuracy: 0.8649\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.4103 - val_accuracy: 0.8649\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.7534 - val_loss: 0.4253 - val_accuracy: 0.8378\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.7382 - val_loss: 0.4368 - val_accuracy: 0.8446\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7652 - val_loss: 0.4336 - val_accuracy: 0.8243\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7517 - val_loss: 0.4226 - val_accuracy: 0.8378\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7703 - val_loss: 0.4184 - val_accuracy: 0.8716\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7618 - val_loss: 0.4054 - val_accuracy: 0.8649\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7753 - val_loss: 0.4210 - val_accuracy: 0.8514\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7348 - val_loss: 0.4262 - val_accuracy: 0.8581\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7483 - val_loss: 0.4197 - val_accuracy: 0.8581\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7736 - val_loss: 0.4299 - val_accuracy: 0.8446\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7551 - val_loss: 0.4232 - val_accuracy: 0.8514\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7466 - val_loss: 0.4221 - val_accuracy: 0.8581\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7314 - val_loss: 0.4217 - val_accuracy: 0.8446\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7500 - val_loss: 0.4192 - val_accuracy: 0.8514\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7669 - val_loss: 0.4334 - val_accuracy: 0.8311\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7736 - val_loss: 0.4153 - val_accuracy: 0.8649\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.4251 - val_accuracy: 0.8581\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.7213 - val_loss: 0.4233 - val_accuracy: 0.8446\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7483 - val_loss: 0.4140 - val_accuracy: 0.8581\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.7568 - val_loss: 0.4216 - val_accuracy: 0.8446\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7517 - val_loss: 0.4217 - val_accuracy: 0.8446\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.7432 - val_loss: 0.4312 - val_accuracy: 0.8446\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7770 - val_loss: 0.4316 - val_accuracy: 0.8514\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.7483 - val_loss: 0.4323 - val_accuracy: 0.8446\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7416 - val_loss: 0.4398 - val_accuracy: 0.8581\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7568 - val_loss: 0.4323 - val_accuracy: 0.8514\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7449 - val_loss: 0.4259 - val_accuracy: 0.8514\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7821 - val_loss: 0.4258 - val_accuracy: 0.8446\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7770 - val_loss: 0.4237 - val_accuracy: 0.8514\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7196 - val_loss: 0.4165 - val_accuracy: 0.8649\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7534 - val_loss: 0.4130 - val_accuracy: 0.8716\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7686 - val_loss: 0.4081 - val_accuracy: 0.8581\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7500 - val_loss: 0.4128 - val_accuracy: 0.8514\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7500 - val_loss: 0.4319 - val_accuracy: 0.8378\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7618 - val_loss: 0.4306 - val_accuracy: 0.8446\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.4323 - val_accuracy: 0.8446\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7618 - val_loss: 0.4243 - val_accuracy: 0.8378\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7601 - val_loss: 0.4184 - val_accuracy: 0.8514\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7618 - val_loss: 0.4271 - val_accuracy: 0.8243\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7449 - val_loss: 0.4241 - val_accuracy: 0.8311\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7618 - val_loss: 0.4203 - val_accuracy: 0.8446\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7551 - val_loss: 0.4271 - val_accuracy: 0.8243\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7534 - val_loss: 0.4314 - val_accuracy: 0.8311\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7568 - val_loss: 0.4156 - val_accuracy: 0.8581\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7584 - val_loss: 0.4075 - val_accuracy: 0.8446\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7652 - val_loss: 0.4146 - val_accuracy: 0.8176\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7551 - val_loss: 0.4252 - val_accuracy: 0.8581\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7584 - val_loss: 0.4212 - val_accuracy: 0.8581\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5871 - accuracy: 0.7635 - val_loss: 0.4239 - val_accuracy: 0.8514\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7466 - val_loss: 0.4320 - val_accuracy: 0.8581\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7584 - val_loss: 0.4268 - val_accuracy: 0.8446\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7483 - val_loss: 0.4323 - val_accuracy: 0.8378\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7517 - val_loss: 0.4138 - val_accuracy: 0.8514\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7601 - val_loss: 0.4216 - val_accuracy: 0.8514\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7432 - val_loss: 0.4155 - val_accuracy: 0.8446\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7601 - val_loss: 0.4247 - val_accuracy: 0.8581\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7348 - val_loss: 0.4311 - val_accuracy: 0.8446\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7686 - val_loss: 0.4294 - val_accuracy: 0.8446\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7584 - val_loss: 0.4280 - val_accuracy: 0.8514\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7889 - val_loss: 0.4137 - val_accuracy: 0.8581\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.7128 - val_loss: 0.4126 - val_accuracy: 0.8716\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7753 - val_loss: 0.4120 - val_accuracy: 0.8716\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7669 - val_loss: 0.4142 - val_accuracy: 0.8716\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7669 - val_loss: 0.4154 - val_accuracy: 0.8649\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7669 - val_loss: 0.4043 - val_accuracy: 0.8716\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7534 - val_loss: 0.4089 - val_accuracy: 0.8581\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.7348 - val_loss: 0.4200 - val_accuracy: 0.8581\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7534 - val_loss: 0.4197 - val_accuracy: 0.8581\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.7432 - val_loss: 0.4247 - val_accuracy: 0.8784\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7601 - val_loss: 0.4249 - val_accuracy: 0.8581\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7534 - val_loss: 0.4303 - val_accuracy: 0.8649\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7652 - val_loss: 0.4176 - val_accuracy: 0.8784\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.7382 - val_loss: 0.4281 - val_accuracy: 0.8514\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7466 - val_loss: 0.4345 - val_accuracy: 0.8514\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7399 - val_loss: 0.4369 - val_accuracy: 0.8581\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7416 - val_loss: 0.4242 - val_accuracy: 0.8581\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7686 - val_loss: 0.4125 - val_accuracy: 0.8581\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.7213 - val_loss: 0.4330 - val_accuracy: 0.8514\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7466 - val_loss: 0.4224 - val_accuracy: 0.8649\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.7314 - val_loss: 0.4269 - val_accuracy: 0.8716\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7905 - val_loss: 0.4226 - val_accuracy: 0.8378\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.7264 - val_loss: 0.4256 - val_accuracy: 0.8378\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.4297 - val_accuracy: 0.8514\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7568 - val_loss: 0.4290 - val_accuracy: 0.8514\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7517 - val_loss: 0.4319 - val_accuracy: 0.8581\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7382 - val_loss: 0.4353 - val_accuracy: 0.8378\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.7280 - val_loss: 0.4331 - val_accuracy: 0.8446\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7416 - val_loss: 0.4257 - val_accuracy: 0.8446\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7635 - val_loss: 0.4203 - val_accuracy: 0.8446\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7534 - val_loss: 0.4224 - val_accuracy: 0.8378\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7635 - val_loss: 0.4207 - val_accuracy: 0.8311\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7669 - val_loss: 0.4219 - val_accuracy: 0.8311\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7618 - val_loss: 0.4215 - val_accuracy: 0.8378\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7449 - val_loss: 0.4174 - val_accuracy: 0.8446\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.7365 - val_loss: 0.4269 - val_accuracy: 0.8446\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7382 - val_loss: 0.4380 - val_accuracy: 0.8311\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7905 - val_loss: 0.4260 - val_accuracy: 0.8581\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7872 - val_loss: 0.4151 - val_accuracy: 0.8784\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7686 - val_loss: 0.4200 - val_accuracy: 0.8581\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7601 - val_loss: 0.4211 - val_accuracy: 0.8784\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7720 - val_loss: 0.4286 - val_accuracy: 0.8311\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7348 - val_loss: 0.4267 - val_accuracy: 0.8378\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5859 - accuracy: 0.7483 - val_loss: 0.4274 - val_accuracy: 0.8446\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7939 - val_loss: 0.4201 - val_accuracy: 0.8514\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7568 - val_loss: 0.4305 - val_accuracy: 0.8514\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7618 - val_loss: 0.4273 - val_accuracy: 0.8514\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 0.4283 - val_accuracy: 0.8581\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7500 - val_loss: 0.4139 - val_accuracy: 0.8784\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7618 - val_loss: 0.4288 - val_accuracy: 0.8514\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7399 - val_loss: 0.4237 - val_accuracy: 0.8581\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.7348 - val_loss: 0.4300 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5705 - accuracy: 0.7584 - val_loss: 0.4137 - val_accuracy: 0.8649\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7838 - val_loss: 0.4238 - val_accuracy: 0.8243\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7872 - val_loss: 0.4096 - val_accuracy: 0.8446\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.7534 - val_loss: 0.4344 - val_accuracy: 0.7973\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7534 - val_loss: 0.4191 - val_accuracy: 0.8243\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7669 - val_loss: 0.4120 - val_accuracy: 0.8243\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.7280 - val_loss: 0.4265 - val_accuracy: 0.7973\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7280 - val_loss: 0.4361 - val_accuracy: 0.8176\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7534 - val_loss: 0.4283 - val_accuracy: 0.8311\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7213 - val_loss: 0.4333 - val_accuracy: 0.8378\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7686 - val_loss: 0.4362 - val_accuracy: 0.8243\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7601 - val_loss: 0.4206 - val_accuracy: 0.8311\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.7601 - val_loss: 0.4317 - val_accuracy: 0.8378\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7736 - val_loss: 0.4444 - val_accuracy: 0.8378\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7399 - val_loss: 0.4409 - val_accuracy: 0.8108\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7449 - val_loss: 0.4438 - val_accuracy: 0.8108\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7720 - val_loss: 0.4372 - val_accuracy: 0.8514\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7365 - val_loss: 0.4307 - val_accuracy: 0.8446\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7703 - val_loss: 0.4231 - val_accuracy: 0.8716\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7601 - val_loss: 0.4274 - val_accuracy: 0.8581\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7584 - val_loss: 0.4265 - val_accuracy: 0.8581\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.7280 - val_loss: 0.4325 - val_accuracy: 0.8716\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7466 - val_loss: 0.4327 - val_accuracy: 0.8514\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7534 - val_loss: 0.4500 - val_accuracy: 0.8108\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7753 - val_loss: 0.4541 - val_accuracy: 0.7973\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7517 - val_loss: 0.4344 - val_accuracy: 0.8581\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7720 - val_loss: 0.4379 - val_accuracy: 0.8243\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7449 - val_loss: 0.4401 - val_accuracy: 0.8176\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7601 - val_loss: 0.4430 - val_accuracy: 0.8311\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7720 - val_loss: 0.4381 - val_accuracy: 0.8446\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7517 - val_loss: 0.4415 - val_accuracy: 0.8378\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7416 - val_loss: 0.4361 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7686 - val_loss: 0.4481 - val_accuracy: 0.8243\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7145 - val_loss: 0.4503 - val_accuracy: 0.8446\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7044 - val_loss: 0.4519 - val_accuracy: 0.8446\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7466 - val_loss: 0.4404 - val_accuracy: 0.8041\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.7230 - val_loss: 0.4479 - val_accuracy: 0.8446\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7432 - val_loss: 0.4460 - val_accuracy: 0.8378\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7517 - val_loss: 0.4355 - val_accuracy: 0.8311\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7517 - val_loss: 0.4275 - val_accuracy: 0.8446\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.4313 - val_accuracy: 0.8378\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7534 - val_loss: 0.4292 - val_accuracy: 0.8446\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7500 - val_loss: 0.4282 - val_accuracy: 0.8378\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7213 - val_loss: 0.4356 - val_accuracy: 0.8378\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7551 - val_loss: 0.4306 - val_accuracy: 0.8514\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7686 - val_loss: 0.4234 - val_accuracy: 0.8514\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7956 - val_loss: 0.4182 - val_accuracy: 0.8378\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7297 - val_loss: 0.4240 - val_accuracy: 0.8378\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.7297 - val_loss: 0.4317 - val_accuracy: 0.8581\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7483 - val_loss: 0.4348 - val_accuracy: 0.8378\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7483 - val_loss: 0.4168 - val_accuracy: 0.8446\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7297 - val_loss: 0.4279 - val_accuracy: 0.8378\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7449 - val_loss: 0.4319 - val_accuracy: 0.8581\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7635 - val_loss: 0.4371 - val_accuracy: 0.8311\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.4294 - val_accuracy: 0.8514\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7500 - val_loss: 0.4233 - val_accuracy: 0.8514\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7669 - val_loss: 0.4267 - val_accuracy: 0.8649\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7348 - val_loss: 0.4304 - val_accuracy: 0.8581\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7787 - val_loss: 0.4339 - val_accuracy: 0.8581\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7770 - val_loss: 0.4228 - val_accuracy: 0.8649\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7551 - val_loss: 0.4249 - val_accuracy: 0.8378\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7584 - val_loss: 0.4285 - val_accuracy: 0.8446\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7855 - val_loss: 0.4176 - val_accuracy: 0.8514\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7365 - val_loss: 0.4326 - val_accuracy: 0.8378\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7568 - val_loss: 0.4204 - val_accuracy: 0.8446\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7382 - val_loss: 0.4182 - val_accuracy: 0.8378\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7905 - val_loss: 0.4221 - val_accuracy: 0.8446\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7179 - val_loss: 0.4252 - val_accuracy: 0.8378\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7416 - val_loss: 0.4336 - val_accuracy: 0.8446\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7703 - val_loss: 0.4374 - val_accuracy: 0.8514\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7568 - val_loss: 0.4300 - val_accuracy: 0.8378\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7264 - val_loss: 0.4207 - val_accuracy: 0.8716\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7365 - val_loss: 0.4161 - val_accuracy: 0.8581\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7905 - val_loss: 0.4272 - val_accuracy: 0.8378\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7720 - val_loss: 0.4226 - val_accuracy: 0.8446\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7635 - val_loss: 0.4190 - val_accuracy: 0.8581\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7635 - val_loss: 0.4204 - val_accuracy: 0.8311\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7703 - val_loss: 0.4076 - val_accuracy: 0.8514\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7720 - val_loss: 0.4120 - val_accuracy: 0.8378\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7230 - val_loss: 0.4202 - val_accuracy: 0.8514\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7280 - val_loss: 0.4203 - val_accuracy: 0.8716\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7500 - val_loss: 0.4180 - val_accuracy: 0.8649\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7618 - val_loss: 0.4234 - val_accuracy: 0.8581\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7399 - val_loss: 0.4389 - val_accuracy: 0.8446\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.7213 - val_loss: 0.4391 - val_accuracy: 0.8514\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7331 - val_loss: 0.4300 - val_accuracy: 0.8649\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7399 - val_loss: 0.4317 - val_accuracy: 0.8581\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.7669 - val_loss: 0.4288 - val_accuracy: 0.8784\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7720 - val_loss: 0.4229 - val_accuracy: 0.8581\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7534 - val_loss: 0.4312 - val_accuracy: 0.8581\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7686 - val_loss: 0.4206 - val_accuracy: 0.8514\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7753 - val_loss: 0.4284 - val_accuracy: 0.8649\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7703 - val_loss: 0.4263 - val_accuracy: 0.8446\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7601 - val_loss: 0.4141 - val_accuracy: 0.8649\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7568 - val_loss: 0.4261 - val_accuracy: 0.8446\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7483 - val_loss: 0.4375 - val_accuracy: 0.8446\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7399 - val_loss: 0.4345 - val_accuracy: 0.8514\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.7652 - val_loss: 0.4412 - val_accuracy: 0.8243\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7365 - val_loss: 0.4410 - val_accuracy: 0.8311\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7449 - val_loss: 0.4209 - val_accuracy: 0.8514\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7889 - val_loss: 0.4152 - val_accuracy: 0.8514\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7331 - val_loss: 0.4354 - val_accuracy: 0.8311\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7618 - val_loss: 0.4284 - val_accuracy: 0.8378\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.7568 - val_loss: 0.4276 - val_accuracy: 0.8378\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5932 - accuracy: 0.7449 - val_loss: 0.4326 - val_accuracy: 0.8243\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7720 - val_loss: 0.4236 - val_accuracy: 0.8446\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.7432 - val_loss: 0.4218 - val_accuracy: 0.8311\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7584 - val_loss: 0.4274 - val_accuracy: 0.8446\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7365 - val_loss: 0.4306 - val_accuracy: 0.8243\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.7500 - val_loss: 0.4339 - val_accuracy: 0.8378\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7449 - val_loss: 0.4370 - val_accuracy: 0.8243\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7635 - val_loss: 0.4194 - val_accuracy: 0.8514\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7348 - val_loss: 0.4264 - val_accuracy: 0.8446\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7466 - val_loss: 0.4202 - val_accuracy: 0.8581\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7348 - val_loss: 0.4180 - val_accuracy: 0.8581\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7635 - val_loss: 0.4267 - val_accuracy: 0.8649\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7584 - val_loss: 0.4262 - val_accuracy: 0.8649\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.7584 - val_loss: 0.4299 - val_accuracy: 0.8784\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7720 - val_loss: 0.4078 - val_accuracy: 0.8716\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7720 - val_loss: 0.4062 - val_accuracy: 0.8581\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7838 - val_loss: 0.4123 - val_accuracy: 0.8649\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7753 - val_loss: 0.4051 - val_accuracy: 0.8716\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7432 - val_loss: 0.4212 - val_accuracy: 0.8581\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7466 - val_loss: 0.4199 - val_accuracy: 0.8649\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7821 - val_loss: 0.4161 - val_accuracy: 0.8514\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7872 - val_loss: 0.4075 - val_accuracy: 0.8446\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7652 - val_loss: 0.4107 - val_accuracy: 0.8581\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7348 - val_loss: 0.4183 - val_accuracy: 0.8581\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.7483 - val_loss: 0.4233 - val_accuracy: 0.8649\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7753 - val_loss: 0.4264 - val_accuracy: 0.8514\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7500 - val_loss: 0.4249 - val_accuracy: 0.8716\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7483 - val_loss: 0.4391 - val_accuracy: 0.8446\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7804 - val_loss: 0.4223 - val_accuracy: 0.8581\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7601 - val_loss: 0.4206 - val_accuracy: 0.8514\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7551 - val_loss: 0.4166 - val_accuracy: 0.8649\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7111 - val_loss: 0.4201 - val_accuracy: 0.8649\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7382 - val_loss: 0.4127 - val_accuracy: 0.8716\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7770 - val_loss: 0.4179 - val_accuracy: 0.8514\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5744 - accuracy: 0.7348 - val_loss: 0.4144 - val_accuracy: 0.8446\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7230 - val_loss: 0.4191 - val_accuracy: 0.8581\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8581\n",
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2b9853e732c7>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "74/74 [==============================] - 2s 5ms/step - loss: 1.3047 - accuracy: 0.5118 - val_loss: 1.0824 - val_accuracy: 0.4865\n",
            "Epoch 2/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.2370 - accuracy: 0.5135 - val_loss: 1.0755 - val_accuracy: 0.4865\n",
            "Epoch 3/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1571 - accuracy: 0.5000 - val_loss: 1.0658 - val_accuracy: 0.4865\n",
            "Epoch 4/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.1079 - accuracy: 0.5101 - val_loss: 1.0504 - val_accuracy: 0.4865\n",
            "Epoch 5/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0976 - accuracy: 0.4780 - val_loss: 1.0315 - val_accuracy: 0.4865\n",
            "Epoch 6/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0555 - accuracy: 0.4932 - val_loss: 1.0183 - val_accuracy: 0.4865\n",
            "Epoch 7/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.4662 - val_loss: 1.0017 - val_accuracy: 0.4865\n",
            "Epoch 8/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 1.0036 - accuracy: 0.4932 - val_loss: 0.9878 - val_accuracy: 0.4932\n",
            "Epoch 9/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9741 - accuracy: 0.5135 - val_loss: 0.9767 - val_accuracy: 0.4932\n",
            "Epoch 10/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9640 - accuracy: 0.5490 - val_loss: 0.9640 - val_accuracy: 0.4932\n",
            "Epoch 11/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9568 - accuracy: 0.5152 - val_loss: 0.9531 - val_accuracy: 0.4865\n",
            "Epoch 12/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.4780 - val_loss: 0.9422 - val_accuracy: 0.4932\n",
            "Epoch 13/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9365 - accuracy: 0.5135 - val_loss: 0.9309 - val_accuracy: 0.4932\n",
            "Epoch 14/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.4747 - val_loss: 0.9212 - val_accuracy: 0.4865\n",
            "Epoch 15/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9134 - accuracy: 0.4882 - val_loss: 0.9094 - val_accuracy: 0.4865\n",
            "Epoch 16/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.5000 - val_loss: 0.8991 - val_accuracy: 0.4865\n",
            "Epoch 17/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.5169 - val_loss: 0.8884 - val_accuracy: 0.4865\n",
            "Epoch 18/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8816 - accuracy: 0.5253 - val_loss: 0.8777 - val_accuracy: 0.4865\n",
            "Epoch 19/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.5101 - val_loss: 0.8683 - val_accuracy: 0.4865\n",
            "Epoch 20/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.5084 - val_loss: 0.8596 - val_accuracy: 0.4865\n",
            "Epoch 21/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8539 - accuracy: 0.5017 - val_loss: 0.8504 - val_accuracy: 0.4865\n",
            "Epoch 22/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8426 - accuracy: 0.5220 - val_loss: 0.8410 - val_accuracy: 0.4865\n",
            "Epoch 23/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.5287 - val_loss: 0.8322 - val_accuracy: 0.4865\n",
            "Epoch 24/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8242 - accuracy: 0.5152 - val_loss: 0.8246 - val_accuracy: 0.4865\n",
            "Epoch 25/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8159 - accuracy: 0.5405 - val_loss: 0.8190 - val_accuracy: 0.4865\n",
            "Epoch 26/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8106 - accuracy: 0.5253 - val_loss: 0.8107 - val_accuracy: 0.4865\n",
            "Epoch 27/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8001 - accuracy: 0.5253 - val_loss: 0.8045 - val_accuracy: 0.4865\n",
            "Epoch 28/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.8016 - accuracy: 0.5034 - val_loss: 0.7976 - val_accuracy: 0.4865\n",
            "Epoch 29/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7907 - accuracy: 0.5372 - val_loss: 0.7908 - val_accuracy: 0.4865\n",
            "Epoch 30/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7875 - accuracy: 0.5051 - val_loss: 0.7853 - val_accuracy: 0.4865\n",
            "Epoch 31/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7803 - accuracy: 0.5186 - val_loss: 0.7783 - val_accuracy: 0.4865\n",
            "Epoch 32/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7756 - accuracy: 0.5051 - val_loss: 0.7734 - val_accuracy: 0.4865\n",
            "Epoch 33/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.4983 - val_loss: 0.7697 - val_accuracy: 0.4865\n",
            "Epoch 34/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.5304 - val_loss: 0.7649 - val_accuracy: 0.4865\n",
            "Epoch 35/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7582 - accuracy: 0.5236 - val_loss: 0.7593 - val_accuracy: 0.4865\n",
            "Epoch 36/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.5490 - val_loss: 0.7571 - val_accuracy: 0.4865\n",
            "Epoch 37/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.5591 - val_loss: 0.7543 - val_accuracy: 0.4865\n",
            "Epoch 38/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7485 - accuracy: 0.5355 - val_loss: 0.7496 - val_accuracy: 0.4865\n",
            "Epoch 39/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7381 - accuracy: 0.5676 - val_loss: 0.7476 - val_accuracy: 0.4865\n",
            "Epoch 40/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.5608 - val_loss: 0.7441 - val_accuracy: 0.5068\n",
            "Epoch 41/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7170 - accuracy: 0.6233 - val_loss: 0.7411 - val_accuracy: 0.5135\n",
            "Epoch 42/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7296 - accuracy: 0.5608 - val_loss: 0.7348 - val_accuracy: 0.5338\n",
            "Epoch 43/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7147 - accuracy: 0.5946 - val_loss: 0.7312 - val_accuracy: 0.5541\n",
            "Epoch 44/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.7140 - accuracy: 0.5963 - val_loss: 0.7191 - val_accuracy: 0.5811\n",
            "Epoch 45/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.7103 - accuracy: 0.6064 - val_loss: 0.7022 - val_accuracy: 0.6014\n",
            "Epoch 46/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.6368 - val_loss: 0.6914 - val_accuracy: 0.6216\n",
            "Epoch 47/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6182 - val_loss: 0.6842 - val_accuracy: 0.6284\n",
            "Epoch 48/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6486 - val_loss: 0.6596 - val_accuracy: 0.6554\n",
            "Epoch 49/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.6503 - val_loss: 0.6631 - val_accuracy: 0.6622\n",
            "Epoch 50/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.6301 - val_loss: 0.6567 - val_accuracy: 0.6689\n",
            "Epoch 51/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6824 - val_loss: 0.6564 - val_accuracy: 0.6689\n",
            "Epoch 52/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6639 - val_loss: 0.6389 - val_accuracy: 0.6892\n",
            "Epoch 53/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.6554 - val_loss: 0.6228 - val_accuracy: 0.6959\n",
            "Epoch 54/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.6655 - val_loss: 0.6380 - val_accuracy: 0.7095\n",
            "Epoch 55/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6791 - val_loss: 0.6357 - val_accuracy: 0.6959\n",
            "Epoch 56/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6761 - accuracy: 0.6554 - val_loss: 0.6277 - val_accuracy: 0.7027\n",
            "Epoch 57/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6756 - accuracy: 0.6622 - val_loss: 0.6346 - val_accuracy: 0.6757\n",
            "Epoch 58/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6520 - val_loss: 0.6338 - val_accuracy: 0.6757\n",
            "Epoch 59/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6758 - accuracy: 0.6571 - val_loss: 0.6224 - val_accuracy: 0.7162\n",
            "Epoch 60/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6858 - val_loss: 0.6255 - val_accuracy: 0.7095\n",
            "Epoch 61/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6723 - val_loss: 0.6173 - val_accuracy: 0.7162\n",
            "Epoch 62/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6655 - val_loss: 0.6078 - val_accuracy: 0.7230\n",
            "Epoch 63/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.7095 - val_loss: 0.5959 - val_accuracy: 0.7365\n",
            "Epoch 64/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.7010 - val_loss: 0.6081 - val_accuracy: 0.7095\n",
            "Epoch 65/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6824 - val_loss: 0.6235 - val_accuracy: 0.6824\n",
            "Epoch 66/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6706 - val_loss: 0.6047 - val_accuracy: 0.7365\n",
            "Epoch 67/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6824 - val_loss: 0.5927 - val_accuracy: 0.7365\n",
            "Epoch 68/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6875 - val_loss: 0.5839 - val_accuracy: 0.7703\n",
            "Epoch 69/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6740 - val_loss: 0.5865 - val_accuracy: 0.7838\n",
            "Epoch 70/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6993 - val_loss: 0.5811 - val_accuracy: 0.7838\n",
            "Epoch 71/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6875 - val_loss: 0.5745 - val_accuracy: 0.8041\n",
            "Epoch 72/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7213 - val_loss: 0.5718 - val_accuracy: 0.8041\n",
            "Epoch 73/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6171 - accuracy: 0.7196 - val_loss: 0.5754 - val_accuracy: 0.7770\n",
            "Epoch 74/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.7010 - val_loss: 0.5786 - val_accuracy: 0.7568\n",
            "Epoch 75/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7213 - val_loss: 0.5744 - val_accuracy: 0.7770\n",
            "Epoch 76/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7145 - val_loss: 0.5690 - val_accuracy: 0.7905\n",
            "Epoch 77/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.7078 - val_loss: 0.5793 - val_accuracy: 0.7703\n",
            "Epoch 78/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6858 - val_loss: 0.5674 - val_accuracy: 0.7703\n",
            "Epoch 79/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6757 - val_loss: 0.5670 - val_accuracy: 0.7770\n",
            "Epoch 80/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6639 - val_loss: 0.5608 - val_accuracy: 0.7973\n",
            "Epoch 81/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.7264 - val_loss: 0.5758 - val_accuracy: 0.7838\n",
            "Epoch 82/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6588 - val_loss: 0.5815 - val_accuracy: 0.7905\n",
            "Epoch 83/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6959 - val_loss: 0.5739 - val_accuracy: 0.8041\n",
            "Epoch 84/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7095 - val_loss: 0.5523 - val_accuracy: 0.7905\n",
            "Epoch 85/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.6858 - val_loss: 0.5456 - val_accuracy: 0.7973\n",
            "Epoch 86/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.7095 - val_loss: 0.5516 - val_accuracy: 0.8041\n",
            "Epoch 87/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7230 - val_loss: 0.5704 - val_accuracy: 0.7568\n",
            "Epoch 88/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6976 - val_loss: 0.5546 - val_accuracy: 0.7905\n",
            "Epoch 89/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6976 - val_loss: 0.5436 - val_accuracy: 0.7905\n",
            "Epoch 90/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7027 - val_loss: 0.5483 - val_accuracy: 0.7905\n",
            "Epoch 91/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7213 - val_loss: 0.5366 - val_accuracy: 0.8041\n",
            "Epoch 92/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7331 - val_loss: 0.5377 - val_accuracy: 0.7905\n",
            "Epoch 93/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7027 - val_loss: 0.5482 - val_accuracy: 0.7973\n",
            "Epoch 94/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6909 - val_loss: 0.5395 - val_accuracy: 0.8108\n",
            "Epoch 95/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.7128 - val_loss: 0.5430 - val_accuracy: 0.7973\n",
            "Epoch 96/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7179 - val_loss: 0.5405 - val_accuracy: 0.7973\n",
            "Epoch 97/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.7264 - val_loss: 0.5349 - val_accuracy: 0.8041\n",
            "Epoch 98/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7314 - val_loss: 0.5295 - val_accuracy: 0.8041\n",
            "Epoch 99/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7213 - val_loss: 0.5261 - val_accuracy: 0.8108\n",
            "Epoch 100/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6255 - accuracy: 0.7044 - val_loss: 0.5413 - val_accuracy: 0.7770\n",
            "Epoch 101/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7128 - val_loss: 0.5299 - val_accuracy: 0.7838\n",
            "Epoch 102/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7247 - val_loss: 0.5363 - val_accuracy: 0.7838\n",
            "Epoch 103/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7314 - val_loss: 0.5270 - val_accuracy: 0.8041\n",
            "Epoch 104/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7314 - val_loss: 0.5279 - val_accuracy: 0.7838\n",
            "Epoch 105/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6875 - val_loss: 0.5198 - val_accuracy: 0.8108\n",
            "Epoch 106/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7382 - val_loss: 0.5285 - val_accuracy: 0.7838\n",
            "Epoch 107/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.7145 - val_loss: 0.5222 - val_accuracy: 0.7838\n",
            "Epoch 108/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7196 - val_loss: 0.5196 - val_accuracy: 0.7770\n",
            "Epoch 109/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6185 - accuracy: 0.7044 - val_loss: 0.5196 - val_accuracy: 0.8176\n",
            "Epoch 110/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7247 - val_loss: 0.5074 - val_accuracy: 0.7905\n",
            "Epoch 111/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7061 - val_loss: 0.5095 - val_accuracy: 0.7973\n",
            "Epoch 112/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.7044 - val_loss: 0.5261 - val_accuracy: 0.7973\n",
            "Epoch 113/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5913 - accuracy: 0.7399 - val_loss: 0.5162 - val_accuracy: 0.7838\n",
            "Epoch 114/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.7196 - val_loss: 0.5187 - val_accuracy: 0.7973\n",
            "Epoch 115/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7010 - val_loss: 0.5153 - val_accuracy: 0.8176\n",
            "Epoch 116/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.7297 - val_loss: 0.5045 - val_accuracy: 0.8108\n",
            "Epoch 117/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.7297 - val_loss: 0.4996 - val_accuracy: 0.8243\n",
            "Epoch 118/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6099 - accuracy: 0.7128 - val_loss: 0.5010 - val_accuracy: 0.8108\n",
            "Epoch 119/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7314 - val_loss: 0.5074 - val_accuracy: 0.8041\n",
            "Epoch 120/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7145 - val_loss: 0.5129 - val_accuracy: 0.8243\n",
            "Epoch 121/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7297 - val_loss: 0.5063 - val_accuracy: 0.8243\n",
            "Epoch 122/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7095 - val_loss: 0.4959 - val_accuracy: 0.8311\n",
            "Epoch 123/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7449 - val_loss: 0.5030 - val_accuracy: 0.7973\n",
            "Epoch 124/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7196 - val_loss: 0.4937 - val_accuracy: 0.8108\n",
            "Epoch 125/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7314 - val_loss: 0.4892 - val_accuracy: 0.7905\n",
            "Epoch 126/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.7145 - val_loss: 0.5034 - val_accuracy: 0.8108\n",
            "Epoch 127/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7365 - val_loss: 0.4973 - val_accuracy: 0.8108\n",
            "Epoch 128/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7500 - val_loss: 0.4939 - val_accuracy: 0.8041\n",
            "Epoch 129/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7128 - val_loss: 0.5045 - val_accuracy: 0.7838\n",
            "Epoch 130/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7297 - val_loss: 0.5041 - val_accuracy: 0.7905\n",
            "Epoch 131/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7230 - val_loss: 0.4939 - val_accuracy: 0.8243\n",
            "Epoch 132/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.7247 - val_loss: 0.4982 - val_accuracy: 0.8176\n",
            "Epoch 133/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7314 - val_loss: 0.5130 - val_accuracy: 0.7703\n",
            "Epoch 134/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.7213 - val_loss: 0.5036 - val_accuracy: 0.7973\n",
            "Epoch 135/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.7551 - val_loss: 0.4857 - val_accuracy: 0.8176\n",
            "Epoch 136/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7551 - val_loss: 0.4766 - val_accuracy: 0.8108\n",
            "Epoch 137/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7331 - val_loss: 0.4848 - val_accuracy: 0.8311\n",
            "Epoch 138/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7432 - val_loss: 0.4833 - val_accuracy: 0.8108\n",
            "Epoch 139/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7551 - val_loss: 0.4713 - val_accuracy: 0.8378\n",
            "Epoch 140/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6993 - val_loss: 0.4879 - val_accuracy: 0.8041\n",
            "Epoch 141/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7399 - val_loss: 0.4810 - val_accuracy: 0.7973\n",
            "Epoch 142/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5939 - accuracy: 0.7432 - val_loss: 0.4869 - val_accuracy: 0.7905\n",
            "Epoch 143/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7466 - val_loss: 0.4793 - val_accuracy: 0.7973\n",
            "Epoch 144/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7432 - val_loss: 0.4974 - val_accuracy: 0.7770\n",
            "Epoch 145/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7449 - val_loss: 0.4868 - val_accuracy: 0.7905\n",
            "Epoch 146/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7466 - val_loss: 0.4807 - val_accuracy: 0.8108\n",
            "Epoch 147/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7331 - val_loss: 0.4799 - val_accuracy: 0.8176\n",
            "Epoch 148/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6065 - accuracy: 0.7297 - val_loss: 0.4936 - val_accuracy: 0.7973\n",
            "Epoch 149/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7551 - val_loss: 0.4758 - val_accuracy: 0.8108\n",
            "Epoch 150/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.7247 - val_loss: 0.4710 - val_accuracy: 0.8243\n",
            "Epoch 151/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5917 - accuracy: 0.7584 - val_loss: 0.4881 - val_accuracy: 0.8041\n",
            "Epoch 152/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7230 - val_loss: 0.4901 - val_accuracy: 0.8108\n",
            "Epoch 153/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7314 - val_loss: 0.4814 - val_accuracy: 0.8378\n",
            "Epoch 154/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7568 - val_loss: 0.4800 - val_accuracy: 0.8243\n",
            "Epoch 155/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.7534 - val_loss: 0.4785 - val_accuracy: 0.8108\n",
            "Epoch 156/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.7449 - val_loss: 0.4756 - val_accuracy: 0.8041\n",
            "Epoch 157/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.7213 - val_loss: 0.4872 - val_accuracy: 0.8176\n",
            "Epoch 158/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7264 - val_loss: 0.4999 - val_accuracy: 0.7973\n",
            "Epoch 159/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.7399 - val_loss: 0.4768 - val_accuracy: 0.8108\n",
            "Epoch 160/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6116 - accuracy: 0.7145 - val_loss: 0.4952 - val_accuracy: 0.7973\n",
            "Epoch 161/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7365 - val_loss: 0.4903 - val_accuracy: 0.8243\n",
            "Epoch 162/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7517 - val_loss: 0.5114 - val_accuracy: 0.7838\n",
            "Epoch 163/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.7297 - val_loss: 0.5023 - val_accuracy: 0.8176\n",
            "Epoch 164/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.7787 - val_loss: 0.4944 - val_accuracy: 0.8108\n",
            "Epoch 165/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7264 - val_loss: 0.4835 - val_accuracy: 0.8041\n",
            "Epoch 166/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.7297 - val_loss: 0.4830 - val_accuracy: 0.8108\n",
            "Epoch 167/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.7483 - val_loss: 0.4767 - val_accuracy: 0.8243\n",
            "Epoch 168/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7534 - val_loss: 0.4821 - val_accuracy: 0.8243\n",
            "Epoch 169/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7382 - val_loss: 0.4849 - val_accuracy: 0.8311\n",
            "Epoch 170/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7449 - val_loss: 0.4793 - val_accuracy: 0.8311\n",
            "Epoch 171/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5773 - accuracy: 0.7416 - val_loss: 0.4907 - val_accuracy: 0.7973\n",
            "Epoch 172/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7804 - val_loss: 0.4822 - val_accuracy: 0.7973\n",
            "Epoch 173/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7720 - val_loss: 0.4682 - val_accuracy: 0.8176\n",
            "Epoch 174/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.7297 - val_loss: 0.4648 - val_accuracy: 0.8176\n",
            "Epoch 175/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.7297 - val_loss: 0.4713 - val_accuracy: 0.8243\n",
            "Epoch 176/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7264 - val_loss: 0.4719 - val_accuracy: 0.8311\n",
            "Epoch 177/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7652 - val_loss: 0.4710 - val_accuracy: 0.8243\n",
            "Epoch 178/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7314 - val_loss: 0.4818 - val_accuracy: 0.7905\n",
            "Epoch 179/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7483 - val_loss: 0.4837 - val_accuracy: 0.7973\n",
            "Epoch 180/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.7382 - val_loss: 0.4706 - val_accuracy: 0.8176\n",
            "Epoch 181/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7027 - val_loss: 0.4719 - val_accuracy: 0.8243\n",
            "Epoch 182/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7061 - val_loss: 0.4794 - val_accuracy: 0.7905\n",
            "Epoch 183/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7382 - val_loss: 0.4599 - val_accuracy: 0.8176\n",
            "Epoch 184/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7449 - val_loss: 0.4659 - val_accuracy: 0.8041\n",
            "Epoch 185/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7331 - val_loss: 0.4635 - val_accuracy: 0.8243\n",
            "Epoch 186/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.7432 - val_loss: 0.4695 - val_accuracy: 0.8243\n",
            "Epoch 187/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7179 - val_loss: 0.4768 - val_accuracy: 0.8041\n",
            "Epoch 188/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7449 - val_loss: 0.4755 - val_accuracy: 0.8243\n",
            "Epoch 189/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7078 - val_loss: 0.4938 - val_accuracy: 0.8176\n",
            "Epoch 190/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7466 - val_loss: 0.4871 - val_accuracy: 0.7973\n",
            "Epoch 191/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7500 - val_loss: 0.4769 - val_accuracy: 0.7973\n",
            "Epoch 192/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7230 - val_loss: 0.4813 - val_accuracy: 0.7973\n",
            "Epoch 193/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7551 - val_loss: 0.4744 - val_accuracy: 0.7973\n",
            "Epoch 194/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7466 - val_loss: 0.4856 - val_accuracy: 0.7905\n",
            "Epoch 195/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7264 - val_loss: 0.4677 - val_accuracy: 0.8108\n",
            "Epoch 196/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7720 - val_loss: 0.4578 - val_accuracy: 0.7973\n",
            "Epoch 197/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7635 - val_loss: 0.4531 - val_accuracy: 0.8041\n",
            "Epoch 198/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7432 - val_loss: 0.4472 - val_accuracy: 0.8108\n",
            "Epoch 199/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6993 - val_loss: 0.4345 - val_accuracy: 0.8243\n",
            "Epoch 200/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7568 - val_loss: 0.4298 - val_accuracy: 0.8378\n",
            "Epoch 201/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7466 - val_loss: 0.4375 - val_accuracy: 0.8176\n",
            "Epoch 202/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.7500 - val_loss: 0.4503 - val_accuracy: 0.8176\n",
            "Epoch 203/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7466 - val_loss: 0.4528 - val_accuracy: 0.8108\n",
            "Epoch 204/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7584 - val_loss: 0.4569 - val_accuracy: 0.8446\n",
            "Epoch 205/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7568 - val_loss: 0.4548 - val_accuracy: 0.8108\n",
            "Epoch 206/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7483 - val_loss: 0.4531 - val_accuracy: 0.8243\n",
            "Epoch 207/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7466 - val_loss: 0.4530 - val_accuracy: 0.8176\n",
            "Epoch 208/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7736 - val_loss: 0.4453 - val_accuracy: 0.8514\n",
            "Epoch 209/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7280 - val_loss: 0.4551 - val_accuracy: 0.8378\n",
            "Epoch 210/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7669 - val_loss: 0.4590 - val_accuracy: 0.8108\n",
            "Epoch 211/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7905 - val_loss: 0.4440 - val_accuracy: 0.8243\n",
            "Epoch 212/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.7449 - val_loss: 0.4357 - val_accuracy: 0.8378\n",
            "Epoch 213/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7652 - val_loss: 0.4449 - val_accuracy: 0.8446\n",
            "Epoch 214/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.7432 - val_loss: 0.4592 - val_accuracy: 0.8176\n",
            "Epoch 215/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7432 - val_loss: 0.4683 - val_accuracy: 0.8243\n",
            "Epoch 216/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6034 - accuracy: 0.7230 - val_loss: 0.4510 - val_accuracy: 0.8311\n",
            "Epoch 217/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7432 - val_loss: 0.4572 - val_accuracy: 0.8378\n",
            "Epoch 218/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7551 - val_loss: 0.4541 - val_accuracy: 0.8378\n",
            "Epoch 219/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7297 - val_loss: 0.4610 - val_accuracy: 0.8446\n",
            "Epoch 220/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.7399 - val_loss: 0.4634 - val_accuracy: 0.8581\n",
            "Epoch 221/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7297 - val_loss: 0.4634 - val_accuracy: 0.8378\n",
            "Epoch 222/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7432 - val_loss: 0.4551 - val_accuracy: 0.8243\n",
            "Epoch 223/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7314 - val_loss: 0.4514 - val_accuracy: 0.8176\n",
            "Epoch 224/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7483 - val_loss: 0.4442 - val_accuracy: 0.8108\n",
            "Epoch 225/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7787 - val_loss: 0.4466 - val_accuracy: 0.8311\n",
            "Epoch 226/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7365 - val_loss: 0.4346 - val_accuracy: 0.8446\n",
            "Epoch 227/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.7568 - val_loss: 0.4271 - val_accuracy: 0.8514\n",
            "Epoch 228/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7280 - val_loss: 0.4394 - val_accuracy: 0.8514\n",
            "Epoch 229/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7449 - val_loss: 0.4517 - val_accuracy: 0.8176\n",
            "Epoch 230/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7280 - val_loss: 0.4596 - val_accuracy: 0.8041\n",
            "Epoch 231/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.7230 - val_loss: 0.4507 - val_accuracy: 0.8176\n",
            "Epoch 232/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7466 - val_loss: 0.4450 - val_accuracy: 0.8581\n",
            "Epoch 233/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.7314 - val_loss: 0.4609 - val_accuracy: 0.8311\n",
            "Epoch 234/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7247 - val_loss: 0.4647 - val_accuracy: 0.8176\n",
            "Epoch 235/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7635 - val_loss: 0.4549 - val_accuracy: 0.8176\n",
            "Epoch 236/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7669 - val_loss: 0.4457 - val_accuracy: 0.8243\n",
            "Epoch 237/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7584 - val_loss: 0.4386 - val_accuracy: 0.8311\n",
            "Epoch 238/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7483 - val_loss: 0.4472 - val_accuracy: 0.8108\n",
            "Epoch 239/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7736 - val_loss: 0.4448 - val_accuracy: 0.8108\n",
            "Epoch 240/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.7399 - val_loss: 0.4515 - val_accuracy: 0.8176\n",
            "Epoch 241/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7500 - val_loss: 0.4538 - val_accuracy: 0.8243\n",
            "Epoch 242/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7432 - val_loss: 0.4484 - val_accuracy: 0.8378\n",
            "Epoch 243/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7568 - val_loss: 0.4491 - val_accuracy: 0.8311\n",
            "Epoch 244/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7365 - val_loss: 0.4482 - val_accuracy: 0.8311\n",
            "Epoch 245/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7517 - val_loss: 0.4622 - val_accuracy: 0.8243\n",
            "Epoch 246/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.7382 - val_loss: 0.4396 - val_accuracy: 0.8446\n",
            "Epoch 247/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7466 - val_loss: 0.4438 - val_accuracy: 0.8378\n",
            "Epoch 248/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.7669 - val_loss: 0.4489 - val_accuracy: 0.8378\n",
            "Epoch 249/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5766 - accuracy: 0.7601 - val_loss: 0.4470 - val_accuracy: 0.8514\n",
            "Epoch 250/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7686 - val_loss: 0.4607 - val_accuracy: 0.8176\n",
            "Epoch 251/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7449 - val_loss: 0.4512 - val_accuracy: 0.8514\n",
            "Epoch 252/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7753 - val_loss: 0.4413 - val_accuracy: 0.8311\n",
            "Epoch 253/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7584 - val_loss: 0.4446 - val_accuracy: 0.8446\n",
            "Epoch 254/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7669 - val_loss: 0.4430 - val_accuracy: 0.8243\n",
            "Epoch 255/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.7399 - val_loss: 0.4486 - val_accuracy: 0.8514\n",
            "Epoch 256/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5695 - accuracy: 0.7264 - val_loss: 0.4368 - val_accuracy: 0.8581\n",
            "Epoch 257/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7416 - val_loss: 0.4607 - val_accuracy: 0.8378\n",
            "Epoch 258/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.7061 - val_loss: 0.4515 - val_accuracy: 0.8649\n",
            "Epoch 259/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.7280 - val_loss: 0.4577 - val_accuracy: 0.8649\n",
            "Epoch 260/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5730 - accuracy: 0.7483 - val_loss: 0.4559 - val_accuracy: 0.8514\n",
            "Epoch 261/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7584 - val_loss: 0.4451 - val_accuracy: 0.8514\n",
            "Epoch 262/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7652 - val_loss: 0.4290 - val_accuracy: 0.8378\n",
            "Epoch 263/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.7753 - val_loss: 0.4220 - val_accuracy: 0.8243\n",
            "Epoch 264/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7584 - val_loss: 0.4174 - val_accuracy: 0.8243\n",
            "Epoch 265/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.7280 - val_loss: 0.4254 - val_accuracy: 0.8378\n",
            "Epoch 266/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7568 - val_loss: 0.4340 - val_accuracy: 0.8378\n",
            "Epoch 267/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.7432 - val_loss: 0.4289 - val_accuracy: 0.8243\n",
            "Epoch 268/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7399 - val_loss: 0.4350 - val_accuracy: 0.8446\n",
            "Epoch 269/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7399 - val_loss: 0.4237 - val_accuracy: 0.8446\n",
            "Epoch 270/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7297 - val_loss: 0.4306 - val_accuracy: 0.8311\n",
            "Epoch 271/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7196 - val_loss: 0.4472 - val_accuracy: 0.8311\n",
            "Epoch 272/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7601 - val_loss: 0.4462 - val_accuracy: 0.8446\n",
            "Epoch 273/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7399 - val_loss: 0.4488 - val_accuracy: 0.8378\n",
            "Epoch 274/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7534 - val_loss: 0.4435 - val_accuracy: 0.8446\n",
            "Epoch 275/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7686 - val_loss: 0.4543 - val_accuracy: 0.8378\n",
            "Epoch 276/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5738 - accuracy: 0.7517 - val_loss: 0.4502 - val_accuracy: 0.8311\n",
            "Epoch 277/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7568 - val_loss: 0.4513 - val_accuracy: 0.8176\n",
            "Epoch 278/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7584 - val_loss: 0.4474 - val_accuracy: 0.8243\n",
            "Epoch 279/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7432 - val_loss: 0.4765 - val_accuracy: 0.8176\n",
            "Epoch 280/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.7517 - val_loss: 0.4737 - val_accuracy: 0.8176\n",
            "Epoch 281/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7736 - val_loss: 0.4742 - val_accuracy: 0.8108\n",
            "Epoch 282/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7618 - val_loss: 0.4733 - val_accuracy: 0.8108\n",
            "Epoch 283/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 0.4691 - val_accuracy: 0.8378\n",
            "Epoch 284/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.7601 - val_loss: 0.4437 - val_accuracy: 0.8243\n",
            "Epoch 285/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7618 - val_loss: 0.4441 - val_accuracy: 0.8243\n",
            "Epoch 286/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7280 - val_loss: 0.4523 - val_accuracy: 0.8311\n",
            "Epoch 287/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6098 - accuracy: 0.7314 - val_loss: 0.4652 - val_accuracy: 0.8378\n",
            "Epoch 288/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7551 - val_loss: 0.4746 - val_accuracy: 0.8311\n",
            "Epoch 289/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.7280 - val_loss: 0.4723 - val_accuracy: 0.8378\n",
            "Epoch 290/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7584 - val_loss: 0.4807 - val_accuracy: 0.8243\n",
            "Epoch 291/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7551 - val_loss: 0.4782 - val_accuracy: 0.8176\n",
            "Epoch 292/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.7416 - val_loss: 0.4744 - val_accuracy: 0.8311\n",
            "Epoch 293/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7652 - val_loss: 0.4801 - val_accuracy: 0.7973\n",
            "Epoch 294/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7736 - val_loss: 0.4679 - val_accuracy: 0.8176\n",
            "Epoch 295/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7432 - val_loss: 0.4623 - val_accuracy: 0.8108\n",
            "Epoch 296/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7449 - val_loss: 0.4665 - val_accuracy: 0.8176\n",
            "Epoch 297/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.4588 - val_accuracy: 0.8243\n",
            "Epoch 298/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7618 - val_loss: 0.4476 - val_accuracy: 0.8446\n",
            "Epoch 299/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7247 - val_loss: 0.4493 - val_accuracy: 0.8378\n",
            "Epoch 300/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.7399 - val_loss: 0.4507 - val_accuracy: 0.8311\n",
            "Epoch 301/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7466 - val_loss: 0.4428 - val_accuracy: 0.8243\n",
            "Epoch 302/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7568 - val_loss: 0.4373 - val_accuracy: 0.8311\n",
            "Epoch 303/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7635 - val_loss: 0.4398 - val_accuracy: 0.8378\n",
            "Epoch 304/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7584 - val_loss: 0.4382 - val_accuracy: 0.8378\n",
            "Epoch 305/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7601 - val_loss: 0.4317 - val_accuracy: 0.8581\n",
            "Epoch 306/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7551 - val_loss: 0.4364 - val_accuracy: 0.8378\n",
            "Epoch 307/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7365 - val_loss: 0.4386 - val_accuracy: 0.8311\n",
            "Epoch 308/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7500 - val_loss: 0.4457 - val_accuracy: 0.8378\n",
            "Epoch 309/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7601 - val_loss: 0.4523 - val_accuracy: 0.8311\n",
            "Epoch 310/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7787 - val_loss: 0.4560 - val_accuracy: 0.8243\n",
            "Epoch 311/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7551 - val_loss: 0.4520 - val_accuracy: 0.8243\n",
            "Epoch 312/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.7568 - val_loss: 0.4518 - val_accuracy: 0.8378\n",
            "Epoch 313/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7686 - val_loss: 0.4554 - val_accuracy: 0.8243\n",
            "Epoch 314/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7416 - val_loss: 0.4481 - val_accuracy: 0.8514\n",
            "Epoch 315/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5931 - accuracy: 0.7348 - val_loss: 0.4514 - val_accuracy: 0.8378\n",
            "Epoch 316/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.7382 - val_loss: 0.4656 - val_accuracy: 0.8311\n",
            "Epoch 317/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7618 - val_loss: 0.4464 - val_accuracy: 0.8514\n",
            "Epoch 318/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7399 - val_loss: 0.4514 - val_accuracy: 0.8446\n",
            "Epoch 319/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.4483 - val_accuracy: 0.8378\n",
            "Epoch 320/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7162 - val_loss: 0.4526 - val_accuracy: 0.8514\n",
            "Epoch 321/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7787 - val_loss: 0.4578 - val_accuracy: 0.8311\n",
            "Epoch 322/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.7331 - val_loss: 0.4553 - val_accuracy: 0.8378\n",
            "Epoch 323/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7568 - val_loss: 0.4571 - val_accuracy: 0.8514\n",
            "Epoch 324/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7720 - val_loss: 0.4464 - val_accuracy: 0.8378\n",
            "Epoch 325/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7568 - val_loss: 0.4426 - val_accuracy: 0.8378\n",
            "Epoch 326/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7297 - val_loss: 0.4485 - val_accuracy: 0.8514\n",
            "Epoch 327/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7821 - val_loss: 0.4436 - val_accuracy: 0.8446\n",
            "Epoch 328/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7618 - val_loss: 0.4387 - val_accuracy: 0.8514\n",
            "Epoch 329/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7500 - val_loss: 0.4453 - val_accuracy: 0.8581\n",
            "Epoch 330/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7551 - val_loss: 0.4463 - val_accuracy: 0.8446\n",
            "Epoch 331/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7568 - val_loss: 0.4490 - val_accuracy: 0.8649\n",
            "Epoch 332/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7686 - val_loss: 0.4480 - val_accuracy: 0.8514\n",
            "Epoch 333/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7652 - val_loss: 0.4410 - val_accuracy: 0.8378\n",
            "Epoch 334/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7838 - val_loss: 0.4376 - val_accuracy: 0.8446\n",
            "Epoch 335/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7280 - val_loss: 0.4512 - val_accuracy: 0.8514\n",
            "Epoch 336/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7669 - val_loss: 0.4490 - val_accuracy: 0.8378\n",
            "Epoch 337/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7500 - val_loss: 0.4447 - val_accuracy: 0.8446\n",
            "Epoch 338/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7855 - val_loss: 0.4412 - val_accuracy: 0.8581\n",
            "Epoch 339/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7399 - val_loss: 0.4534 - val_accuracy: 0.8243\n",
            "Epoch 340/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.7466 - val_loss: 0.4615 - val_accuracy: 0.8108\n",
            "Epoch 341/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7348 - val_loss: 0.4547 - val_accuracy: 0.8311\n",
            "Epoch 342/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7601 - val_loss: 0.4462 - val_accuracy: 0.8378\n",
            "Epoch 343/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7449 - val_loss: 0.4353 - val_accuracy: 0.8311\n",
            "Epoch 344/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7686 - val_loss: 0.4405 - val_accuracy: 0.8378\n",
            "Epoch 345/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.7449 - val_loss: 0.4514 - val_accuracy: 0.8378\n",
            "Epoch 346/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7483 - val_loss: 0.4586 - val_accuracy: 0.8243\n",
            "Epoch 347/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7618 - val_loss: 0.4663 - val_accuracy: 0.8243\n",
            "Epoch 348/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7483 - val_loss: 0.4711 - val_accuracy: 0.7973\n",
            "Epoch 349/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7314 - val_loss: 0.4690 - val_accuracy: 0.8176\n",
            "Epoch 350/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7584 - val_loss: 0.4766 - val_accuracy: 0.8311\n",
            "Epoch 351/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7703 - val_loss: 0.4622 - val_accuracy: 0.8378\n",
            "Epoch 352/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7416 - val_loss: 0.4421 - val_accuracy: 0.8581\n",
            "Epoch 353/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7500 - val_loss: 0.4605 - val_accuracy: 0.8243\n",
            "Epoch 354/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7399 - val_loss: 0.4594 - val_accuracy: 0.8378\n",
            "Epoch 355/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5708 - accuracy: 0.7483 - val_loss: 0.4539 - val_accuracy: 0.8243\n",
            "Epoch 356/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7534 - val_loss: 0.4521 - val_accuracy: 0.8311\n",
            "Epoch 357/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.7517 - val_loss: 0.4520 - val_accuracy: 0.8378\n",
            "Epoch 358/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7449 - val_loss: 0.4496 - val_accuracy: 0.8446\n",
            "Epoch 359/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.7247 - val_loss: 0.4589 - val_accuracy: 0.8514\n",
            "Epoch 360/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.7584 - val_loss: 0.4519 - val_accuracy: 0.8311\n",
            "Epoch 361/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7365 - val_loss: 0.4570 - val_accuracy: 0.8581\n",
            "Epoch 362/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.7517 - val_loss: 0.4585 - val_accuracy: 0.8446\n",
            "Epoch 363/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7568 - val_loss: 0.4534 - val_accuracy: 0.8581\n",
            "Epoch 364/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7466 - val_loss: 0.4506 - val_accuracy: 0.8581\n",
            "Epoch 365/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7331 - val_loss: 0.4487 - val_accuracy: 0.8514\n",
            "Epoch 366/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5702 - accuracy: 0.7432 - val_loss: 0.4570 - val_accuracy: 0.8581\n",
            "Epoch 367/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7568 - val_loss: 0.4494 - val_accuracy: 0.8514\n",
            "Epoch 368/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7331 - val_loss: 0.4406 - val_accuracy: 0.8514\n",
            "Epoch 369/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5914 - accuracy: 0.7449 - val_loss: 0.4500 - val_accuracy: 0.8514\n",
            "Epoch 370/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7466 - val_loss: 0.4469 - val_accuracy: 0.8446\n",
            "Epoch 371/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7618 - val_loss: 0.4525 - val_accuracy: 0.8581\n",
            "Epoch 372/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7297 - val_loss: 0.4529 - val_accuracy: 0.8649\n",
            "Epoch 373/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7703 - val_loss: 0.4512 - val_accuracy: 0.8514\n",
            "Epoch 374/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7601 - val_loss: 0.4392 - val_accuracy: 0.8446\n",
            "Epoch 375/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7855 - val_loss: 0.4476 - val_accuracy: 0.8649\n",
            "Epoch 376/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7331 - val_loss: 0.4579 - val_accuracy: 0.8514\n",
            "Epoch 377/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7314 - val_loss: 0.4665 - val_accuracy: 0.8378\n",
            "Epoch 378/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7568 - val_loss: 0.4466 - val_accuracy: 0.8514\n",
            "Epoch 379/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.7500 - val_loss: 0.4507 - val_accuracy: 0.8581\n",
            "Epoch 380/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7382 - val_loss: 0.4584 - val_accuracy: 0.8446\n",
            "Epoch 381/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7601 - val_loss: 0.4563 - val_accuracy: 0.8243\n",
            "Epoch 382/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.7652 - val_loss: 0.4545 - val_accuracy: 0.8243\n",
            "Epoch 383/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.7584 - val_loss: 0.4513 - val_accuracy: 0.8378\n",
            "Epoch 384/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7618 - val_loss: 0.4445 - val_accuracy: 0.8311\n",
            "Epoch 385/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.7382 - val_loss: 0.4538 - val_accuracy: 0.8243\n",
            "Epoch 386/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.7483 - val_loss: 0.4345 - val_accuracy: 0.8514\n",
            "Epoch 387/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7483 - val_loss: 0.4366 - val_accuracy: 0.8514\n",
            "Epoch 388/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7584 - val_loss: 0.4346 - val_accuracy: 0.8649\n",
            "Epoch 389/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7686 - val_loss: 0.4385 - val_accuracy: 0.8784\n",
            "Epoch 390/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7551 - val_loss: 0.4472 - val_accuracy: 0.8581\n",
            "Epoch 391/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8024 - val_loss: 0.4409 - val_accuracy: 0.8649\n",
            "Epoch 392/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.7314 - val_loss: 0.4523 - val_accuracy: 0.8446\n",
            "Epoch 393/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7432 - val_loss: 0.4390 - val_accuracy: 0.8446\n",
            "Epoch 394/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7534 - val_loss: 0.4409 - val_accuracy: 0.8446\n",
            "Epoch 395/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7416 - val_loss: 0.4430 - val_accuracy: 0.8378\n",
            "Epoch 396/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5705 - accuracy: 0.7331 - val_loss: 0.4423 - val_accuracy: 0.8378\n",
            "Epoch 397/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7331 - val_loss: 0.4461 - val_accuracy: 0.8378\n",
            "Epoch 398/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7568 - val_loss: 0.4491 - val_accuracy: 0.8108\n",
            "Epoch 399/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7703 - val_loss: 0.4450 - val_accuracy: 0.8176\n",
            "Epoch 400/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7534 - val_loss: 0.4377 - val_accuracy: 0.8378\n",
            "Epoch 401/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7652 - val_loss: 0.4375 - val_accuracy: 0.8243\n",
            "Epoch 402/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7686 - val_loss: 0.4428 - val_accuracy: 0.8378\n",
            "Epoch 403/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7517 - val_loss: 0.4451 - val_accuracy: 0.8243\n",
            "Epoch 404/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7669 - val_loss: 0.4328 - val_accuracy: 0.8784\n",
            "Epoch 405/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7551 - val_loss: 0.4501 - val_accuracy: 0.8649\n",
            "Epoch 406/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7297 - val_loss: 0.4537 - val_accuracy: 0.8243\n",
            "Epoch 407/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7382 - val_loss: 0.4488 - val_accuracy: 0.8378\n",
            "Epoch 408/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.7145 - val_loss: 0.4468 - val_accuracy: 0.8581\n",
            "Epoch 409/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6078 - accuracy: 0.7264 - val_loss: 0.4545 - val_accuracy: 0.8514\n",
            "Epoch 410/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7416 - val_loss: 0.4524 - val_accuracy: 0.8378\n",
            "Epoch 411/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7753 - val_loss: 0.4659 - val_accuracy: 0.8446\n",
            "Epoch 412/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7314 - val_loss: 0.4582 - val_accuracy: 0.8378\n",
            "Epoch 413/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7416 - val_loss: 0.4563 - val_accuracy: 0.8446\n",
            "Epoch 414/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7753 - val_loss: 0.4477 - val_accuracy: 0.8581\n",
            "Epoch 415/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.7652 - val_loss: 0.4583 - val_accuracy: 0.8243\n",
            "Epoch 416/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7449 - val_loss: 0.4536 - val_accuracy: 0.8581\n",
            "Epoch 417/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5766 - accuracy: 0.7382 - val_loss: 0.4581 - val_accuracy: 0.8784\n",
            "Epoch 418/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7669 - val_loss: 0.4414 - val_accuracy: 0.8514\n",
            "Epoch 419/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.7179 - val_loss: 0.4470 - val_accuracy: 0.8716\n",
            "Epoch 420/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7568 - val_loss: 0.4467 - val_accuracy: 0.8581\n",
            "Epoch 421/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7500 - val_loss: 0.4430 - val_accuracy: 0.8514\n",
            "Epoch 422/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7551 - val_loss: 0.4422 - val_accuracy: 0.8514\n",
            "Epoch 423/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7568 - val_loss: 0.4409 - val_accuracy: 0.8446\n",
            "Epoch 424/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7821 - val_loss: 0.4341 - val_accuracy: 0.8581\n",
            "Epoch 425/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7584 - val_loss: 0.4359 - val_accuracy: 0.8446\n",
            "Epoch 426/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7365 - val_loss: 0.4562 - val_accuracy: 0.8446\n",
            "Epoch 427/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7601 - val_loss: 0.4574 - val_accuracy: 0.8378\n",
            "Epoch 428/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7382 - val_loss: 0.4603 - val_accuracy: 0.8446\n",
            "Epoch 429/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7483 - val_loss: 0.4615 - val_accuracy: 0.8514\n",
            "Epoch 430/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.7078 - val_loss: 0.4706 - val_accuracy: 0.8446\n",
            "Epoch 431/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7669 - val_loss: 0.4613 - val_accuracy: 0.8311\n",
            "Epoch 432/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7297 - val_loss: 0.4690 - val_accuracy: 0.8446\n",
            "Epoch 433/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7534 - val_loss: 0.4595 - val_accuracy: 0.8378\n",
            "Epoch 434/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7449 - val_loss: 0.4552 - val_accuracy: 0.8446\n",
            "Epoch 435/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7551 - val_loss: 0.4480 - val_accuracy: 0.8378\n",
            "Epoch 436/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7399 - val_loss: 0.4474 - val_accuracy: 0.8378\n",
            "Epoch 437/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7821 - val_loss: 0.4515 - val_accuracy: 0.8378\n",
            "Epoch 438/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7416 - val_loss: 0.4442 - val_accuracy: 0.8446\n",
            "Epoch 439/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7618 - val_loss: 0.4468 - val_accuracy: 0.8311\n",
            "Epoch 440/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7466 - val_loss: 0.4521 - val_accuracy: 0.8311\n",
            "Epoch 441/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7517 - val_loss: 0.4334 - val_accuracy: 0.8446\n",
            "Epoch 442/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7432 - val_loss: 0.4397 - val_accuracy: 0.8514\n",
            "Epoch 443/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.7652 - val_loss: 0.4439 - val_accuracy: 0.8581\n",
            "Epoch 444/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7652 - val_loss: 0.4313 - val_accuracy: 0.8446\n",
            "Epoch 445/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7618 - val_loss: 0.4340 - val_accuracy: 0.8581\n",
            "Epoch 446/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7483 - val_loss: 0.4346 - val_accuracy: 0.8446\n",
            "Epoch 447/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.7416 - val_loss: 0.4544 - val_accuracy: 0.8176\n",
            "Epoch 448/500\n",
            "74/74 [==============================] - 0s 4ms/step - loss: 0.5737 - accuracy: 0.7534 - val_loss: 0.4487 - val_accuracy: 0.8243\n",
            "Epoch 449/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7770 - val_loss: 0.4349 - val_accuracy: 0.8581\n",
            "Epoch 450/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.7483 - val_loss: 0.4415 - val_accuracy: 0.8446\n",
            "Epoch 451/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7500 - val_loss: 0.4544 - val_accuracy: 0.8378\n",
            "Epoch 452/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7635 - val_loss: 0.4425 - val_accuracy: 0.8514\n",
            "Epoch 453/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7382 - val_loss: 0.4567 - val_accuracy: 0.8446\n",
            "Epoch 454/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7483 - val_loss: 0.4503 - val_accuracy: 0.8243\n",
            "Epoch 455/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7432 - val_loss: 0.4404 - val_accuracy: 0.8514\n",
            "Epoch 456/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7584 - val_loss: 0.4384 - val_accuracy: 0.8446\n",
            "Epoch 457/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.7449 - val_loss: 0.4348 - val_accuracy: 0.8378\n",
            "Epoch 458/500\n",
            "74/74 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7703 - val_loss: 0.4378 - val_accuracy: 0.8514\n",
            "Epoch 459/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7416 - val_loss: 0.4491 - val_accuracy: 0.8446\n",
            "Epoch 460/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7331 - val_loss: 0.4337 - val_accuracy: 0.8514\n",
            "Epoch 461/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7213 - val_loss: 0.4522 - val_accuracy: 0.8446\n",
            "Epoch 462/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7382 - val_loss: 0.4446 - val_accuracy: 0.8311\n",
            "Epoch 463/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7872 - val_loss: 0.4477 - val_accuracy: 0.8446\n",
            "Epoch 464/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7635 - val_loss: 0.4403 - val_accuracy: 0.8514\n",
            "Epoch 465/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7568 - val_loss: 0.4367 - val_accuracy: 0.8514\n",
            "Epoch 466/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7770 - val_loss: 0.4418 - val_accuracy: 0.8446\n",
            "Epoch 467/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7517 - val_loss: 0.4440 - val_accuracy: 0.8311\n",
            "Epoch 468/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7213 - val_loss: 0.4413 - val_accuracy: 0.8243\n",
            "Epoch 469/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7416 - val_loss: 0.4504 - val_accuracy: 0.8311\n",
            "Epoch 470/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7534 - val_loss: 0.4421 - val_accuracy: 0.8041\n",
            "Epoch 471/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7466 - val_loss: 0.4432 - val_accuracy: 0.8378\n",
            "Epoch 472/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.7821 - val_loss: 0.4386 - val_accuracy: 0.8378\n",
            "Epoch 473/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.7365 - val_loss: 0.4464 - val_accuracy: 0.8378\n",
            "Epoch 474/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7686 - val_loss: 0.4413 - val_accuracy: 0.8446\n",
            "Epoch 475/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5670 - accuracy: 0.7551 - val_loss: 0.4435 - val_accuracy: 0.8311\n",
            "Epoch 476/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7213 - val_loss: 0.4352 - val_accuracy: 0.8446\n",
            "Epoch 477/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7618 - val_loss: 0.4401 - val_accuracy: 0.8311\n",
            "Epoch 478/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5740 - accuracy: 0.7517 - val_loss: 0.4343 - val_accuracy: 0.8446\n",
            "Epoch 479/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.7348 - val_loss: 0.4503 - val_accuracy: 0.8176\n",
            "Epoch 480/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7517 - val_loss: 0.4550 - val_accuracy: 0.8243\n",
            "Epoch 481/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.7551 - val_loss: 0.4514 - val_accuracy: 0.8311\n",
            "Epoch 482/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7365 - val_loss: 0.4459 - val_accuracy: 0.8446\n",
            "Epoch 483/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7466 - val_loss: 0.4430 - val_accuracy: 0.8446\n",
            "Epoch 484/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7500 - val_loss: 0.4513 - val_accuracy: 0.8581\n",
            "Epoch 485/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7517 - val_loss: 0.4388 - val_accuracy: 0.8446\n",
            "Epoch 486/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7720 - val_loss: 0.4473 - val_accuracy: 0.8243\n",
            "Epoch 487/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7517 - val_loss: 0.4467 - val_accuracy: 0.8378\n",
            "Epoch 488/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.7432 - val_loss: 0.4528 - val_accuracy: 0.8311\n",
            "Epoch 489/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7568 - val_loss: 0.4503 - val_accuracy: 0.8378\n",
            "Epoch 490/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7449 - val_loss: 0.4524 - val_accuracy: 0.8108\n",
            "Epoch 491/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7804 - val_loss: 0.4298 - val_accuracy: 0.8378\n",
            "Epoch 492/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7618 - val_loss: 0.4360 - val_accuracy: 0.8378\n",
            "Epoch 493/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7686 - val_loss: 0.4248 - val_accuracy: 0.8378\n",
            "Epoch 494/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7635 - val_loss: 0.4252 - val_accuracy: 0.8243\n",
            "Epoch 495/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7449 - val_loss: 0.4243 - val_accuracy: 0.8108\n",
            "Epoch 496/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7416 - val_loss: 0.4285 - val_accuracy: 0.8514\n",
            "Epoch 497/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7416 - val_loss: 0.4374 - val_accuracy: 0.8311\n",
            "Epoch 498/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7804 - val_loss: 0.4376 - val_accuracy: 0.8243\n",
            "Epoch 499/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7449 - val_loss: 0.4401 - val_accuracy: 0.8378\n",
            "Epoch 500/500\n",
            "74/74 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7517 - val_loss: 0.4419 - val_accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8243\n",
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-2b9853e732c7>:219: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n",
            "  TPR.append(interp(meanFPR, fpr, tpr))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8175675868988037, 0.8243243098258972, 0.8310810923576355, 0.8581081032752991, 0.8243243098258972]\n",
            "Accuracy: 0.83\n",
            "Sensitivity: 0.8462\n",
            "Specificity: 0.8149\n",
            "MCC: 0.6605\n",
            "Precision: 0.8253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn')\n",
        "model.save_weights('acp_mhcnn_weights')"
      ],
      "metadata": {
        "id": "i-ySuIJePlfJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('acp_mhcnn.keras')"
      ],
      "metadata": {
        "id": "sUnKQ39Oql-p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/acp_mhcnn.zip /content/acp_mhcnn"
      ],
      "metadata": {
        "id": "TCPrPTFlq03j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b38813c-3b05-4de1-e2c8-09bb3a770e03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/acp_mhcnn/ (stored 0%)\n",
            "updating: content/acp_mhcnn/keras_metadata.pb (deflated 92%)\n",
            "updating: content/acp_mhcnn/saved_model.pb (deflated 89%)\n",
            "updating: content/acp_mhcnn/variables/ (stored 0%)\n",
            "updating: content/acp_mhcnn/variables/variables.index (deflated 67%)\n",
            "updating: content/acp_mhcnn/variables/variables.data-00000-of-00001 (deflated 33%)\n",
            "updating: content/acp_mhcnn/assets/ (stored 0%)\n",
            "updating: content/acp_mhcnn/fingerprint.pb (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('acp_mhcnn_weights.h5')"
      ],
      "metadata": {
        "id": "t1YZag2MrItN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Network()\n",
        "discriminator.load_weights('./acp_mhcnn_weights.h5')"
      ],
      "metadata": {
        "id": "TwWTbybNIxbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkTpxUpTJDkp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}